{"sha": "328215a912721ecf054f53544ef27047984fc574", "log": "Remove a duplicate LinkedNode class", "commit": "\n--- a/src/main/java/com/fasterxml/jackson/databind/util/LinkedNode.java\n+++ b/src/main/java/com/fasterxml/jackson/databind/util/LinkedNode.java\n  */\n public final class LinkedNode<T>\n {\n-    final T _value;\n-    final LinkedNode<T> _next;\n+    private final T value;\n+\n+    private LinkedNode<T> next;\n     \n     public LinkedNode(T value, LinkedNode<T> next)\n     {\n-        _value = value;\n-        _next = next;\n+        this.value = value;\n+        this.next = next;\n     }\n     \n-    public LinkedNode<T> next() { return _next; }\n+    public void linkNext(LinkedNode<T> n)\n+    {\n+        if (next != null) { // sanity check\n+            throw new IllegalStateException();\n+        }\n+        next = n;\n+    }\n     \n-    public T value() { return _value; }\n+    public LinkedNode<T> next() { return next; }\n+    \n+    public T value() { return value; }\n     \n     /**\n      * Convenience method that can be used to check if a linked list\n--- a/src/main/java/com/fasterxml/jackson/databind/util/ObjectBuffer.java\n+++ b/src/main/java/com/fasterxml/jackson/databind/util/ObjectBuffer.java\n     // // // Config constants\n \n     /**\n-     * Let's start with small chunks; typical usage is for small arrays anyway.\n-     */\n-    final static int INITIAL_CHUNK_SIZE = 12;\n-\n-    /**\n      * Also: let's expand by doubling up until 64k chunks (which is 16k entries for\n      * 32-bit machines)\n      */\n-    final static int SMALL_CHUNK_SIZE = (1 << 14);\n+    private final static int SMALL_CHUNK = (1 << 14);\n \n     /**\n      * Let's limit maximum size of chunks we use; helps avoid excessive allocation\n      * For now, let's limit to quarter million entries, 1 meg chunks for 32-bit\n      * machines.\n      */\n-    final static int MAX_CHUNK_SIZE = (1 << 18);\n+    private final static int MAX_CHUNK = (1 << 18);\n \n     // // // Data storage\n \n-    private Node _bufferHead;\n-\n-    private Node _bufferTail;\n+    private LinkedNode<Object[]> _head;\n+\n+    private LinkedNode<Object[]> _tail;\n \n     /**\n      * Number of total buffered entries in this buffer, counting all instances\n-     * within linked list formed by following {@link #_bufferHead}.\n-     */\n-    private int _bufferedEntryCount;\n+     * within linked list formed by following {@link #_head}.\n+     */\n+    private int _size;\n \n     // // // Simple reuse\n \n     {\n         _reset();\n         if (_freeBuffer == null) {\n-            return new Object[INITIAL_CHUNK_SIZE];\n+            return new Object[12];\n         }\n         return _freeBuffer;\n     }\n      */\n     public Object[] appendCompletedChunk(Object[] fullChunk)\n     {\n-        Node next = new Node(fullChunk);\n-        if (_bufferHead == null) { // first chunk\n-            _bufferHead = _bufferTail = next;\n+        LinkedNode<Object[]> next = new LinkedNode<Object[]>(fullChunk, null);\n+        if (_head == null) { // first chunk\n+            _head = _tail = next;\n         } else { // have something already\n-            _bufferTail.linkNext(next);\n-            _bufferTail = next;\n+            _tail.linkNext(next);\n+            _tail = next;\n         }\n         int len = fullChunk.length;\n-        _bufferedEntryCount += len;\n+        _size += len;\n         // double the size for small chunks\n-        if (len < SMALL_CHUNK_SIZE) {\n+        if (len < SMALL_CHUNK) {\n             len += len;\n-        } else { // but by +25% for larger (to limit overhead)\n+        } else if (len < MAX_CHUNK) { // but by +25% for larger (to limit overhead)\n             len += (len >> 2);\n         }\n         return new Object[len];\n      */\n     public Object[] completeAndClearBuffer(Object[] lastChunk, int lastChunkEntries)\n     {\n-        int totalSize = lastChunkEntries + _bufferedEntryCount;\n+        int totalSize = lastChunkEntries + _size;\n         Object[] result = new Object[totalSize];\n         _copyTo(result, totalSize, lastChunk, lastChunkEntries);\n         return result;\n      */\n     public <T> T[] completeAndClearBuffer(Object[] lastChunk, int lastChunkEntries, Class<T> componentType)\n     {\n-       int totalSize = lastChunkEntries + _bufferedEntryCount;\n+       int totalSize = lastChunkEntries + _size;\n  \t   @SuppressWarnings(\"unchecked\")\n         T[] result = (T[]) Array.newInstance(componentType, totalSize);\n         _copyTo(result, totalSize, lastChunk, lastChunkEntries);\n \n     public void completeAndClearBuffer(Object[] lastChunk, int lastChunkEntries, List<Object> resultList)\n     {\n-        for (Node n = _bufferHead; n != null; n = n.next()) {\n-            Object[] curr = n.getData();\n+        for (LinkedNode<Object[]> n = _head; n != null; n = n.next()) {\n+            Object[] curr = n.value();\n             for (int i = 0, len = curr.length; i < len; ++i) {\n                 resultList.add(curr[i]);\n             }\n      * instance to reuse, based on size of reusable object chunk\n      * buffer holds reference to.\n      */\n-    public int initialCapacity()\n-    {\n+    public int initialCapacity() {\n         return (_freeBuffer == null) ? 0 : _freeBuffer.length;\n     }\n \n      * Method that can be used to check how many Objects have been buffered\n      * within this buffer.\n      */\n-    public int bufferedSize() { return _bufferedEntryCount; }\n+    public int bufferedSize() { return _size; }\n \n     /*\n     /**********************************************************\n     protected void _reset()\n     {\n         // can we reuse the last (and thereby biggest) array for next time?\n-        if (_bufferTail != null) {\n-            _freeBuffer = _bufferTail.getData();\n+        if (_tail != null) {\n+            _freeBuffer = _tail.value();\n         }\n         // either way, must discard current contents\n-        _bufferHead = _bufferTail = null;\n-        _bufferedEntryCount = 0;\n+        _head = _tail = null;\n+        _size = 0;\n     }\n \n     protected final void _copyTo(Object resultArray, int totalSize,\n-                                 Object[] lastChunk, int lastChunkEntries)\n+            Object[] lastChunk, int lastChunkEntries)\n     {\n         int ptr = 0;\n \n-        for (Node n = _bufferHead; n != null; n = n.next()) {\n-            Object[] curr = n.getData();\n+        for (LinkedNode<Object[]> n = _head; n != null; n = n.next()) {\n+            Object[] curr = n.value();\n             int len = curr.length;\n             System.arraycopy(curr, 0, resultArray, ptr, len);\n             ptr += len;\n             throw new IllegalStateException(\"Should have gotten \"+totalSize+\" entries, got \"+ptr);\n         }\n     }\n-\n-    /*\n-    /**********************************************************\n-    /* Helper classes\n-    /**********************************************************\n-     */\n-\n-    /**\n-     * Helper class used to store actual data, in a linked list.\n-     */\n-    final static class Node\n-    {\n-        /**\n-         * Data stored in this node. Array is considered to be full.\n-         */\n-        final Object[] _data;\n-\n-        Node _next;\n-\n-        public Node(Object[] data) {\n-            _data = data;\n-        }\n-\n-        public Object[] getData() { return _data; }\n-\n-        public Node next() { return _next; }\n-\n-        public void linkNext(Node next)\n-        {\n-            if (_next != null) { // sanity check\n-                throw new IllegalStateException();\n-            }\n-            _next = next;\n-        }\n-    }\n }", "timestamp": 1398545701, "metainfo": ""}