{"sha": "61a879bf681402a7986165c32c9e1c4e3fb94b18", "log": "Replace assertTokenEquals with Token matcher  ", "commit": "\n--- a/src/test/java/org/apache/commons/csv/CSVLexerTest.java\n+++ b/src/test/java/org/apache/commons/csv/CSVLexerTest.java\n import static org.apache.commons.csv.Token.Type.EOF;\n import static org.apache.commons.csv.Token.Type.EORECORD;\n import static org.apache.commons.csv.Token.Type.TOKEN;\n-import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.assertTrue;\n import static org.junit.Assert.assertThat;\n import static org.apache.commons.csv.TokenMatchers.hasContent;\n+import static org.apache.commons.csv.TokenMatchers.matches;\n \n import java.io.IOException;\n import java.io.StringReader;\n         return new CSVLexer(format, new ExtendedBufferedReader(new StringReader(input)));\n     }\n \n-    private void assertTokenEquals(final Token.Type expectedType, final String expectedContent, final Token token) {\n-        assertEquals(\"Token type\", expectedType, token.type);\n-        assertEquals(\"Token content\", expectedContent, token.content.toString());\n-    }\n-\n     // Single line (without comment)\n     @Test\n     public void testNextToken1() throws IOException {\n         final String code = \"abc,def, hijk,  lmnop,   qrst,uv ,wxy   ,z , ,\";\n         final Lexer parser = getLexer(code, CSVFormat.newBuilder().withIgnoreSurroundingSpaces(true).build());\n-        assertTokenEquals(TOKEN, \"abc\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"def\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"hijk\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"lmnop\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"qrst\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"uv\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"wxy\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"z\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"\", parser.nextToken(new Token()));\n-        assertTokenEquals(EOF, \"\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"abc\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"def\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"hijk\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"lmnop\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"qrst\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"uv\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"wxy\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"z\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"\"));\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"\"));\n     }\n \n     // multiline including comments (and empty lines)\n         final Lexer parser = getLexer(code, format);\n \n \n-        assertTokenEquals(TOKEN, \"1\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"2\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"3\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 1\n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"b x\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"c#no-comment\", parser.nextToken(new Token())); // 2\n-        assertTokenEquals(COMMENT, \"foo\", parser.nextToken(new Token()));              // 3\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"1\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"2\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"3\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 1\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"b x\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"c#no-comment\")); // 2\n+        assertThat(parser.nextToken(new Token()), matches(COMMENT, \"foo\"));              // 3\n         // 4 empty line, ignored                                                    // 4\n-        assertTokenEquals(TOKEN, \"d\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"e\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"#no-comment\", parser.nextToken(new Token()));  // 5\n-        assertTokenEquals(COMMENT, \"penultimate comment\", parser.nextToken(new Token()));              // 6\n-        assertTokenEquals(COMMENT, \"Final comment\", parser.nextToken(new Token()));              // 7\n-        assertTokenEquals(EOF, \"\", parser.nextToken(new Token()));\n-        assertTokenEquals(EOF, \"\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"d\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"e\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"#no-comment\"));  // 5\n+        assertThat(parser.nextToken(new Token()), matches(COMMENT, \"penultimate comment\"));              // 6\n+        assertThat(parser.nextToken(new Token()), matches(COMMENT, \"Final comment\"));              // 7\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"\"));\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"\"));\n \n     }\n \n         final Lexer parser = getLexer(code, format);\n \n \n-        assertTokenEquals(TOKEN, \"1\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"2\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"3\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 1\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 1b\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 1c\n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"b x\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"c#no-comment\", parser.nextToken(new Token())); // 2\n-        assertTokenEquals(COMMENT, \"foo\", parser.nextToken(new Token()));           // 3\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 4\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 4b\n-        assertTokenEquals(TOKEN, \"d\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"e\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"#no-comment\", parser.nextToken(new Token()));  // 5\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 5b\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 5c\n-        assertTokenEquals(COMMENT, \"penultimate comment\", parser.nextToken(new Token()));              // 6\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 6b\n-        assertTokenEquals(EORECORD, \"\", parser.nextToken(new Token()));             // 6c\n-        assertTokenEquals(COMMENT, \"Final comment\", parser.nextToken(new Token()));              // 7\n-        assertTokenEquals(EOF, \"\", parser.nextToken(new Token()));\n-        assertTokenEquals(EOF, \"\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"1\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"2\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"3\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 1\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 1b\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 1c\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"b x\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"c#no-comment\")); // 2\n+        assertThat(parser.nextToken(new Token()), matches(COMMENT, \"foo\"));           // 3\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 4\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 4b\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"d\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"e\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"#no-comment\"));  // 5\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 5b\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 5c\n+        assertThat(parser.nextToken(new Token()), matches(COMMENT, \"penultimate comment\"));              // 6\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 6b\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"\"));             // 6c\n+        assertThat(parser.nextToken(new Token()), matches(COMMENT, \"Final comment\"));              // 7\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"\"));\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"\"));\n \n     }\n \n         assertFalse(format.isEscaping());\n         final Lexer parser = getLexer(code, format);\n \n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n         // an unquoted single backslash is not an escape char\n-        assertTokenEquals(TOKEN, \"\\\\\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"b\\\\\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"\\\\\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"b\\\\\"));\n         // an unquoted single backslash is not an escape char\n-        assertTokenEquals(TOKEN, \"\\\\\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"\", parser.nextToken(new Token()));\n-        assertTokenEquals(EOF, \"\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"\\\\\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"\"));\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"\"));\n     }\n \n     // simple token with escaping enabled\n         assertTrue(format.isEscaping());\n         final Lexer parser = getLexer(code, format);\n \n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \",\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"b\\\\\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \",\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"\\nc\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"d\\r\", parser.nextToken(new Token()));\n-        assertTokenEquals(EOF, \"e\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \",\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"b\\\\\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \",\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"\\nc\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"d\\r\"));\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"e\"));\n     }\n \n     // encapsulator tokenizer (single line)\n         */\n         final String code = \"a,\\\"foo\\\",b\\na,   \\\" foo\\\",b\\na,\\\"foo \\\"  ,b\\na,  \\\" foo \\\"  ,b\";\n         final Lexer parser = getLexer(code, CSVFormat.newBuilder().withIgnoreSurroundingSpaces(true).build());\n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"foo\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"b\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \" foo\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"b\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"foo \", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"b\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \" foo \", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"foo\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"b\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \" foo\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"b\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"foo \"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"b\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \" foo \"));\n //      assertTokenEquals(EORECORD, \"b\", parser.nextToken(new Token()));\n-        assertTokenEquals(EOF, \"b\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"b\"));\n     }\n \n     // encapsulator tokenizer (multi line, delimiter in string)\n     public void testNextToken5() throws IOException {\n         final String code = \"a,\\\"foo\\n\\\",b\\n\\\"foo\\n  baar ,,,\\\"\\n\\\"\\n\\t \\n\\\"\";\n         final Lexer parser = getLexer(code, CSVFormat.DEFAULT);\n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"foo\\n\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"b\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"foo\\n  baar ,,,\", parser.nextToken(new Token()));\n-        assertTokenEquals(EOF, \"\\n\\t \\n\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"foo\\n\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"b\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"foo\\n  baar ,,,\"));\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"\\n\\t \\n\"));\n \n     }\n \n         final String code = \"a;'b and '' more\\n'\\n!comment;;;;\\n;;\";\n         final CSVFormat format = CSVFormat.newBuilder().withDelimiter(';').withQuoteChar('\\'').withCommentStart('!').build();\n         final Lexer parser = getLexer(code, format);\n-        assertTokenEquals(TOKEN, \"a\", parser.nextToken(new Token()));\n-        assertTokenEquals(EORECORD, \"b and ' more\\n\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"a\"));\n+        assertThat(parser.nextToken(new Token()), matches(EORECORD, \"b and ' more\\n\"));\n     }\n \n     // From CSV-1\n     public void testDelimiterIsWhitespace() throws IOException {\n         final String code = \"one\\ttwo\\t\\tfour \\t five\\t six\";\n         final Lexer parser = getLexer(code, CSVFormat.TDF);\n-        assertTokenEquals(TOKEN, \"one\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"two\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"four\", parser.nextToken(new Token()));\n-        assertTokenEquals(TOKEN, \"five\", parser.nextToken(new Token()));\n-        assertTokenEquals(EOF, \"six\", parser.nextToken(new Token()));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"one\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"two\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"four\"));\n+        assertThat(parser.nextToken(new Token()), matches(TOKEN, \"five\"));\n+        assertThat(parser.nextToken(new Token()), matches(EOF, \"six\"));\n     }\n \n     @Test", "timestamp": 1365443391, "metainfo": ""}