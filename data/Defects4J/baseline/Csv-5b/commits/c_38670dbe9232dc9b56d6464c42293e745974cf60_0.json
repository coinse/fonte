{"sha": "38670dbe9232dc9b56d6464c42293e745974cf60", "log": "Moved the lexer in a separate file  ", "commit": "\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/csv/CSVLexer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.csv;\n+\n+import java.io.IOException;\n+\n+import static org.apache.commons.csv.CSVLexer.Token.Type.*;\n+\n+class CSVLexer {\n+\n+    /** length of the initial token (content-)buffer */\n+    private static final int INITIAL_TOKEN_LENGTH = 50;\n+    \n+    private final StringBuilder wsBuf = new StringBuilder();\n+    \n+    private final CSVFormat format;\n+    \n+    /** The input stream */\n+    private final ExtendedBufferedReader in;\n+\n+    /**\n+     * Token is an internal token representation.\n+     * <p/>\n+     * It is used as contract between the lexer and the parser.\n+     */\n+    static class Token {\n+\n+        enum Type {\n+            /** Token has no valid content, i.e. is in its initialized state. */\n+            INVALID,\n+            \n+            /** Token with content, at beginning or in the middle of a line. */\n+            TOKEN,\n+            \n+            /** Token (which can have content) when end of file is reached. */\n+            EOF,\n+            \n+            /** Token with content when end of a line is reached. */\n+            EORECORD\n+        }\n+        \n+        /** Token type */\n+        Type type = INVALID;\n+        \n+        /** The content buffer. */\n+        StringBuilder content = new StringBuilder(INITIAL_TOKEN_LENGTH);\n+        \n+        /** Token ready flag: indicates a valid token with content (ready for the parser). */\n+        boolean isReady;\n+\n+        Token reset() {\n+            content.setLength(0);\n+            type = INVALID;\n+            isReady = false;\n+            return this;\n+        }\n+    }\n+\n+    CSVLexer(CSVFormat format, ExtendedBufferedReader in) {\n+        this.format = format;\n+        this.in = in;\n+    }\n+\n+    public int getLineNumber() {\n+        return in.getLineNumber();\n+    }\n+\n+    /**\n+     * Returns the next token.\n+     * <p/>\n+     * A token corresponds to a term, a record change or an end-of-file indicator.\n+     *\n+     * @param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n+     * @return the next token found\n+     * @throws java.io.IOException on stream access error\n+     */\n+    Token nextToken(Token tkn) throws IOException {\n+        wsBuf.setLength(0); // reuse\n+\n+        // get the last read char (required for empty line detection)\n+        int lastChar = in.readAgain();\n+\n+        //  read the next char and set eol\n+        /* note: unfortunately isEndOfLine may consumes a character silently.\n+        *       this has no effect outside of the method. so a simple workaround\n+        *       is to call 'readAgain' on the stream...\n+        */\n+        int c = in.read();\n+        boolean eol = isEndOfLine(c);\n+        c = in.readAgain();\n+\n+        //  empty line detection: eol AND (last char was EOL or beginning)\n+        if (format.isEmptyLinesIgnored()) {\n+            while (eol\n+                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n+                    && !isEndOfFile(lastChar)) {\n+                // go on char ahead ...\n+                lastChar = c;\n+                c = in.read();\n+                eol = isEndOfLine(c);\n+                c = in.readAgain();\n+                // reached end of file without any content (empty line at the end)\n+                if (isEndOfFile(c)) {\n+                    tkn.type = EOF;\n+                    return tkn;\n+                }\n+            }\n+        }\n+\n+        // did we reach eof during the last iteration already ? EOF\n+        if (isEndOfFile(lastChar) || (lastChar != format.getDelimiter() && isEndOfFile(c))) {\n+            tkn.type = EOF;\n+            return tkn;\n+        }\n+\n+        //  important: make sure a new char gets consumed in each iteration\n+        while (!tkn.isReady && tkn.type != EOF) {\n+            // ignore whitespaces at beginning of a token\n+            if (format.isLeadingSpacesIgnored()) {\n+                while (isWhitespace(c) && !eol) {\n+                    wsBuf.append((char) c);\n+                    c = in.read();\n+                    eol = isEndOfLine(c);\n+                }\n+            }\n+            \n+            // ok, start of token reached: comment, encapsulated, or token\n+            if (c == format.getCommentStart()) {\n+                // ignore everything till end of line and continue (incr linecount)\n+                in.readLine();\n+                tkn = nextToken(tkn.reset());\n+            } else if (c == format.getDelimiter()) {\n+                // empty token return TOKEN(\"\")\n+                tkn.type = TOKEN;\n+                tkn.isReady = true;\n+            } else if (eol) {\n+                // empty token return EORECORD(\"\")\n+                //noop: tkn.content.append(\"\");\n+                tkn.type = EORECORD;\n+                tkn.isReady = true;\n+            } else if (c == format.getEncapsulator()) {\n+                // consume encapsulated token\n+                encapsulatedTokenLexer(tkn, c);\n+            } else if (isEndOfFile(c)) {\n+                // end of file return EOF()\n+                //noop: tkn.content.append(\"\");\n+                tkn.type = EOF;\n+                tkn.isReady = true;\n+            } else {\n+                // next token must be a simple token\n+                // add removed blanks when not ignoring whitespace chars...\n+                if (!format.isLeadingSpacesIgnored()) {\n+                    tkn.content.append(wsBuf);\n+                }\n+                simpleTokenLexer(tkn, c);\n+            }\n+        }\n+        return tkn;\n+    }\n+\n+    /**\n+     * A simple token lexer\n+     * <p/>\n+     * Simple token are tokens which are not surrounded by encapsulators.\n+     * A simple token might contain escaped delimiters (as \\, or \\;). The\n+     * token is finished when one of the following conditions become true:\n+     * <ul>\n+     *   <li>end of line has been reached (EORECORD)</li>\n+     *   <li>end of stream has been reached (EOF)</li>\n+     *   <li>an unescaped delimiter has been reached (TOKEN)</li>\n+     * </ul>\n+     *\n+     * @param tkn the current token\n+     * @param c   the current character\n+     * @return the filled token\n+     * @throws IOException on stream access error\n+     */\n+    private Token simpleTokenLexer(Token tkn, int c) throws IOException {\n+        while (true) {\n+            if (isEndOfLine(c)) {\n+                // end of record\n+                tkn.type = EORECORD;\n+                tkn.isReady = true;\n+                break;\n+            } else if (isEndOfFile(c)) {\n+                // end of file\n+                tkn.type = EOF;\n+                tkn.isReady = true;\n+                break;\n+            } else if (c == format.getDelimiter()) {\n+                // end of token\n+                tkn.type = TOKEN;\n+                tkn.isReady = true;\n+                break;\n+            } else if (c == format.getEscape()) {\n+                tkn.content.append((char) readEscape(c));\n+            } else {\n+                tkn.content.append((char) c);\n+            }\n+\n+            c = in.read();\n+        }\n+\n+        if (format.isTrailingSpacesIgnored()) {\n+            trimTrailingSpaces(tkn.content);\n+        }\n+\n+        return tkn;\n+    }\n+\n+    private void trimTrailingSpaces(StringBuilder buffer) {\n+        int length = buffer.length();\n+        while (length > 0 && Character.isWhitespace(buffer.charAt(length - 1))) {\n+            length = length - 1;\n+        }\n+        if (length != buffer.length()) {\n+            buffer.setLength(length);\n+        }\n+    }\n+\n+    /**\n+     * An encapsulated token lexer\n+     * <p/>\n+     * Encapsulated tokens are surrounded by the given encapsulating-string.\n+     * The encapsulator itself might be included in the token using a\n+     * doubling syntax (as \"\", '') or using escaping (as in \\\", \\').\n+     * Whitespaces before and after an encapsulated token are ignored.\n+     *\n+     * @param tkn the current token\n+     * @param c   the current character\n+     * @return a valid token object\n+     * @throws IOException on invalid state\n+     */\n+    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n+        // save current line\n+        int startLineNumber = getLineNumber();\n+        // ignore the given delimiter\n+        // assert c == delimiter;\n+        while (true) {\n+            c = in.read();\n+            \n+            if (c == format.getEscape()) {\n+                tkn.content.append((char) readEscape(c));\n+            } else if (c == format.getEncapsulator()) {\n+                if (in.lookAhead() == format.getEncapsulator()) {\n+                    // double or escaped encapsulator -> add single encapsulator to token\n+                    c = in.read();\n+                    tkn.content.append((char) c);\n+                } else {\n+                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n+                    while (true) {\n+                        c = in.read();\n+                        if (c == format.getDelimiter()) {\n+                            tkn.type = TOKEN;\n+                            tkn.isReady = true;\n+                            return tkn;\n+                        } else if (isEndOfFile(c)) {\n+                            tkn.type = EOF;\n+                            tkn.isReady = true;\n+                            return tkn;\n+                        } else if (isEndOfLine(c)) {\n+                            // ok eo token reached\n+                            tkn.type = EORECORD;\n+                            tkn.isReady = true;\n+                            return tkn;\n+                        } else if (!isWhitespace(c)) {\n+                            // error invalid char between token and next delimiter\n+                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n+                        }\n+                    }\n+                }\n+            } else if (isEndOfFile(c)) {\n+                // error condition (end of file before end of token)\n+                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n+            } else {\n+                // consume character\n+                tkn.content.append((char) c);\n+            }\n+        }\n+    }\n+\n+    private int readEscape(int c) throws IOException {\n+        // assume c is the escape char (normally a backslash)\n+        c = in.read();\n+        switch (c) {\n+            case 'r':\n+                return '\\r';\n+            case 'n':\n+                return '\\n';\n+            case 't':\n+                return '\\t';\n+            case 'b':\n+                return '\\b';\n+            case 'f':\n+                return '\\f';\n+            default:\n+                return c;\n+        }\n+    }\n+\n+    /**\n+     * @return true if the given char is a whitespace character\n+     */\n+    private boolean isWhitespace(int c) {\n+        return (c != format.getDelimiter()) && Character.isWhitespace((char) c);\n+    }\n+\n+    /**\n+     * Greedy - accepts \\n, \\r and \\r\\n\n+     * This checker consumes silently the second control-character...\n+     *\n+     * @return true if the given character is a line-terminator\n+     */\n+    private boolean isEndOfLine(int c) throws IOException {\n+        // check if we have \\r\\n...\n+        if (c == '\\r' && in.lookAhead() == '\\n') {\n+            // note: does not change c outside of this method !!\n+            c = in.read();\n+        }\n+        return (c == '\\n' || c == '\\r');\n+    }\n+\n+    /**\n+     * @return true if the given character indicates end of file\n+     */\n+    private boolean isEndOfFile(int c) {\n+        return c == ExtendedBufferedReader.END_OF_STREAM;\n+    }\n+}\n--- a/src/main/java/org/apache/commons/csv/CSVParser.java\n+++ b/src/main/java/org/apache/commons/csv/CSVParser.java\n         return lexer.getLineNumber();\n     }\n }\n-\n-\n-class CSVLexer {\n-\n-    /** length of the initial token (content-)buffer */\n-    private static final int INITIAL_TOKEN_LENGTH = 50;\n-    \n-    private final StringBuilder wsBuf = new StringBuilder();\n-    \n-    private final CSVFormat format;\n-    \n-    /** The input stream */\n-    private final ExtendedBufferedReader in;\n-\n-    /**\n-     * Token is an internal token representation.\n-     * <p/>\n-     * It is used as contract between the lexer and the parser.\n-     */\n-    static class Token {\n-\n-        enum Type {\n-            /** Token has no valid content, i.e. is in its initialized state. */\n-            INVALID,\n-            \n-            /** Token with content, at beginning or in the middle of a line. */\n-            TOKEN,\n-            \n-            /** Token (which can have content) when end of file is reached. */\n-            EOF,\n-            \n-            /** Token with content when end of a line is reached. */\n-            EORECORD\n-        }\n-        \n-        /** Token type */\n-        Type type = INVALID;\n-        \n-        /** The content buffer. */\n-        StringBuilder content = new StringBuilder(INITIAL_TOKEN_LENGTH);\n-        \n-        /** Token ready flag: indicates a valid token with content (ready for the parser). */\n-        boolean isReady;\n-\n-        Token reset() {\n-            content.setLength(0);\n-            type = INVALID;\n-            isReady = false;\n-            return this;\n-        }\n-    }\n-\n-    CSVLexer(CSVFormat format, ExtendedBufferedReader in) {\n-        this.format = format;\n-        this.in = in;\n-    }\n-\n-    public int getLineNumber() {\n-        return in.getLineNumber();\n-    }\n-\n-    /**\n-     * Returns the next token.\n-     * <p/>\n-     * A token corresponds to a term, a record change or an end-of-file indicator.\n-     *\n-     * @param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n-     * @return the next token found\n-     * @throws IOException on stream access error\n-     */\n-    Token nextToken(Token tkn) throws IOException {\n-        wsBuf.setLength(0); // reuse\n-\n-        // get the last read char (required for empty line detection)\n-        int lastChar = in.readAgain();\n-\n-        //  read the next char and set eol\n-        /* note: unfortunately isEndOfLine may consumes a character silently.\n-        *       this has no effect outside of the method. so a simple workaround\n-        *       is to call 'readAgain' on the stream...\n-        */\n-        int c = in.read();\n-        boolean eol = isEndOfLine(c);\n-        c = in.readAgain();\n-\n-        //  empty line detection: eol AND (last char was EOL or beginning)\n-        if (format.isEmptyLinesIgnored()) {\n-            while (eol\n-                    && (lastChar == '\\n' || lastChar == '\\r' || lastChar == ExtendedBufferedReader.UNDEFINED)\n-                    && !isEndOfFile(lastChar)) {\n-                // go on char ahead ...\n-                lastChar = c;\n-                c = in.read();\n-                eol = isEndOfLine(c);\n-                c = in.readAgain();\n-                // reached end of file without any content (empty line at the end)\n-                if (isEndOfFile(c)) {\n-                    tkn.type = EOF;\n-                    return tkn;\n-                }\n-            }\n-        }\n-\n-        // did we reach eof during the last iteration already ? EOF\n-        if (isEndOfFile(lastChar) || (lastChar != format.getDelimiter() && isEndOfFile(c))) {\n-            tkn.type = EOF;\n-            return tkn;\n-        }\n-\n-        //  important: make sure a new char gets consumed in each iteration\n-        while (!tkn.isReady && tkn.type != EOF) {\n-            // ignore whitespaces at beginning of a token\n-            if (format.isLeadingSpacesIgnored()) {\n-                while (isWhitespace(c) && !eol) {\n-                    wsBuf.append((char) c);\n-                    c = in.read();\n-                    eol = isEndOfLine(c);\n-                }\n-            }\n-            \n-            // ok, start of token reached: comment, encapsulated, or token\n-            if (c == format.getCommentStart()) {\n-                // ignore everything till end of line and continue (incr linecount)\n-                in.readLine();\n-                tkn = nextToken(tkn.reset());\n-            } else if (c == format.getDelimiter()) {\n-                // empty token return TOKEN(\"\")\n-                tkn.type = TOKEN;\n-                tkn.isReady = true;\n-            } else if (eol) {\n-                // empty token return EORECORD(\"\")\n-                //noop: tkn.content.append(\"\");\n-                tkn.type = EORECORD;\n-                tkn.isReady = true;\n-            } else if (c == format.getEncapsulator()) {\n-                // consume encapsulated token\n-                encapsulatedTokenLexer(tkn, c);\n-            } else if (isEndOfFile(c)) {\n-                // end of file return EOF()\n-                //noop: tkn.content.append(\"\");\n-                tkn.type = EOF;\n-                tkn.isReady = true;\n-            } else {\n-                // next token must be a simple token\n-                // add removed blanks when not ignoring whitespace chars...\n-                if (!format.isLeadingSpacesIgnored()) {\n-                    tkn.content.append(wsBuf);\n-                }\n-                simpleTokenLexer(tkn, c);\n-            }\n-        }\n-        return tkn;\n-    }\n-\n-    /**\n-     * A simple token lexer\n-     * <p/>\n-     * Simple token are tokens which are not surrounded by encapsulators.\n-     * A simple token might contain escaped delimiters (as \\, or \\;). The\n-     * token is finished when one of the following conditions become true:\n-     * <ul>\n-     *   <li>end of line has been reached (EORECORD)</li>\n-     *   <li>end of stream has been reached (EOF)</li>\n-     *   <li>an unescaped delimiter has been reached (TOKEN)</li>\n-     * </ul>\n-     *\n-     * @param tkn the current token\n-     * @param c   the current character\n-     * @return the filled token\n-     * @throws IOException on stream access error\n-     */\n-    private Token simpleTokenLexer(Token tkn, int c) throws IOException {\n-        while (true) {\n-            if (isEndOfLine(c)) {\n-                // end of record\n-                tkn.type = EORECORD;\n-                tkn.isReady = true;\n-                break;\n-            } else if (isEndOfFile(c)) {\n-                // end of file\n-                tkn.type = EOF;\n-                tkn.isReady = true;\n-                break;\n-            } else if (c == format.getDelimiter()) {\n-                // end of token\n-                tkn.type = TOKEN;\n-                tkn.isReady = true;\n-                break;\n-            } else if (c == format.getEscape()) {\n-                tkn.content.append((char) readEscape(c));\n-            } else {\n-                tkn.content.append((char) c);\n-            }\n-\n-            c = in.read();\n-        }\n-\n-        if (format.isTrailingSpacesIgnored()) {\n-            trimTrailingSpaces(tkn.content);\n-        }\n-\n-        return tkn;\n-    }\n-\n-    private void trimTrailingSpaces(StringBuilder buffer) {\n-        int length = buffer.length();\n-        while (length > 0 && Character.isWhitespace(buffer.charAt(length - 1))) {\n-            length = length - 1;\n-        }\n-        if (length != buffer.length()) {\n-            buffer.setLength(length);\n-        }\n-    }\n-\n-    /**\n-     * An encapsulated token lexer\n-     * <p/>\n-     * Encapsulated tokens are surrounded by the given encapsulating-string.\n-     * The encapsulator itself might be included in the token using a\n-     * doubling syntax (as \"\", '') or using escaping (as in \\\", \\').\n-     * Whitespaces before and after an encapsulated token are ignored.\n-     *\n-     * @param tkn the current token\n-     * @param c   the current character\n-     * @return a valid token object\n-     * @throws IOException on invalid state\n-     */\n-    private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n-        // save current line\n-        int startLineNumber = getLineNumber();\n-        // ignore the given delimiter\n-        // assert c == delimiter;\n-        while (true) {\n-            c = in.read();\n-            \n-            if (c == format.getEscape()) {\n-                tkn.content.append((char) readEscape(c));\n-            } else if (c == format.getEncapsulator()) {\n-                if (in.lookAhead() == format.getEncapsulator()) {\n-                    // double or escaped encapsulator -> add single encapsulator to token\n-                    c = in.read();\n-                    tkn.content.append((char) c);\n-                } else {\n-                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n-                    while (true) {\n-                        c = in.read();\n-                        if (c == format.getDelimiter()) {\n-                            tkn.type = TOKEN;\n-                            tkn.isReady = true;\n-                            return tkn;\n-                        } else if (isEndOfFile(c)) {\n-                            tkn.type = EOF;\n-                            tkn.isReady = true;\n-                            return tkn;\n-                        } else if (isEndOfLine(c)) {\n-                            // ok eo token reached\n-                            tkn.type = EORECORD;\n-                            tkn.isReady = true;\n-                            return tkn;\n-                        } else if (!isWhitespace(c)) {\n-                            // error invalid char between token and next delimiter\n-                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n-                        }\n-                    }\n-                }\n-            } else if (isEndOfFile(c)) {\n-                // error condition (end of file before end of token)\n-                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n-            } else {\n-                // consume character\n-                tkn.content.append((char) c);\n-            }\n-        }\n-    }\n-\n-    private int readEscape(int c) throws IOException {\n-        // assume c is the escape char (normally a backslash)\n-        c = in.read();\n-        switch (c) {\n-            case 'r':\n-                return '\\r';\n-            case 'n':\n-                return '\\n';\n-            case 't':\n-                return '\\t';\n-            case 'b':\n-                return '\\b';\n-            case 'f':\n-                return '\\f';\n-            default:\n-                return c;\n-        }\n-    }\n-\n-    /**\n-     * @return true if the given char is a whitespace character\n-     */\n-    private boolean isWhitespace(int c) {\n-        return (c != format.getDelimiter()) && Character.isWhitespace((char) c);\n-    }\n-\n-    /**\n-     * Greedy - accepts \\n, \\r and \\r\\n\n-     * This checker consumes silently the second control-character...\n-     *\n-     * @return true if the given character is a line-terminator\n-     */\n-    private boolean isEndOfLine(int c) throws IOException {\n-        // check if we have \\r\\n...\n-        if (c == '\\r' && in.lookAhead() == '\\n') {\n-            // note: does not change c outside of this method !!\n-            c = in.read();\n-        }\n-        return (c == '\\n' || c == '\\r');\n-    }\n-\n-    /**\n-     * @return true if the given character indicates end of file\n-     */\n-    private boolean isEndOfFile(int c) {\n-        return c == ExtendedBufferedReader.END_OF_STREAM;\n-    }\n-}", "timestamp": 1331801525, "metainfo": ""}