{"sha": "3f753c8b3e033dda43e8b2ac7667fa85f6bcfb7e", "log": "Use the new differentiation framework in optimization package.  As a temporary hack for backward compatibility, some optimizers do provide \"optimize\" methods which accept the new functions signatures (i.e. MultivariateDifferentiableXxxFunction), but they do *not* advertise it in their \"implements\" clause. The reason for that is that Java forbid implementing a parameterized interface with two different parameters. These optimizers already implement the interface with the older functions signatures, and this cannot be removed as of 3.1.  When 4.0 will be started, the old signatures will be removed, and the \"implements\" declarations will be updated.  ", "commit": "\n--- a/src/main/java/org/apache/commons/math3/analysis/DifferentiableMultivariateFunction.java\n+++ b/src/main/java/org/apache/commons/math3/analysis/DifferentiableMultivariateFunction.java\n  * multivariate real function.\n  * @version $Id$\n  * @since 2.0\n+ * @deprecated as of 3.1 replaced by {@link org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction}\n  */\n public interface DifferentiableMultivariateFunction extends MultivariateFunction {\n \n--- a/src/main/java/org/apache/commons/math3/analysis/DifferentiableMultivariateVectorFunction.java\n+++ b/src/main/java/org/apache/commons/math3/analysis/DifferentiableMultivariateVectorFunction.java\n \n package org.apache.commons.math3.analysis;\n \n-\n /**\n  * Extension of {@link MultivariateVectorFunction} representing a differentiable\n  * multivariate vectorial function.\n  * @version $Id$\n  * @since 2.0\n+ * @deprecated as of 3.1 replaced by {@link org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction}\n  */\n public interface DifferentiableMultivariateVectorFunction\n     extends MultivariateVectorFunction {\n--- a/src/main/java/org/apache/commons/math3/optimization/BaseMultivariateOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/BaseMultivariateOptimizer.java\n  * the following interfaces:\n  * <ul>\n  *  <li>{@link org.apache.commons.math3.optimization.MultivariateOptimizer}</li>\n- *  <li>{@link org.apache.commons.math3.optimization.DifferentiableMultivariateOptimizer}</li>\n+ *  <li>{@link org.apache.commons.math3.optimization.MultivariateDifferentiableOptimizer}</li>\n  * </ul>\n  *\n  * @param <FUNC> Type of the objective function to be optimized.\n--- a/src/main/java/org/apache/commons/math3/optimization/BaseMultivariateSimpleBoundsOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/BaseMultivariateSimpleBoundsOptimizer.java\n  * the following interfaces:\n  * <ul>\n  *  <li>{@link org.apache.commons.math3.optimization.MultivariateOptimizer}</li>\n- *  <li>{@link org.apache.commons.math3.optimization.DifferentiableMultivariateOptimizer}</li>\n+ *  <li>{@link org.apache.commons.math3.optimization.MultivariateDifferentiableOptimizer}</li>\n  * </ul>\n  *\n  * @param <FUNC> Type of the objective function to be optimized.\n--- a/src/main/java/org/apache/commons/math3/optimization/BaseOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/BaseOptimizer.java\n  * the following interfaces:\n  * <ul>\n  *  <li>{@link org.apache.commons.math3.optimization.MultivariateOptimizer}</li>\n- *  <li>{@link org.apache.commons.math3.optimization.DifferentiableMultivariateOptimizer}</li>\n- *  <li>{@link org.apache.commons.math3.optimization.DifferentiableMultivariateVectorOptimizer}</li>\n+ *  <li>{@link org.apache.commons.math3.optimization.MultivariateDifferentiableOptimizer}</li>\n+ *  <li>{@link org.apache.commons.math3.optimization.MultivariateDifferentiableVectorOptimizer}</li>\n  *  <li>{@link org.apache.commons.math3.optimization.univariate.UnivariateOptimizer}</li>\n  * </ul>\n  *\n--- a/src/main/java/org/apache/commons/math3/optimization/DifferentiableMultivariateMultiStartOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/DifferentiableMultivariateMultiStartOptimizer.java\n  *\n  * @version $Id$\n  * @since 2.0\n+ * @deprecated as of 3.1 replaced by {@link MultivariateDifferentiableMultiStartOptimizer}\n  */\n public class DifferentiableMultivariateMultiStartOptimizer\n     extends BaseMultivariateMultiStartOptimizer<DifferentiableMultivariateFunction>\n      * @param generator Random vector generator to use for restarts.\n      */\n     public DifferentiableMultivariateMultiStartOptimizer(final DifferentiableMultivariateOptimizer optimizer,\n-                                                             final int starts,\n-                                                             final RandomVectorGenerator generator) {\n+                                                         final int starts,\n+                                                         final RandomVectorGenerator generator) {\n         super(optimizer, starts, generator);\n     }\n }\n--- a/src/main/java/org/apache/commons/math3/optimization/DifferentiableMultivariateOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/DifferentiableMultivariateOptimizer.java\n  *\n  * @version $Id$\n  * @since 2.0\n+ * @deprecated as of 3.1 replaced by {@link MultivariateDifferentiableOptimizer}\n  */\n+@Deprecated\n public interface DifferentiableMultivariateOptimizer\n     extends BaseMultivariateOptimizer<DifferentiableMultivariateFunction> {}\n--- a/src/main/java/org/apache/commons/math3/optimization/DifferentiableMultivariateVectorMultiStartOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/DifferentiableMultivariateVectorMultiStartOptimizer.java\n  *\n  * @version $Id$\n  * @since 2.0\n+ * @deprecated as of 3.1 replaced by {@link MultivariateDifferentiableVectorMultiStartOptimizer}\n  */\n+@Deprecated\n public class DifferentiableMultivariateVectorMultiStartOptimizer\n     extends BaseMultivariateVectorMultiStartOptimizer<DifferentiableMultivariateVectorFunction>\n     implements DifferentiableMultivariateVectorOptimizer {\n--- a/src/main/java/org/apache/commons/math3/optimization/DifferentiableMultivariateVectorOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/DifferentiableMultivariateVectorOptimizer.java\n  *\n  * @version $Id$\n  * @since 3.0\n+ * @deprecated as of 3.1 replaced by {@link MultivariateDifferentiableVectorOptimizer}\n  */\n+@Deprecated\n public interface DifferentiableMultivariateVectorOptimizer\n     extends BaseMultivariateVectorOptimizer<DifferentiableMultivariateVectorFunction> {}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optimization/MultivariateDifferentiableMultiStartOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization;\n+\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+\n+/**\n+ * Special implementation of the {@link MultivariateDifferentiableOptimizer}\n+ * interface adding multi-start features to an existing optimizer.\n+ *\n+ * This class wraps a classical optimizer to use it several times in\n+ * turn with different starting points in order to avoid being trapped\n+ * into a local extremum when looking for a global one.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class MultivariateDifferentiableMultiStartOptimizer\n+    extends BaseMultivariateMultiStartOptimizer<MultivariateDifferentiableFunction>\n+    implements MultivariateDifferentiableOptimizer {\n+    /**\n+     * Create a multi-start optimizer from a single-start optimizer.\n+     *\n+     * @param optimizer Single-start optimizer to wrap.\n+     * @param starts Number of starts to perform (including the\n+     * first one), multi-start is disabled if value is less than or\n+     * equal to 1.\n+     * @param generator Random vector generator to use for restarts.\n+     */\n+    public MultivariateDifferentiableMultiStartOptimizer(final MultivariateDifferentiableOptimizer optimizer,\n+                                                         final int starts,\n+                                                         final RandomVectorGenerator generator) {\n+        super(optimizer, starts, generator);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optimization/MultivariateDifferentiableOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization;\n+\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction;\n+\n+/**\n+ * This interface represents an optimization algorithm for\n+ * {@link MultivariateDifferentiableFunction scalar differentiable objective\n+ * functions}.\n+ * Optimization algorithms find the input point set that either {@link GoalType\n+ * maximize or minimize} an objective function.\n+ *\n+ * @see MultivariateOptimizer\n+ * @see MultivariateDifferentiableVectorOptimizer\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public interface MultivariateDifferentiableOptimizer\n+    extends BaseMultivariateOptimizer<MultivariateDifferentiableFunction> {}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optimization/MultivariateDifferentiableVectorMultiStartOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization;\n+\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+\n+/**\n+ * Special implementation of the {@link MultivariateDifferentiableVectorOptimizer}\n+ * interface adding multi-start features to an existing optimizer.\n+ *\n+ * This class wraps a classical optimizer to use it several times in\n+ * turn with different starting points in order to avoid being trapped\n+ * into a local extremum when looking for a global one.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class MultivariateDifferentiableVectorMultiStartOptimizer\n+    extends BaseMultivariateVectorMultiStartOptimizer<MultivariateDifferentiableVectorFunction>\n+    implements MultivariateDifferentiableVectorOptimizer {\n+    /**\n+     * Create a multi-start optimizer from a single-start optimizer.\n+     *\n+     * @param optimizer Single-start optimizer to wrap.\n+     * @param starts Number of starts to perform (including the\n+     * first one), multi-start is disabled if value is less than or\n+     * equal to 1.\n+     * @param generator Random vector generator to use for restarts.\n+     */\n+    public MultivariateDifferentiableVectorMultiStartOptimizer(\n+                final MultivariateDifferentiableVectorOptimizer optimizer,\n+                final int starts,\n+                final RandomVectorGenerator generator) {\n+        super(optimizer, starts, generator);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optimization/MultivariateDifferentiableVectorOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization;\n+\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n+\n+/**\n+ * This interface represents an optimization algorithm for\n+ * {@link MultivariateDifferentiableVectorFunction differentiable vectorial\n+ * objective functions}.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public interface MultivariateDifferentiableVectorOptimizer\n+    extends BaseMultivariateVectorOptimizer<MultivariateDifferentiableVectorFunction> {}\n--- a/src/main/java/org/apache/commons/math3/optimization/MultivariateOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/MultivariateOptimizer.java\n  * <p>Optimization algorithms find the input point set that either {@link GoalType\n  * maximize or minimize} an objective function.</p>\n  *\n- * @see DifferentiableMultivariateOptimizer\n- * @see DifferentiableMultivariateVectorOptimizer\n+ * @see MultivariateDifferentiableOptimizer\n+ * @see MultivariateDifferentiableVectorOptimizer\n  * @version $Id$\n  * @since 2.0\n  */\n--- a/src/main/java/org/apache/commons/math3/optimization/direct/BaseAbstractMultivariateOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/direct/BaseAbstractMultivariateOptimizer.java\n     /** {@inheritDoc} */\n     public PointValuePair optimize(int maxEval, FUNC f, GoalType goalType,\n                                        double[] startPoint) {\n+        return optimizeInternal(maxEval, f, goalType, startPoint);\n+    }\n+\n+    /**\n+     * Optimize an objective function.\n+     *\n+     * @param f Objective function.\n+     * @param goalType Type of optimization goal: either\n+     * {@link GoalType#MAXIMIZE} or {@link GoalType#MINIMIZE}.\n+     * @param startPoint Start point for optimization.\n+     * @param maxEval Maximum number of function evaluations.\n+     * @return the point/value pair giving the optimal value for objective\n+     * function.\n+     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n+     * if the start point dimension is wrong.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+     * if the maximal number of evaluations is exceeded.\n+     * @throws org.apache.commons.math3.exception.NullArgumentException if\n+     * any argument is {@code null}.\n+     */\n+    protected PointValuePair optimizeInternal(int maxEval, MultivariateFunction f, GoalType goalType,\n+                                              double[] startPoint) {\n         // Checks.\n         if (f == null) {\n             throw new NullArgumentException();\n--- a/src/main/java/org/apache/commons/math3/optimization/direct/BaseAbstractMultivariateVectorOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/direct/BaseAbstractMultivariateVectorOptimizer.java\n \n     /** {@inheritDoc} */\n     public PointVectorValuePair optimize(int maxEval, FUNC f, double[] t, double[] w,\n-                                            double[] startPoint) {\n+                                         double[] startPoint) {\n+        return optimizeInternal(maxEval, f, t, w, startPoint);\n+    }\n+\n+    /**\n+     * Optimize an objective function.\n+     * Optimization is considered to be a weighted least-squares minimization.\n+     * The cost function to be minimized is\n+     * <code>&sum;weight<sub>i</sub>(objective<sub>i</sub> - target<sub>i</sub>)<sup>2</sup></code>\n+     *\n+     * @param f Objective function.\n+     * @param target Target value for the objective functions at optimum.\n+     * @param weight Weights for the least squares cost computation.\n+     * @param startPoint Start point for optimization.\n+     * @return the point/value pair giving the optimal value for objective\n+     * function.\n+     * @param maxEval Maximum number of function evaluations.\n+     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n+     * if the start point dimension is wrong.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+     * if the maximal number of evaluations is exceeded.\n+     * @throws org.apache.commons.math3.exception.NullArgumentException if\n+     * any argument is {@code null}.\n+     */\n+    protected PointVectorValuePair optimizeInternal(final int maxEval, final MultivariateVectorFunction f,\n+                                                    final double[] t, final double[] w,\n+                                                    final double[] startPoint) {\n         // Checks.\n         if (f == null) {\n             throw new NullArgumentException();\n \n         // Perform computation.\n         return doOptimize();\n+\n     }\n \n     /**\n--- a/src/main/java/org/apache/commons/math3/optimization/fitting/CurveFitter.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/fitting/CurveFitter.java\n import java.util.List;\n \n import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n import org.apache.commons.math3.analysis.ParametricUnivariateFunction;\n-import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n import org.apache.commons.math3.optimization.DifferentiableMultivariateVectorOptimizer;\n+import org.apache.commons.math3.optimization.MultivariateDifferentiableVectorOptimizer;\n import org.apache.commons.math3.optimization.PointVectorValuePair;\n \n /** Fitter for parametric univariate real functions y = f(x).\n  * @since 2.0\n  */\n public class CurveFitter<T extends ParametricUnivariateFunction> {\n+\n+    /** Optimizer to use for the fitting.\n+     * @deprecated as of 3.1 replaced by {@link #optimizer}\n+     */\n+    @Deprecated\n+    private final DifferentiableMultivariateVectorOptimizer oldOptimizer;\n+\n     /** Optimizer to use for the fitting. */\n-    private final DifferentiableMultivariateVectorOptimizer optimizer;\n+    private final MultivariateDifferentiableVectorOptimizer optimizer;\n+\n     /** Observed points. */\n     private final List<WeightedObservedPoint> observations;\n \n     /** Simple constructor.\n      * @param optimizer optimizer to use for the fitting\n+     * @deprecated as of 3.1 replaced by {@link #CurveFitter(MultivariateDifferentiableVectorOptimizer)}\n      */\n     public CurveFitter(final DifferentiableMultivariateVectorOptimizer optimizer) {\n-        this.optimizer = optimizer;\n-        observations = new ArrayList<WeightedObservedPoint>();\n+        this.oldOptimizer = optimizer;\n+        this.optimizer    = null;\n+        observations      = new ArrayList<WeightedObservedPoint>();\n+    }\n+\n+    /** Simple constructor.\n+     * @param optimizer optimizer to use for the fitting\n+     * @since 3.1\n+     */\n+    public CurveFitter(final MultivariateDifferentiableVectorOptimizer optimizer) {\n+        this.oldOptimizer = null;\n+        this.optimizer    = optimizer;\n+        observations      = new ArrayList<WeightedObservedPoint>();\n     }\n \n     /** Add an observed (x,y) point to the sample with unit weight.\n         }\n \n         // perform the fit\n-        PointVectorValuePair optimum =\n-            optimizer.optimize(maxEval, new TheoreticalValuesFunction(f),\n-                               target, weights, initialGuess);\n+        final PointVectorValuePair optimum;\n+        if (optimizer == null) {\n+            // to be removed in 4.0\n+            optimum = oldOptimizer.optimize(maxEval, new OldTheoreticalValuesFunction(f),\n+                                            target, weights, initialGuess);\n+        } else {\n+            optimum = optimizer.optimize(maxEval, new TheoreticalValuesFunction(f),\n+                                         target, weights, initialGuess);\n+        }\n \n         // extract the coefficients\n         return optimum.getPointRef();\n     }\n \n     /** Vectorial function computing function theoretical values. */\n-    private class TheoreticalValuesFunction\n+    @Deprecated\n+    private class OldTheoreticalValuesFunction\n         implements DifferentiableMultivariateVectorFunction {\n         /** Function to fit. */\n         private final ParametricUnivariateFunction f;\n         /** Simple constructor.\n          * @param f function to fit.\n          */\n-        public TheoreticalValuesFunction(final ParametricUnivariateFunction f) {\n+        public OldTheoreticalValuesFunction(final ParametricUnivariateFunction f) {\n             this.f = f;\n         }\n \n             return values;\n         }\n     }\n+\n+    /** Vectorial function computing function theoretical values. */\n+    private class TheoreticalValuesFunction implements MultivariateDifferentiableVectorFunction {\n+\n+        /** Function to fit. */\n+        private final ParametricUnivariateFunction f;\n+\n+        /** Simple constructor.\n+         * @param f function to fit.\n+         */\n+        public TheoreticalValuesFunction(final ParametricUnivariateFunction f) {\n+            this.f = f;\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double[] value(double[] point) {\n+            // compute the residuals\n+            final double[] values = new double[observations.size()];\n+            int i = 0;\n+            for (WeightedObservedPoint observed : observations) {\n+                values[i++] = f.value(observed.getX(), point);\n+            }\n+\n+            return values;\n+        }\n+\n+        /** {@inheritDoc} */\n+        public DerivativeStructure[] value(DerivativeStructure[] point) {\n+\n+            // extract parameters\n+            final double[] parameters = new double[point.length];\n+            for (int k = 0; k < point.length; ++k) {\n+                parameters[k] = point[k].getValue();\n+            }\n+\n+            // compute the residuals\n+            final DerivativeStructure[] values = new DerivativeStructure[observations.size()];\n+            int i = 0;\n+            for (WeightedObservedPoint observed : observations) {\n+\n+                // build the DerivativeStructure by adding first the value as a constant\n+                // and then adding derivatives\n+                DerivativeStructure vi = new DerivativeStructure(point.length, 1, f.value(observed.getX(), parameters));\n+                for (int k = 0; k < point.length; ++k) {\n+                    vi = vi.add(new DerivativeStructure(point.length, 1, k, 0.0));\n+                }\n+\n+                values[i++] = vi;\n+\n+            }\n+\n+            return values;\n+        }\n+\n+    }\n+\n }\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optimization/general/AbstractDifferentiableOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization.general;\n+\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.differentiation.GradientFunction;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction;\n+import org.apache.commons.math3.optimization.ConvergenceChecker;\n+import org.apache.commons.math3.optimization.GoalType;\n+import org.apache.commons.math3.optimization.MultivariateDifferentiableOptimizer;\n+import org.apache.commons.math3.optimization.PointValuePair;\n+import org.apache.commons.math3.optimization.direct.BaseAbstractMultivariateOptimizer;\n+\n+/**\n+ * Base class for implementing optimizers for multivariate scalar\n+ * differentiable functions.\n+ * It contains boiler-plate code for dealing with gradient evaluation.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class AbstractDifferentiableOptimizer\n+    extends BaseAbstractMultivariateOptimizer<MultivariateDifferentiableFunction>\n+    implements MultivariateDifferentiableOptimizer {\n+\n+    /**\n+     * Objective function gradient.\n+     */\n+    private MultivariateVectorFunction gradient;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected AbstractDifferentiableOptimizer(ConvergenceChecker<PointValuePair> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * Compute the gradient vector.\n+     *\n+     * @param evaluationPoint Point at which the gradient must be evaluated.\n+     * @return the gradient at the specified point.\n+     */\n+    protected double[] computeObjectiveGradient(final double[] evaluationPoint) {\n+        return gradient.value(evaluationPoint);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public PointValuePair optimize(final int maxEval, final MultivariateDifferentiableFunction f,\n+                                   final GoalType goalType, final double[] startPoint) {\n+\n+        // store optimization problem characteristics\n+        gradient = new GradientFunction(f);\n+\n+        // perform optimization\n+        return super.optimize(maxEval, f, goalType, startPoint);\n+\n+    }\n+\n+}\n--- a/src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java\n import org.apache.commons.math3.exception.DimensionMismatchException;\n import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.differentiation.JacobianFunction;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n import org.apache.commons.math3.exception.util.LocalizedFormats;\n import org.apache.commons.math3.linear.QRDecomposition;\n import org.apache.commons.math3.linear.DecompositionSolver;\n  * It handles the boilerplate methods associated to thresholds settings,\n  * jacobian and error estimation.\n  * <br/>\n- * This class uses the {@link DifferentiableMultivariateVectorFunction#jacobian()}\n- * of the function argument in method\n- * {@link #optimize(int,DifferentiableMultivariateVectorFunction,double[],double[],double[])\n+ * This class uses the {@link JacobianFunction Jacobian} of the function argument in method\n+ * {@link #optimize(int, MultivariateDifferentiableVectorFunction, double[], double[], double[])\n  * optimize} and assumes that, in the matrix returned by the\n- * {@link MultivariateMatrixFunction#value(double[]) value} method, the rows\n+ * {@link JacobianFunction#value(double[]) value} method, the rows\n  * iterate on the model functions while the columns iterate on the parameters; thus,\n  * the numbers of rows is equal to the length of the {@code target} array while the\n  * number of columns is equal to the length of the {@code startPoint} array.\n         return sig;\n     }\n \n-    /** {@inheritDoc} */\n+    /** {@inheritDoc}\n+     * @deprecated as of 3.1 replaced by {@link #optimize(int,\n+     * MultivariateDifferentiableVectorFunction, double[], double[], double[])}\n+     */\n     @Override\n+    @Deprecated\n     public PointVectorValuePair optimize(int maxEval,\n                                          final DifferentiableMultivariateVectorFunction f,\n                                          final double[] target, final double[] weights,\n \n         cost = Double.POSITIVE_INFINITY;\n \n-        return super.optimize(maxEval, f, target, weights, startPoint);\n-    }\n+        return optimizeInternal(maxEval, f, target, weights, startPoint);\n+    }\n+\n+    /**\n+     * Optimize an objective function.\n+     * Optimization is considered to be a weighted least-squares minimization.\n+     * The cost function to be minimized is\n+     * <code>&sum;weight<sub>i</sub>(objective<sub>i</sub> - target<sub>i</sub>)<sup>2</sup></code>\n+     *\n+     * @param f Objective function.\n+     * @param target Target value for the objective functions at optimum.\n+     * @param weight Weights for the least squares cost computation.\n+     * @param startPoint Start point for optimization.\n+     * @return the point/value pair giving the optimal value for objective\n+     * function.\n+     * @param maxEval Maximum number of function evaluations.\n+     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n+     * if the start point dimension is wrong.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+     * if the maximal number of evaluations is exceeded.\n+     * @throws org.apache.commons.math3.exception.NullArgumentException if\n+     * any argument is {@code null}.\n+     */\n+    public PointVectorValuePair optimize(final int maxEval,\n+                                         final MultivariateDifferentiableVectorFunction f,\n+                                         final double[] target, final double[] weights,\n+                                         final double[] startPoint) {\n+\n+        // Reset counter.\n+        jacobianEvaluations = 0;\n+\n+        // Store least squares problem characteristics.\n+        jF = new JacobianFunction(f);\n+\n+        // Arrays shared with the other private methods.\n+        point = startPoint.clone();\n+        rows = target.length;\n+        cols = point.length;\n+\n+        weightedResidualJacobian = new double[rows][cols];\n+        this.weightedResiduals = new double[rows];\n+\n+        cost = Double.POSITIVE_INFINITY;\n+\n+        return optimizeInternal(maxEval, f, target, weights, startPoint);\n+    }\n+\n }\n--- a/src/main/java/org/apache/commons/math3/optimization/general/AbstractScalarDifferentiableOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/general/AbstractScalarDifferentiableOptimizer.java\n \n import org.apache.commons.math3.analysis.DifferentiableMultivariateFunction;\n import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.differentiation.GradientFunction;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction;\n import org.apache.commons.math3.optimization.DifferentiableMultivariateOptimizer;\n import org.apache.commons.math3.optimization.GoalType;\n import org.apache.commons.math3.optimization.ConvergenceChecker;\n  *\n  * @version $Id$\n  * @since 2.0\n+ * @deprecated as of 3.1 replaced by {@link AbstractDifferentiableOptimizer}\n  */\n+@Deprecated\n public abstract class AbstractScalarDifferentiableOptimizer\n     extends BaseAbstractMultivariateOptimizer<DifferentiableMultivariateFunction>\n     implements DifferentiableMultivariateOptimizer {\n         // Store optimization problem characteristics.\n         gradient = f.gradient();\n \n-        return super.optimize(maxEval, f, goalType, startPoint);\n+        return optimizeInternal(maxEval, f, goalType, startPoint);\n+    }\n+\n+    /**\n+     * Optimize an objective function.\n+     *\n+     * @param f Objective function.\n+     * @param goalType Type of optimization goal: either\n+     * {@link GoalType#MAXIMIZE} or {@link GoalType#MINIMIZE}.\n+     * @param startPoint Start point for optimization.\n+     * @param maxEval Maximum number of function evaluations.\n+     * @return the point/value pair giving the optimal value for objective\n+     * function.\n+     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n+     * if the start point dimension is wrong.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+     * if the maximal number of evaluations is exceeded.\n+     * @throws org.apache.commons.math3.exception.NullArgumentException if\n+     * any argument is {@code null}.\n+     */\n+    public PointValuePair optimize(final int maxEval,\n+                                   final MultivariateDifferentiableFunction f,\n+                                   final GoalType goalType,\n+                                   final double[] startPoint) {\n+        // Store optimization problem characteristics.\n+        gradient = new GradientFunction(f);\n+\n+        return optimizeInternal(maxEval, f, goalType, startPoint);\n     }\n }\n--- a/src/main/java/org/apache/commons/math3/optimization/package-info.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/package-info.java\n  *  <li>{@link org.apache.commons.math3.optimization.MultivariateOptimizer\n  *      MultivariateOptimizer} for {@link org.apache.commons.math3.analysis.MultivariateFunction\n  *      multivariate real functions}</li>\n- *  <li>{@link org.apache.commons.math3.optimization.DifferentiableMultivariateOptimizer\n- *      DifferentiableMultivariateOptimizer} for {@link\n- *      org.apache.commons.math3.analysis.DifferentiableMultivariateFunction\n+ *  <li>{@link org.apache.commons.math3.optimization.MultivariateDifferentiableOptimizer\n+ *      MultivariateDifferentiableOptimizer} for {@link\n+ *      org.apache.commons.math3.analysis.MultivariateDifferentiableFunction\n  *      differentiable multivariate real functions}</li>\n- *  <li>{@link org.apache.commons.math3.optimization.DifferentiableMultivariateVectorOptimizer\n- *      DifferentiableMultivariateVectorOptimizer} for {@link\n- *      org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction\n+ *  <li>{@link org.apache.commons.math3.optimization.MultivariateDifferentiableVectorOptimizer\n+ *      MultivariateDifferentiableVectorOptimizer} for {@link\n+ *      org.apache.commons.math3.analysis.MultivariateDifferentiableVectorFunction\n  *      differentiable multivariate vectorial functions}</li>\n  * </ul>\n  * </p>\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optimization/MultivariateDifferentiableMultiStartOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization;\n+\n+\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n+import org.apache.commons.math3.optimization.general.CircleScalar;\n+import org.apache.commons.math3.optimization.general.ConjugateGradientFormula;\n+import org.apache.commons.math3.optimization.general.NonLinearConjugateGradientOptimizer;\n+import org.apache.commons.math3.random.GaussianRandomGenerator;\n+import org.apache.commons.math3.random.JDKRandomGenerator;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+import org.apache.commons.math3.random.UncorrelatedRandomVectorGenerator;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class MultivariateDifferentiableMultiStartOptimizerTest {\n+\n+    @Test\n+    public void testCircleFitting() {\n+        CircleScalar circle = new CircleScalar();\n+        circle.addPoint( 30.0,  68.0);\n+        circle.addPoint( 50.0,  -6.0);\n+        circle.addPoint(110.0, -20.0);\n+        circle.addPoint( 35.0,  15.0);\n+        circle.addPoint( 45.0,  97.0);\n+        // TODO: the wrapper around NonLinearConjugateGradientOptimizer is a temporary hack for\n+        // version 3.1 of the library. It should be removed when NonLinearConjugateGradientOptimizer\n+        // will officially be declared as implementing MultivariateDifferentiableOptimizer\n+        MultivariateDifferentiableOptimizer underlying =\n+                new MultivariateDifferentiableOptimizer() {\n+\n+            private final NonLinearConjugateGradientOptimizer cg =\n+                    new NonLinearConjugateGradientOptimizer(ConjugateGradientFormula.POLAK_RIBIERE,\n+                                                            new SimpleValueChecker(1.0e-10, 1.0e-10));\n+            public PointValuePair optimize(int maxEval,\n+                                           MultivariateDifferentiableFunction f,\n+                                           GoalType goalType,\n+                                           double[] startPoint) {\n+                return cg.optimize(maxEval, f, goalType, startPoint);\n+            }\n+\n+            public int getMaxEvaluations() {\n+                return cg.getMaxEvaluations();\n+            }\n+\n+            public int getEvaluations() {\n+                return cg.getEvaluations();\n+            }\n+\n+            public ConvergenceChecker<PointValuePair> getConvergenceChecker() {\n+                return cg.getConvergenceChecker();\n+            }\n+        };\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(753289573253l);\n+        RandomVectorGenerator generator =\n+            new UncorrelatedRandomVectorGenerator(new double[] { 50.0, 50.0 }, new double[] { 10.0, 10.0 },\n+                                                  new GaussianRandomGenerator(g));\n+        MultivariateDifferentiableMultiStartOptimizer optimizer =\n+            new MultivariateDifferentiableMultiStartOptimizer(underlying, 10, generator);\n+        PointValuePair optimum =\n+            optimizer.optimize(200, circle, GoalType.MINIMIZE, new double[] { 98.680, 47.345 });\n+        Assert.assertEquals(200, optimizer.getMaxEvaluations());\n+        PointValuePair[] optima = optimizer.getOptima();\n+        for (PointValuePair o : optima) {\n+            Vector2D center = new Vector2D(o.getPointRef()[0], o.getPointRef()[1]);\n+            Assert.assertEquals(69.960161753, circle.getRadius(center), 1.0e-8);\n+            Assert.assertEquals(96.075902096, center.getX(), 1.0e-8);\n+            Assert.assertEquals(48.135167894, center.getY(), 1.0e-8);\n+        }\n+        Assert.assertTrue(optimizer.getEvaluations() > 70);\n+        Assert.assertTrue(optimizer.getEvaluations() < 90);\n+        Assert.assertEquals(3.1267527, optimum.getValue(), 1.0e-8);\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optimization/MultivariateDifferentiableVectorMultiStartOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization;\n+\n+\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.linear.BlockRealMatrix;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.optimization.general.GaussNewtonOptimizer;\n+import org.apache.commons.math3.random.GaussianRandomGenerator;\n+import org.apache.commons.math3.random.JDKRandomGenerator;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+import org.apache.commons.math3.random.UncorrelatedRandomVectorGenerator;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files.\n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class MultivariateDifferentiableVectorMultiStartOptimizerTest {\n+\n+    @Test\n+    public void testTrivial() {\n+        LinearProblem problem =\n+            new LinearProblem(new double[][] { { 2 } }, new double[] { 3 });\n+        // TODO: the wrapper around GaussNewtonOptimizer is a temporary hack for\n+        // version 3.1 of the library. It should be removed when GaussNewtonOptimizer\n+        // will officialy be declared as implementing MultivariateDifferentiableVectorOptimizer\n+        MultivariateDifferentiableVectorOptimizer underlyingOptimizer =\n+                new MultivariateDifferentiableVectorOptimizer() {\n+            private GaussNewtonOptimizer gn =\n+                    new GaussNewtonOptimizer(true,\n+                                             new SimpleVectorValueChecker(1.0e-6, 1.0e-6));\n+\n+            public PointVectorValuePair optimize(int maxEval,\n+                                                 MultivariateDifferentiableVectorFunction f,\n+                                                 double[] target,\n+                                                 double[] weight,\n+                                                 double[] startPoint) {\n+                return gn.optimize(maxEval, f, target, weight, startPoint);\n+            }\n+\n+            public int getMaxEvaluations() {\n+                return gn.getMaxEvaluations();\n+            }\n+\n+            public int getEvaluations() {\n+                return gn.getEvaluations();\n+            }\n+\n+            public ConvergenceChecker<PointVectorValuePair> getConvergenceChecker() {\n+                return gn.getConvergenceChecker();\n+            }\n+        };\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(16069223052l);\n+        RandomVectorGenerator generator =\n+            new UncorrelatedRandomVectorGenerator(1, new GaussianRandomGenerator(g));\n+        MultivariateDifferentiableVectorMultiStartOptimizer optimizer =\n+            new MultivariateDifferentiableVectorMultiStartOptimizer(underlyingOptimizer,\n+                                                                       10, generator);\n+\n+        // no optima before first optimization attempt\n+        try {\n+            optimizer.getOptima();\n+            Assert.fail(\"an exception should have been thrown\");\n+        } catch (MathIllegalStateException ise) {\n+            // expected\n+        }\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(100, problem, problem.target, new double[] { 1 }, new double[] { 0 });\n+        Assert.assertEquals(1.5, optimum.getPoint()[0], 1.0e-10);\n+        Assert.assertEquals(3.0, optimum.getValue()[0], 1.0e-10);\n+        PointVectorValuePair[] optima = optimizer.getOptima();\n+        Assert.assertEquals(10, optima.length);\n+        for (int i = 0; i < optima.length; ++i) {\n+            Assert.assertEquals(1.5, optima[i].getPoint()[0], 1.0e-10);\n+            Assert.assertEquals(3.0, optima[i].getValue()[0], 1.0e-10);\n+        }\n+        Assert.assertTrue(optimizer.getEvaluations() > 20);\n+        Assert.assertTrue(optimizer.getEvaluations() < 50);\n+        Assert.assertEquals(100, optimizer.getMaxEvaluations());\n+    }\n+\n+    @Test(expected=TestException.class)\n+    public void testNoOptimum() {\n+\n+        // TODO: the wrapper around GaussNewtonOptimizer is a temporary hack for\n+        // version 3.1 of the library. It should be removed when GaussNewtonOptimizer\n+        // will officialy be declared as implementing MultivariateDifferentiableVectorOptimizer\n+        MultivariateDifferentiableVectorOptimizer underlyingOptimizer =\n+                new MultivariateDifferentiableVectorOptimizer() {\n+            private GaussNewtonOptimizer gn =\n+                    new GaussNewtonOptimizer(true,\n+                                             new SimpleVectorValueChecker(1.0e-6, 1.0e-6));\n+\n+            public PointVectorValuePair optimize(int maxEval,\n+                                                 MultivariateDifferentiableVectorFunction f,\n+                                                 double[] target,\n+                                                 double[] weight,\n+                                                 double[] startPoint) {\n+                return gn.optimize(maxEval, f, target, weight, startPoint);\n+            }\n+\n+            public int getMaxEvaluations() {\n+                return gn.getMaxEvaluations();\n+            }\n+\n+            public int getEvaluations() {\n+                return gn.getEvaluations();\n+            }\n+\n+            public ConvergenceChecker<PointVectorValuePair> getConvergenceChecker() {\n+                return gn.getConvergenceChecker();\n+            }\n+        };\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(12373523445l);\n+        RandomVectorGenerator generator =\n+            new UncorrelatedRandomVectorGenerator(1, new GaussianRandomGenerator(g));\n+        MultivariateDifferentiableVectorMultiStartOptimizer optimizer =\n+            new MultivariateDifferentiableVectorMultiStartOptimizer(underlyingOptimizer,\n+                                                                       10, generator);\n+        optimizer.optimize(100, new MultivariateDifferentiableVectorFunction() {\n+            public double[] value(double[] point) {\n+                throw new TestException();\n+            }\n+            public DerivativeStructure[] value(DerivativeStructure[] point) {\n+                return point;\n+            }\n+            }, new double[] { 2 }, new double[] { 1 }, new double[] { 0 });\n+    }\n+\n+    private static class TestException extends RuntimeException {\n+        private static final long serialVersionUID = -7809988995389067683L;\n+    }\n+\n+    private static class LinearProblem implements MultivariateDifferentiableVectorFunction {\n+\n+        final RealMatrix factors;\n+        final double[] target;\n+        public LinearProblem(double[][] factors, double[] target) {\n+            this.factors = new BlockRealMatrix(factors);\n+            this.target  = target;\n+        }\n+\n+        public double[] value(double[] variables) {\n+            return factors.operate(variables);\n+        }\n+\n+        public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+            DerivativeStructure[] y = new DerivativeStructure[factors.getRowDimension()];\n+            for (int i = 0; i < y.length; ++i) {\n+                y[i] = variables[0].getField().getZero();\n+                for (int j = 0; j < factors.getColumnDimension(); ++j) {\n+                    y[i] = y[i].add(variables[j].multiply(factors.getEntry(i, j)));\n+                }\n+            }\n+            return y;\n+        }\n+\n+    }\n+\n+}\n--- a/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerAbstractTest.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerAbstractTest.java\n  */\n package org.apache.commons.math3.optimization.general;\n \n-import java.awt.geom.Point2D;\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Arrays;\n \n-import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n-import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n import org.apache.commons.math3.exception.ConvergenceException;\n import org.apache.commons.math3.exception.DimensionMismatchException;\n import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n import org.apache.commons.math3.linear.BlockRealMatrix;\n import org.apache.commons.math3.linear.RealMatrix;\n import org.apache.commons.math3.optimization.PointVectorValuePair;\n         Assert.assertTrue(optimizer.getJacobianEvaluations() < 10);\n         double rms = optimizer.getRMS();\n         Assert.assertEquals(1.768262623567235,  FastMath.sqrt(circle.getN()) * rms,  1.0e-10);\n-        Point2D.Double center = new Point2D.Double(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n+        Vector2D center = new Vector2D(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n         Assert.assertEquals(69.96016176931406, circle.getRadius(center), 1.0e-6);\n-        Assert.assertEquals(96.07590211815305, center.x,      1.0e-6);\n-        Assert.assertEquals(48.13516790438953, center.y,      1.0e-6);\n+        Assert.assertEquals(96.07590211815305, center.getX(),            1.0e-6);\n+        Assert.assertEquals(48.13516790438953, center.getY(),            1.0e-6);\n         double[][] cov = optimizer.getCovariances();\n         Assert.assertEquals(1.839, cov[0][0], 0.001);\n         Assert.assertEquals(0.731, cov[0][1], 0.001);\n         // add perfect measurements and check errors are reduced\n         double  r = circle.getRadius(center);\n         for (double d= 0; d < 2 * FastMath.PI; d += 0.01) {\n-            circle.addPoint(center.x + r * FastMath.cos(d), center.y + r * FastMath.sin(d));\n+            circle.addPoint(center.getX() + r * FastMath.cos(d), center.getY() + r * FastMath.sin(d));\n         }\n         double[] target = new double[circle.getN()];\n         Arrays.fill(target, 0.0);\n         AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n         PointVectorValuePair optimum =\n             optimizer.optimize(100, circle, target, weights, new double[] { -12, -12 });\n-        Point2D.Double center = new Point2D.Double(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n+        Vector2D center = new Vector2D(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n         Assert.assertTrue(optimizer.getEvaluations() < 25);\n         Assert.assertTrue(optimizer.getJacobianEvaluations() < 20);\n         Assert.assertEquals( 0.043, optimizer.getRMS(), 1.0e-3);\n         Assert.assertEquals( 0.292235,  circle.getRadius(center), 1.0e-6);\n-        Assert.assertEquals(-0.151738,  center.x,      1.0e-6);\n-        Assert.assertEquals( 0.2075001, center.y,      1.0e-6);\n+        Assert.assertEquals(-0.151738,  center.getX(),            1.0e-6);\n+        Assert.assertEquals( 0.2075001, center.getY(),            1.0e-6);\n     }\n \n     @Test\n \n         final double[][] data = dataset.getData();\n         final double[] initial = dataset.getStartingPoint(0);\n-        final DifferentiableMultivariateVectorFunction problem;\n+        final MultivariateDifferentiableVectorFunction problem;\n         problem = dataset.getLeastSquaresProblem();\n         final PointVectorValuePair optimum;\n         optimum = optimizer.optimize(100, problem, data[1], w, initial);\n         doTestStRD(StatisticalReferenceDatasetFactory.createHahn1(), 1E-7, 1E-4);\n     }\n \n-    static class LinearProblem implements DifferentiableMultivariateVectorFunction, Serializable {\n+    static class LinearProblem implements MultivariateDifferentiableVectorFunction, Serializable {\n \n         private static final long serialVersionUID = 703247177355019415L;\n         final RealMatrix factors;\n             return factors.operate(variables);\n         }\n \n-        public MultivariateMatrixFunction jacobian() {\n-            return new MultivariateMatrixFunction() {\n-                public double[][] value(double[] point) {\n-                    return factors.getData();\n+        public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+            DerivativeStructure[] value = new DerivativeStructure[factors.getRowDimension()];\n+            for (int i = 0; i < value.length; ++i) {\n+                value[i] = variables[0].getField().getZero();\n+                for (int j = 0; j < factors.getColumnDimension(); ++j) {\n+                    value[i] = value[i].add(variables[j].multiply(factors.getEntry(i, j)));\n                 }\n-            };\n-        }\n+                \n+            }\n+            return value;\n+        }\n+\n     }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerTest.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerTest.java\n         for (int i = 0; i < sig.length; i++) {\n             final double actual = FastMath.sqrt(optimizer.getChiSquare()/dof)*sig[i];\n             Assert.assertEquals(dataset.getName() + \", parameter #\" + i,\n-                                actual, expected[i], 1E-8 * expected[i]);\n+                                expected[i], actual, 1.3e-8 * expected[i]);\n         }\n     }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/CircleProblem.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/CircleProblem.java\n package org.apache.commons.math3.optimization.general;\n \n import java.util.ArrayList;\n-import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n-import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n-import org.apache.commons.math3.util.MathUtils;\n+\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n import org.apache.commons.math3.util.FastMath;\n \n /**\n  *   corresponding circle.</li>\n  * </ul>\n  */\n-class CircleProblem implements DifferentiableMultivariateVectorFunction {\n+class CircleProblem implements MultivariateDifferentiableVectorFunction {\n     /** Cloud of points assumed to be fitted by a circle. */\n-    private final ArrayList<double[]> points;\n+    private final ArrayList<Vector2D> points;\n     /** Error on the x-coordinate of the points. */\n     private final double xSigma;\n     /** Error on the y-coordinate of the points. */\n     private final double ySigma;\n-    /** Number of points on the circumference (when searching which\n-        model point is closest to a given \"observation\". */\n-    private final int resolution;\n-\n-    /**\n-     * @param xError Assumed error for the x-coordinate of the circle points.\n-     * @param yError Assumed error for the y-coordinate of the circle points.\n-     * @param searchResolution Number of points to try when searching the one\n-     * that is closest to a given \"observed\" point.\n-     */\n-    public CircleProblem(double xError,\n-                         double yError,\n-                         int searchResolution) {\n-        points = new ArrayList<double[]>();\n-        xSigma = xError;\n-        ySigma = yError;\n-        resolution = searchResolution;\n-    }\n \n     /**\n      * @param xError Assumed error for the x-coordinate of the circle points.\n      */\n     public CircleProblem(double xError,\n                          double yError) {\n-        this(xError, yError, 500);\n+        points = new ArrayList<Vector2D>();\n+        xSigma = xError;\n+        ySigma = yError;\n     }\n \n-    public void addPoint(double px, double py) {\n-        points.add(new double[] { px, py });\n+    public void addPoint(Vector2D p) {\n+        points.add(p);\n     }\n \n     public double[] target() {\n         final double[] t = new double[points.size() * 2];\n         for (int i = 0; i < points.size(); i++) {\n-            final double[] p = points.get(i);\n+            final Vector2D p = points.get(i);\n             final int index = i * 2;\n-            t[index] = p[0];\n-            t[index + 1] = p[1];\n+            t[index]     = p.getX();\n+            t[index + 1] = p.getY();\n         }\n \n         return t;\n \n         final double[] model = new double[points.size() * 2];\n \n-        final double deltaTheta = MathUtils.TWO_PI / resolution;\n         for (int i = 0; i < points.size(); i++) {\n-            final double[] p = points.get(i);\n-            final double px = p[0];\n-            final double py = p[1];\n+            final Vector2D p = points.get(i);\n \n-            double bestX = 0;\n-            double bestY = 0;\n-            double dMin = Double.POSITIVE_INFINITY;\n+            // Find the circle point closest to the observed point\n+            // (observed points are points add through the addPoint method above)\n+            final double dX = cx - p.getX();\n+            final double dY = cy - p.getY();\n+            final double scaling = r / FastMath.hypot(dX, dY);\n+            final int index  = i * 2;\n+            model[index]     = cx - scaling * dX;\n+            model[index + 1] = cy - scaling * dY;\n \n-            // Find the angle for which the circle passes closest to the\n-            // current point (using a resolution of 100 points along the\n-            // circumference).\n-            for (double theta = 0; theta <= MathUtils.TWO_PI; theta += deltaTheta) {\n-                final double currentX = cx + r * FastMath.cos(theta);\n-                final double currentY = cy + r * FastMath.sin(theta);\n-                final double dX = currentX - px;\n-                final double dY = currentY - py;\n-                final double d = dX * dX + dY * dY;\n-                if (d < dMin) {\n-                    dMin = d;\n-                    bestX = currentX;\n-                    bestY = currentY;\n-                }\n-            }\n-\n-            final int index = i * 2;\n-            model[index] = bestX;\n-            model[index + 1] = bestY;\n         }\n \n         return model;\n     }\n \n-    public MultivariateMatrixFunction jacobian() {\n-        return new MultivariateMatrixFunction() {\n-            public double[][] value(double[] point) {\n-                return jacobian(point);\n-            }\n-        };\n+    public DerivativeStructure[] value(DerivativeStructure[] params) {\n+        final DerivativeStructure cx = params[0];\n+        final DerivativeStructure cy = params[1];\n+        final DerivativeStructure r = params[2];\n+\n+        final DerivativeStructure[] model = new DerivativeStructure[points.size() * 2];\n+\n+        for (int i = 0; i < points.size(); i++) {\n+            final Vector2D p = points.get(i);\n+\n+            // Find the circle point closest to the observed point\n+            // (observed points are points add through the addPoint method above)\n+            final DerivativeStructure dX = cx.subtract(p.getX());\n+            final DerivativeStructure dY = cy.subtract(p.getY());\n+            final DerivativeStructure scaling = r.divide(dX.multiply(dX).add(dY.multiply(dY)).sqrt());\n+            final int index  = i * 2;\n+            model[index]     = cx.subtract(scaling.multiply(dX));\n+            model[index + 1] = cy.subtract(scaling.multiply(dY));\n+\n+        }\n+\n+        return model;\n+\n     }\n \n-    private double[][] jacobian(double[] params) {\n-        final double[][] jacobian = new double[points.size() * 2][3];\n-\n-        for (int i = 0; i < points.size(); i++) {\n-            final int index = i * 2;\n-            // Partial derivative wrt x-coordinate of center. \n-            jacobian[index][0] = 1;\n-            jacobian[index + 1][0] = 0;\n-            // Partial derivative wrt y-coordinate of center.\n-            jacobian[index][1] = 0;\n-            jacobian[index + 1][1] = 1;\n-            // Partial derivative wrt radius.\n-            final double[] p = points.get(i);\n-            jacobian[index][2] = (p[0] - params[0]) / params[2];\n-            jacobian[index + 1][2] = (p[1] - params[1]) / params[2];\n-        }\n-\n-        return jacobian;\n-    }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/CircleScalar.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/CircleScalar.java\n \n package org.apache.commons.math3.optimization.general;\n \n-import java.awt.geom.Point2D;\n import java.util.ArrayList;\n-import org.apache.commons.math3.analysis.DifferentiableMultivariateFunction;\n-import org.apache.commons.math3.analysis.MultivariateFunction;\n-import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n \n /**\n  * Class used in the tests.\n  */\n-class CircleScalar implements DifferentiableMultivariateFunction {\n-    private ArrayList<Point2D.Double> points;\n+public class CircleScalar implements MultivariateDifferentiableFunction {\n+    private ArrayList<Vector2D> points;\n \n     public CircleScalar() {\n-        points  = new ArrayList<Point2D.Double>();\n+        points  = new ArrayList<Vector2D>();\n     }\n \n     public void addPoint(double px, double py) {\n-        points.add(new Point2D.Double(px, py));\n+        points.add(new Vector2D(px, py));\n     }\n \n-    public double getRadius(Point2D.Double center) {\n+    public double getRadius(Vector2D center) {\n         double r = 0;\n-        for (Point2D.Double point : points) {\n+        for (Vector2D point : points) {\n             r += point.distance(center);\n         }\n         return r / points.size();\n     }\n \n-    private double[] gradient(double[] point) {\n-        // optimal radius\n-        Point2D.Double center = new Point2D.Double(point[0], point[1]);\n-        double radius = getRadius(center);\n+    private DerivativeStructure distance(Vector2D point,\n+                                         DerivativeStructure cx, DerivativeStructure cy) {\n+        DerivativeStructure dx = cx.subtract(point.getX());\n+        DerivativeStructure dy = cy.subtract(point.getY());\n+        return dx.multiply(dx).add(dy.multiply(dy)).sqrt();\n+    }\n \n-        // gradient of the sum of squared residuals\n-        double dJdX = 0;\n-        double dJdY = 0;\n-        for (Point2D.Double pk : points) {\n-            double dk = pk.distance(center);\n-            dJdX += (center.x - pk.x) * (dk - radius) / dk;\n-            dJdY += (center.y - pk.y) * (dk - radius) / dk;\n+    public DerivativeStructure getRadius(DerivativeStructure cx, DerivativeStructure cy) {\n+        DerivativeStructure r = cx.getField().getZero();\n+        for (Vector2D point : points) {\n+            r = r.add(distance(point, cx, cy));\n         }\n-        dJdX *= 2;\n-        dJdY *= 2;\n-\n-        return new double[] { dJdX, dJdY };\n+        return r.divide(points.size());\n     }\n \n     public double value(double[] variables)  {\n-        Point2D.Double center = new Point2D.Double(variables[0], variables[1]);\n+        Vector2D center = new Vector2D(variables[0], variables[1]);\n         double radius = getRadius(center);\n \n         double sum = 0;\n-        for (Point2D.Double point : points) {\n+        for (Vector2D point : points) {\n             double di = point.distance(center) - radius;\n             sum += di * di;\n         }\n         return sum;\n     }\n \n-    public MultivariateVectorFunction gradient() {\n-        return new MultivariateVectorFunction() {\n-            public double[] value(double[] point) {\n-                return gradient(point);\n-            }\n-        };\n+    public DerivativeStructure value(DerivativeStructure[] variables)  {\n+        DerivativeStructure radius = getRadius(variables[0], variables[1]);\n+\n+        DerivativeStructure sum = variables[0].getField().getZero();\n+        for (Vector2D point : points) {\n+            DerivativeStructure di = distance(point, variables[0], variables[1]).subtract(radius);\n+            sum = sum.add(di.multiply(di));\n+        }\n+\n+        return sum;\n     }\n \n-    public MultivariateFunction partialDerivative(final int k) {\n-        return new MultivariateFunction() {\n-            public double value(double[] point) {\n-                return gradient(point)[k];\n-            }\n-        };\n-    }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/CircleVectorial.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/CircleVectorial.java\n \n package org.apache.commons.math3.optimization.general;\n \n-import java.awt.geom.Point2D;\n import java.util.ArrayList;\n-import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n-import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n \n /**\n  * Class used in the tests.\n  */\n-class CircleVectorial implements DifferentiableMultivariateVectorFunction {\n-    private ArrayList<Point2D.Double> points;\n+class CircleVectorial implements MultivariateDifferentiableVectorFunction {\n+    private ArrayList<Vector2D> points;\n \n     public CircleVectorial() {\n-        points  = new ArrayList<Point2D.Double>();\n+        points  = new ArrayList<Vector2D>();\n     }\n \n     public void addPoint(double px, double py) {\n-        points.add(new Point2D.Double(px, py));\n+        points.add(new Vector2D(px, py));\n     }\n \n     public int getN() {\n         return points.size();\n     }\n \n-    public double getRadius(Point2D.Double center) {\n+    public double getRadius(Vector2D center) {\n         double r = 0;\n-        for (Point2D.Double point : points) {\n+        for (Vector2D point : points) {\n             r += point.distance(center);\n         }\n         return r / points.size();\n     }\n \n-    private double[][] jacobian(double[] point) {\n-        int n = points.size();\n-        Point2D.Double center = new Point2D.Double(point[0], point[1]);\n+    private DerivativeStructure distance(Vector2D point,\n+                                         DerivativeStructure cx, DerivativeStructure cy) {\n+        DerivativeStructure dx = cx.subtract(point.getX());\n+        DerivativeStructure dy = cy.subtract(point.getY());\n+        return dx.multiply(dx).add(dy.multiply(dy)).sqrt();\n+    }\n \n-        // gradient of the optimal radius\n-        double dRdX = 0;\n-        double dRdY = 0;\n-        for (Point2D.Double pk : points) {\n-            double dk = pk.distance(center);\n-            dRdX += (center.x - pk.x) / dk;\n-            dRdY += (center.y - pk.y) / dk;\n+    public DerivativeStructure getRadius(DerivativeStructure cx, DerivativeStructure cy) {\n+        DerivativeStructure r = cx.getField().getZero();\n+        for (Vector2D point : points) {\n+            r = r.add(distance(point, cx, cy));\n         }\n-        dRdX /= n;\n-        dRdY /= n;\n-\n-        // jacobian of the radius residuals\n-        double[][] jacobian = new double[n][2];\n-        for (int i = 0; i < n; ++i) {\n-            Point2D.Double pi = points.get(i);\n-            double di   = pi.distance(center);\n-            jacobian[i][0] = (center.x - pi.x) / di - dRdX;\n-            jacobian[i][1] = (center.y - pi.y) / di - dRdY;\n-        }\n-\n-        return jacobian;\n+        return r.divide(points.size());\n     }\n \n     public double[] value(double[] variables) {\n-        Point2D.Double center = new Point2D.Double(variables[0], variables[1]);\n+        Vector2D center = new Vector2D(variables[0], variables[1]);\n         double radius = getRadius(center);\n \n         double[] residuals = new double[points.size()];\n         return residuals;\n     }\n \n-    public MultivariateMatrixFunction jacobian() {\n-        return new MultivariateMatrixFunction() {\n-            public double[][] value(double[] point) {\n-                return jacobian(point);\n-            }\n-        };\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure radius = getRadius(variables[0], variables[1]);\n+\n+        DerivativeStructure[] residuals = new DerivativeStructure[points.size()];\n+        for (int i = 0; i < residuals.length; ++i) {\n+            residuals[i] = distance(points.get(i), variables[0], variables[1]).subtract(radius);\n+        }\n+\n+        return residuals;\n     }\n+\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/LevenbergMarquardtOptimizerTest.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/LevenbergMarquardtOptimizerTest.java\n \n package org.apache.commons.math3.optimization.general;\n \n-import java.awt.geom.Point2D;\n import java.io.Serializable;\n import java.util.ArrayList;\n import java.util.List;\n \n-import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n-import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n import org.apache.commons.math3.exception.ConvergenceException;\n import org.apache.commons.math3.exception.DimensionMismatchException;\n import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n import org.apache.commons.math3.linear.SingularMatrixException;\n import org.apache.commons.math3.optimization.PointVectorValuePair;\n import org.apache.commons.math3.util.FastMath;\n         optimizer.optimize(100, problem, problem.target, new double[] { 1, 1, 1 }, new double[] { 0, 0, 0 });\n         Assert.assertTrue(FastMath.sqrt(problem.target.length) * optimizer.getRMS() > 0.6);\n \n-        double[][] cov = optimizer.getCovariances(1.5e-14);\n+        optimizer.getCovariances(1.5e-14);\n     }\n \n     @Test\n         checkEstimate(circle, 0.1, 20, 1.0e-18, 1.0e-16, 1.0e-10, true);\n     }\n \n-    private void checkEstimate(DifferentiableMultivariateVectorFunction problem,\n+    private void checkEstimate(MultivariateDifferentiableVectorFunction problem,\n                                double initialStepBoundFactor, int maxCostEval,\n                                double costRelativeTolerance, double parRelativeTolerance,\n                                double orthoTolerance, boolean shouldFail) {\n             optimizer.optimize(100, problem, dataPoints[1], weights,\n                                new double[] { 10, 900, 80, 27, 225 });\n \n-        final double chi2 = optimizer.getChiSquare();\n         final double[] solution = optimum.getPoint();\n         final double[] expectedSolution = { 10.4, 958.3, 131.4, 33.9, 205.0 };\n \n         final CircleProblem circle = new CircleProblem(xSigma, ySigma);\n \n         final int numPoints = 10;\n-        for (Point2D.Double p : factory.generate(numPoints)) {\n-            circle.addPoint(p.x, p.y);\n+        for (Vector2D p : factory.generate(numPoints)) {\n+            circle.addPoint(p);\n             // System.out.println(p.x + \" \" + p.y);\n         }\n \n         Assert.assertEquals(radius, paramFound[2], asymptoticStandardErrorFound[2]);\n     }\n \n-    private static class QuadraticProblem implements DifferentiableMultivariateVectorFunction, Serializable {\n+    private static class QuadraticProblem implements MultivariateDifferentiableVectorFunction, Serializable {\n \n         private static final long serialVersionUID = 7072187082052755854L;\n         private List<Double> x;\n         public void addPoint(double x, double y) {\n             this.x.add(x);\n             this.y.add(y);\n-        }\n-\n-        private double[][] jacobian(double[] variables) {\n-            double[][] jacobian = new double[x.size()][3];\n-            for (int i = 0; i < jacobian.length; ++i) {\n-                jacobian[i][0] = x.get(i) * x.get(i);\n-                jacobian[i][1] = x.get(i);\n-                jacobian[i][2] = 1.0;\n-            }\n-            return jacobian;\n         }\n \n         public double[] value(double[] variables) {\n             return values;\n         }\n \n-        public MultivariateMatrixFunction jacobian() {\n-            return new MultivariateMatrixFunction() {\n-                public double[][] value(double[] point) {\n-                    return jacobian(point);\n-                }\n-            };\n-        }\n+        public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+            DerivativeStructure[] values = new DerivativeStructure[x.size()];\n+            for (int i = 0; i < values.length; ++i) {\n+                values[i] = (variables[0].multiply(x.get(i)).add(variables[1])).multiply(x.get(i)).add(variables[2]);\n+            }\n+            return values;\n+        }\n+\n     }\n \n     private static class BevingtonProblem\n-        implements DifferentiableMultivariateVectorFunction {\n+        implements MultivariateDifferentiableVectorFunction {\n         private List<Double> time;\n         private List<Double> count;\n \n         public void addPoint(double t, double c) {\n             time.add(t);\n             count.add(c);\n-        }\n-\n-        private double[][] jacobian(double[] params) {\n-            double[][] jacobian = new double[time.size()][5];\n-\n-            for (int i = 0; i < jacobian.length; ++i) {\n-                final double t = time.get(i);\n-                jacobian[i][0] = 1;\n-\n-                final double p3 =  params[3];\n-                final double p4 =  params[4];\n-                final double tOp3 = t / p3;\n-                final double tOp4 = t / p4;\n-                jacobian[i][1] = Math.exp(-tOp3);\n-                jacobian[i][2] = Math.exp(-tOp4);\n-                jacobian[i][3] = params[1] * Math.exp(-tOp3) * tOp3 / p3;\n-                jacobian[i][4] = params[2] * Math.exp(-tOp4) * tOp4 / p4;\n-            }\n-            return jacobian;\n         }\n \n         public double[] value(double[] params) {\n             return values;\n         }\n \n-        public MultivariateMatrixFunction jacobian() {\n-            return new MultivariateMatrixFunction() {\n-                public double[][] value(double[] point) {\n-                    return jacobian(point);\n-                }\n-            };\n-        }\n+        public DerivativeStructure[] value(DerivativeStructure[] params) {\n+            DerivativeStructure[] values = new DerivativeStructure[time.size()];\n+            for (int i = 0; i < values.length; ++i) {\n+                final double t = time.get(i);\n+                values[i] = params[0].add(\n+                    params[1].multiply(params[3].reciprocal().multiply(-t).exp())).add(\n+                    params[2].multiply(params[4].reciprocal().multiply(-t).exp()));\n+            }\n+            return values;\n+        }\n+\n     }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/MinpackTest.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/MinpackTest.java\n \n \n import org.apache.commons.math3.exception.TooManyEvaluationsException;\n-import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n-import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n import org.apache.commons.math3.optimization.PointVectorValuePair;\n import org.apache.commons.math3.util.FastMath;\n import org.junit.Assert;\n   }\n \n   private static abstract class MinpackFunction\n-      implements DifferentiableMultivariateVectorFunction, Serializable {\n+      implements MultivariateDifferentiableVectorFunction, Serializable {\n \n       private static final long serialVersionUID = -6209760235478794233L;\n       protected int      n;\n           }\n       }\n \n-      public MultivariateMatrixFunction jacobian() {\n-          return new MultivariateMatrixFunction() {\n-            public double[][] value(double[] point) {\n-                  return jacobian(point);\n-              }\n-          };\n-      }\n-\n-      public abstract double[][] jacobian(double[] variables);\n-\n-      public abstract double[] value(double[] variables);\n+      public double[] value(double[] variables) {\n+          DerivativeStructure[] dsV = new DerivativeStructure[variables.length];\n+          for (int i = 0; i < variables.length; ++i) {\n+              dsV[i] = new DerivativeStructure(0, 0, variables[i]);\n+          }\n+          DerivativeStructure[] dsY = value(dsV);\n+          double[] y = new double[dsY.length];\n+          for (int i = 0; i < dsY.length; ++i) {\n+              y[i] = dsY[i].getValue();\n+          }\n+          return y;\n+      }\n+\n+      public abstract DerivativeStructure[] value(DerivativeStructure[] variables);\n \n   }\n \n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double t = 2.0 / m;\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        jacobian[i] = new double[n];\n-        for (int j = 0; j < n; ++j) {\n-          jacobian[i][j] = (i == j) ? (1 - t) : -t;\n-        }\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double sum = 0;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+      DerivativeStructure sum = variables[0].getField().getZero();\n       for (int i = 0; i < n; ++i) {\n-        sum += variables[i];\n-      }\n-      double t  = 1 + 2 * sum / m;\n-      double[] f = new double[m];\n+        sum = sum.add(variables[i]);\n+      }\n+      DerivativeStructure t  = sum.multiply(2.0 / m).add(1);\n+      DerivativeStructure[] f = new DerivativeStructure[m];\n       for (int i = 0; i < n; ++i) {\n-        f[i] = variables[i] - t;\n-      }\n-      Arrays.fill(f, n, m, -t);\n+        f[i] = variables[i].subtract(t);\n+      }\n+      Arrays.fill(f, n, m, t.negate());\n       return f;\n     }\n \n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        jacobian[i] = new double[n];\n-        for (int j = 0; j < n; ++j) {\n-          jacobian[i][j] = (i + 1) * (j + 1);\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        DerivativeStructure sum = variables[0].getField().getZero();\n+        for (int i = 0; i < n; ++i) {\n+            sum = sum.add(variables[i].multiply(i + 1));\n         }\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double[] f = new double[m];\n-      double sum = 0;\n-      for (int i = 0; i < n; ++i) {\n-        sum += (i + 1) * variables[i];\n-      }\n-      for (int i = 0; i < m; ++i) {\n-        f[i] = (i + 1) * sum - 1;\n-      }\n-      return f;\n+        for (int i = 0; i < m; ++i) {\n+            f[i] = sum.multiply(i + 1).subtract(1);\n+        }\n+        return f;\n     }\n \n   }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        jacobian[i] = new double[n];\n-        jacobian[i][0] = 0;\n-        for (int j = 1; j < (n - 1); ++j) {\n-          if (i == 0) {\n-            jacobian[i][j] = 0;\n-          } else if (i != (m - 1)) {\n-            jacobian[i][j] = i * (j + 1);\n-          } else {\n-            jacobian[i][j] = 0;\n-          }\n-        }\n-        jacobian[i][n - 1] = 0;\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double[] f = new double[m];\n-      double sum = 0;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        DerivativeStructure sum = variables[0].getField().getZero();\n       for (int i = 1; i < (n - 1); ++i) {\n-        sum += (i + 1) * variables[i];\n+          sum = sum.add(variables[i].multiply(i + 1));\n       }\n       for (int i = 0; i < (m - 1); ++i) {\n-        f[i] = i * sum - 1;\n-      }\n-      f[m - 1] = -1;\n+        f[i] = sum.multiply(i).subtract(1);\n+      }\n+      f[m - 1] = variables[0].getField().getOne().negate();\n       return f;\n     }\n \n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double x1 = variables[0];\n-      return new double[][] { { -20 * x1, 10 }, { -1, 0 } };\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      return new double[] { 10 * (x2 - x1 * x1), 1 - x1 };\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        return new DerivativeStructure[] {\n+            x2.subtract(x1.multiply(x1)).multiply(10),\n+            x1.negate().add(1)\n+        };\n     }\n \n   }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double tmpSquare = x1 * x1 + x2 * x2;\n-      double tmp1 = twoPi * tmpSquare;\n-      double tmp2 = FastMath.sqrt(tmpSquare);\n-      return new double[][] {\n-        {  100 * x2 / tmp1, -100 * x1 / tmp1, 10 },\n-        { 10 * x1 / tmp2, 10 * x2 / tmp2, 0 },\n-        { 0, 0, 1 }\n-      };\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double x3 = variables[2];\n-      double tmp1;\n-      if (x1 == 0) {\n-        tmp1 = (x2 >= 0) ? 0.25 : -0.25;\n-      } else {\n-        tmp1 = FastMath.atan(x2 / x1) / twoPi;\n-        if (x1 < 0) {\n-          tmp1 += 0.5;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        DerivativeStructure x3 = variables[2];\n+        DerivativeStructure tmp1 = variables[0].getField().getZero();\n+        if (x1.getValue() == 0) {\n+            tmp1 = tmp1.add((x2.getValue() >= 0) ? 0.25 : -0.25);\n+        } else {\n+            tmp1 = x2.divide(x1).atan().divide(twoPi);\n+            if (x1.getValue() < 0) {\n+                tmp1 = tmp1.add(0.5);\n+            }\n         }\n-      }\n-      double tmp2 = FastMath.sqrt(x1 * x1 + x2 * x2);\n-      return new double[] {\n-        10.0 * (x3 - 10 * tmp1),\n-        10.0 * (tmp2 - 1),\n-        x3\n-      };\n+        DerivativeStructure tmp2 = x1.multiply(x1).add(x2.multiply(x2)).sqrt();\n+        return new DerivativeStructure[] {\n+            x3.subtract(tmp1.multiply(10)).multiply(10),\n+            tmp2.subtract(1).multiply(10),\n+            x3\n+        };\n     }\n \n     private static final double twoPi = 2.0 * FastMath.PI;\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double x3 = variables[2];\n-      double x4 = variables[3];\n-      return new double[][] {\n-        { 1, 10, 0, 0 },\n-        { 0, 0, sqrt5, -sqrt5 },\n-        { 0, 2 * (x2 - 2 * x3), -4 * (x2 - 2 * x3), 0 },\n-        { 2 * sqrt10 * (x1 - x4), 0, 0, -2 * sqrt10 * (x1 - x4) }\n-      };\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double x3 = variables[2];\n-      double x4 = variables[3];\n-      return new double[] {\n-        x1 + 10 * x2,\n-        sqrt5 * (x3 - x4),\n-        (x2 - 2 * x3) * (x2 - 2 * x3),\n-        sqrt10 * (x1 - x4) * (x1 - x4)\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        DerivativeStructure x3 = variables[2];\n+        DerivativeStructure x4 = variables[3];\n+      return new DerivativeStructure[] {\n+        x1.add(x2.multiply(10)),\n+        x3.subtract(x4).multiply(sqrt5),\n+        x2.subtract(x3.multiply(2)).multiply(x2.subtract(x3.multiply(2))),\n+        x1.subtract(x4).multiply(x1.subtract(x4)).multiply(sqrt10)\n       };\n     }\n \n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double x2 = variables[1];\n-      return new double[][] {\n-        { 1, x2 * (10 - 3 * x2) -  2 },\n-        { 1, x2 * ( 2 + 3 * x2) - 14, }\n-      };\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      return new double[] {\n-       -13.0 + x1 + ((5.0 - x2) * x2 -  2.0) * x2,\n-       -29.0 + x1 + ((1.0 + x2) * x2 - 14.0) * x2\n-      };\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        return new DerivativeStructure[] {\n+            x1.subtract(13.0).add(x2.negate().add(5.0).multiply(x2).subtract(2).multiply(x2)),\n+            x1.subtract(29.0).add(x2.add(1).multiply(x2).subtract(14).multiply(x2))\n+        };\n     }\n \n   }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double   x2 = variables[1];\n-      double   x3 = variables[2];\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        double tmp1 = i  + 1;\n-        double tmp2 = 15 - i;\n-        double tmp3 = (i <= 7) ? tmp1 : tmp2;\n-        double tmp4 = x2 * tmp2 + x3 * tmp3;\n-        tmp4 *= tmp4;\n-        jacobian[i] = new double[] { -1, tmp1 * tmp2 / tmp4, tmp1 * tmp3 / tmp4 };\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double   x1 = variables[0];\n-      double   x2 = variables[1];\n-      double   x3 = variables[2];\n-      double[] f = new double[m];\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure   x1 = variables[0];\n+        DerivativeStructure   x2 = variables[1];\n+        DerivativeStructure   x3 = variables[2];\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n       for (int i = 0; i < m; ++i) {\n         double tmp1 = i + 1;\n         double tmp2 = 15 - i;\n         double tmp3 = (i <= 7) ? tmp1 : tmp2;\n-        f[i] = y[i] - (x1 + tmp1 / (x2 * tmp2 + x3 * tmp3));\n+        f[i] = x1.add(x2.multiply(tmp2).add(x3.multiply(tmp3)).reciprocal().multiply(tmp1)).negate().add(y[i]);\n       }\n       return f;\n     }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double   x1 = variables[0];\n-      double   x2 = variables[1];\n-      double   x3 = variables[2];\n-      double   x4 = variables[3];\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        double tmp = v[i] * (v[i] + x3) + x4;\n-        double j1  = -v[i] * (v[i] + x2) / tmp;\n-        double j2  = -v[i] * x1 / tmp;\n-        double j3  = j1 * j2;\n-        double j4  = j3 / v[i];\n-        jacobian[i] = new double[] { j1, j2, j3, j4 };\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double x3 = variables[2];\n-      double x4 = variables[3];\n-      double[] f = new double[m];\n-      for (int i = 0; i < m; ++i) {\n-        f[i] = y[i] - x1 * (v[i] * (v[i] + x2)) / (v[i] * (v[i] + x3) + x4);\n-      }\n-      return f;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        DerivativeStructure x3 = variables[2];\n+        DerivativeStructure x4 = variables[3];\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        for (int i = 0; i < m; ++i) {\n+            f[i] = x1.multiply(x2.add(v[i]).multiply(v[i])).divide(x4.add(x3.add(v[i]).multiply(v[i]))).negate().add(y[i]);\n+        }\n+        return f;\n     }\n \n     private static final double[] v = {\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double   x1 = variables[0];\n-      double   x2 = variables[1];\n-      double   x3 = variables[2];\n-      double[][] jacobian = new double[m][];\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        DerivativeStructure x3 = variables[2];\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n       for (int i = 0; i < m; ++i) {\n-        double temp = 5.0 * (i + 1) + 45.0 + x3;\n-        double tmp1 = x2 / temp;\n-        double tmp2 = FastMath.exp(tmp1);\n-        double tmp3 = x1 * tmp2 / temp;\n-        jacobian[i] = new double[] { tmp2, tmp3, -tmp1 * tmp3 };\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double x3 = variables[2];\n-      double[] f = new double[m];\n-      for (int i = 0; i < m; ++i) {\n-        f[i] = x1 * FastMath.exp(x2 / (5.0 * (i + 1) + 45.0 + x3)) - y[i];\n+        f[i] = x1.multiply(x2.divide(x3.add(5.0 * (i + 1) + 45.0)).exp()).subtract(y[i]);\n       }\n      return f;\n     }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-\n-      double[][] jacobian = new double[m][];\n-\n-      for (int i = 0; i < (m - 2); ++i) {\n-        double div = (i + 1) / 29.0;\n-        double s2  = 0.0;\n-        double dx  = 1.0;\n-        for (int j = 0; j < n; ++j) {\n-          s2 += dx * variables[j];\n-          dx *= div;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        for (int i = 0; i < (m - 2); ++i) {\n+            double div = (i + 1) / 29.0;\n+            DerivativeStructure s1 = variables[0].getField().getZero();\n+            DerivativeStructure dx = variables[0].getField().getOne();\n+            for (int j = 1; j < n; ++j) {\n+                s1 = s1.add(dx.multiply(j).multiply(variables[j]));\n+                dx = dx.multiply(div);\n+            }\n+            DerivativeStructure s2 = variables[0].getField().getZero();\n+            dx = variables[0].getField().getOne();\n+            for (int j = 0; j < n; ++j) {\n+                s2 = s2.add(dx.multiply(variables[j]));\n+                dx = dx.multiply(div);\n+            }\n+            f[i] = s1.subtract(s2.multiply(s2)).subtract(1);\n         }\n-        double temp= 2 * div * s2;\n-        dx = 1.0 / div;\n-        jacobian[i] = new double[n];\n-        for (int j = 0; j < n; ++j) {\n-          jacobian[i][j] = dx * (j - temp);\n-          dx *= div;\n-        }\n-      }\n-\n-      jacobian[m - 2]    = new double[n];\n-      jacobian[m - 2][0] = 1;\n-\n-      jacobian[m - 1]   = new double[n];\n-      jacobian[m - 1][0]= -2 * variables[0];\n-      jacobian[m - 1][1]= 1;\n-\n-      return jacobian;\n-\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-     double[] f = new double[m];\n-     for (int i = 0; i < (m - 2); ++i) {\n-       double div = (i + 1) / 29.0;\n-       double s1 = 0;\n-       double dx = 1;\n-       for (int j = 1; j < n; ++j) {\n-         s1 += j * dx * variables[j];\n-         dx *= div;\n-       }\n-       double s2 =0;\n-       dx =1;\n-       for (int j = 0; j < n; ++j) {\n-         s2 += dx * variables[j];\n-         dx *= div;\n-       }\n-       f[i] = s1 - s2 * s2 - 1;\n-     }\n-\n-     double x1 = variables[0];\n-     double x2 = variables[1];\n-     f[m - 2] = x1;\n-     f[m - 1] = x2 - x1 * x1 - 1;\n-\n-     return f;\n+\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        f[m - 2] = x1;\n+        f[m - 1] = x2.subtract(x1.multiply(x1)).subtract(1);\n+\n+        return f;\n \n     }\n \n    }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double   x1 = variables[0];\n-      double   x2 = variables[1];\n-      double[][] jacobian = new double[m][];\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        DerivativeStructure x3 = variables[2];\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n       for (int i = 0; i < m; ++i) {\n         double tmp = (i + 1) / 10.0;\n-        jacobian[i] = new double[] {\n-          -tmp * FastMath.exp(-tmp * x1),\n-           tmp * FastMath.exp(-tmp * x2),\n-          FastMath.exp(-i - 1) - FastMath.exp(-tmp)\n-        };\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double x3 = variables[2];\n-      double[] f = new double[m];\n-      for (int i = 0; i < m; ++i) {\n-        double tmp = (i + 1) / 10.0;\n-        f[i] = FastMath.exp(-tmp * x1) - FastMath.exp(-tmp * x2)\n-             + (FastMath.exp(-i - 1) - FastMath.exp(-tmp)) * x3;\n+        f[i] = x1.multiply(-tmp).exp().subtract(x2.multiply(-tmp).exp()).add(\n+                  x3.multiply(FastMath.exp(-i - 1) - FastMath.exp(-tmp)));\n       }\n       return f;\n     }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double   x1 = variables[0];\n-      double   x2 = variables[1];\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        double t = i + 1;\n-        jacobian[i] = new double[] { -t * FastMath.exp(t * x1), -t * FastMath.exp(t * x2) };\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double[] f = new double[m];\n-      for (int i = 0; i < m; ++i) {\n-        double temp = i + 1;\n-        f[i] = 2 + 2 * temp - FastMath.exp(temp * x1) - FastMath.exp(temp * x2);\n-      }\n-      return f;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        for (int i = 0; i < m; ++i) {\n+            double temp = i + 1;\n+            f[i] = x1.multiply(temp).exp().add(x2.multiply(temp).exp()).subtract(2 + 2 * temp).negate();\n+        }\n+        return f;\n     }\n \n   }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double   x1 = variables[0];\n-      double   x2 = variables[1];\n-      double   x3 = variables[2];\n-      double   x4 = variables[3];\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        double temp = (i + 1) / 5.0;\n-        double ti   = FastMath.sin(temp);\n-        double tmp1 = x1 + temp * x2 - FastMath.exp(temp);\n-        double tmp2 = x3 + ti   * x4 - FastMath.cos(temp);\n-        jacobian[i] = new double[] {\n-          2 * tmp1, 2 * temp * tmp1, 2 * tmp2, 2 * ti * tmp2\n-        };\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double x3 = variables[2];\n-      double x4 = variables[3];\n-      double[] f = new double[m];\n-      for (int i = 0; i < m; ++i) {\n-        double temp = (i + 1) / 5.0;\n-        double tmp1 = x1 + temp * x2 - FastMath.exp(temp);\n-        double tmp2 = x3 + FastMath.sin(temp) * x4 - FastMath.cos(temp);\n-        f[i] = tmp1 * tmp1 + tmp2 * tmp2;\n-      }\n-      return f;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        DerivativeStructure x3 = variables[2];\n+        DerivativeStructure x4 = variables[3];\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        for (int i = 0; i < m; ++i) {\n+            double temp = (i + 1) / 5.0;\n+            DerivativeStructure tmp1 = x1.add(x2.multiply(temp)).subtract(FastMath.exp(temp));\n+            DerivativeStructure tmp2 = x3.add(x4.multiply(FastMath.sin(temp))).subtract(FastMath.cos(temp));\n+            f[i] = tmp1.multiply(tmp1).add(tmp2.multiply(tmp2));\n+        }\n+        return f;\n     }\n \n   }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        jacobian[i] = new double[n];\n-      }\n-\n-      double dx = 1.0 / n;\n-      for (int j = 0; j < n; ++j) {\n-        double tmp1 = 1;\n-        double tmp2 = 2 * variables[j] - 1;\n-        double temp = 2 * tmp2;\n-        double tmp3 = 0;\n-        double tmp4 = 2;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        Arrays.fill(f, variables[0].getField().getZero());\n+\n+        for (int j = 0; j < n; ++j) {\n+            DerivativeStructure tmp1 = variables[0].getField().getOne();\n+            DerivativeStructure tmp2 = variables[j].multiply(2).subtract(1);\n+            DerivativeStructure temp = tmp2.multiply(2);\n+            for (int i = 0; i < m; ++i) {\n+                f[i] = f[i].add(tmp2);\n+                DerivativeStructure ti = temp.multiply(tmp2).subtract(tmp1);\n+                tmp1 = tmp2;\n+                tmp2 = ti;\n+            }\n+        }\n+\n+        double dx = 1.0 / n;\n+        boolean iev = false;\n         for (int i = 0; i < m; ++i) {\n-          jacobian[i][j] = dx * tmp4;\n-          double ti = 4 * tmp2 + temp * tmp4 - tmp3;\n-          tmp3 = tmp4;\n-          tmp4 = ti;\n-          ti   = temp * tmp2 - tmp1;\n-          tmp1 = tmp2;\n-          tmp2 = ti;\n+            f[i] = f[i].multiply(dx);\n+            if (iev) {\n+                f[i] = f[i].add(1.0 / (i * (i + 2)));\n+            }\n+            iev = ! iev;\n         }\n-      }\n-\n-      return jacobian;\n-\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-\n-      double[] f = new double[m];\n-\n-      for (int j = 0; j < n; ++j) {\n-        double tmp1 = 1;\n-        double tmp2 = 2 * variables[j] - 1;\n-        double temp = 2 * tmp2;\n-        for (int i = 0; i < m; ++i) {\n-          f[i] += tmp2;\n-          double ti = temp * tmp2 - tmp1;\n-          tmp1 = tmp2;\n-          tmp2 = ti;\n-        }\n-      }\n-\n-      double dx = 1.0 / n;\n-      boolean iev = false;\n-      for (int i = 0; i < m; ++i) {\n-        f[i] *= dx;\n-        if (iev) {\n-          f[i] += 1.0 / (i * (i + 2));\n-        }\n-        iev = ! iev;\n-      }\n-\n-      return f;\n+\n+        return f;\n \n     }\n \n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        jacobian[i] = new double[n];\n-      }\n-\n-      double prod = 1;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        DerivativeStructure sum  = variables[0].getField().getZero().subtract(n + 1);\n+        DerivativeStructure prod = variables[0].getField().getOne();\n       for (int j = 0; j < n; ++j) {\n-        prod *= variables[j];\n-        for (int i = 0; i < n; ++i) {\n-          jacobian[i][j] = 1;\n-        }\n-        jacobian[j][j] = 2;\n-      }\n-\n-      for (int j = 0; j < n; ++j) {\n-        double temp = variables[j];\n-        if (temp == 0) {\n-          temp = 1;\n-          prod = 1;\n-          for (int k = 0; k < n; ++k) {\n-            if (k != j) {\n-              prod *= variables[k];\n-            }\n-          }\n-        }\n-        jacobian[n - 1][j] = prod / temp;\n-      }\n-\n-      return jacobian;\n-\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double[] f = new double[m];\n-      double sum  = -(n + 1);\n-      double prod = 1;\n-      for (int j = 0; j < n; ++j) {\n-        sum  += variables[j];\n-        prod *= variables[j];\n+        sum  = sum.add(variables[j]);\n+        prod = prod.multiply(variables[j]);\n       }\n       for (int i = 0; i < n; ++i) {\n-        f[i] = variables[i] + sum;\n-      }\n-      f[n - 1] = prod - 1;\n+        f[i] = variables[i].add(sum);\n+      }\n+      f[n - 1] = prod.subtract(1);\n       return f;\n     }\n \n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double   x2 = variables[1];\n-      double   x3 = variables[2];\n-      double   x4 = variables[3];\n-      double   x5 = variables[4];\n-      double[][] jacobian = new double[m][];\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x1 = variables[0];\n+        DerivativeStructure x2 = variables[1];\n+        DerivativeStructure x3 = variables[2];\n+        DerivativeStructure x4 = variables[3];\n+        DerivativeStructure x5 = variables[4];\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n       for (int i = 0; i < m; ++i) {\n         double temp = 10.0 * i;\n-        double tmp1 = FastMath.exp(-temp * x4);\n-        double tmp2 = FastMath.exp(-temp * x5);\n-        jacobian[i] = new double[] {\n-          -1, -tmp1, -tmp2, temp * x2 * tmp1, temp * x3 * tmp2\n-        };\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x1 = variables[0];\n-      double x2 = variables[1];\n-      double x3 = variables[2];\n-      double x4 = variables[3];\n-      double x5 = variables[4];\n-      double[] f = new double[m];\n-      for (int i = 0; i < m; ++i) {\n-        double temp = 10.0 * i;\n-        double tmp1 = FastMath.exp(-temp * x4);\n-        double tmp2 = FastMath.exp(-temp * x5);\n-        f[i] = y[i] - (x1 + x2 * tmp1 + x3 * tmp2);\n+        DerivativeStructure tmp1 = x4.multiply(-temp).exp();\n+        DerivativeStructure tmp2 = x5.multiply(-temp).exp();\n+        f[i] = x1.add(x2.multiply(tmp1)).add(x3.multiply(tmp2)).negate().add(y[i]);\n       }\n       return f;\n     }\n     }\n \n     @Override\n-    public double[][] jacobian(double[] variables) {\n-      double   x01 = variables[0];\n-      double   x02 = variables[1];\n-      double   x03 = variables[2];\n-      double   x04 = variables[3];\n-      double   x05 = variables[4];\n-      double   x06 = variables[5];\n-      double   x07 = variables[6];\n-      double   x08 = variables[7];\n-      double   x09 = variables[8];\n-      double   x10 = variables[9];\n-      double   x11 = variables[10];\n-      double[][] jacobian = new double[m][];\n-      for (int i = 0; i < m; ++i) {\n-        double temp = i / 10.0;\n-        double tmp1 = FastMath.exp(-x05 * temp);\n-        double tmp2 = FastMath.exp(-x06 * (temp - x09) * (temp - x09));\n-        double tmp3 = FastMath.exp(-x07 * (temp - x10) * (temp - x10));\n-        double tmp4 = FastMath.exp(-x08 * (temp - x11) * (temp - x11));\n-        jacobian[i] = new double[] {\n-          -tmp1,\n-          -tmp2,\n-          -tmp3,\n-          -tmp4,\n-          temp * x01 * tmp1,\n-          x02 * (temp - x09) * (temp - x09) * tmp2,\n-          x03 * (temp - x10) * (temp - x10) * tmp3,\n-          x04 * (temp - x11) * (temp - x11) * tmp4,\n-          -2 * x02 * x06 * (temp - x09) * tmp2,\n-          -2 * x03 * x07 * (temp - x10) * tmp3,\n-          -2 * x04 * x08 * (temp - x11) * tmp4\n-        };\n-      }\n-      return jacobian;\n-    }\n-\n-    @Override\n-    public double[] value(double[] variables) {\n-      double x01 = variables[0];\n-      double x02 = variables[1];\n-      double x03 = variables[2];\n-      double x04 = variables[3];\n-      double x05 = variables[4];\n-      double x06 = variables[5];\n-      double x07 = variables[6];\n-      double x08 = variables[7];\n-      double x09 = variables[8];\n-      double x10 = variables[9];\n-      double x11 = variables[10];\n-      double[] f = new double[m];\n-      for (int i = 0; i < m; ++i) {\n-        double temp = i / 10.0;\n-        double tmp1 = FastMath.exp(-x05 * temp);\n-        double tmp2 = FastMath.exp(-x06 * (temp - x09) * (temp - x09));\n-        double tmp3 = FastMath.exp(-x07 * (temp - x10) * (temp - x10));\n-        double tmp4 = FastMath.exp(-x08 * (temp - x11) * (temp - x11));\n-        f[i] = y[i] - (x01 * tmp1 + x02 * tmp2 + x03 * tmp3 + x04 * tmp4);\n-      }\n-      return f;\n+    public DerivativeStructure[] value(DerivativeStructure[] variables) {\n+        DerivativeStructure x01 = variables[0];\n+        DerivativeStructure x02 = variables[1];\n+        DerivativeStructure x03 = variables[2];\n+        DerivativeStructure x04 = variables[3];\n+        DerivativeStructure x05 = variables[4];\n+        DerivativeStructure x06 = variables[5];\n+        DerivativeStructure x07 = variables[6];\n+        DerivativeStructure x08 = variables[7];\n+        DerivativeStructure x09 = variables[8];\n+        DerivativeStructure x10 = variables[9];\n+        DerivativeStructure x11 = variables[10];\n+        DerivativeStructure[] f = new DerivativeStructure[m];\n+        for (int i = 0; i < m; ++i) {\n+            double temp = i / 10.0;\n+            DerivativeStructure tmp1 = x05.multiply(-temp).exp();\n+            DerivativeStructure tmp2 = x06.negate().multiply(x09.subtract(temp).multiply(x09.subtract(temp))).exp();\n+            DerivativeStructure tmp3 = x07.negate().multiply(x10.subtract(temp).multiply(x10.subtract(temp))).exp();\n+            DerivativeStructure tmp4 = x08.negate().multiply(x11.subtract(temp).multiply(x11.subtract(temp))).exp();\n+            f[i] = x01.multiply(tmp1).add(x02.multiply(tmp2)).add(x03.multiply(tmp3)).add(x04.multiply(tmp4)).negate().add(y[i]);\n+        }\n+        return f;\n     }\n \n     private static final double[] y = {\n--- a/src/test/java/org/apache/commons/math3/optimization/general/NonLinearConjugateGradientOptimizerTest.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/NonLinearConjugateGradientOptimizerTest.java\n \n package org.apache.commons.math3.optimization.general;\n \n-import java.awt.geom.Point2D;\n import java.io.Serializable;\n+\n import org.apache.commons.math3.analysis.DifferentiableMultivariateFunction;\n import org.apache.commons.math3.analysis.MultivariateFunction;\n import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction;\n import org.apache.commons.math3.analysis.solvers.BrentSolver;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.MathIllegalArgumentException;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n import org.apache.commons.math3.linear.BlockRealMatrix;\n import org.apache.commons.math3.linear.RealMatrix;\n import org.apache.commons.math3.optimization.GoalType;\n                                                     new BrentSolver(1e-15, 1e-13));\n         PointValuePair optimum =\n             optimizer.optimize(100, circle, GoalType.MINIMIZE, new double[] { 98.680, 47.345 });\n-        Point2D.Double center = new Point2D.Double(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n+        Vector2D center = new Vector2D(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n         Assert.assertEquals(69.960161753, circle.getRadius(center), 1.0e-8);\n-        Assert.assertEquals(96.075902096, center.x, 1.0e-8);\n-        Assert.assertEquals(48.135167894, center.y, 1.0e-8);\n-    }\n-\n-    private static class LinearProblem implements DifferentiableMultivariateFunction, Serializable {\n+        Assert.assertEquals(96.075902096, center.getX(), 1.0e-8);\n+        Assert.assertEquals(48.135167894, center.getY(), 1.0e-8);\n+    }\n+\n+    private static class LinearProblem implements MultivariateDifferentiableFunction, Serializable {\n \n         private static final long serialVersionUID = 703247177355019415L;\n         final RealMatrix factors;\n         public LinearProblem(double[][] factors, double[] target) {\n             this.factors = new BlockRealMatrix(factors);\n             this.target  = target;\n-        }\n-\n-        private double[] gradient(double[] point) {\n-            double[] r = factors.operate(point);\n-            for (int i = 0; i < r.length; ++i) {\n-                r[i] -= target[i];\n-            }\n-            double[] p = factors.transpose().operate(r);\n-            for (int i = 0; i < p.length; ++i) {\n-                p[i] *= 2;\n-            }\n-            return p;\n         }\n \n         public double value(double[] variables) {\n             return sum;\n         }\n \n-        public MultivariateVectorFunction gradient() {\n-            return new MultivariateVectorFunction() {\n-                public double[] value(double[] point) {\n-                    return gradient(point);\n+        public DerivativeStructure value(DerivativeStructure[] variables) {\n+            DerivativeStructure[] y = new DerivativeStructure[factors.getRowDimension()];\n+            for (int i = 0; i < y.length; ++i) {\n+                y[i] = variables[0].getField().getZero();\n+                for (int j = 0; j < factors.getColumnDimension(); ++j) {\n+                    y[i] = y[i].add(variables[j].multiply(factors.getEntry(i, j)));\n                 }\n-            };\n+            }\n+\n+            DerivativeStructure sum = variables[0].getField().getZero();\n+            for (int i = 0; i < y.length; ++i) {\n+                DerivativeStructure ri = y[i].subtract(target[i]);\n+                sum = sum.add(ri.multiply(ri));\n+            }\n+            return sum;\n         }\n \n-        public MultivariateFunction partialDerivative(final int k) {\n-            return new MultivariateFunction() {\n-                public double value(double[] point) {\n-                    return gradient(point)[k];\n-                }\n-            };\n-        }\n     }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/RandomCirclePointGenerator.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/RandomCirclePointGenerator.java\n \n package org.apache.commons.math3.optimization.general;\n \n-import java.awt.geom.Point2D;\n import org.apache.commons.math3.random.RandomGenerator;\n import org.apache.commons.math3.random.Well44497b;\n import org.apache.commons.math3.util.MathUtils;\n import org.apache.commons.math3.distribution.RealDistribution;\n import org.apache.commons.math3.distribution.UniformRealDistribution;\n import org.apache.commons.math3.distribution.NormalDistribution;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n \n /**\n  * Factory for generating a cloud of points that approximate a circle.\n      * @param n Number of points to create.\n      * @return the cloud of {@code n} points.\n      */\n-    public Point2D.Double[] generate(int n) {\n-        final Point2D.Double[] cloud = new Point2D.Double[n];\n+    public Vector2D[] generate(int n) {\n+        final Vector2D[] cloud = new Vector2D[n];\n         for (int i = 0; i < n; i++) {\n             cloud[i] = create();\n         }\n      *\n      * @return a point.\n      */\n-    private Point2D.Double create() {\n+    private Vector2D create() {\n         final double t = tP.sample();\n         final double pX = cX.sample() + radius * FastMath.cos(t);\n         final double pY = cY.sample() + radius * FastMath.sin(t);\n \n-        return new Point2D.Double(pX, pY);\n+        return new Vector2D(pX, pY);\n     }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/StatisticalReferenceDataset.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/StatisticalReferenceDataset.java\n import java.io.IOException;\n import java.util.ArrayList;\n \n-import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n-import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n import org.apache.commons.math3.util.MathArrays;\n \n /**\n     private double residualSumOfSquares;\n \n     /** The least-squares problem. */\n-    private final DifferentiableMultivariateVectorFunction problem;\n+    private final MultivariateDifferentiableVectorFunction problem;\n \n     /**\n      * Creates a new instance of this class from the specified data file. The\n         }\n         this.name = dummyString;\n \n-        this.problem = new DifferentiableMultivariateVectorFunction() {\n+        this.problem = new MultivariateDifferentiableVectorFunction() {\n+\n             public double[] value(final double[] a) {\n+                DerivativeStructure[] dsA = new DerivativeStructure[a.length];\n+                for (int i = 0; i < a.length; ++i) {\n+                    dsA[i] = new DerivativeStructure(a.length, 0, a[i]);\n+                }\n                 final int n = getNumObservations();\n                 final double[] yhat = new double[n];\n+                for (int i = 0; i < n; i++) {\n+                    yhat[i] = getModelValue(getX(i), dsA).getValue();\n+                }\n+                return yhat;\n+            }\n+\n+            public DerivativeStructure[] value(final DerivativeStructure[] a) {\n+                final int n = getNumObservations();\n+                final DerivativeStructure[] yhat = new DerivativeStructure[n];\n                 for (int i = 0; i < n; i++) {\n                     yhat[i] = getModelValue(getX(i), a);\n                 }\n                 return yhat;\n             }\n \n-            public MultivariateMatrixFunction jacobian() {\n-                return new MultivariateMatrixFunction() {\n-                    public double[][] value(final double[] a)\n-                        throws IllegalArgumentException {\n-                        final int n = getNumObservations();\n-                        final double[][] j = new double[n][];\n-                        for (int i = 0; i < n; i++) {\n-                            j[i] = getModelDerivatives(getX(i), a);\n-                        }\n-                        return j;\n-                    }\n-                };\n-            }\n         };\n     }\n \n      *\n      * @return the least-squares problem\n      */\n-    public DifferentiableMultivariateVectorFunction getLeastSquaresProblem() {\n+    public MultivariateDifferentiableVectorFunction getLeastSquaresProblem() {\n         return problem;\n     }\n \n      * @param a the parameters\n      * @return the value of the model\n      */\n-    public abstract double getModelValue(final double x, final double[] a);\n-\n-    /**\n-     * Returns the values of the partial derivatives of the model with respect\n-     * to the parameters.\n-     *\n-     * @param x the predictor variable\n-     * @param a the parameters\n-     * @return the partial derivatives\n-     */\n-    public abstract double[] getModelDerivatives(final double x,\n-                                                 final double[] a);\n+    public abstract DerivativeStructure getModelValue(final double x, final DerivativeStructure[] a);\n \n     /**\n      * <p>\n--- a/src/test/java/org/apache/commons/math3/optimization/general/StatisticalReferenceDatasetFactory.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/StatisticalReferenceDatasetFactory.java\n import java.io.InputStream;\n import java.io.InputStreamReader;\n \n-import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n \n /**\n  * A factory to create instances of {@link StatisticalReferenceDataset} from\n             dataset = new StatisticalReferenceDataset(in) {\n \n                 @Override\n-                public double getModelValue(final double x, final double[] a) {\n-                    final double p = a[0] + x * (a[1] + x * a[2]);\n-                    final double q = 1.0 + x * (a[3] + x * a[4]);\n-                    return p / q;\n+                public DerivativeStructure getModelValue(final double x, final DerivativeStructure[] a) {\n+                    final DerivativeStructure p = a[0].add(a[1].add(a[2].multiply(x)).multiply(x));\n+                    final DerivativeStructure q = a[3].add(a[4].multiply(x)).multiply(x).add(1.0);\n+                    return p.divide(q);\n                 }\n \n-                @Override\n-                public double[] getModelDerivatives(final double x,\n-                                                    final double[] a) {\n-                    final double[] dy = new double[5];\n-                    final double p = a[0] + x * (a[1] + x * a[2]);\n-                    final double q = 1.0 + x * (a[3] + x * a[4]);\n-                    dy[0] = 1.0 / q;\n-                    dy[1] = x / q;\n-                    dy[2] = x * dy[1];\n-                    dy[3] = -x * p / (q * q);\n-                    dy[4] = x * dy[3];\n-                    return dy;\n-                }\n             };\n         } finally {\n             in.close();\n             dataset = new StatisticalReferenceDataset(in) {\n \n                 @Override\n-                public double getModelValue(final double x, final double[] a) {\n-                    final double p = a[0] + x * (a[1] + x * (a[2] + x * a[3]));\n-                    final double q = 1.0 + x * (a[4] + x * (a[5] + x * a[6]));\n-                    return p / q;\n+                public DerivativeStructure getModelValue(final double x, final DerivativeStructure[] a) {\n+                    final DerivativeStructure p = a[0].add(a[1].add(a[2].add(a[3].multiply(x)).multiply(x)).multiply(x));\n+                    final DerivativeStructure q = a[4].add(a[5].add(a[6].multiply(x)).multiply(x)).multiply(x).add(1.0);\n+                    return p.divide(q);\n                 }\n \n-                @Override\n-                public double[] getModelDerivatives(final double x,\n-                                                    final double[] a) {\n-                    final double[] dy = new double[7];\n-                    final double p = a[0] + x * (a[1] + x * (a[2] + x * a[3]));\n-                    final double q = 1.0 + x * (a[4] + x * (a[5] + x * a[6]));\n-                    dy[0] = 1.0 / q;\n-                    dy[1] = x * dy[0];\n-                    dy[2] = x * dy[1];\n-                    dy[3] = x * dy[2];\n-                    dy[4] = -x * p / (q * q);\n-                    dy[5] = x * dy[4];\n-                    dy[6] = x * dy[5];\n-                    return dy;\n-                }\n             };\n         } finally {\n             in.close();\n             dataset = new StatisticalReferenceDataset(in) {\n \n                 @Override\n-                public double getModelValue(final double x, final double[] a) {\n-                    return a[0] + a[1] * FastMath.exp(-a[3] * x) + a[2] *\n-                           FastMath.exp(-a[4] * x);\n+                public DerivativeStructure getModelValue(final double x, final DerivativeStructure[] a) {\n+                    return a[0].add(a[1].multiply(a[3].multiply(-x).exp())).add(a[2].multiply(a[4].multiply(-x).exp()));\n                 }\n \n-                @Override\n-                public double[] getModelDerivatives(final double x,\n-                                                    final double[] a) {\n-                    final double[] dy = new double[5];\n-                    dy[0] = 1.0;\n-                    dy[1] = FastMath.exp(-x * a[3]);\n-                    dy[2] = FastMath.exp(-x * a[4]);\n-                    dy[3] = -x * a[1] * dy[1];\n-                    dy[4] = -x * a[2] * dy[2];\n-                    return dy;\n-                }\n             };\n         } finally {\n             in.close();\n             dataset = new StatisticalReferenceDataset(in) {\n \n                 @Override\n-                public double getModelValue(final double x, final double[] a) {\n-                    System.out.println(a[0]+\", \"+a[1]+\", \"+a[2]+\", \"+a[3]+\", \"+a[4]+\", \"+a[5]);\n-                    return a[0] * FastMath.exp(-a[3] * x) +\n-                           a[1] * FastMath.exp(-a[4] * x) +\n-                           a[2] * FastMath.exp(-a[5] * x);\n+                public DerivativeStructure getModelValue(final double x, final DerivativeStructure[] a) {\n+                    return a[0].multiply(a[3].multiply(-x).exp()).add(\n+                                a[1].multiply(a[4].multiply(-x).exp())).add(\n+                                     a[2].multiply(a[5].multiply(-x).exp()));\n                 }\n \n-                @Override\n-                public double[] getModelDerivatives(final double x,\n-                    final double[] a) {\n-                    final double[] dy = new double[6];\n-                    dy[0] = FastMath.exp(-x * a[3]);\n-                    dy[1] = FastMath.exp(-x * a[4]);\n-                    dy[2] = FastMath.exp(-x * a[5]);\n-                    dy[3] = -x * a[0] * dy[0];\n-                    dy[4] = -x * a[1] * dy[1];\n-                    dy[5] = -x * a[2] * dy[2];\n-                    return dy;\n-                }\n             };\n         } finally {\n             in.close();\n--- a/src/test/java/org/apache/commons/math3/optimization/general/StraightLineProblem.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/StraightLineProblem.java\n package org.apache.commons.math3.optimization.general;\n \n import java.util.ArrayList;\n-import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n-import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n-import org.apache.commons.math3.analysis.UnivariateFunction;\n+\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;\n+import org.apache.commons.math3.analysis.differentiation.UnivariateDifferentiableFunction;\n import org.apache.commons.math3.stat.regression.SimpleRegression;\n \n /**\n  *  <li>for each pair (a, b), the y-coordinate of the line.</li>\n  * </ul>\n  */\n-class StraightLineProblem implements DifferentiableMultivariateVectorFunction {\n+class StraightLineProblem implements MultivariateDifferentiableVectorFunction {\n     /** Cloud of points assumed to be fitted by a straight line. */\n     private final ArrayList<double[]> points;\n     /** Error (on the y-coordinate of the points). */\n     }\n \n     public double[] value(double[] params) {\n-        final Model line = new Model(params[0], params[1]);\n+        final Model line = new Model(new DerivativeStructure(0, 0, params[0]),\n+                                     new DerivativeStructure(0, 0, params[1]));\n \n         final double[] model = new double[points.size()];\n         for (int i = 0; i < points.size(); i++) {\n         return model;\n     }\n \n-    public MultivariateMatrixFunction jacobian() {\n-        return new MultivariateMatrixFunction() {\n-            public double[][] value(double[] point) {\n-                return jacobian(point);\n-            }\n-        };\n+    public DerivativeStructure[] value(DerivativeStructure[] params) {\n+        final Model line = new Model(params[0], params[1]);\n+\n+        final DerivativeStructure[] model = new DerivativeStructure[points.size()];\n+        for (int i = 0; i < points.size(); i++) {\n+            final DerivativeStructure p0 = params[0].getField().getZero().add(points.get(i)[0]);\n+            model[i] = line.value(p0);\n+        }\n+\n+        return model;\n     }\n \n     /**\n         return result;\n     }\n \n-    private double[][] jacobian(double[] params) {\n-        final double[][] jacobian = new double[points.size()][2];\n-\n-        for (int i = 0; i < points.size(); i++) {\n-            final double[] p = points.get(i);\n-            // Partial derivative wrt \"a\".\n-            jacobian[i][0] = p[0];\n-            // Partial derivative wrt \"b\".\n-            jacobian[i][1] = 1;\n-        }\n-\n-        return jacobian;\n-    }\n-\n     /**\n      * Linear function.\n      */\n-    public static class Model implements UnivariateFunction {\n-        final double a;\n-        final double b;\n+    public static class Model implements UnivariateDifferentiableFunction {\n+        final DerivativeStructure a;\n+        final DerivativeStructure b;\n \n-        public Model(double a,\n-                     double b) {\n+        public Model(DerivativeStructure a,\n+                     DerivativeStructure b) {\n             this.a = a;\n             this.b = b;\n         }\n \n         public double value(double x) {\n-            return a * x + b;\n+            return a.getValue() * x + b.getValue();\n         }\n+\n+        public DerivativeStructure value(DerivativeStructure x) {\n+            return x.multiply(a).add(b);\n+        }\n+\n     }\n }", "timestamp": 1347653820, "metainfo": ""}