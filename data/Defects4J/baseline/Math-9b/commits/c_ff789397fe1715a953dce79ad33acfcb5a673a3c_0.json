{"sha": "ff789397fe1715a953dce79ad33acfcb5a673a3c", "log": "Added nontrivial GLS regression test.  JIRA: MATH-408.  ", "commit": "\n--- a/src/test/java/org/apache/commons/math/stat/regression/GLSMultipleLinearRegressionTest.java\n+++ b/src/test/java/org/apache/commons/math/stat/regression/GLSMultipleLinearRegressionTest.java\n import org.apache.commons.math.linear.MatrixUtils;\n import org.apache.commons.math.linear.RealMatrix;\n import org.apache.commons.math.linear.RealVector;\n+import org.apache.commons.math.random.CorrelatedRandomVectorGenerator;\n+import org.apache.commons.math.random.JDKRandomGenerator;\n+import org.apache.commons.math.random.GaussianRandomGenerator;\n+import org.apache.commons.math.random.RandomGenerator;\n+import org.apache.commons.math.stat.correlation.Covariance;\n+import org.apache.commons.math.stat.descriptive.DescriptiveStatistics;\n \n public class GLSMultipleLinearRegressionTest extends MultipleLinearRegressionAbstractTest {\n \n     private double[] y;\n     private double[][] x;\n     private double[][] omega;\n+    private double[] longley = new double[] {\n+            60323,83.0,234289,2356,1590,107608,1947,\n+            61122,88.5,259426,2325,1456,108632,1948,\n+            60171,88.2,258054,3682,1616,109773,1949,\n+            61187,89.5,284599,3351,1650,110929,1950,\n+            63221,96.2,328975,2099,3099,112075,1951,\n+            63639,98.1,346999,1932,3594,113270,1952,\n+            64989,99.0,365385,1870,3547,115094,1953,\n+            63761,100.0,363112,3578,3350,116219,1954,\n+            66019,101.2,397469,2904,3048,117388,1955,\n+            67857,104.6,419180,2822,2857,118734,1956,\n+            68169,108.4,442769,2936,2798,120445,1957,\n+            66513,110.8,444546,4681,2637,121950,1958,\n+            68655,112.6,482704,3813,2552,123366,1959,\n+            69564,114.2,502601,3931,2514,125368,1960,\n+            69331,115.7,518173,4806,2572,127852,1961,\n+            70551,116.9,554894,4007,2827,130081,1962\n+        };\n \n     @Before\n     @Override\n      * as OLS.\n      */\n     @Test\n-    public void testGLSOLSConsistency() throws Exception {\n-        // Use Longley data to test\n-        double[] design = new double[] {\n-                60323,83.0,234289,2356,1590,107608,1947,\n-                61122,88.5,259426,2325,1456,108632,1948,\n-                60171,88.2,258054,3682,1616,109773,1949,\n-                61187,89.5,284599,3351,1650,110929,1950,\n-                63221,96.2,328975,2099,3099,112075,1951,\n-                63639,98.1,346999,1932,3594,113270,1952,\n-                64989,99.0,365385,1870,3547,115094,1953,\n-                63761,100.0,363112,3578,3350,116219,1954,\n-                66019,101.2,397469,2904,3048,117388,1955,\n-                67857,104.6,419180,2822,2857,118734,1956,\n-                68169,108.4,442769,2936,2798,120445,1957,\n-                66513,110.8,444546,4681,2637,121950,1958,\n-                68655,112.6,482704,3813,2552,123366,1959,\n-                69564,114.2,502601,3931,2514,125368,1960,\n-                69331,115.7,518173,4806,2572,127852,1961,\n-                70551,116.9,554894,4007,2827,130081,1962\n-            };\n+    public void testGLSOLSConsistency() throws Exception {      \n         RealMatrix identityCov = MatrixUtils.createRealIdentityMatrix(16);\n         GLSMultipleLinearRegression glsModel = new GLSMultipleLinearRegression();\n         OLSMultipleLinearRegression olsModel = new OLSMultipleLinearRegression();\n-        glsModel.newSampleData(design, 16, 6);\n-        olsModel.newSampleData(design, 16, 6);\n+        glsModel.newSampleData(longley, 16, 6);\n+        olsModel.newSampleData(longley, 16, 6);\n         glsModel.newCovarianceData(identityCov.getData());\n         double[] olsBeta = olsModel.calculateBeta().getData();\n         double[] glsBeta = glsModel.calculateBeta().getData();\n             TestUtils.assertRelativelyEquals(olsBeta[i], glsBeta[i], 10E-7);\n         }\n     }\n+    \n+    /**\n+     * Generate an error covariance matrix and sample data representing models\n+     * with this error structure. Then verify that GLS estimated coefficients,\n+     * on average, perform better than OLS.\n+     */\n+    @Test\n+    public void testGLSEfficiency() throws Exception {\n+        RandomGenerator rg = new JDKRandomGenerator();\n+        rg.setSeed(200);  // Seed has been selected to generate non-trivial covariance\n+        \n+        // Assume model has 16 observations (will use Longley data).  Start by generating\n+        // non-constant variances for the 16 error terms.\n+        final int nObs = 16;\n+        double[] sigma = new double[nObs];\n+        for (int i = 0; i < nObs; i++) {\n+            sigma[i] = 10 * rg.nextDouble();\n+        }\n+        \n+        // Now generate 1000 error vectors to use to estimate the covariance matrix\n+        // Columns are draws on N(0, sigma[col])\n+        final int numSeeds = 1000;\n+        RealMatrix errorSeeds = MatrixUtils.createRealMatrix(numSeeds, nObs);\n+        for (int i = 0; i < numSeeds; i++) {\n+            for (int j = 0; j < nObs; j++) {\n+                errorSeeds.setEntry(i, j, rg.nextGaussian() * sigma[j]);\n+            }\n+        }\n+        \n+        // Get covariance matrix for columns\n+        RealMatrix cov = (new Covariance(errorSeeds)).getCovarianceMatrix();\n+          \n+        // Create a CorrelatedRandomVectorGenerator to use to generate correlated errors\n+        GaussianRandomGenerator rawGenerator = new GaussianRandomGenerator(rg);\n+        double[] errorMeans = new double[nObs];  // Counting on init to 0 here\n+        CorrelatedRandomVectorGenerator gen = new CorrelatedRandomVectorGenerator(errorMeans, cov,\n+         1.0e-12 * cov.getNorm(), rawGenerator);\n+        \n+        // Now start generating models.  Use Longley X matrix on LHS\n+        // and Longley OLS beta vector as \"true\" beta.  Generate\n+        // Y values by XB + u where u is a CorrelatedRandomVector generated\n+        // from cov.\n+        OLSMultipleLinearRegression ols = new OLSMultipleLinearRegression();\n+        ols.newSampleData(longley, nObs, 6);\n+        final RealVector b = ols.calculateBeta().copy();\n+        final RealMatrix x = ols.X.copy();\n+        \n+        // Create a GLS model to reuse\n+        GLSMultipleLinearRegression gls = new GLSMultipleLinearRegression();\n+        gls.newSampleData(longley, nObs, 6);\n+        gls.newCovarianceData(cov.getData());\n+        \n+        // Create aggregators for stats measuring model performance\n+        DescriptiveStatistics olsBetaStats = new DescriptiveStatistics();\n+        DescriptiveStatistics glsBetaStats = new DescriptiveStatistics();\n+        \n+        // Generate Y vectors for 10000 models, estimate GLS and OLS and\n+        // Verify that OLS estimates are better\n+        final int nModels = 10000;\n+        for (int i = 0; i < nModels; i++) {\n+            \n+            // Generate y = xb + u with u cov\n+            RealVector u = MatrixUtils.createRealVector(gen.nextVector());\n+            double[] y = u.add(x.operate(b)).getData();\n+            \n+            // Estimate OLS parameters\n+            ols.newYSampleData(y);\n+            RealVector olsBeta = ols.calculateBeta();\n+            \n+            // Estimate GLS parameters\n+            gls.newYSampleData(y);\n+            RealVector glsBeta = gls.calculateBeta();\n+            \n+            // Record deviations from \"true\" beta\n+            double dist = olsBeta.getDistance(b);\n+            olsBetaStats.addValue(dist * dist);\n+            dist = glsBeta.getDistance(b);\n+            glsBetaStats.addValue(dist * dist);\n+            \n+        }\n+        \n+        // Verify that GLS is on average more efficient, lower variance\n+        assert(olsBetaStats.getMean() > 1.5 * glsBetaStats.getMean());\n+        assert(olsBetaStats.getStandardDeviation() > glsBetaStats.getStandardDeviation());  \n+    }\n+    \n }", "timestamp": 1292190402, "metainfo": ""}