{"sha": "76ab3aae807cc824cf7415f2966a2d99d3f07fe2", "log": "Changed OLSMultipleLinearRegression implementation to use QR decomposition to solve the normal equations. JIRA: MATH-217    ", "commit": "\n--- a/src/java/org/apache/commons/math/stat/regression/OLSMultipleLinearRegression.java\n+++ b/src/java/org/apache/commons/math/stat/regression/OLSMultipleLinearRegression.java\n  */\n package org.apache.commons.math.stat.regression;\n \n+import org.apache.commons.math.linear.QRDecomposition;\n+import org.apache.commons.math.linear.QRDecompositionImpl;\n import org.apache.commons.math.linear.RealMatrix;\n-\n+import org.apache.commons.math.linear.RealMatrixImpl;\n \n /**\n- * The OLS implementation of the multiple linear regression.\n+ * <p>Implements ordinary least squares (OLS) to estimate the parameters of a \n+ * multiple linear regression model.</p>\n  * \n- * OLS assumes the covariance matrix of the error to be diagonal and with equal variance.\n+ * <p>OLS assumes the covariance matrix of the error to be diagonal and with\n+ * equal variance.\n  * <pre>\n  * u ~ N(0, sigma^2*I)\n+ * </pre></p>\n+ * \n+ * <p>The regression coefficients, b, satisfy the normal equations:\n+ * <pre>\n+ * X^T X b = X^T y\n+ * </pre></p>\n+ * \n+ * <p>To solve the normal equations, this implementation uses QR decomposition\n+ * of the X matrix. (See {@link QRDecompositionImpl} for details on the\n+ * decomposition algorithm.)\n+ * <pre>\n+ * X^T X b = X^T y\n+ * (QR)^T (QR) b = (QR)^T y\n+ * R^T (Q^T Q) R b = R^T Q^T y\n+ * R^T R b = R^T Q^T y\n+ * (R^T)^{-1} R^T R b = (R^T)^{-1} R^T Q^T y\n+ * R b = Q^T y\n  * </pre>\n+ * Given Q and R, the last equation is solved by back-subsitution.</p>\n  * \n- * Estimated by OLS, \n- * <pre>\n- * b=(X'X)^-1X'y\n- * </pre>\n- * whose variance is\n- * <pre>\n- * Var(b)=MSE*(X'X)^-1, MSE=u'u/(n-k)\n- * </pre>\n  * @version $Revision$ $Date$\n  * @since 2.0\n  */\n public class OLSMultipleLinearRegression extends AbstractMultipleLinearRegression {\n+    \n+    /** Cached QR decomposition of X matrix */\n+    private QRDecomposition qr = null;\n \n+    /*\n+     * {@inheritDoc}\n+     * \n+     * Computes and caches QR decomposition of the X matrix.\n+     */\n     public void newSampleData(double[] y, double[][] x) {\n         validateSampleData(x, y);\n         newYSampleData(y);\n     }\n     \n     /**\n-     * Calculates beta by OLS.\n-     * <pre>\n-     * b=(X'X)^-1X'y\n-     * </pre> \n+     * {@inheritDoc}\n+     * \n+     * Computes and caches QR decomposition of the X matrix\n+     */\n+    public void newSampleData(double[] data, int nobs, int nvars) {\n+        super.newSampleData(data, nobs, nvars);\n+        qr = new QRDecompositionImpl(X);\n+    }\n+    \n+    /**\n+     * Loads new x sample data, overriding any previous sample\n+     * \n+     * @param x the [n,k] array representing the x sample\n+     */\n+    protected void newXSampleData(double[][] x) {\n+        this.X = new RealMatrixImpl(x);\n+        qr = new QRDecompositionImpl(X);\n+    }\n+    \n+    /**\n+     * Calculates regression coefficients using OLS.\n+     * \n      * @return beta\n      */\n     protected RealMatrix calculateBeta() {\n-        RealMatrix XTX = X.transpose().multiply(X);\n-        return XTX.inverse().multiply(X.transpose()).multiply(Y);\n+        return solveUpperTriangular((RealMatrixImpl) qr.getR(),\n+                (RealMatrixImpl) qr.getQ().transpose().multiply(Y));\n     }\n \n     /**\n         RealMatrix sse = u.transpose().multiply(u);\n         return sse.getTrace()/(X.getRowDimension()-X.getColumnDimension());\n     }\n-\n+    \n+    /** TODO:  Find a home for the following methods in the linear package */   \n+    \n+    /**\n+     * <p>Uses back substitution to solve the system</p>\n+     * \n+     * <p>coefficients X = constants</p>\n+     * \n+     * <p>coefficients must upper-triangular and constants must be a column \n+     * matrix.  The solution is returned as a column matrix.</p>\n+     * \n+     * <p>The number of columns in coefficients determines the length\n+     * of the returned solution vector (column matrix).  If constants\n+     * has more rows than coefficients has columns, excess rows are ignored.\n+     * Similarly, extra (zero) rows in coefficients are ignored</p>\n+     * \n+     * @param coefficients upper-triangular coefficients matrix\n+     * @param constants column RHS constants matrix\n+     * @return solution matrix as a column matrix\n+     * \n+     */\n+    private static RealMatrix solveUpperTriangular(RealMatrixImpl coefficients,\n+            RealMatrixImpl constants) {\n+        if (!isUpperTriangular(coefficients, 1E-12)) {\n+            throw new IllegalArgumentException(\n+                   \"Coefficients is not upper-triangular\");\n+        }\n+        if (constants.getColumnDimension() != 1) {\n+            throw new IllegalArgumentException(\n+                    \"Constants not a column matrix.\");\n+        }\n+        int length = coefficients.getColumnDimension();\n+        double[][] cons = constants.getDataRef();\n+        double[][] coef = coefficients.getDataRef();\n+        double x[] = new double[length];\n+        for (int i = 0; i < length; i++) {\n+            int index = length - 1 - i;\n+            double sum = 0;\n+            for (int j = index + 1; j < length; j++) {\n+                sum += coef[index][j] * x[j];\n+            }\n+            x[index] = (cons[index][0] - sum) / coef[index][index];\n+        } \n+        return new RealMatrixImpl(x);\n+    }\n+    \n+    /**\n+     * <p>Returns true iff m is an upper-triangular matrix.</p>\n+     * \n+     * <p>Makes sure all below-diagonal elements are within epsilon of 0.</p>\n+     * \n+     * @param m matrix to check\n+     * @param epsilon maximum allowable absolute value for elements below\n+     * the main diagonal\n+     * \n+     * @return true if m is upper-triangular; false otherwise\n+     * @throws NullPointerException if m is null\n+     */\n+    private static boolean isUpperTriangular(RealMatrixImpl m, double epsilon) {\n+        double[][] data = m.getDataRef();\n+        int nCols = m.getColumnDimension();\n+        int nRows = m.getRowDimension();\n+        for (int r = 0; r < nRows; r++) {\n+            int bound = Math.min(r, nCols);\n+            for (int c = 0; c < bound; c++) {\n+                if (Math.abs(data[r][c]) > epsilon) {\n+                    return false;\n+                }\n+            }\n+        }\n+        return true;\n+    }\n }\n--- a/src/test/org/apache/commons/math/stat/regression/AbstractMultipleLinearRegressionTest.java\n+++ b/src/test/org/apache/commons/math/stat/regression/AbstractMultipleLinearRegressionTest.java\n \n     @Test\n     public void canEstimateRegressandVariance(){\n-        double variance = regression.estimateRegressandVariance();\n-        assertTrue(variance > 0.0);\n+        if (getSampleSize() > getNumberOfRegressors()) {\n+            double variance = regression.estimateRegressandVariance();\n+            assertTrue(variance > 0.0);\n+        }\n     }   \n \n }\n--- a/src/test/org/apache/commons/math/stat/regression/OLSMultipleLinearRegressionTest.java\n+++ b/src/test/org/apache/commons/math/stat/regression/OLSMultipleLinearRegressionTest.java\n \n import org.junit.Before;\n import org.junit.Test;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n import org.apache.commons.math.TestUtils;\n+import org.apache.commons.math.linear.RealMatrixImpl;\n \n public class OLSMultipleLinearRegressionTest extends AbstractMultipleLinearRegressionTest {\n \n           new double[]{-3482258.63459582, 15.0618722713733,\n                 -0.358191792925910E-01,-2.02022980381683,\n                 -1.03322686717359,-0.511041056535807E-01,\n-                 1829.15146461355}, 1E-1); // <- UGH! need better accuracy!\n+                 1829.15146461355}, 1E-8); // \n         \n         // Check expected residuals from R\n         double[] residuals = model.estimateResiduals();\n                  455.394094551857,-17.26892711483297,-39.0550425226967,\n                 -155.5499735953195,-85.6713080421283,341.9315139607727,\n                 -206.7578251937366},\n-                      1E-2); // <- UGH again! need better accuracy!\n+                      1E-8);\n         \n         // Check standard errors from NIST\n         double[][] errors = model.estimateRegressionParametersVariance();", "timestamp": 1217184758, "metainfo": ""}