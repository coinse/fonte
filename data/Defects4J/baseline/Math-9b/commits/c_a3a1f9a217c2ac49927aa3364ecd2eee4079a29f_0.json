{"sha": "a3a1f9a217c2ac49927aa3364ecd2eee4079a29f", "log": "MATH-874 Refactored of the contents of package \"o.a.c.m.optimization\" into the new \"o.a.c.m.optim\" and \"o.a.c.m.fitting\" packages. * All deprecated classes/fields/methods have been removed in the   replacement packages. * Simplified API: a single \"optimize(OptimizationData... data)\"   for all optimizer types. * Simplified class hierarchy, merged interfaces and abstract   classes, only base classes are generic. * The new classes do not use the \"DerivativeStructure\" type.   ", "commit": "\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/exception/TooManyIterationsException.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.exception;\n+\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+\n+/**\n+ * Exception to be thrown when the maximal number of iterations is exceeded.\n+ *\n+ * @since 3.1\n+ * @version $Id$\n+ */\n+public class TooManyIterationsException extends MaxCountExceededException {\n+    /** Serializable version Id. */\n+    private static final long serialVersionUID = 20121211L;\n+\n+    /**\n+     * Construct the exception.\n+     *\n+     * @param max Maximum number of evaluations.\n+     */\n+    public TooManyIterationsException(Number max) {\n+        super(max);\n+        getContext().addMessage(LocalizedFormats.ITERATIONS);\n+    }\n+}\n--- a/src/main/java/org/apache/commons/math3/exception/util/LocalizedFormats.java\n+++ b/src/main/java/org/apache/commons/math3/exception/util/LocalizedFormats.java\n     INVALID_REGRESSION_OBSERVATION(\"length of regressor array = {0} does not match the number of variables = {1} in the model\"),\n     INVALID_ROUNDING_METHOD(\"invalid rounding method {0}, valid methods: {1} ({2}), {3} ({4}), {5} ({6}), {7} ({8}), {9} ({10}), {11} ({12}), {13} ({14}), {15} ({16})\"),\n     ITERATOR_EXHAUSTED(\"iterator exhausted\"),\n+    ITERATIONS(\"iterations\"), /* keep */\n     LCM_OVERFLOW_32_BITS(\"overflow: lcm({0}, {1}) is 2^31\"),\n     LCM_OVERFLOW_64_BITS(\"overflow: lcm({0}, {1}) is 2^63\"),\n     LIST_OF_CHROMOSOMES_BIGGER_THAN_POPULATION_SIZE(\"list of chromosomes bigger than maxPopulationSize\"),\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/fitting/CurveFitter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.ParametricUnivariateFunction;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.nonlinear.vector.MultivariateVectorOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+import org.apache.commons.math3.optim.nonlinear.vector.Target;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+\n+/**\n+ * Fitter for parametric univariate real functions y = f(x).\n+ * <br/>\n+ * When a univariate real function y = f(x) does depend on some\n+ * unknown parameters p<sub>0</sub>, p<sub>1</sub> ... p<sub>n-1</sub>,\n+ * this class can be used to find these parameters. It does this\n+ * by <em>fitting</em> the curve so it remains very close to a set of\n+ * observed points (x<sub>0</sub>, y<sub>0</sub>), (x<sub>1</sub>,\n+ * y<sub>1</sub>) ... (x<sub>k-1</sub>, y<sub>k-1</sub>). This fitting\n+ * is done by finding the parameters values that minimizes the objective\n+ * function &sum;(y<sub>i</sub>-f(x<sub>i</sub>))<sup>2</sup>. This is\n+ * really a least squares problem.\n+ *\n+ * @param <T> Function to use for the fit.\n+ *\n+ * @version $Id: CurveFitter.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class CurveFitter<T extends ParametricUnivariateFunction> {\n+    /** Optimizer to use for the fitting. */\n+    private final MultivariateVectorOptimizer optimizer;\n+    /** Observed points. */\n+    private final List<WeightedObservedPoint> observations;\n+\n+    /**\n+     * Simple constructor.\n+     *\n+     * @param optimizer Optimizer to use for the fitting.\n+     * @since 3.1\n+     */\n+    public CurveFitter(final MultivariateVectorOptimizer optimizer) {\n+        this.optimizer = optimizer;\n+        observations = new ArrayList<WeightedObservedPoint>();\n+    }\n+\n+    /** Add an observed (x,y) point to the sample with unit weight.\n+     * <p>Calling this method is equivalent to call\n+     * {@code addObservedPoint(1.0, x, y)}.</p>\n+     * @param x abscissa of the point\n+     * @param y observed value of the point at x, after fitting we should\n+     * have f(x) as close as possible to this value\n+     * @see #addObservedPoint(double, double, double)\n+     * @see #addObservedPoint(WeightedObservedPoint)\n+     * @see #getObservations()\n+     */\n+    public void addObservedPoint(double x, double y) {\n+        addObservedPoint(1.0, x, y);\n+    }\n+\n+    /** Add an observed weighted (x,y) point to the sample.\n+     * @param weight weight of the observed point in the fit\n+     * @param x abscissa of the point\n+     * @param y observed value of the point at x, after fitting we should\n+     * have f(x) as close as possible to this value\n+     * @see #addObservedPoint(double, double)\n+     * @see #addObservedPoint(WeightedObservedPoint)\n+     * @see #getObservations()\n+     */\n+    public void addObservedPoint(double weight, double x, double y) {\n+        observations.add(new WeightedObservedPoint(weight, x, y));\n+    }\n+\n+    /** Add an observed weighted (x,y) point to the sample.\n+     * @param observed observed point to add\n+     * @see #addObservedPoint(double, double)\n+     * @see #addObservedPoint(double, double, double)\n+     * @see #getObservations()\n+     */\n+    public void addObservedPoint(WeightedObservedPoint observed) {\n+        observations.add(observed);\n+    }\n+\n+    /** Get the observed points.\n+     * @return observed points\n+     * @see #addObservedPoint(double, double)\n+     * @see #addObservedPoint(double, double, double)\n+     * @see #addObservedPoint(WeightedObservedPoint)\n+     */\n+    public WeightedObservedPoint[] getObservations() {\n+        return observations.toArray(new WeightedObservedPoint[observations.size()]);\n+    }\n+\n+    /**\n+     * Remove all observations.\n+     */\n+    public void clearObservations() {\n+        observations.clear();\n+    }\n+\n+    /**\n+     * Fit a curve.\n+     * This method compute the coefficients of the curve that best\n+     * fit the sample of observed points previously given through calls\n+     * to the {@link #addObservedPoint(WeightedObservedPoint)\n+     * addObservedPoint} method.\n+     *\n+     * @param f parametric function to fit.\n+     * @param initialGuess first guess of the function parameters.\n+     * @return the fitted parameters.\n+     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n+     * if the start point dimension is wrong.\n+     */\n+    public double[] fit(T f, final double[] initialGuess) {\n+        return fit(Integer.MAX_VALUE, f, initialGuess);\n+    }\n+\n+    /**\n+     * Fit a curve.\n+     * This method compute the coefficients of the curve that best\n+     * fit the sample of observed points previously given through calls\n+     * to the {@link #addObservedPoint(WeightedObservedPoint)\n+     * addObservedPoint} method.\n+     *\n+     * @param f parametric function to fit.\n+     * @param initialGuess first guess of the function parameters.\n+     * @param maxEval Maximum number of function evaluations.\n+     * @return the fitted parameters.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+     * if the number of allowed evaluations is exceeded.\n+     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n+     * if the start point dimension is wrong.\n+     * @since 3.0\n+     */\n+    public double[] fit(int maxEval, T f,\n+                        final double[] initialGuess) {\n+        // Prepare least squares problem.\n+        double[] target  = new double[observations.size()];\n+        double[] weights = new double[observations.size()];\n+        int i = 0;\n+        for (WeightedObservedPoint point : observations) {\n+            target[i]  = point.getY();\n+            weights[i] = point.getWeight();\n+            ++i;\n+        }\n+\n+        // Input to the optimizer: the model and its Jacobian.\n+        final TheoreticalValuesFunction model = new TheoreticalValuesFunction(f);\n+\n+        // Perform the fit.\n+        final PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(maxEval),\n+                                 model.getModelFunction(),\n+                                 model.getModelFunctionJacobian(),\n+                                 new Target(target),\n+                                 new Weight(weights),\n+                                 new InitialGuess(initialGuess));\n+        // Extract the coefficients.\n+        return optimum.getPointRef();\n+    }\n+\n+    /** Vectorial function computing function theoretical values. */\n+    private class TheoreticalValuesFunction {\n+        /** Function to fit. */\n+        private final ParametricUnivariateFunction f;\n+\n+        /**\n+         * @param f function to fit.\n+         */\n+        public TheoreticalValuesFunction(final ParametricUnivariateFunction f) {\n+            this.f = f;\n+        }\n+\n+        /**\n+         * @return the model function values.\n+         */\n+        public ModelFunction getModelFunction() {\n+            return new ModelFunction(new MultivariateVectorFunction() {\n+                    /** {@inheritDoc} */\n+                    public double[] value(double[] point) {\n+                        // compute the residuals\n+                        final double[] values = new double[observations.size()];\n+                        int i = 0;\n+                        for (WeightedObservedPoint observed : observations) {\n+                            values[i++] = f.value(observed.getX(), point);\n+                        }\n+\n+                        return values;\n+                    }\n+                });\n+        }\n+\n+        /**\n+         * @return the model function Jacobian.\n+         */\n+        public ModelFunctionJacobian getModelFunctionJacobian() {\n+            return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                    public double[][] value(double[] point) {\n+                        final double[][] jacobian = new double[observations.size()][];\n+                        int i = 0;\n+                        for (WeightedObservedPoint observed : observations) {\n+                            jacobian[i++] = f.gradient(observed.getX(), point);\n+                        }\n+                        return jacobian;\n+                    }\n+                });\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/fitting/GaussianFitter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import org.apache.commons.math3.analysis.function.Gaussian;\n+import org.apache.commons.math3.exception.NullArgumentException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.OutOfRangeException;\n+import org.apache.commons.math3.exception.ZeroException;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.optim.nonlinear.vector.MultivariateVectorOptimizer;\n+import org.apache.commons.math3.util.FastMath;\n+\n+/**\n+ * Fits points to a {@link\n+ * org.apache.commons.math3.analysis.function.Gaussian.Parametric Gaussian} function.\n+ * <p>\n+ * Usage example:\n+ * <pre>\n+ *   GaussianFitter fitter = new GaussianFitter(\n+ *     new LevenbergMarquardtOptimizer());\n+ *   fitter.addObservedPoint(4.0254623,  531026.0);\n+ *   fitter.addObservedPoint(4.03128248, 984167.0);\n+ *   fitter.addObservedPoint(4.03839603, 1887233.0);\n+ *   fitter.addObservedPoint(4.04421621, 2687152.0);\n+ *   fitter.addObservedPoint(4.05132976, 3461228.0);\n+ *   fitter.addObservedPoint(4.05326982, 3580526.0);\n+ *   fitter.addObservedPoint(4.05779662, 3439750.0);\n+ *   fitter.addObservedPoint(4.0636168,  2877648.0);\n+ *   fitter.addObservedPoint(4.06943698, 2175960.0);\n+ *   fitter.addObservedPoint(4.07525716, 1447024.0);\n+ *   fitter.addObservedPoint(4.08237071, 717104.0);\n+ *   fitter.addObservedPoint(4.08366408, 620014.0);\n+ *   double[] parameters = fitter.fit();\n+ * </pre>\n+ *\n+ * @since 2.2\n+ * @version $Id: GaussianFitter.java 1416643 2012-12-03 19:37:14Z tn $\n+ */\n+public class GaussianFitter extends CurveFitter<Gaussian.Parametric> {\n+    /**\n+     * Constructs an instance using the specified optimizer.\n+     *\n+     * @param optimizer Optimizer to use for the fitting.\n+     */\n+    public GaussianFitter(MultivariateVectorOptimizer optimizer) {\n+        super(optimizer);\n+    }\n+\n+    /**\n+     * Fits a Gaussian function to the observed points.\n+     *\n+     * @param initialGuess First guess values in the following order:\n+     * <ul>\n+     *  <li>Norm</li>\n+     *  <li>Mean</li>\n+     *  <li>Sigma</li>\n+     * </ul>\n+     * @return the parameters of the Gaussian function that best fits the\n+     * observed points (in the same order as above).\n+     * @since 3.0\n+     */\n+    public double[] fit(double[] initialGuess) {\n+        final Gaussian.Parametric f = new Gaussian.Parametric() {\n+                @Override\n+                public double value(double x, double ... p) {\n+                    double v = Double.POSITIVE_INFINITY;\n+                    try {\n+                        v = super.value(x, p);\n+                    } catch (NotStrictlyPositiveException e) {\n+                        // Do nothing.\n+                    }\n+                    return v;\n+                }\n+\n+                @Override\n+                public double[] gradient(double x, double ... p) {\n+                    double[] v = { Double.POSITIVE_INFINITY,\n+                                   Double.POSITIVE_INFINITY,\n+                                   Double.POSITIVE_INFINITY };\n+                    try {\n+                        v = super.gradient(x, p);\n+                    } catch (NotStrictlyPositiveException e) {\n+                        // Do nothing.\n+                    }\n+                    return v;\n+                }\n+            };\n+\n+        return fit(f, initialGuess);\n+    }\n+\n+    /**\n+     * Fits a Gaussian function to the observed points.\n+     *\n+     * @return the parameters of the Gaussian function that best fits the\n+     * observed points (in the same order as above).\n+     */\n+    public double[] fit() {\n+        final double[] guess = (new ParameterGuesser(getObservations())).guess();\n+        return fit(guess);\n+    }\n+\n+    /**\n+     * Guesses the parameters {@code norm}, {@code mean}, and {@code sigma}\n+     * of a {@link org.apache.commons.math3.analysis.function.Gaussian.Parametric}\n+     * based on the specified observed points.\n+     */\n+    public static class ParameterGuesser {\n+        /** Normalization factor. */\n+        private final double norm;\n+        /** Mean. */\n+        private final double mean;\n+        /** Standard deviation. */\n+        private final double sigma;\n+\n+        /**\n+         * Constructs instance with the specified observed points.\n+         *\n+         * @param observations Observed points from which to guess the\n+         * parameters of the Gaussian.\n+         * @throws NullArgumentException if {@code observations} is\n+         * {@code null}.\n+         * @throws NumberIsTooSmallException if there are less than 3\n+         * observations.\n+         */\n+        public ParameterGuesser(WeightedObservedPoint[] observations) {\n+            if (observations == null) {\n+                throw new NullArgumentException(LocalizedFormats.INPUT_ARRAY);\n+            }\n+            if (observations.length < 3) {\n+                throw new NumberIsTooSmallException(observations.length, 3, true);\n+            }\n+\n+            final WeightedObservedPoint[] sorted = sortObservations(observations);\n+            final double[] params = basicGuess(sorted);\n+\n+            norm = params[0];\n+            mean = params[1];\n+            sigma = params[2];\n+        }\n+\n+        /**\n+         * Gets an estimation of the parameters.\n+         *\n+         * @return the guessed parameters, in the following order:\n+         * <ul>\n+         *  <li>Normalization factor</li>\n+         *  <li>Mean</li>\n+         *  <li>Standard deviation</li>\n+         * </ul>\n+         */\n+        public double[] guess() {\n+            return new double[] { norm, mean, sigma };\n+        }\n+\n+        /**\n+         * Sort the observations.\n+         *\n+         * @param unsorted Input observations.\n+         * @return the input observations, sorted.\n+         */\n+        private WeightedObservedPoint[] sortObservations(WeightedObservedPoint[] unsorted) {\n+            final WeightedObservedPoint[] observations = unsorted.clone();\n+            final Comparator<WeightedObservedPoint> cmp\n+                = new Comparator<WeightedObservedPoint>() {\n+                public int compare(WeightedObservedPoint p1,\n+                                   WeightedObservedPoint p2) {\n+                    if (p1 == null && p2 == null) {\n+                        return 0;\n+                    }\n+                    if (p1 == null) {\n+                        return -1;\n+                    }\n+                    if (p2 == null) {\n+                        return 1;\n+                    }\n+                    if (p1.getX() < p2.getX()) {\n+                        return -1;\n+                    }\n+                    if (p1.getX() > p2.getX()) {\n+                        return 1;\n+                    }\n+                    if (p1.getY() < p2.getY()) {\n+                        return -1;\n+                    }\n+                    if (p1.getY() > p2.getY()) {\n+                        return 1;\n+                    }\n+                    if (p1.getWeight() < p2.getWeight()) {\n+                        return -1;\n+                    }\n+                    if (p1.getWeight() > p2.getWeight()) {\n+                        return 1;\n+                    }\n+                    return 0;\n+                }\n+            };\n+\n+            Arrays.sort(observations, cmp);\n+            return observations;\n+        }\n+\n+        /**\n+         * Guesses the parameters based on the specified observed points.\n+         *\n+         * @param points Observed points, sorted.\n+         * @return the guessed parameters (normalization factor, mean and\n+         * sigma).\n+         */\n+        private double[] basicGuess(WeightedObservedPoint[] points) {\n+            final int maxYIdx = findMaxY(points);\n+            final double n = points[maxYIdx].getY();\n+            final double m = points[maxYIdx].getX();\n+\n+            double fwhmApprox;\n+            try {\n+                final double halfY = n + ((m - n) / 2);\n+                final double fwhmX1 = interpolateXAtY(points, maxYIdx, -1, halfY);\n+                final double fwhmX2 = interpolateXAtY(points, maxYIdx, 1, halfY);\n+                fwhmApprox = fwhmX2 - fwhmX1;\n+            } catch (OutOfRangeException e) {\n+                // TODO: Exceptions should not be used for flow control.\n+                fwhmApprox = points[points.length - 1].getX() - points[0].getX();\n+            }\n+            final double s = fwhmApprox / (2 * FastMath.sqrt(2 * FastMath.log(2)));\n+\n+            return new double[] { n, m, s };\n+        }\n+\n+        /**\n+         * Finds index of point in specified points with the largest Y.\n+         *\n+         * @param points Points to search.\n+         * @return the index in specified points array.\n+         */\n+        private int findMaxY(WeightedObservedPoint[] points) {\n+            int maxYIdx = 0;\n+            for (int i = 1; i < points.length; i++) {\n+                if (points[i].getY() > points[maxYIdx].getY()) {\n+                    maxYIdx = i;\n+                }\n+            }\n+            return maxYIdx;\n+        }\n+\n+        /**\n+         * Interpolates using the specified points to determine X at the\n+         * specified Y.\n+         *\n+         * @param points Points to use for interpolation.\n+         * @param startIdx Index within points from which to start the search for\n+         * interpolation bounds points.\n+         * @param idxStep Index step for searching interpolation bounds points.\n+         * @param y Y value for which X should be determined.\n+         * @return the value of X for the specified Y.\n+         * @throws ZeroException if {@code idxStep} is 0.\n+         * @throws OutOfRangeException if specified {@code y} is not within the\n+         * range of the specified {@code points}.\n+         */\n+        private double interpolateXAtY(WeightedObservedPoint[] points,\n+                                       int startIdx,\n+                                       int idxStep,\n+                                       double y)\n+            throws OutOfRangeException {\n+            if (idxStep == 0) {\n+                throw new ZeroException();\n+            }\n+            final WeightedObservedPoint[] twoPoints\n+                = getInterpolationPointsForY(points, startIdx, idxStep, y);\n+            final WeightedObservedPoint p1 = twoPoints[0];\n+            final WeightedObservedPoint p2 = twoPoints[1];\n+            if (p1.getY() == y) {\n+                return p1.getX();\n+            }\n+            if (p2.getY() == y) {\n+                return p2.getX();\n+            }\n+            return p1.getX() + (((y - p1.getY()) * (p2.getX() - p1.getX())) /\n+                                (p2.getY() - p1.getY()));\n+        }\n+\n+        /**\n+         * Gets the two bounding interpolation points from the specified points\n+         * suitable for determining X at the specified Y.\n+         *\n+         * @param points Points to use for interpolation.\n+         * @param startIdx Index within points from which to start search for\n+         * interpolation bounds points.\n+         * @param idxStep Index step for search for interpolation bounds points.\n+         * @param y Y value for which X should be determined.\n+         * @return the array containing two points suitable for determining X at\n+         * the specified Y.\n+         * @throws ZeroException if {@code idxStep} is 0.\n+         * @throws OutOfRangeException if specified {@code y} is not within the\n+         * range of the specified {@code points}.\n+         */\n+        private WeightedObservedPoint[] getInterpolationPointsForY(WeightedObservedPoint[] points,\n+                                                                   int startIdx,\n+                                                                   int idxStep,\n+                                                                   double y)\n+            throws OutOfRangeException {\n+            if (idxStep == 0) {\n+                throw new ZeroException();\n+            }\n+            for (int i = startIdx;\n+                 idxStep < 0 ? i + idxStep >= 0 : i + idxStep < points.length;\n+                 i += idxStep) {\n+                final WeightedObservedPoint p1 = points[i];\n+                final WeightedObservedPoint p2 = points[i + idxStep];\n+                if (isBetween(y, p1.getY(), p2.getY())) {\n+                    if (idxStep < 0) {\n+                        return new WeightedObservedPoint[] { p2, p1 };\n+                    } else {\n+                        return new WeightedObservedPoint[] { p1, p2 };\n+                    }\n+                }\n+            }\n+\n+            // Boundaries are replaced by dummy values because the raised\n+            // exception is caught and the message never displayed.\n+            // TODO: Exceptions should not be used for flow control.\n+            throw new OutOfRangeException(y,\n+                                          Double.NEGATIVE_INFINITY,\n+                                          Double.POSITIVE_INFINITY);\n+        }\n+\n+        /**\n+         * Determines whether a value is between two other values.\n+         *\n+         * @param value Value to test whether it is between {@code boundary1}\n+         * and {@code boundary2}.\n+         * @param boundary1 One end of the range.\n+         * @param boundary2 Other end of the range.\n+         * @return {@code true} if {@code value} is between {@code boundary1} and\n+         * {@code boundary2} (inclusive), {@code false} otherwise.\n+         */\n+        private boolean isBetween(double value,\n+                                  double boundary1,\n+                                  double boundary2) {\n+            return (value >= boundary1 && value <= boundary2) ||\n+                (value >= boundary2 && value <= boundary1);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/fitting/HarmonicFitter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import org.apache.commons.math3.optim.nonlinear.vector.MultivariateVectorOptimizer;\n+import org.apache.commons.math3.analysis.function.HarmonicOscillator;\n+import org.apache.commons.math3.exception.ZeroException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.util.FastMath;\n+\n+/**\n+ * Class that implements a curve fitting specialized for sinusoids.\n+ *\n+ * Harmonic fitting is a very simple case of curve fitting. The\n+ * estimated coefficients are the amplitude a, the pulsation &omega; and\n+ * the phase &phi;: <code>f (t) = a cos (&omega; t + &phi;)</code>. They are\n+ * searched by a least square estimator initialized with a rough guess\n+ * based on integrals.\n+ *\n+ * @version $Id: HarmonicFitter.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class HarmonicFitter extends CurveFitter<HarmonicOscillator.Parametric> {\n+    /**\n+     * Simple constructor.\n+     * @param optimizer Optimizer to use for the fitting.\n+     */\n+    public HarmonicFitter(final MultivariateVectorOptimizer optimizer) {\n+        super(optimizer);\n+    }\n+\n+    /**\n+     * Fit an harmonic function to the observed points.\n+     *\n+     * @param initialGuess First guess values in the following order:\n+     * <ul>\n+     *  <li>Amplitude</li>\n+     *  <li>Angular frequency</li>\n+     *  <li>Phase</li>\n+     * </ul>\n+     * @return the parameters of the harmonic function that best fits the\n+     * observed points (in the same order as above).\n+     */\n+    public double[] fit(double[] initialGuess) {\n+        return fit(new HarmonicOscillator.Parametric(), initialGuess);\n+    }\n+\n+    /**\n+     * Fit an harmonic function to the observed points.\n+     * An initial guess will be automatically computed.\n+     *\n+     * @return the parameters of the harmonic function that best fits the\n+     * observed points (see the other {@link #fit(double[]) fit} method.\n+     * @throws NumberIsTooSmallException if the sample is too short for the\n+     * the first guess to be computed.\n+     * @throws ZeroException if the first guess cannot be computed because\n+     * the abscissa range is zero.\n+     */\n+    public double[] fit() {\n+        return fit((new ParameterGuesser(getObservations())).guess());\n+    }\n+\n+    /**\n+     * This class guesses harmonic coefficients from a sample.\n+     * <p>The algorithm used to guess the coefficients is as follows:</p>\n+     *\n+     * <p>We know f (t) at some sampling points t<sub>i</sub> and want to find a,\n+     * &omega; and &phi; such that f (t) = a cos (&omega; t + &phi;).\n+     * </p>\n+     *\n+     * <p>From the analytical expression, we can compute two primitives :\n+     * <pre>\n+     *     If2  (t) = &int; f<sup>2</sup>  = a<sup>2</sup> &times; [t + S (t)] / 2\n+     *     If'2 (t) = &int; f'<sup>2</sup> = a<sup>2</sup> &omega;<sup>2</sup> &times; [t - S (t)] / 2\n+     *     where S (t) = sin (2 (&omega; t + &phi;)) / (2 &omega;)\n+     * </pre>\n+     * </p>\n+     *\n+     * <p>We can remove S between these expressions :\n+     * <pre>\n+     *     If'2 (t) = a<sup>2</sup> &omega;<sup>2</sup> t - &omega;<sup>2</sup> If2 (t)\n+     * </pre>\n+     * </p>\n+     *\n+     * <p>The preceding expression shows that If'2 (t) is a linear\n+     * combination of both t and If2 (t): If'2 (t) = A &times; t + B &times; If2 (t)\n+     * </p>\n+     *\n+     * <p>From the primitive, we can deduce the same form for definite\n+     * integrals between t<sub>1</sub> and t<sub>i</sub> for each t<sub>i</sub> :\n+     * <pre>\n+     *   If2 (t<sub>i</sub>) - If2 (t<sub>1</sub>) = A &times; (t<sub>i</sub> - t<sub>1</sub>) + B &times; (If2 (t<sub>i</sub>) - If2 (t<sub>1</sub>))\n+     * </pre>\n+     * </p>\n+     *\n+     * <p>We can find the coefficients A and B that best fit the sample\n+     * to this linear expression by computing the definite integrals for\n+     * each sample points.\n+     * </p>\n+     *\n+     * <p>For a bilinear expression z (x<sub>i</sub>, y<sub>i</sub>) = A &times; x<sub>i</sub> + B &times; y<sub>i</sub>, the\n+     * coefficients A and B that minimize a least square criterion\n+     * &sum; (z<sub>i</sub> - z (x<sub>i</sub>, y<sub>i</sub>))<sup>2</sup> are given by these expressions:</p>\n+     * <pre>\n+     *\n+     *         &sum;y<sub>i</sub>y<sub>i</sub> &sum;x<sub>i</sub>z<sub>i</sub> - &sum;x<sub>i</sub>y<sub>i</sub> &sum;y<sub>i</sub>z<sub>i</sub>\n+     *     A = ------------------------\n+     *         &sum;x<sub>i</sub>x<sub>i</sub> &sum;y<sub>i</sub>y<sub>i</sub> - &sum;x<sub>i</sub>y<sub>i</sub> &sum;x<sub>i</sub>y<sub>i</sub>\n+     *\n+     *         &sum;x<sub>i</sub>x<sub>i</sub> &sum;y<sub>i</sub>z<sub>i</sub> - &sum;x<sub>i</sub>y<sub>i</sub> &sum;x<sub>i</sub>z<sub>i</sub>\n+     *     B = ------------------------\n+     *         &sum;x<sub>i</sub>x<sub>i</sub> &sum;y<sub>i</sub>y<sub>i</sub> - &sum;x<sub>i</sub>y<sub>i</sub> &sum;x<sub>i</sub>y<sub>i</sub>\n+     * </pre>\n+     * </p>\n+     *\n+     *\n+     * <p>In fact, we can assume both a and &omega; are positive and\n+     * compute them directly, knowing that A = a<sup>2</sup> &omega;<sup>2</sup> and that\n+     * B = - &omega;<sup>2</sup>. The complete algorithm is therefore:</p>\n+     * <pre>\n+     *\n+     * for each t<sub>i</sub> from t<sub>1</sub> to t<sub>n-1</sub>, compute:\n+     *   f  (t<sub>i</sub>)\n+     *   f' (t<sub>i</sub>) = (f (t<sub>i+1</sub>) - f(t<sub>i-1</sub>)) / (t<sub>i+1</sub> - t<sub>i-1</sub>)\n+     *   x<sub>i</sub> = t<sub>i</sub> - t<sub>1</sub>\n+     *   y<sub>i</sub> = &int; f<sup>2</sup> from t<sub>1</sub> to t<sub>i</sub>\n+     *   z<sub>i</sub> = &int; f'<sup>2</sup> from t<sub>1</sub> to t<sub>i</sub>\n+     *   update the sums &sum;x<sub>i</sub>x<sub>i</sub>, &sum;y<sub>i</sub>y<sub>i</sub>, &sum;x<sub>i</sub>y<sub>i</sub>, &sum;x<sub>i</sub>z<sub>i</sub> and &sum;y<sub>i</sub>z<sub>i</sub>\n+     * end for\n+     *\n+     *            |--------------------------\n+     *         \\  | &sum;y<sub>i</sub>y<sub>i</sub> &sum;x<sub>i</sub>z<sub>i</sub> - &sum;x<sub>i</sub>y<sub>i</sub> &sum;y<sub>i</sub>z<sub>i</sub>\n+     * a     =  \\ | ------------------------\n+     *           \\| &sum;x<sub>i</sub>y<sub>i</sub> &sum;x<sub>i</sub>z<sub>i</sub> - &sum;x<sub>i</sub>x<sub>i</sub> &sum;y<sub>i</sub>z<sub>i</sub>\n+     *\n+     *\n+     *            |--------------------------\n+     *         \\  | &sum;x<sub>i</sub>y<sub>i</sub> &sum;x<sub>i</sub>z<sub>i</sub> - &sum;x<sub>i</sub>x<sub>i</sub> &sum;y<sub>i</sub>z<sub>i</sub>\n+     * &omega;     =  \\ | ------------------------\n+     *           \\| &sum;x<sub>i</sub>x<sub>i</sub> &sum;y<sub>i</sub>y<sub>i</sub> - &sum;x<sub>i</sub>y<sub>i</sub> &sum;x<sub>i</sub>y<sub>i</sub>\n+     *\n+     * </pre>\n+     * </p>\n+     *\n+     * <p>Once we know &omega;, we can compute:\n+     * <pre>\n+     *    fc = &omega; f (t) cos (&omega; t) - f' (t) sin (&omega; t)\n+     *    fs = &omega; f (t) sin (&omega; t) + f' (t) cos (&omega; t)\n+     * </pre>\n+     * </p>\n+     *\n+     * <p>It appears that <code>fc = a &omega; cos (&phi;)</code> and\n+     * <code>fs = -a &omega; sin (&phi;)</code>, so we can use these\n+     * expressions to compute &phi;. The best estimate over the sample is\n+     * given by averaging these expressions.\n+     * </p>\n+     *\n+     * <p>Since integrals and means are involved in the preceding\n+     * estimations, these operations run in O(n) time, where n is the\n+     * number of measurements.</p>\n+     */\n+    public static class ParameterGuesser {\n+        /** Amplitude. */\n+        private final double a;\n+        /** Angular frequency. */\n+        private final double omega;\n+        /** Phase. */\n+        private final double phi;\n+\n+        /**\n+         * Simple constructor.\n+         *\n+         * @param observations Sampled observations.\n+         * @throws NumberIsTooSmallException if the sample is too short.\n+         * @throws ZeroException if the abscissa range is zero.\n+         * @throws MathIllegalStateException when the guessing procedure cannot\n+         * produce sensible results.\n+         */\n+        public ParameterGuesser(WeightedObservedPoint[] observations) {\n+            if (observations.length < 4) {\n+                throw new NumberIsTooSmallException(LocalizedFormats.INSUFFICIENT_OBSERVED_POINTS_IN_SAMPLE,\n+                                                    observations.length, 4, true);\n+            }\n+\n+            final WeightedObservedPoint[] sorted = sortObservations(observations);\n+\n+            final double aOmega[] = guessAOmega(sorted);\n+            a = aOmega[0];\n+            omega = aOmega[1];\n+\n+            phi = guessPhi(sorted);\n+        }\n+\n+        /**\n+         * Gets an estimation of the parameters.\n+         *\n+         * @return the guessed parameters, in the following order:\n+         * <ul>\n+         *  <li>Amplitude</li>\n+         *  <li>Angular frequency</li>\n+         *  <li>Phase</li>\n+         * </ul>\n+         */\n+        public double[] guess() {\n+            return new double[] { a, omega, phi };\n+        }\n+\n+        /**\n+         * Sort the observations with respect to the abscissa.\n+         *\n+         * @param unsorted Input observations.\n+         * @return the input observations, sorted.\n+         */\n+        private WeightedObservedPoint[] sortObservations(WeightedObservedPoint[] unsorted) {\n+            final WeightedObservedPoint[] observations = unsorted.clone();\n+\n+            // Since the samples are almost always already sorted, this\n+            // method is implemented as an insertion sort that reorders the\n+            // elements in place. Insertion sort is very efficient in this case.\n+            WeightedObservedPoint curr = observations[0];\n+            for (int j = 1; j < observations.length; ++j) {\n+                WeightedObservedPoint prec = curr;\n+                curr = observations[j];\n+                if (curr.getX() < prec.getX()) {\n+                    // the current element should be inserted closer to the beginning\n+                    int i = j - 1;\n+                    WeightedObservedPoint mI = observations[i];\n+                    while ((i >= 0) && (curr.getX() < mI.getX())) {\n+                        observations[i + 1] = mI;\n+                        if (i-- != 0) {\n+                            mI = observations[i];\n+                        }\n+                    }\n+                    observations[i + 1] = curr;\n+                    curr = observations[j];\n+                }\n+            }\n+\n+            return observations;\n+        }\n+\n+        /**\n+         * Estimate a first guess of the amplitude and angular frequency.\n+         * This method assumes that the {@link #sortObservations()} method\n+         * has been called previously.\n+         *\n+         * @param observations Observations, sorted w.r.t. abscissa.\n+         * @throws ZeroException if the abscissa range is zero.\n+         * @throws MathIllegalStateException when the guessing procedure cannot\n+         * produce sensible results.\n+         * @return the guessed amplitude (at index 0) and circular frequency\n+         * (at index 1).\n+         */\n+        private double[] guessAOmega(WeightedObservedPoint[] observations) {\n+            final double[] aOmega = new double[2];\n+\n+            // initialize the sums for the linear model between the two integrals\n+            double sx2 = 0;\n+            double sy2 = 0;\n+            double sxy = 0;\n+            double sxz = 0;\n+            double syz = 0;\n+\n+            double currentX = observations[0].getX();\n+            double currentY = observations[0].getY();\n+            double f2Integral = 0;\n+            double fPrime2Integral = 0;\n+            final double startX = currentX;\n+            for (int i = 1; i < observations.length; ++i) {\n+                // one step forward\n+                final double previousX = currentX;\n+                final double previousY = currentY;\n+                currentX = observations[i].getX();\n+                currentY = observations[i].getY();\n+\n+                // update the integrals of f<sup>2</sup> and f'<sup>2</sup>\n+                // considering a linear model for f (and therefore constant f')\n+                final double dx = currentX - previousX;\n+                final double dy = currentY - previousY;\n+                final double f2StepIntegral =\n+                    dx * (previousY * previousY + previousY * currentY + currentY * currentY) / 3;\n+                final double fPrime2StepIntegral = dy * dy / dx;\n+\n+                final double x = currentX - startX;\n+                f2Integral += f2StepIntegral;\n+                fPrime2Integral += fPrime2StepIntegral;\n+\n+                sx2 += x * x;\n+                sy2 += f2Integral * f2Integral;\n+                sxy += x * f2Integral;\n+                sxz += x * fPrime2Integral;\n+                syz += f2Integral * fPrime2Integral;\n+            }\n+\n+            // compute the amplitude and pulsation coefficients\n+            double c1 = sy2 * sxz - sxy * syz;\n+            double c2 = sxy * sxz - sx2 * syz;\n+            double c3 = sx2 * sy2 - sxy * sxy;\n+            if ((c1 / c2 < 0) || (c2 / c3 < 0)) {\n+                final int last = observations.length - 1;\n+                // Range of the observations, assuming that the\n+                // observations are sorted.\n+                final double xRange = observations[last].getX() - observations[0].getX();\n+                if (xRange == 0) {\n+                    throw new ZeroException();\n+                }\n+                aOmega[1] = 2 * Math.PI / xRange;\n+\n+                double yMin = Double.POSITIVE_INFINITY;\n+                double yMax = Double.NEGATIVE_INFINITY;\n+                for (int i = 1; i < observations.length; ++i) {\n+                    final double y = observations[i].getY();\n+                    if (y < yMin) {\n+                        yMin = y;\n+                    }\n+                    if (y > yMax) {\n+                        yMax = y;\n+                    }\n+                }\n+                aOmega[0] = 0.5 * (yMax - yMin);\n+            } else {\n+                if (c2 == 0) {\n+                    // In some ill-conditioned cases (cf. MATH-844), the guesser\n+                    // procedure cannot produce sensible results.\n+                    throw new MathIllegalStateException(LocalizedFormats.ZERO_DENOMINATOR);\n+                }\n+\n+                aOmega[0] = FastMath.sqrt(c1 / c2);\n+                aOmega[1] = FastMath.sqrt(c2 / c3);\n+            }\n+\n+            return aOmega;\n+        }\n+\n+        /**\n+         * Estimate a first guess of the phase.\n+         *\n+         * @param observations Observations, sorted w.r.t. abscissa.\n+         * @return the guessed phase.\n+         */\n+        private double guessPhi(WeightedObservedPoint[] observations) {\n+            // initialize the means\n+            double fcMean = 0;\n+            double fsMean = 0;\n+\n+            double currentX = observations[0].getX();\n+            double currentY = observations[0].getY();\n+            for (int i = 1; i < observations.length; ++i) {\n+                // one step forward\n+                final double previousX = currentX;\n+                final double previousY = currentY;\n+                currentX = observations[i].getX();\n+                currentY = observations[i].getY();\n+                final double currentYPrime = (currentY - previousY) / (currentX - previousX);\n+\n+                double omegaX = omega * currentX;\n+                double cosine = FastMath.cos(omegaX);\n+                double sine = FastMath.sin(omegaX);\n+                fcMean += omega * currentY * cosine - currentYPrime * sine;\n+                fsMean += omega * currentY * sine + currentYPrime * cosine;\n+            }\n+\n+            return FastMath.atan2(-fsMean, fcMean);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/fitting/PolynomialFitter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import org.apache.commons.math3.analysis.polynomials.PolynomialFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.MultivariateVectorOptimizer;\n+\n+/**\n+ * Polynomial fitting is a very simple case of {@link CurveFitter curve fitting}.\n+ * The estimated coefficients are the polynomial coefficients (see the\n+ * {@link #fit(double[]) fit} method).\n+ *\n+ * @version $Id: PolynomialFitter.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class PolynomialFitter extends CurveFitter<PolynomialFunction.Parametric> {\n+    /**\n+     * Simple constructor.\n+     *\n+     * @param optimizer Optimizer to use for the fitting.\n+     */\n+    public PolynomialFitter(MultivariateVectorOptimizer optimizer) {\n+        super(optimizer);\n+    }\n+\n+    /**\n+     * Get the coefficients of the polynomial fitting the weighted data points.\n+     * The degree of the fitting polynomial is {@code guess.length - 1}.\n+     *\n+     * @param guess First guess for the coefficients. They must be sorted in\n+     * increasing order of the polynomial's degree.\n+     * @param maxEval Maximum number of evaluations of the polynomial.\n+     * @return the coefficients of the polynomial that best fits the observed points.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException if\n+     * the number of evaluations exceeds {@code maxEval}.\n+     * @throws org.apache.commons.math3.exception.ConvergenceException\n+     * if the algorithm failed to converge.\n+     */\n+    public double[] fit(int maxEval, double[] guess) {\n+        return fit(maxEval, new PolynomialFunction.Parametric(), guess);\n+    }\n+\n+    /**\n+     * Get the coefficients of the polynomial fitting the weighted data points.\n+     * The degree of the fitting polynomial is {@code guess.length - 1}.\n+     *\n+     * @param guess First guess for the coefficients. They must be sorted in\n+     * increasing order of the polynomial's degree.\n+     * @return the coefficients of the polynomial that best fits the observed points.\n+     * @throws org.apache.commons.math3.exception.ConvergenceException\n+     * if the algorithm failed to converge.\n+     */\n+    public double[] fit(double[] guess) {\n+        return fit(new PolynomialFunction.Parametric(), guess);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/fitting/WeightedObservedPoint.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * This class is a simple container for weighted observed point in\n+ * {@link CurveFitter curve fitting}.\n+ * <p>Instances of this class are guaranteed to be immutable.</p>\n+ * @version $Id: WeightedObservedPoint.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class WeightedObservedPoint implements Serializable {\n+    /** Serializable version id. */\n+    private static final long serialVersionUID = 5306874947404636157L;\n+    /** Weight of the measurement in the fitting process. */\n+    private final double weight;\n+    /** Abscissa of the point. */\n+    private final double x;\n+    /** Observed value of the function at x. */\n+    private final double y;\n+\n+    /**\n+     * Simple constructor.\n+     *\n+     * @param weight Weight of the measurement in the fitting process.\n+     * @param x Abscissa of the measurement.\n+     * @param y Ordinate of the measurement.\n+     */\n+    public WeightedObservedPoint(final double weight, final double x, final double y) {\n+        this.weight = weight;\n+        this.x      = x;\n+        this.y      = y;\n+    }\n+\n+    /**\n+     * Gets the weight of the measurement in the fitting process.\n+     *\n+     * @return the weight of the measurement in the fitting process.\n+     */\n+    public double getWeight() {\n+        return weight;\n+    }\n+\n+    /**\n+     * Gets the abscissa of the point.\n+     *\n+     * @return the abscissa of the point.\n+     */\n+    public double getX() {\n+        return x;\n+    }\n+\n+    /**\n+     * Gets the observed value of the function at x.\n+     *\n+     * @return the observed value of the function at x.\n+     */\n+    public double getY() {\n+        return y;\n+    }\n+\n+}\n+\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/fitting/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+/**\n+ * Classes to perform curve fitting.\n+ *\n+ * Curve fitting is a special case of a least squares problem\n+ * were the parameters are the coefficients of a function {@code f}\n+ * whose graph {@code y = f(x)} should pass through sample points, and\n+ * were the objective function is the squared sum of the residuals\n+ * <code>f(x<sub>i</sub>) - y<sub>i</sub></code> for observed points\n+ * <code>(x<sub>i</sub>, y<sub>i</sub>)</code>.\n+ */\n+package org.apache.commons.math3.fitting;\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/AbstractConvergenceChecker.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+/**\n+ * Base class for all convergence checker implementations.\n+ *\n+ * @param <PAIR> Type of (point, value) pair.\n+ *\n+ * @version $Id: AbstractConvergenceChecker.java 1370215 2012-08-07 12:38:59Z sebb $\n+ * @since 3.0\n+ */\n+public abstract class AbstractConvergenceChecker<PAIR>\n+    implements ConvergenceChecker<PAIR> {\n+    /**\n+     * Relative tolerance threshold.\n+     */\n+    private final double relativeThreshold;\n+    /**\n+     * Absolute tolerance threshold.\n+     */\n+    private final double absoluteThreshold;\n+\n+    /**\n+     * Build an instance with a specified thresholds.\n+     *\n+     * @param relativeThreshold relative tolerance threshold\n+     * @param absoluteThreshold absolute tolerance threshold\n+     */\n+    public AbstractConvergenceChecker(final double relativeThreshold,\n+                                      final double absoluteThreshold) {\n+        this.relativeThreshold = relativeThreshold;\n+        this.absoluteThreshold = absoluteThreshold;\n+    }\n+\n+    /**\n+     * @return the relative threshold.\n+     */\n+    public double getRelativeThreshold() {\n+        return relativeThreshold;\n+    }\n+\n+    /**\n+     * @return the absolute threshold.\n+     */\n+    public double getAbsoluteThreshold() {\n+        return absoluteThreshold;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    public abstract boolean converged(int iteration,\n+                                      PAIR previous,\n+                                      PAIR current);\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/BaseMultiStartMultivariateOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.exception.NullArgumentException;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+import org.apache.commons.math3.optim.InitialGuess;\n+\n+/**\n+ * Base class multi-start optimizer for a multivariate function.\n+ * <br/>\n+ * This class wraps an optimizer in order to use it several times in\n+ * turn with different starting points (trying to avoid being trapped\n+ * in a local extremum when looking for a global one).\n+ * <em>It is not a \"user\" class.</em>\n+ *\n+ * @param <PAIR> Type of the point/value pair returned by the optimization\n+ * algorithm.\n+ *\n+ * @version $Id$\n+ * @since 3.0\n+ */\n+public abstract class BaseMultiStartMultivariateOptimizer<PAIR>\n+    extends BaseMultivariateOptimizer<PAIR> {\n+    /** Underlying classical optimizer. */\n+    private final BaseMultivariateOptimizer<PAIR> optimizer;\n+    /** Number of evaluations already performed for all starts. */\n+    private int totalEvaluations;\n+    /** Number of starts to go. */\n+    private int starts;\n+    /** Random generator for multi-start. */\n+    private RandomVectorGenerator generator;\n+    /** Optimization data. */\n+    private OptimizationData[] optimData;\n+    /**\n+     * Location in {@link #optimData} where the updated maximum\n+     * number of evaluations will be stored.\n+     */\n+    private int maxEvalIndex = -1;\n+    /**\n+     * Location in {@link #optimData} where the updated start value\n+     * will be stored.\n+     */\n+    private int initialGuessIndex = -1;\n+\n+    /**\n+     * Create a multi-start optimizer from a single-start optimizer.\n+     *\n+     * @param optimizer Single-start optimizer to wrap.\n+     * @param starts Number of starts to perform. If {@code starts == 1},\n+     * the {@link #optimize(OptimizationData[]) optimize} will return the\n+     * same solution as the given {@code optimizer} would return.\n+     * @param generator Random vector generator to use for restarts.\n+     * @throws NullArgumentException if {@code optimizer} or {@code generator}\n+     * is {@code null}.\n+     * @throws NotStrictlyPositiveException if {@code starts < 1}.\n+     */\n+    public BaseMultiStartMultivariateOptimizer(final BaseMultivariateOptimizer<PAIR> optimizer,\n+                                               final int starts,\n+                                               final RandomVectorGenerator generator) {\n+        super(optimizer.getConvergenceChecker());\n+\n+        if (optimizer == null ||\n+            generator == null) {\n+            throw new NullArgumentException();\n+        }\n+        if (starts < 1) {\n+            throw new NotStrictlyPositiveException(starts);\n+        }\n+\n+        this.optimizer = optimizer;\n+        this.starts = starts;\n+        this.generator = generator;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public int getEvaluations() {\n+        return totalEvaluations;\n+    }\n+\n+    /**\n+     * Gets all the optima found during the last call to {@code optimize}.\n+     * The optimizer stores all the optima found during a set of\n+     * restarts. The {@code optimize} method returns the best point only.\n+     * This method returns all the points found at the end of each starts,\n+     * including the best one already returned by the {@code optimize} method.\n+     * <br/>\n+     * The returned array as one element for each start as specified\n+     * in the constructor. It is ordered with the results from the\n+     * runs that did converge first, sorted from best to worst\n+     * objective value (i.e in ascending order if minimizing and in\n+     * descending order if maximizing), followed by {@code null} elements\n+     * corresponding to the runs that did not converge. This means all\n+     * elements will be {@code null} if the {@code optimize} method did throw\n+     * an exception.\n+     * This also means that if the first element is not {@code null}, it is\n+     * the best point found across all starts.\n+     * <br/>\n+     * The behaviour is undefined if this method is called before\n+     * {@code optimize}; it will likely throw {@code NullPointerException}.\n+     *\n+     * @return an array containing the optima sorted from best to worst.\n+     */\n+    public abstract PAIR[] getOptima();\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @throws MathIllegalStateException if {@code optData} does not contain an\n+     * instance of {@link MaxEval} or {@link InitialGuess}.\n+     */\n+    @Override\n+    public PAIR optimize(OptimizationData... optData) {\n+        // Store arguments in order to pass them to the internal optimizer.\n+       optimData = optData;\n+        // Set up base class and perform computations.\n+        return super.optimize(optData);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected PAIR doOptimize() {\n+        // Remove all instances of \"MaxEval\" and \"InitialGuess\" from the\n+        // array that will be passed to the internal optimizer.\n+        // The former is to enforce smaller numbers of allowed evaluations\n+        // (according to how many have been used up already), and the latter\n+        // to impose a different start value for each start.\n+        for (int i = 0; i < optimData.length; i++) {\n+            if (optimData[i] instanceof MaxEval) {\n+                optimData[i] = null;\n+                maxEvalIndex = i;\n+            }\n+            if (optimData[i] instanceof InitialGuess) {\n+                optimData[i] = null;\n+                initialGuessIndex = i;\n+                continue;\n+            }\n+        }\n+        if (maxEvalIndex == -1) {\n+            throw new MathIllegalStateException();\n+        }\n+        if (initialGuessIndex == -1) {\n+            throw new MathIllegalStateException();\n+        }\n+\n+        RuntimeException lastException = null;\n+        totalEvaluations = 0;\n+        clear();\n+\n+        final int maxEval = getMaxEvaluations();\n+        final double[] min = getLowerBound();\n+        final double[] max = getUpperBound();\n+        final double[] startPoint = getStartPoint();\n+\n+        // Multi-start loop.\n+        for (int i = 0; i < starts; i++) {\n+            // CHECKSTYLE: stop IllegalCatch\n+            try {\n+                // Decrease number of allowed evaluations.\n+                optimData[maxEvalIndex] = new MaxEval(maxEval - totalEvaluations);\n+                // New start value.\n+                final double[] s = (i == 0) ?\n+                    startPoint :\n+                    generator.nextVector(); // XXX This does not enforce bounds!\n+                optimData[initialGuessIndex] = new InitialGuess(s);\n+                // Optimize.\n+                final PAIR result = optimizer.optimize(optimData);\n+                store(result);\n+            } catch (RuntimeException mue) {\n+                lastException = mue;\n+            }\n+            // CHECKSTYLE: resume IllegalCatch\n+\n+            totalEvaluations += optimizer.getEvaluations();\n+        }\n+\n+        final PAIR[] optima = getOptima();\n+        if (optima.length == 0) {\n+            // All runs failed.\n+            throw lastException; // Cannot be null if starts >= 1.\n+        }\n+\n+        // Return the best optimum.\n+        return optima[0];\n+    }\n+\n+    /**\n+     * Method that will be called in order to store each found optimum.\n+     *\n+     * @param optimum Result of an optimization run.\n+     */\n+    protected abstract void store(PAIR optimum);\n+    /**\n+     * Method that will called in order to clear all stored optima.\n+     */\n+    protected abstract void clear();\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/BaseMultivariateOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.SimpleBounds;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.NumberIsTooLargeException;\n+\n+/**\n+ * Base class for implementing optimizers for multivariate functions.\n+ * It contains the boiler-plate code for initial guess and bounds\n+ * specifications.\n+ * <em>It is not a \"user\" class.</em>\n+ *\n+ * @param <PAIR> Type of the point/value pair returned by the optimization\n+ * algorithm.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class BaseMultivariateOptimizer<PAIR>\n+    extends BaseOptimizer<PAIR> {\n+    /** Initial guess. */\n+    private double[] start;\n+    /** Lower bounds. */\n+    private double[] lowerBound;\n+    /** Upper bounds. */\n+    private double[] upperBound;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected BaseMultivariateOptimizer(ConvergenceChecker<PAIR> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link MaxEval}</li>\n+     *  <li>{@link InitialGuess}</li>\n+     *  <li>{@link SimpleBounds}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     */\n+    @Override\n+    public PAIR optimize(OptimizationData... optData) {\n+        // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Check input consistency.\n+        checkParameters();\n+        // Perform optimization.\n+        return super.optimize(optData);\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link InitialGuess}</li>\n+     *  <li>{@link SimpleBounds}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof InitialGuess) {\n+                start = ((InitialGuess) data).getInitialGuess();\n+                continue;\n+            }\n+            if (data instanceof SimpleBounds) {\n+                final SimpleBounds bounds = (SimpleBounds) data;\n+                lowerBound = bounds.getLower();\n+                upperBound = bounds.getUpper();\n+                continue;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Gets the initial guess.\n+     *\n+     * @return the initial guess, or {@code null} if not set.\n+     */\n+    public double[] getStartPoint() {\n+        return start == null ? null : start.clone();\n+    }\n+    /**\n+     * @return the lower bounds, or {@code null} if not set.\n+     */\n+    public double[] getLowerBound() {\n+        return lowerBound == null ? null : lowerBound.clone();\n+    }\n+    /**\n+     * @return the upper bounds, or {@code null} if not set.\n+     */\n+    public double[] getUpperBound() {\n+        return upperBound == null ? null : upperBound.clone();\n+    }\n+\n+    /**\n+     * Check parameters consistency.\n+     */\n+    private void checkParameters() {\n+        if (start != null) {\n+            final int dim = start.length;\n+            if (lowerBound != null) {\n+                if (lowerBound.length != dim) {\n+                    throw new DimensionMismatchException(lowerBound.length, dim);\n+                }\n+                for (int i = 0; i < dim; i++) {\n+                    final double v = start[i];\n+                    final double lo = lowerBound[i];\n+                    if (v < lo) {\n+                        throw new NumberIsTooSmallException(v, lo, true);\n+                    }\n+                }\n+            }\n+            if (upperBound != null) {\n+                if (upperBound.length != dim) {\n+                    throw new DimensionMismatchException(upperBound.length, dim);\n+                }\n+                for (int i = 0; i < dim; i++) {\n+                    final double v = start[i];\n+                    final double hi = upperBound[i];\n+                    if (v > hi) {\n+                        throw new NumberIsTooLargeException(v, hi, true);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/BaseOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.util.Incrementor;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.exception.TooManyIterationsException;\n+\n+/**\n+ * Base class for implementing optimizers.\n+ * It contains the boiler-plate code for counting the number of evaluations\n+ * of the objective function and the number of iterations of the algorithm,\n+ * and storing the convergence checker.\n+ * <em>It is not a \"user\" class.</em>\n+ *\n+ * @param <PAIR> Type of the point/value pair returned by the optimization\n+ * algorithm.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class BaseOptimizer<PAIR> {\n+    /** Evaluations counter. */\n+    protected final Incrementor evaluations;\n+    /** Iterations counter. */\n+    protected final Incrementor iterations;\n+    /** Convergence checker. */\n+    private ConvergenceChecker<PAIR> checker;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected BaseOptimizer(ConvergenceChecker<PAIR> checker) {\n+        this.checker = checker;\n+\n+        evaluations = new Incrementor(0, new MaxEvalCallback());\n+        iterations = new Incrementor(0, new MaxIterCallback());\n+    }\n+\n+    /**\n+     * Gets the maximal number of function evaluations.\n+     *\n+     * @return the maximal number of function evaluations.\n+     */\n+    public int getMaxEvaluations() {\n+        return evaluations.getMaximalCount();\n+    }\n+\n+    /**\n+     * Gets the number of evaluations of the objective function.\n+     * The number of evaluations corresponds to the last call to the\n+     * {@code optimize} method. It is 0 if the method has not been\n+     * called yet.\n+     *\n+     * @return the number of evaluations of the objective function.\n+     */\n+    public int getEvaluations() {\n+        return evaluations.getCount();\n+    }\n+\n+    /**\n+     * Gets the maximal number of iterations.\n+     *\n+     * @return the maximal number of iterations.\n+     */\n+    public int getMaxIterations() {\n+        return iterations.getMaximalCount();\n+    }\n+\n+    /**\n+     * Gets the number of iterations performed by the algorithm.\n+     * The number iterations corresponds to the last call to the\n+     * {@code optimize} method. It is 0 if the method has not been\n+     * called yet.\n+     *\n+     * @return the number of evaluations of the objective function.\n+     */\n+    public int getIterations() {\n+        return iterations.getCount();\n+    }\n+\n+    /**\n+     * Gets the convergence checker.\n+     *\n+     * @return the object used to check for convergence.\n+     */\n+    public ConvergenceChecker<PAIR> getConvergenceChecker() {\n+        return checker;\n+    }\n+\n+    /**\n+     * Stores data and performs the optimization.\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link MaxEval}</li>\n+     *  <li>{@link MaxIter}</li>\n+     * </ul>\n+     * @return a point/value pair that satifies the convergence criteria.\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     * @throws TooManyIterationsException if the maximal number of\n+     * iterations is exceeded.\n+     */\n+    public PAIR optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException,\n+               TooManyIterationsException {\n+        // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Reset counters.\n+        evaluations.resetCount();\n+        iterations.resetCount();\n+        // Perform optimization.\n+        return doOptimize();\n+    }\n+\n+    /**\n+     * Performs the bulk of the optimization algorithm.\n+     *\n+     * @return the point/value pair giving the optimal value of the\n+     * objective function.\n+     */\n+    protected abstract PAIR doOptimize();\n+\n+    /**\n+     * Increment the evaluation count.\n+     *\n+     * @throws TooManyEvaluationsException if the allowed evaluations\n+     * have been exhausted.\n+     */\n+    protected void incrementEvaluationCount()\n+        throws TooManyEvaluationsException {\n+        evaluations.incrementCount();\n+    }\n+\n+    /**\n+     * Increment the iteration count.\n+     *\n+     * @throws TooManyIterationsException if the allowed iterations\n+     * have been exhausted.\n+     */\n+    protected void incrementIterationCount()\n+        throws TooManyIterationsException {\n+        iterations.incrementCount();\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link MaxEval}</li>\n+     *  <li>{@link MaxIter}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof MaxEval) {\n+                evaluations.setMaximalCount(((MaxEval) data).getMaxEval());\n+                continue;\n+            }\n+            if (data instanceof MaxIter) {\n+                iterations.setMaximalCount(((MaxIter) data).getMaxIter());\n+                continue;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Defines the action to perform when reaching the maximum number\n+     * of evaluations.\n+     */\n+    private static class MaxEvalCallback\n+        implements  Incrementor.MaxCountExceededCallback {\n+        /**\n+         * {@inheritDoc}\n+         * @throws TooManyEvaluationsException.\n+         */\n+        public void trigger(int max) {\n+            throw new TooManyEvaluationsException(max);\n+        }\n+    }\n+\n+    /**\n+     * Defines the action to perform when reaching the maximum number\n+     * of evaluations.\n+     */\n+    private static class MaxIterCallback\n+        implements Incrementor.MaxCountExceededCallback {\n+        /**\n+         * {@inheritDoc}\n+         * @throws TooManyIterationsException.\n+         */\n+        public void trigger(int max) {\n+            throw new TooManyIterationsException(max);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/ConvergenceChecker.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim;\n+\n+/**\n+ * This interface specifies how to check if an optimization algorithm has\n+ * converged.\n+ * <br/>\n+ * Deciding if convergence has been reached is a problem-dependent issue. The\n+ * user should provide a class implementing this interface to allow the\n+ * optimization algorithm to stop its search according to the problem at hand.\n+ * <br/>\n+ * For convenience, three implementations that fit simple needs are already\n+ * provided: {@link SimpleValueChecker}, {@link SimpleVectorValueChecker} and\n+ * {@link SimplePointChecker}. The first two consider that convergence is\n+ * reached when the objective function value does not change much anymore, it\n+ * does not use the point set at all.\n+ * The third one considers that convergence is reached when the input point\n+ * set does not change much anymore, it does not use objective function value\n+ * at all.\n+ *\n+ * @param <PAIR> Type of the (point, objective value) pair.\n+ *\n+ * @see org.apache.commons.math3.optim.SimplePointChecker\n+ * @see org.apache.commons.math3.optim.SimpleValueChecker\n+ * @see org.apache.commons.math3.optim.SimpleVectorValueChecker\n+ *\n+ * @version $Id: ConvergenceChecker.java 1364392 2012-07-22 18:27:12Z tn $\n+ * @since 3.0\n+ */\n+public interface ConvergenceChecker<PAIR> {\n+    /**\n+     * Check if the optimization algorithm has converged.\n+     *\n+     * @param iteration Current iteration.\n+     * @param previous Best point in the previous iteration.\n+     * @param current Best point in the current iteration.\n+     * @return {@code true} if the algorithm is considered to have converged.\n+     */\n+    boolean converged(int iteration, PAIR previous, PAIR current);\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/GoalType.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+/**\n+ * Goal type for an optimization problem (minimization or maximization of\n+ * a scalar function.\n+ *\n+ * @version $Id: GoalType.java 1364392 2012-07-22 18:27:12Z tn $\n+ * @since 2.0\n+ */\n+public enum GoalType implements OptimizationData {\n+    /** Maximization. */\n+    MAXIMIZE,\n+    /** Minimization. */\n+    MINIMIZE\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/InitialGuess.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim;\n+\n+/**\n+ * Starting point (first guess) of the optimization procedure.\n+ * <br/>\n+ * Immutable class.\n+ *\n+ * @version $Id: InitialGuess.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.1\n+ */\n+public class InitialGuess implements OptimizationData {\n+    /** Initial guess. */\n+    private final double[] init;\n+\n+    /**\n+     * @param startPoint Initial guess.\n+     */\n+    public InitialGuess(double[] startPoint) {\n+        init = startPoint.clone();\n+    }\n+\n+    /**\n+     * Gets the initial guess.\n+     *\n+     * @return the initial guess.\n+     */\n+    public double[] getInitialGuess() {\n+        return init.clone();\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/MaxEval.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+\n+/**\n+ * Maximum number of evaluations of the function to be optimized.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class MaxEval implements OptimizationData {\n+    /** Allowed number of evalutations. */\n+    private final int maxEval;\n+\n+    /**\n+     * @param max Allowed number of evalutations.\n+     * @throws NotStrictlyPositiveException if {@code max <= 0}.\n+     */\n+    public MaxEval(int max) {\n+        if (max <= 0) {\n+            throw new NotStrictlyPositiveException(max);\n+        }\n+\n+        maxEval = max;\n+    }\n+\n+    /**\n+     * Gets the maximum number of evaluations.\n+     *\n+     * @return the allowed number of evaluations.\n+     */\n+    public int getMaxEval() {\n+        return maxEval;\n+    }\n+\n+    /**\n+     * Factory method that creates instance of this class that represents\n+     * a virtually unlimited number of evaluations.\n+     *\n+     * @return a new instance suitable for allowing {@link Integer#MAX_VALUE}\n+     * evaluations.\n+     */\n+    public static MaxEval unlimited() {\n+        return new MaxEval(Integer.MAX_VALUE);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/MaxIter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+\n+/**\n+ * Maximum number of iterations performed by an (iterative) algorithm.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class MaxIter implements OptimizationData {\n+    /** Allowed number of evalutations. */\n+    private final int maxIter;\n+\n+    /**\n+     * @param max Allowed number of iterations.\n+     * @throws NotStrictlyPositiveException if {@code max <= 0}.\n+     */\n+    public MaxIter(int max) {\n+        if (max <= 0) {\n+            throw new NotStrictlyPositiveException(max);\n+        }\n+\n+        maxIter = max;\n+    }\n+\n+    /**\n+     * Gets the maximum number of evaluations.\n+     *\n+     * @return the allowed number of evaluations.\n+     */\n+    public int getMaxIter() {\n+        return maxIter;\n+    }\n+\n+    /**\n+     * Factory method that creates instance of this class that represents\n+     * a virtually unlimited number of iterations.\n+     *\n+     * @return a new instance suitable for allowing {@link Integer#MAX_VALUE}\n+     * evaluations.\n+     */\n+    public static MaxIter unlimited() {\n+        return new MaxIter(Integer.MAX_VALUE);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/ObjectiveFunction.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+\n+/**\n+ * Scalar function to be optimized.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class ObjectiveFunction implements OptimizationData {\n+    /** Function to be optimized. */\n+    private final MultivariateFunction function;\n+\n+    /**\n+     * @param f Function to be optimized.\n+     */\n+    public ObjectiveFunction(MultivariateFunction f) {\n+        function = f;\n+    }\n+\n+    /**\n+     * Gets the function to be optimized.\n+     *\n+     * @return the objective function.\n+     */\n+    public MultivariateFunction getObjectiveFunction() {\n+        return function;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/OptimizationData.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+/**\n+ * Marker interface.\n+ * Implementations will provide functionality (optional or required) needed\n+ * by the optimizers, and those will need to check the actual type of the\n+ * arguments and perform the appropriate cast in order to access the data\n+ * they need.\n+ *\n+ * @version $Id: OptimizationData.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.1\n+ */\n+public interface OptimizationData {}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/PointValuePair.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import java.io.Serializable;\n+import org.apache.commons.math3.util.Pair;\n+\n+/**\n+ * This class holds a point and the value of an objective function at\n+ * that point.\n+ *\n+ * @see PointVectorValuePair\n+ * @see org.apache.commons.math3.analysis.MultivariateFunction\n+ * @version $Id: PointValuePair.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.0\n+ */\n+public class PointValuePair extends Pair<double[], Double> implements Serializable {\n+    /** Serializable UID. */\n+    private static final long serialVersionUID = 20120513L;\n+\n+    /**\n+     * Builds a point/objective function value pair.\n+     *\n+     * @param point Point coordinates. This instance will store\n+     * a copy of the array, not the array passed as argument.\n+     * @param value Value of the objective function at the point.\n+     */\n+    public PointValuePair(final double[] point,\n+                          final double value) {\n+        this(point, value, true);\n+    }\n+\n+    /**\n+     * Builds a point/objective function value pair.\n+     *\n+     * @param point Point coordinates.\n+     * @param value Value of the objective function at the point.\n+     * @param copyArray if {@code true}, the input array will be copied,\n+     * otherwise it will be referenced.\n+     */\n+    public PointValuePair(final double[] point,\n+                          final double value,\n+                          final boolean copyArray) {\n+        super(copyArray ? ((point == null) ? null :\n+                           point.clone()) :\n+              point,\n+              value);\n+    }\n+\n+    /**\n+     * Gets the point.\n+     *\n+     * @return a copy of the stored point.\n+     */\n+    public double[] getPoint() {\n+        final double[] p = getKey();\n+        return p == null ? null : p.clone();\n+    }\n+\n+    /**\n+     * Gets a reference to the point.\n+     *\n+     * @return a reference to the internal array storing the point.\n+     */\n+    public double[] getPointRef() {\n+        return getKey();\n+    }\n+\n+    /**\n+     * Replace the instance with a data transfer object for serialization.\n+     * @return data transfer object that will be serialized\n+     */\n+    private Object writeReplace() {\n+        return new DataTransferObject(getKey(), getValue());\n+    }\n+\n+    /** Internal class used only for serialization. */\n+    private static class DataTransferObject implements Serializable {\n+        /** Serializable UID. */\n+        private static final long serialVersionUID = 20120513L;\n+        /**\n+         * Point coordinates.\n+         * @Serial\n+         */\n+        private final double[] point;\n+        /**\n+         * Value of the objective function at the point.\n+         * @Serial\n+         */\n+        private final double value;\n+\n+        /** Simple constructor.\n+         * @param point Point coordinates.\n+         * @param value Value of the objective function at the point.\n+         */\n+        public DataTransferObject(final double[] point, final double value) {\n+            this.point = point.clone();\n+            this.value = value;\n+        }\n+\n+        /** Replace the deserialized data transfer object with a {@link PointValuePair}.\n+         * @return replacement {@link PointValuePair}\n+         */\n+        private Object readResolve() {\n+            return new PointValuePair(point, value, false);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/PointVectorValuePair.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import java.io.Serializable;\n+import org.apache.commons.math3.util.Pair;\n+\n+/**\n+ * This class holds a point and the vectorial value of an objective function at\n+ * that point.\n+ *\n+ * @see PointValuePair\n+ * @see org.apache.commons.math3.analysis.MultivariateVectorFunction\n+ * @version $Id: PointVectorValuePair.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.0\n+ */\n+public class PointVectorValuePair extends Pair<double[], double[]> implements Serializable {\n+    /** Serializable UID. */\n+    private static final long serialVersionUID = 20120513L;\n+\n+    /**\n+     * Builds a point/objective function value pair.\n+     *\n+     * @param point Point coordinates. This instance will store\n+     * a copy of the array, not the array passed as argument.\n+     * @param value Value of the objective function at the point.\n+     */\n+    public PointVectorValuePair(final double[] point,\n+                                final double[] value) {\n+        this(point, value, true);\n+    }\n+\n+    /**\n+     * Build a point/objective function value pair.\n+     *\n+     * @param point Point coordinates.\n+     * @param value Value of the objective function at the point.\n+     * @param copyArray if {@code true}, the input arrays will be copied,\n+     * otherwise they will be referenced.\n+     */\n+    public PointVectorValuePair(final double[] point,\n+                                final double[] value,\n+                                final boolean copyArray) {\n+        super(copyArray ?\n+              ((point == null) ? null :\n+               point.clone()) :\n+              point,\n+              copyArray ?\n+              ((value == null) ? null :\n+               value.clone()) :\n+              value);\n+    }\n+\n+    /**\n+     * Gets the point.\n+     *\n+     * @return a copy of the stored point.\n+     */\n+    public double[] getPoint() {\n+        final double[] p = getKey();\n+        return p == null ? null : p.clone();\n+    }\n+\n+    /**\n+     * Gets a reference to the point.\n+     *\n+     * @return a reference to the internal array storing the point.\n+     */\n+    public double[] getPointRef() {\n+        return getKey();\n+    }\n+\n+    /**\n+     * Gets the value of the objective function.\n+     *\n+     * @return a copy of the stored value of the objective function.\n+     */\n+    @Override\n+    public double[] getValue() {\n+        final double[] v = super.getValue();\n+        return v == null ? null : v.clone();\n+    }\n+\n+    /**\n+     * Gets a reference to the value of the objective function.\n+     *\n+     * @return a reference to the internal array storing the value of\n+     * the objective function.\n+     */\n+    public double[] getValueRef() {\n+        return super.getValue();\n+    }\n+\n+    /**\n+     * Replace the instance with a data transfer object for serialization.\n+     * @return data transfer object that will be serialized\n+     */\n+    private Object writeReplace() {\n+        return new DataTransferObject(getKey(), getValue());\n+    }\n+\n+    /** Internal class used only for serialization. */\n+    private static class DataTransferObject implements Serializable {\n+        /** Serializable UID. */\n+        private static final long serialVersionUID = 20120513L;\n+        /**\n+         * Point coordinates.\n+         * @Serial\n+         */\n+        private final double[] point;\n+        /**\n+         * Value of the objective function at the point.\n+         * @Serial\n+         */\n+        private final double[] value;\n+\n+        /** Simple constructor.\n+         * @param point Point coordinates.\n+         * @param value Value of the objective function at the point.\n+         */\n+        public DataTransferObject(final double[] point, final double[] value) {\n+            this.point = point.clone();\n+            this.value = value.clone();\n+        }\n+\n+        /** Replace the deserialized data transfer object with a {@link PointValuePair}.\n+         * @return replacement {@link PointValuePair}\n+         */\n+        private Object readResolve() {\n+            return new PointVectorValuePair(point, value, false);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/SimpleBounds.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Simple optimization constraints: lower and upper bounds.\n+ * The valid range of the parameters is an interval that can be infinite\n+ * (in one or both directions).\n+ * <br/>\n+ * Immutable class.\n+ *\n+ * @version $Id: SimpleBounds.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.1\n+ */\n+public class SimpleBounds implements OptimizationData {\n+    /** Lower bounds. */\n+    private final double[] lower;\n+    /** Upper bounds. */\n+    private final double[] upper;\n+\n+    /**\n+     * @param lB Lower bounds.\n+     * @param uB Upper bounds.\n+     */\n+    public SimpleBounds(double[] lB,\n+                        double[] uB) {\n+        lower = lB.clone();\n+        upper = uB.clone();\n+    }\n+\n+    /**\n+     * Gets the lower bounds.\n+     *\n+     * @return the lower bounds.\n+     */\n+    public double[] getLower() {\n+        return lower.clone();\n+    }\n+    /**\n+     * Gets the upper bounds.\n+     *\n+     * @return the upper bounds.\n+     */\n+    public double[] getUpper() {\n+        return upper.clone();\n+    }\n+\n+    /**\n+     * Factory method that creates instance of this class that represents\n+     * unbounded ranges.\n+     *\n+     * @param dim Number of parameters.\n+     * @return a new instance suitable for passing to an optimizer that\n+     * requires bounds specification.\n+     */\n+    public static SimpleBounds unbounded(int dim) {\n+        final double[] lB = new double[dim];\n+        Arrays.fill(lB, Double.NEGATIVE_INFINITY);\n+        final double[] uB = new double[dim];\n+        Arrays.fill(uB, Double.POSITIVE_INFINITY);\n+\n+        return new SimpleBounds(lB, uB);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/SimplePointChecker.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.util.Pair;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+\n+/**\n+ * Simple implementation of the {@link ConvergenceChecker} interface using\n+ * only point coordinates.\n+ *\n+ * Convergence is considered to have been reached if either the relative\n+ * difference between each point coordinate are smaller than a threshold\n+ * or if either the absolute difference between the point coordinates are\n+ * smaller than another threshold.\n+ * <br/>\n+ * The {@link #converged(int,Pair,Pair) converged} method will also return\n+ * {@code true} if the number of iterations has been set (see\n+ * {@link #SimplePointChecker(double,double,int) this constructor}).\n+ *\n+ * @param <PAIR> Type of the (point, value) pair.\n+ * The type of the \"value\" part of the pair (not used by this class).\n+ *\n+ * @version $Id: SimplePointChecker.java 1413127 2012-11-24 04:37:30Z psteitz $\n+ * @since 3.0\n+ */\n+public class SimplePointChecker<PAIR extends Pair<double[], ? extends Object>>\n+    extends AbstractConvergenceChecker<PAIR> {\n+    /**\n+     * If {@link #maxIterationCount} is set to this value, the number of\n+     * iterations will never cause {@link #converged(int, Pair, Pair)}\n+     * to return {@code true}.\n+     */\n+    private static final int ITERATION_CHECK_DISABLED = -1;\n+    /**\n+     * Number of iterations after which the\n+     * {@link #converged(int, Pair, Pair)} method\n+     * will return true (unless the check is disabled).\n+     */\n+    private final int maxIterationCount;\n+\n+    /**\n+     * Build an instance with specified thresholds.\n+     * In order to perform only relative checks, the absolute tolerance\n+     * must be set to a negative value. In order to perform only absolute\n+     * checks, the relative tolerance must be set to a negative value.\n+     *\n+     * @param relativeThreshold relative tolerance threshold\n+     * @param absoluteThreshold absolute tolerance threshold\n+     */\n+    public SimplePointChecker(final double relativeThreshold,\n+                              final double absoluteThreshold) {\n+        super(relativeThreshold, absoluteThreshold);\n+        maxIterationCount = ITERATION_CHECK_DISABLED;\n+    }\n+\n+    /**\n+     * Builds an instance with specified thresholds.\n+     * In order to perform only relative checks, the absolute tolerance\n+     * must be set to a negative value. In order to perform only absolute\n+     * checks, the relative tolerance must be set to a negative value.\n+     *\n+     * @param relativeThreshold Relative tolerance threshold.\n+     * @param absoluteThreshold Absolute tolerance threshold.\n+     * @param maxIter Maximum iteration count.\n+     * @throws NotStrictlyPositiveException if {@code maxIter <= 0}.\n+     *\n+     * @since 3.1\n+     */\n+    public SimplePointChecker(final double relativeThreshold,\n+                              final double absoluteThreshold,\n+                              final int maxIter) {\n+        super(relativeThreshold, absoluteThreshold);\n+\n+        if (maxIter <= 0) {\n+            throw new NotStrictlyPositiveException(maxIter);\n+        }\n+        maxIterationCount = maxIter;\n+    }\n+\n+    /**\n+     * Check if the optimization algorithm has converged considering the\n+     * last two points.\n+     * This method may be called several times from the same algorithm\n+     * iteration with different points. This can be detected by checking the\n+     * iteration number at each call if needed. Each time this method is\n+     * called, the previous and current point correspond to points with the\n+     * same role at each iteration, so they can be compared. As an example,\n+     * simplex-based algorithms call this method for all points of the simplex,\n+     * not only for the best or worst ones.\n+     *\n+     * @param iteration Index of current iteration\n+     * @param previous Best point in the previous iteration.\n+     * @param current Best point in the current iteration.\n+     * @return {@code true} if the arguments satify the convergence criterion.\n+     */\n+    @Override\n+    public boolean converged(final int iteration,\n+                             final PAIR previous,\n+                             final PAIR current) {\n+        if (maxIterationCount != ITERATION_CHECK_DISABLED) {\n+            if (iteration >= maxIterationCount) {\n+                return true;\n+            }\n+        }\n+\n+        final double[] p = previous.getKey();\n+        final double[] c = current.getKey();\n+        for (int i = 0; i < p.length; ++i) {\n+            final double pi = p[i];\n+            final double ci = c[i];\n+            final double difference = FastMath.abs(pi - ci);\n+            final double size = FastMath.max(FastMath.abs(pi), FastMath.abs(ci));\n+            if (difference > size * getRelativeThreshold() &&\n+                difference > getAbsoluteThreshold()) {\n+                return false;\n+            }\n+        }\n+        return true;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/SimpleValueChecker.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+\n+/**\n+ * Simple implementation of the {@link ConvergenceChecker} interface using\n+ * only objective function values.\n+ *\n+ * Convergence is considered to have been reached if either the relative\n+ * difference between the objective function values is smaller than a\n+ * threshold or if either the absolute difference between the objective\n+ * function values is smaller than another threshold.\n+ * <br/>\n+ * The {@link #converged(int,PointValuePair,PointValuePair) converged}\n+ * method will also return {@code true} if the number of iterations has been set\n+ * (see {@link #SimpleValueChecker(double,double,int) this constructor}).\n+ *\n+ * @version $Id: SimpleValueChecker.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.0\n+ */\n+public class SimpleValueChecker\n+    extends AbstractConvergenceChecker<PointValuePair> {\n+    /**\n+     * If {@link #maxIterationCount} is set to this value, the number of\n+     * iterations will never cause\n+     * {@link #converged(int,PointValuePair,PointValuePair)}\n+     * to return {@code true}.\n+     */\n+    private static final int ITERATION_CHECK_DISABLED = -1;\n+    /**\n+     * Number of iterations after which the\n+     * {@link #converged(int,PointValuePair,PointValuePair)} method\n+     * will return true (unless the check is disabled).\n+     */\n+    private final int maxIterationCount;\n+\n+    /** Build an instance with specified thresholds.\n+     *\n+     * In order to perform only relative checks, the absolute tolerance\n+     * must be set to a negative value. In order to perform only absolute\n+     * checks, the relative tolerance must be set to a negative value.\n+     *\n+     * @param relativeThreshold relative tolerance threshold\n+     * @param absoluteThreshold absolute tolerance threshold\n+     */\n+    public SimpleValueChecker(final double relativeThreshold,\n+                              final double absoluteThreshold) {\n+        super(relativeThreshold, absoluteThreshold);\n+        maxIterationCount = ITERATION_CHECK_DISABLED;\n+    }\n+\n+    /**\n+     * Builds an instance with specified thresholds.\n+     *\n+     * In order to perform only relative checks, the absolute tolerance\n+     * must be set to a negative value. In order to perform only absolute\n+     * checks, the relative tolerance must be set to a negative value.\n+     *\n+     * @param relativeThreshold relative tolerance threshold\n+     * @param absoluteThreshold absolute tolerance threshold\n+     * @param maxIter Maximum iteration count.\n+     * @throws NotStrictlyPositiveException if {@code maxIter <= 0}.\n+     *\n+     * @since 3.1\n+     */\n+    public SimpleValueChecker(final double relativeThreshold,\n+                              final double absoluteThreshold,\n+                              final int maxIter) {\n+        super(relativeThreshold, absoluteThreshold);\n+\n+        if (maxIter <= 0) {\n+            throw new NotStrictlyPositiveException(maxIter);\n+        }\n+        maxIterationCount = maxIter;\n+    }\n+\n+    /**\n+     * Check if the optimization algorithm has converged considering the\n+     * last two points.\n+     * This method may be called several time from the same algorithm\n+     * iteration with different points. This can be detected by checking the\n+     * iteration number at each call if needed. Each time this method is\n+     * called, the previous and current point correspond to points with the\n+     * same role at each iteration, so they can be compared. As an example,\n+     * simplex-based algorithms call this method for all points of the simplex,\n+     * not only for the best or worst ones.\n+     *\n+     * @param iteration Index of current iteration\n+     * @param previous Best point in the previous iteration.\n+     * @param current Best point in the current iteration.\n+     * @return {@code true} if the algorithm has converged.\n+     */\n+    @Override\n+    public boolean converged(final int iteration,\n+                             final PointValuePair previous,\n+                             final PointValuePair current) {\n+        if (maxIterationCount != ITERATION_CHECK_DISABLED) {\n+            if (iteration >= maxIterationCount) {\n+                return true;\n+            }\n+        }\n+\n+        final double p = previous.getValue();\n+        final double c = current.getValue();\n+        final double difference = FastMath.abs(p - c);\n+        final double size = FastMath.max(FastMath.abs(p), FastMath.abs(c));\n+        return difference <= size * getRelativeThreshold() ||\n+            difference <= getAbsoluteThreshold();\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/SimpleVectorValueChecker.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+\n+/**\n+ * Simple implementation of the {@link ConvergenceChecker} interface using\n+ * only objective function values.\n+ *\n+ * Convergence is considered to have been reached if either the relative\n+ * difference between the objective function values is smaller than a\n+ * threshold or if either the absolute difference between the objective\n+ * function values is smaller than another threshold for all vectors elements.\n+ * <br/>\n+ * The {@link #converged(int,PointVectorValuePair,PointVectorValuePair) converged}\n+ * method will also return {@code true} if the number of iterations has been set\n+ * (see {@link #SimpleVectorValueChecker(double,double,int) this constructor}).\n+ *\n+ * @version $Id: SimpleVectorValueChecker.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.0\n+ */\n+public class SimpleVectorValueChecker\n+    extends AbstractConvergenceChecker<PointVectorValuePair> {\n+    /**\n+     * If {@link #maxIterationCount} is set to this value, the number of\n+     * iterations will never cause\n+     * {@link #converged(int,PointVectorValuePair,PointVectorValuePair)}\n+     * to return {@code true}.\n+     */\n+    private static final int ITERATION_CHECK_DISABLED = -1;\n+    /**\n+     * Number of iterations after which the\n+     * {@link #converged(int,PointVectorValuePair,PointVectorValuePair)} method\n+     * will return true (unless the check is disabled).\n+     */\n+    private final int maxIterationCount;\n+\n+    /**\n+     * Build an instance with specified thresholds.\n+     *\n+     * In order to perform only relative checks, the absolute tolerance\n+     * must be set to a negative value. In order to perform only absolute\n+     * checks, the relative tolerance must be set to a negative value.\n+     *\n+     * @param relativeThreshold relative tolerance threshold\n+     * @param absoluteThreshold absolute tolerance threshold\n+     */\n+    public SimpleVectorValueChecker(final double relativeThreshold,\n+                                    final double absoluteThreshold) {\n+        super(relativeThreshold, absoluteThreshold);\n+        maxIterationCount = ITERATION_CHECK_DISABLED;\n+    }\n+\n+    /**\n+     * Builds an instance with specified tolerance thresholds and\n+     * iteration count.\n+     *\n+     * In order to perform only relative checks, the absolute tolerance\n+     * must be set to a negative value. In order to perform only absolute\n+     * checks, the relative tolerance must be set to a negative value.\n+     *\n+     * @param relativeThreshold Relative tolerance threshold.\n+     * @param absoluteThreshold Absolute tolerance threshold.\n+     * @param maxIter Maximum iteration count.\n+     * @throws NotStrictlyPositiveException if {@code maxIter <= 0}.\n+     *\n+     * @since 3.1\n+     */\n+    public SimpleVectorValueChecker(final double relativeThreshold,\n+                                    final double absoluteThreshold,\n+                                    final int maxIter) {\n+        super(relativeThreshold, absoluteThreshold);\n+\n+        if (maxIter <= 0) {\n+            throw new NotStrictlyPositiveException(maxIter);\n+        }\n+        maxIterationCount = maxIter;\n+    }\n+\n+    /**\n+     * Check if the optimization algorithm has converged considering the\n+     * last two points.\n+     * This method may be called several times from the same algorithm\n+     * iteration with different points. This can be detected by checking the\n+     * iteration number at each call if needed. Each time this method is\n+     * called, the previous and current point correspond to points with the\n+     * same role at each iteration, so they can be compared. As an example,\n+     * simplex-based algorithms call this method for all points of the simplex,\n+     * not only for the best or worst ones.\n+     *\n+     * @param iteration Index of current iteration\n+     * @param previous Best point in the previous iteration.\n+     * @param current Best point in the current iteration.\n+     * @return {@code true} if the arguments satify the convergence criterion.\n+     */\n+    @Override\n+    public boolean converged(final int iteration,\n+                             final PointVectorValuePair previous,\n+                             final PointVectorValuePair current) {\n+        if (maxIterationCount != ITERATION_CHECK_DISABLED) {\n+            if (iteration >= maxIterationCount) {\n+                return true;\n+            }\n+        }\n+\n+        final double[] p = previous.getValueRef();\n+        final double[] c = current.getValueRef();\n+        for (int i = 0; i < p.length; ++i) {\n+            final double pi         = p[i];\n+            final double ci         = c[i];\n+            final double difference = FastMath.abs(pi - ci);\n+            final double size       = FastMath.max(FastMath.abs(pi), FastMath.abs(ci));\n+            if (difference > size * getRelativeThreshold() &&\n+                difference > getAbsoluteThreshold()) {\n+                return false;\n+            }\n+        }\n+        return true;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/LinearConstraint.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import java.io.IOException;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.io.Serializable;\n+import org.apache.commons.math3.linear.MatrixUtils;\n+import org.apache.commons.math3.linear.RealVector;\n+import org.apache.commons.math3.linear.ArrayRealVector;\n+\n+/**\n+ * A linear constraint for a linear optimization problem.\n+ * <p>\n+ * A linear constraint has one of the forms:\n+ * <ul>\n+ *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> = v</li>\n+ *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> &lt;= v</li>\n+ *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> >= v</li>\n+ *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> =\n+ *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+ *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> &lt;=\n+ *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+ *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> >=\n+ *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+ * </ul>\n+ * The c<sub>i</sub>, l<sub>i</sub> or r<sub>i</sub> are the coefficients of the constraints, the x<sub>i</sub>\n+ * are the coordinates of the current point and v is the value of the constraint.\n+ * </p>\n+ *\n+ * @version $Id: LinearConstraint.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class LinearConstraint implements Serializable {\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -764632794033034092L;\n+    /** Coefficients of the constraint (left hand side). */\n+    private final transient RealVector coefficients;\n+    /** Relationship between left and right hand sides (=, &lt;=, >=). */\n+    private final Relationship relationship;\n+    /** Value of the constraint (right hand side). */\n+    private final double value;\n+\n+    /**\n+     * Build a constraint involving a single linear equation.\n+     * <p>\n+     * A linear constraint with a single linear equation has one of the forms:\n+     * <ul>\n+     *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> = v</li>\n+     *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> &lt;= v</li>\n+     *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> >= v</li>\n+     * </ul>\n+     * </p>\n+     * @param coefficients The coefficients of the constraint (left hand side)\n+     * @param relationship The type of (in)equality used in the constraint\n+     * @param value The value of the constraint (right hand side)\n+     */\n+    public LinearConstraint(final double[] coefficients,\n+                            final Relationship relationship,\n+                            final double value) {\n+        this(new ArrayRealVector(coefficients), relationship, value);\n+    }\n+\n+    /**\n+     * Build a constraint involving a single linear equation.\n+     * <p>\n+     * A linear constraint with a single linear equation has one of the forms:\n+     * <ul>\n+     *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> = v</li>\n+     *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> &lt;= v</li>\n+     *   <li>c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> >= v</li>\n+     * </ul>\n+     * </p>\n+     * @param coefficients The coefficients of the constraint (left hand side)\n+     * @param relationship The type of (in)equality used in the constraint\n+     * @param value The value of the constraint (right hand side)\n+     */\n+    public LinearConstraint(final RealVector coefficients,\n+                            final Relationship relationship,\n+                            final double value) {\n+        this.coefficients = coefficients;\n+        this.relationship = relationship;\n+        this.value        = value;\n+    }\n+\n+    /**\n+     * Build a constraint involving two linear equations.\n+     * <p>\n+     * A linear constraint with two linear equation has one of the forms:\n+     * <ul>\n+     *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> =\n+     *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+     *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> &lt;=\n+     *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+     *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> >=\n+     *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+     * </ul>\n+     * </p>\n+     * @param lhsCoefficients The coefficients of the linear expression on the left hand side of the constraint\n+     * @param lhsConstant The constant term of the linear expression on the left hand side of the constraint\n+     * @param relationship The type of (in)equality used in the constraint\n+     * @param rhsCoefficients The coefficients of the linear expression on the right hand side of the constraint\n+     * @param rhsConstant The constant term of the linear expression on the right hand side of the constraint\n+     */\n+    public LinearConstraint(final double[] lhsCoefficients, final double lhsConstant,\n+                            final Relationship relationship,\n+                            final double[] rhsCoefficients, final double rhsConstant) {\n+        double[] sub = new double[lhsCoefficients.length];\n+        for (int i = 0; i < sub.length; ++i) {\n+            sub[i] = lhsCoefficients[i] - rhsCoefficients[i];\n+        }\n+        this.coefficients = new ArrayRealVector(sub, false);\n+        this.relationship = relationship;\n+        this.value        = rhsConstant - lhsConstant;\n+    }\n+\n+    /**\n+     * Build a constraint involving two linear equations.\n+     * <p>\n+     * A linear constraint with two linear equation has one of the forms:\n+     * <ul>\n+     *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> =\n+     *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+     *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> &lt;=\n+     *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+     *   <li>l<sub>1</sub>x<sub>1</sub> + ... l<sub>n</sub>x<sub>n</sub> + l<sub>cst</sub> >=\n+     *       r<sub>1</sub>x<sub>1</sub> + ... r<sub>n</sub>x<sub>n</sub> + r<sub>cst</sub></li>\n+     * </ul>\n+     * </p>\n+     * @param lhsCoefficients The coefficients of the linear expression on the left hand side of the constraint\n+     * @param lhsConstant The constant term of the linear expression on the left hand side of the constraint\n+     * @param relationship The type of (in)equality used in the constraint\n+     * @param rhsCoefficients The coefficients of the linear expression on the right hand side of the constraint\n+     * @param rhsConstant The constant term of the linear expression on the right hand side of the constraint\n+     */\n+    public LinearConstraint(final RealVector lhsCoefficients, final double lhsConstant,\n+                            final Relationship relationship,\n+                            final RealVector rhsCoefficients, final double rhsConstant) {\n+        this.coefficients = lhsCoefficients.subtract(rhsCoefficients);\n+        this.relationship = relationship;\n+        this.value        = rhsConstant - lhsConstant;\n+    }\n+\n+    /**\n+     * Gets the coefficients of the constraint (left hand side).\n+     *\n+     * @return the coefficients of the constraint (left hand side).\n+     */\n+    public RealVector getCoefficients() {\n+        return coefficients;\n+    }\n+\n+    /**\n+     * Gets the relationship between left and right hand sides.\n+     *\n+     * @return the relationship between left and right hand sides.\n+     */\n+    public Relationship getRelationship() {\n+        return relationship;\n+    }\n+\n+    /**\n+     * Gets the value of the constraint (right hand side).\n+     *\n+     * @return the value of the constraint (right hand side).\n+     */\n+    public double getValue() {\n+        return value;\n+    }\n+\n+    @Override\n+    public boolean equals(Object other) {\n+        if (this == other) {\n+            return true;\n+        }\n+        if (other instanceof LinearConstraint) {\n+            LinearConstraint rhs = (LinearConstraint) other;\n+            return relationship == rhs.relationship &&\n+                value == rhs.value &&\n+                coefficients.equals(rhs.coefficients);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return relationship.hashCode() ^\n+            Double.valueOf(value).hashCode() ^\n+            coefficients.hashCode();\n+    }\n+\n+    /**\n+     * Serialize the instance.\n+     * @param oos stream where object should be written\n+     * @throws IOException if object cannot be written to stream\n+     */\n+    private void writeObject(ObjectOutputStream oos)\n+        throws IOException {\n+        oos.defaultWriteObject();\n+        MatrixUtils.serializeRealVector(coefficients, oos);\n+    }\n+\n+    /**\n+     * Deserialize the instance.\n+     * @param ois stream from which the object should be read\n+     * @throws ClassNotFoundException if a class in the stream cannot be found\n+     * @throws IOException if object cannot be read from the stream\n+     */\n+    private void readObject(ObjectInputStream ois)\n+      throws ClassNotFoundException, IOException {\n+        ois.defaultReadObject();\n+        MatrixUtils.deserializeRealVector(this, \"coefficients\", ois);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/LinearConstraintSet.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import java.util.Set;\n+import java.util.HashSet;\n+import java.util.Collection;\n+import java.util.Collections;\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * Class that represents a set of {@link LinearConstraint linear constraints}.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class LinearConstraintSet implements OptimizationData {\n+    /** Set of constraints. */\n+    private final Set<LinearConstraint> linearConstraints\n+        = new HashSet<LinearConstraint>();\n+\n+    /**\n+     * Creates a set containing the given constraints.\n+     *\n+     * @param constraints Constraints.\n+     */\n+    public LinearConstraintSet(LinearConstraint... constraints) {\n+        for (LinearConstraint c : constraints) {\n+            linearConstraints.add(c);\n+        }\n+    }\n+\n+    /**\n+     * Creates a set containing the given constraints.\n+     *\n+     * @param constraints Constraints.\n+     */\n+    public LinearConstraintSet(Collection<LinearConstraint> constraints) {\n+        linearConstraints.addAll(constraints);\n+    }\n+\n+    /**\n+     * Gets the set of linear constraints.\n+     *\n+     * @return the constraints.\n+     */\n+    public Collection<LinearConstraint> getConstraints() {\n+        return Collections.unmodifiableSet(linearConstraints);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/LinearObjectiveFunction.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import java.io.IOException;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.io.Serializable;\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.linear.MatrixUtils;\n+import org.apache.commons.math3.linear.RealVector;\n+import org.apache.commons.math3.linear.ArrayRealVector;\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * An objective function for a linear optimization problem.\n+ * <p>\n+ * A linear objective function has one the form:\n+ * <pre>\n+ * c<sub>1</sub>x<sub>1</sub> + ... c<sub>n</sub>x<sub>n</sub> + d\n+ * </pre>\n+ * The c<sub>i</sub> and d are the coefficients of the equation,\n+ * the x<sub>i</sub> are the coordinates of the current point.\n+ * </p>\n+ *\n+ * @version $Id: LinearObjectiveFunction.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class LinearObjectiveFunction\n+    implements MultivariateFunction,\n+               OptimizationData,\n+               Serializable {\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -4531815507568396090L;\n+    /** Coefficients of the linear equation (c<sub>i</sub>). */\n+    private final transient RealVector coefficients;\n+    /** Constant term of the linear equation. */\n+    private final double constantTerm;\n+\n+    /**\n+     * @param coefficients Coefficients for the linear equation being optimized.\n+     * @param constantTerm Constant term of the linear equation.\n+     */\n+    public LinearObjectiveFunction(double[] coefficients, double constantTerm) {\n+        this(new ArrayRealVector(coefficients), constantTerm);\n+    }\n+\n+    /**\n+     * @param coefficients Coefficients for the linear equation being optimized.\n+     * @param constantTerm Constant term of the linear equation.\n+     */\n+    public LinearObjectiveFunction(RealVector coefficients, double constantTerm) {\n+        this.coefficients = coefficients;\n+        this.constantTerm = constantTerm;\n+    }\n+\n+    /**\n+     * Gets the coefficients of the linear equation being optimized.\n+     *\n+     * @return coefficients of the linear equation being optimized.\n+     */\n+    public RealVector getCoefficients() {\n+        return coefficients;\n+    }\n+\n+    /**\n+     * Gets the constant of the linear equation being optimized.\n+     *\n+     * @return constant of the linear equation being optimized.\n+     */\n+    public double getConstantTerm() {\n+        return constantTerm;\n+    }\n+\n+    /**\n+     * Computes the value of the linear equation at the current point.\n+     *\n+     * @param point Point at which linear equation must be evaluated.\n+     * @return the value of the linear equation at the current point.\n+     */\n+    public double value(final double[] point) {\n+        return value(new ArrayRealVector(point, false));\n+    }\n+\n+    /**\n+     * Computes the value of the linear equation at the current point.\n+     *\n+     * @param point Point at which linear equation must be evaluated.\n+     * @return the value of the linear equation at the current point.\n+     */\n+    public double value(final RealVector point) {\n+        return coefficients.dotProduct(point) + constantTerm;\n+    }\n+\n+    @Override\n+    public boolean equals(Object other) {\n+        if (this == other) {\n+            return true;\n+        }\n+        if (other instanceof LinearObjectiveFunction) {\n+            LinearObjectiveFunction rhs = (LinearObjectiveFunction) other;\n+          return (constantTerm == rhs.constantTerm) && coefficients.equals(rhs.coefficients);\n+        }\n+\n+        return false;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Double.valueOf(constantTerm).hashCode() ^ coefficients.hashCode();\n+    }\n+\n+    /**\n+     * Serialize the instance.\n+     * @param oos stream where object should be written\n+     * @throws IOException if object cannot be written to stream\n+     */\n+    private void writeObject(ObjectOutputStream oos)\n+        throws IOException {\n+        oos.defaultWriteObject();\n+        MatrixUtils.serializeRealVector(coefficients, oos);\n+    }\n+\n+    /**\n+     * Deserialize the instance.\n+     * @param ois stream from which the object should be read\n+     * @throws ClassNotFoundException if a class in the stream cannot be found\n+     * @throws IOException if object cannot be read from the stream\n+     */\n+    private void readObject(ObjectInputStream ois)\n+      throws ClassNotFoundException, IOException {\n+        ois.defaultReadObject();\n+        MatrixUtils.deserializeRealVector(this, \"coefficients\", ois);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/LinearOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import org.apache.commons.math3.exception.TooManyIterationsException;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\n+\n+/**\n+ * Base class for implementing linear optimizers.\n+ *\n+ * @version $Id: AbstractLinearOptimizer.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.1\n+ */\n+public abstract class LinearOptimizer\n+    extends MultivariateOptimizer {\n+    /**\n+     * Linear objective function.\n+     */\n+    private LinearObjectiveFunction function;\n+    /**\n+     * Linear constraints.\n+     */\n+    private Collection<LinearConstraint> linearConstraints;\n+    /**\n+     * Whether to restrict the variables to non-negative values.\n+     */\n+    private boolean nonNegative;\n+\n+    /**\n+     * Simple constructor with default settings.\n+     *\n+     */\n+    protected LinearOptimizer() {\n+        super(null); // No convergence checker.\n+    }\n+\n+    /**\n+     * @return {@code true} if the variables are restricted to non-negative values.\n+     */\n+    protected boolean isRestrictedToNonNegative() {\n+        return nonNegative;\n+    }\n+\n+    /**\n+     * @return the optimization type.\n+     */\n+    protected LinearObjectiveFunction getFunction() {\n+        return function;\n+    }\n+\n+    /**\n+     * @return the optimization type.\n+     */\n+    protected Collection<LinearConstraint> getConstraints() {\n+        return Collections.unmodifiableCollection(linearConstraints);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxIter}</li>\n+     *  <li>{@link LinearObjectiveFunction}</li>\n+     *  <li>{@link LinearConstraintSet}</li>\n+     *  <li>{@link NonNegativeConstraint}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyIterationsException if the maximal number of\n+     * iterations is exceeded.\n+     */\n+    @Override\n+    public PointValuePair optimize(OptimizationData... optData)\n+        throws TooManyIterationsException {\n+         // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link LinearObjectiveFunction}</li>\n+     *  <li>{@link LinearConstraintSet}</li>\n+     *  <li>{@link NonNegativeConstraint}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof LinearObjectiveFunction) {\n+                function = (LinearObjectiveFunction) data;\n+                continue;\n+            }\n+            if (data instanceof LinearConstraintSet) {\n+                linearConstraints = ((LinearConstraintSet) data).getConstraints();\n+                continue;\n+            }\n+            if  (data instanceof NonNegativeConstraint) {\n+                nonNegative = ((NonNegativeConstraint) data).isRestrictedToNonNegative();\n+                continue;\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/NoFeasibleSolutionException.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+\n+/**\n+ * This class represents exceptions thrown by optimizers when no solution fulfills the constraints.\n+ *\n+ * @version $Id: NoFeasibleSolutionException.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class NoFeasibleSolutionException extends MathIllegalStateException {\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -3044253632189082760L;\n+\n+    /**\n+     * Simple constructor using a default message.\n+     */\n+    public NoFeasibleSolutionException() {\n+        super(LocalizedFormats.NO_FEASIBLE_SOLUTION);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/NonNegativeConstraint.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * A constraint for a linear optimization problem indicating whether all\n+ * variables must be restricted to non-negative values.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class NonNegativeConstraint implements OptimizationData {\n+    /** Whether the variables are all positive. */\n+    private final boolean isRestricted;\n+\n+    /**\n+     * @param restricted If {@code true}, all the variables must be positive.\n+     */\n+    public NonNegativeConstraint(boolean restricted) {\n+        isRestricted = restricted;\n+    }\n+\n+    /**\n+     * Indicates whether all the variables must be restricted to non-negative\n+     * values.\n+     *\n+     * @return {@code true} if all the variables must be positive.\n+     */\n+    public boolean isRestrictedToNonNegative() {\n+        return isRestricted;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/Relationship.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+/**\n+ * Types of relationships between two cells in a Solver {@link LinearConstraint}.\n+ *\n+ * @version $Id: Relationship.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public enum Relationship {\n+    /** Equality relationship. */\n+    EQ(\"=\"),\n+    /** Lesser than or equal relationship. */\n+    LEQ(\"<=\"),\n+    /** Greater than or equal relationship. */\n+    GEQ(\">=\");\n+\n+    /** Display string for the relationship. */\n+    private final String stringValue;\n+\n+    /**\n+     * Simple constructor.\n+     *\n+     * @param stringValue Display string for the relationship.\n+     */\n+    private Relationship(String stringValue) {\n+        this.stringValue = stringValue;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return stringValue;\n+    }\n+\n+    /**\n+     * Gets the relationship obtained when multiplying all coefficients by -1.\n+     *\n+     * @return the opposite relationship.\n+     */\n+    public Relationship oppositeRelationship() {\n+        switch (this) {\n+        case LEQ :\n+            return GEQ;\n+        case GEQ :\n+            return LEQ;\n+        default :\n+            return EQ;\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/SimplexSolver.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.math3.exception.TooManyIterationsException;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.util.Precision;\n+\n+/**\n+ * Solves a linear problem using the \"Two-Phase Simplex\" method.\n+ *\n+ * @version $Id: SimplexSolver.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class SimplexSolver extends LinearOptimizer {\n+    /** Default amount of error to accept for algorithm convergence. */\n+    private static final double DEFAULT_EPSILON = 1.0e-6;\n+\n+    /** Default amount of error to accept in floating point comparisons (as ulps). */\n+    private static final int DEFAULT_ULPS = 10;\n+\n+    /** Amount of error to accept for algorithm convergence. */\n+    private final double epsilon;\n+\n+    /** Amount of error to accept in floating point comparisons (as ulps). */\n+    private final int maxUlps;\n+\n+    /**\n+     * Builds a simplex solver with default settings.\n+     */\n+    public SimplexSolver() {\n+        this(DEFAULT_EPSILON, DEFAULT_ULPS);\n+    }\n+\n+    /**\n+     * Builds a simplex solver with a specified accepted amount of error.\n+     *\n+     * @param epsilon Amount of error to accept for algorithm convergence.\n+     * @param maxUlps Amount of error to accept in floating point comparisons.\n+     */\n+    public SimplexSolver(final double epsilon,\n+                         final int maxUlps) {\n+        this.epsilon = epsilon;\n+        this.maxUlps = maxUlps;\n+    }\n+\n+    /**\n+     * Returns the column with the most negative coefficient in the objective function row.\n+     *\n+     * @param tableau Simple tableau for the problem.\n+     * @return the column with the most negative coefficient.\n+     */\n+    private Integer getPivotColumn(SimplexTableau tableau) {\n+        double minValue = 0;\n+        Integer minPos = null;\n+        for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getWidth() - 1; i++) {\n+            final double entry = tableau.getEntry(0, i);\n+            // check if the entry is strictly smaller than the current minimum\n+            // do not use a ulp/epsilon check\n+            if (entry < minValue) {\n+                minValue = entry;\n+                minPos = i;\n+            }\n+        }\n+        return minPos;\n+    }\n+\n+    /**\n+     * Returns the row with the minimum ratio as given by the minimum ratio test (MRT).\n+     *\n+     * @param tableau Simple tableau for the problem.\n+     * @param col Column to test the ratio of (see {@link #getPivotColumn(SimplexTableau)}).\n+     * @return the row with the minimum ratio.\n+     */\n+    private Integer getPivotRow(SimplexTableau tableau, final int col) {\n+        // create a list of all the rows that tie for the lowest score in the minimum ratio test\n+        List<Integer> minRatioPositions = new ArrayList<Integer>();\n+        double minRatio = Double.MAX_VALUE;\n+        for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getHeight(); i++) {\n+            final double rhs = tableau.getEntry(i, tableau.getWidth() - 1);\n+            final double entry = tableau.getEntry(i, col);\n+\n+            if (Precision.compareTo(entry, 0d, maxUlps) > 0) {\n+                final double ratio = rhs / entry;\n+                // check if the entry is strictly equal to the current min ratio\n+                // do not use a ulp/epsilon check\n+                final int cmp = Double.compare(ratio, minRatio);\n+                if (cmp == 0) {\n+                    minRatioPositions.add(i);\n+                } else if (cmp < 0) {\n+                    minRatio = ratio;\n+                    minRatioPositions = new ArrayList<Integer>();\n+                    minRatioPositions.add(i);\n+                }\n+            }\n+        }\n+\n+        if (minRatioPositions.size() == 0) {\n+            return null;\n+        } else if (minRatioPositions.size() > 1) {\n+            // there's a degeneracy as indicated by a tie in the minimum ratio test\n+\n+            // 1. check if there's an artificial variable that can be forced out of the basis\n+            if (tableau.getNumArtificialVariables() > 0) {\n+                for (Integer row : minRatioPositions) {\n+                    for (int i = 0; i < tableau.getNumArtificialVariables(); i++) {\n+                        int column = i + tableau.getArtificialVariableOffset();\n+                        final double entry = tableau.getEntry(row, column);\n+                        if (Precision.equals(entry, 1d, maxUlps) && row.equals(tableau.getBasicRow(column))) {\n+                            return row;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // 2. apply Bland's rule to prevent cycling:\n+            //    take the row for which the corresponding basic variable has the smallest index\n+            //\n+            // see http://www.stanford.edu/class/msande310/blandrule.pdf\n+            // see http://en.wikipedia.org/wiki/Bland%27s_rule (not equivalent to the above paper)\n+            //\n+            // Additional heuristic: if we did not get a solution after half of maxIterations\n+            //                       revert to the simple case of just returning the top-most row\n+            // This heuristic is based on empirical data gathered while investigating MATH-828.\n+            if (getEvaluations() < getMaxEvaluations() / 2) {\n+                Integer minRow = null;\n+                int minIndex = tableau.getWidth();\n+                final int varStart = tableau.getNumObjectiveFunctions();\n+                final int varEnd = tableau.getWidth() - 1;\n+                for (Integer row : minRatioPositions) {\n+                    for (int i = varStart; i < varEnd && !row.equals(minRow); i++) {\n+                        final Integer basicRow = tableau.getBasicRow(i);\n+                        if (basicRow != null && basicRow.equals(row)) {\n+                            if (i < minIndex) {\n+                                minIndex = i;\n+                                minRow = row;\n+                            }\n+                        }\n+                    }\n+                }\n+                return minRow;\n+            }\n+        }\n+        return minRatioPositions.get(0);\n+    }\n+\n+    /**\n+     * Runs one iteration of the Simplex method on the given model.\n+     *\n+     * @param tableau Simple tableau for the problem.\n+     * @throws TooManyIterationsException if the allowed number of iterations has been exhausted.\n+     * @throws UnboundedSolutionException if the model is found not to have a bounded solution.\n+     */\n+    protected void doIteration(final SimplexTableau tableau)\n+        throws TooManyIterationsException,\n+               UnboundedSolutionException {\n+\n+        incrementIterationCount();\n+\n+        Integer pivotCol = getPivotColumn(tableau);\n+        Integer pivotRow = getPivotRow(tableau, pivotCol);\n+        if (pivotRow == null) {\n+            throw new UnboundedSolutionException();\n+        }\n+\n+        // set the pivot element to 1\n+        double pivotVal = tableau.getEntry(pivotRow, pivotCol);\n+        tableau.divideRow(pivotRow, pivotVal);\n+\n+        // set the rest of the pivot column to 0\n+        for (int i = 0; i < tableau.getHeight(); i++) {\n+            if (i != pivotRow) {\n+                final double multiplier = tableau.getEntry(i, pivotCol);\n+                tableau.subtractRow(i, pivotRow, multiplier);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Solves Phase 1 of the Simplex method.\n+     *\n+     * @param tableau Simple tableau for the problem.\n+     * @throws TooManyIterationsException if the allowed number of iterations has been exhausted.\n+     * @throws UnboundedSolutionException if the model is found not to have a bounded solution.\n+     * @throws NoFeasibleSolutionException if there is no feasible solution?\n+     */\n+    protected void solvePhase1(final SimplexTableau tableau)\n+        throws TooManyIterationsException,\n+               UnboundedSolutionException,\n+               NoFeasibleSolutionException {\n+\n+        // make sure we're in Phase 1\n+        if (tableau.getNumArtificialVariables() == 0) {\n+            return;\n+        }\n+\n+        while (!tableau.isOptimal()) {\n+            doIteration(tableau);\n+        }\n+\n+        // if W is not zero then we have no feasible solution\n+        if (!Precision.equals(tableau.getEntry(0, tableau.getRhsOffset()), 0d, epsilon)) {\n+            throw new NoFeasibleSolutionException();\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public PointValuePair doOptimize()\n+        throws TooManyIterationsException,\n+               UnboundedSolutionException,\n+               NoFeasibleSolutionException {\n+        final SimplexTableau tableau =\n+            new SimplexTableau(getFunction(),\n+                               getConstraints(),\n+                               getGoalType(),\n+                               isRestrictedToNonNegative(),\n+                               epsilon,\n+                               maxUlps);\n+\n+        solvePhase1(tableau);\n+        tableau.dropPhase1Objective();\n+\n+        while (!tableau.isOptimal()) {\n+            doIteration(tableau);\n+        }\n+        return tableau.getSolution();\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/SimplexTableau.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import java.io.IOException;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.commons.math3.linear.Array2DRowRealMatrix;\n+import org.apache.commons.math3.linear.MatrixUtils;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.linear.RealVector;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.util.Precision;\n+\n+/**\n+ * A tableau for use in the Simplex method.\n+ *\n+ * <p>\n+ * Example:\n+ * <pre>\n+ *   W |  Z |  x1 |  x2 |  x- | s1 |  s2 |  a1 |  RHS\n+ * ---------------------------------------------------\n+ *  -1    0    0     0     0     0     0     1     0   &lt;= phase 1 objective\n+ *   0    1   -15   -10    0     0     0     0     0   &lt;= phase 2 objective\n+ *   0    0    1     0     0     1     0     0     2   &lt;= constraint 1\n+ *   0    0    0     1     0     0     1     0     3   &lt;= constraint 2\n+ *   0    0    1     1     0     0     0     1     4   &lt;= constraint 3\n+ * </pre>\n+ * W: Phase 1 objective function</br>\n+ * Z: Phase 2 objective function</br>\n+ * x1 &amp; x2: Decision variables</br>\n+ * x-: Extra decision variable to allow for negative values</br>\n+ * s1 &amp; s2: Slack/Surplus variables</br>\n+ * a1: Artificial variable</br>\n+ * RHS: Right hand side</br>\n+ * </p>\n+ * @version $Id: SimplexTableau.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+class SimplexTableau implements Serializable {\n+\n+    /** Column label for negative vars. */\n+    private static final String NEGATIVE_VAR_COLUMN_LABEL = \"x-\";\n+\n+    /** Default amount of error to accept in floating point comparisons (as ulps). */\n+    private static final int DEFAULT_ULPS = 10;\n+\n+    /** The cut-off threshold to zero-out entries. */\n+    private static final double CUTOFF_THRESHOLD = 1e-12;\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -1369660067587938365L;\n+\n+    /** Linear objective function. */\n+    private final LinearObjectiveFunction f;\n+\n+    /** Linear constraints. */\n+    private final List<LinearConstraint> constraints;\n+\n+    /** Whether to restrict the variables to non-negative values. */\n+    private final boolean restrictToNonNegative;\n+\n+    /** The variables each column represents */\n+    private final List<String> columnLabels = new ArrayList<String>();\n+\n+    /** Simple tableau. */\n+    private transient RealMatrix tableau;\n+\n+    /** Number of decision variables. */\n+    private final int numDecisionVariables;\n+\n+    /** Number of slack variables. */\n+    private final int numSlackVariables;\n+\n+    /** Number of artificial variables. */\n+    private int numArtificialVariables;\n+\n+    /** Amount of error to accept when checking for optimality. */\n+    private final double epsilon;\n+\n+    /** Amount of error to accept in floating point comparisons. */\n+    private final int maxUlps;\n+\n+    /**\n+     * Builds a tableau for a linear problem.\n+     *\n+     * @param f Linear objective function.\n+     * @param constraints Linear constraints.\n+     * @param goalType Optimization goal: either {@link GoalType#MAXIMIZE}\n+     * or {@link GoalType#MINIMIZE}.\n+     * @param restrictToNonNegative Whether to restrict the variables to non-negative values.\n+     * @param epsilon Amount of error to accept when checking for optimality.\n+     */\n+    SimplexTableau(final LinearObjectiveFunction f,\n+                   final Collection<LinearConstraint> constraints,\n+                   final GoalType goalType,\n+                   final boolean restrictToNonNegative,\n+                   final double epsilon) {\n+        this(f, constraints, goalType, restrictToNonNegative, epsilon, DEFAULT_ULPS);\n+    }\n+\n+    /**\n+     * Build a tableau for a linear problem.\n+     * @param f linear objective function\n+     * @param constraints linear constraints\n+     * @param goalType type of optimization goal: either {@link GoalType#MAXIMIZE} or {@link GoalType#MINIMIZE}\n+     * @param restrictToNonNegative whether to restrict the variables to non-negative values\n+     * @param epsilon amount of error to accept when checking for optimality\n+     * @param maxUlps amount of error to accept in floating point comparisons\n+     */\n+    SimplexTableau(final LinearObjectiveFunction f,\n+                   final Collection<LinearConstraint> constraints,\n+                   final GoalType goalType,\n+                   final boolean restrictToNonNegative,\n+                   final double epsilon,\n+                   final int maxUlps) {\n+        this.f                      = f;\n+        this.constraints            = normalizeConstraints(constraints);\n+        this.restrictToNonNegative  = restrictToNonNegative;\n+        this.epsilon                = epsilon;\n+        this.maxUlps                = maxUlps;\n+        this.numDecisionVariables   = f.getCoefficients().getDimension() +\n+                                      (restrictToNonNegative ? 0 : 1);\n+        this.numSlackVariables      = getConstraintTypeCounts(Relationship.LEQ) +\n+                                      getConstraintTypeCounts(Relationship.GEQ);\n+        this.numArtificialVariables = getConstraintTypeCounts(Relationship.EQ) +\n+                                      getConstraintTypeCounts(Relationship.GEQ);\n+        this.tableau = createTableau(goalType == GoalType.MAXIMIZE);\n+        initializeColumnLabels();\n+    }\n+\n+    /**\n+     * Initialize the labels for the columns.\n+     */\n+    protected void initializeColumnLabels() {\n+      if (getNumObjectiveFunctions() == 2) {\n+        columnLabels.add(\"W\");\n+      }\n+      columnLabels.add(\"Z\");\n+      for (int i = 0; i < getOriginalNumDecisionVariables(); i++) {\n+        columnLabels.add(\"x\" + i);\n+      }\n+      if (!restrictToNonNegative) {\n+        columnLabels.add(NEGATIVE_VAR_COLUMN_LABEL);\n+      }\n+      for (int i = 0; i < getNumSlackVariables(); i++) {\n+        columnLabels.add(\"s\" + i);\n+      }\n+      for (int i = 0; i < getNumArtificialVariables(); i++) {\n+        columnLabels.add(\"a\" + i);\n+      }\n+      columnLabels.add(\"RHS\");\n+    }\n+\n+    /**\n+     * Create the tableau by itself.\n+     * @param maximize if true, goal is to maximize the objective function\n+     * @return created tableau\n+     */\n+    protected RealMatrix createTableau(final boolean maximize) {\n+\n+        // create a matrix of the correct size\n+        int width = numDecisionVariables + numSlackVariables +\n+        numArtificialVariables + getNumObjectiveFunctions() + 1; // + 1 is for RHS\n+        int height = constraints.size() + getNumObjectiveFunctions();\n+        Array2DRowRealMatrix matrix = new Array2DRowRealMatrix(height, width);\n+\n+        // initialize the objective function rows\n+        if (getNumObjectiveFunctions() == 2) {\n+            matrix.setEntry(0, 0, -1);\n+        }\n+        int zIndex = (getNumObjectiveFunctions() == 1) ? 0 : 1;\n+        matrix.setEntry(zIndex, zIndex, maximize ? 1 : -1);\n+        RealVector objectiveCoefficients =\n+            maximize ? f.getCoefficients().mapMultiply(-1) : f.getCoefficients();\n+        copyArray(objectiveCoefficients.toArray(), matrix.getDataRef()[zIndex]);\n+        matrix.setEntry(zIndex, width - 1,\n+            maximize ? f.getConstantTerm() : -1 * f.getConstantTerm());\n+\n+        if (!restrictToNonNegative) {\n+            matrix.setEntry(zIndex, getSlackVariableOffset() - 1,\n+                getInvertedCoefficientSum(objectiveCoefficients));\n+        }\n+\n+        // initialize the constraint rows\n+        int slackVar = 0;\n+        int artificialVar = 0;\n+        for (int i = 0; i < constraints.size(); i++) {\n+            LinearConstraint constraint = constraints.get(i);\n+            int row = getNumObjectiveFunctions() + i;\n+\n+            // decision variable coefficients\n+            copyArray(constraint.getCoefficients().toArray(), matrix.getDataRef()[row]);\n+\n+            // x-\n+            if (!restrictToNonNegative) {\n+                matrix.setEntry(row, getSlackVariableOffset() - 1,\n+                    getInvertedCoefficientSum(constraint.getCoefficients()));\n+            }\n+\n+            // RHS\n+            matrix.setEntry(row, width - 1, constraint.getValue());\n+\n+            // slack variables\n+            if (constraint.getRelationship() == Relationship.LEQ) {\n+                matrix.setEntry(row, getSlackVariableOffset() + slackVar++, 1);  // slack\n+            } else if (constraint.getRelationship() == Relationship.GEQ) {\n+                matrix.setEntry(row, getSlackVariableOffset() + slackVar++, -1); // excess\n+            }\n+\n+            // artificial variables\n+            if ((constraint.getRelationship() == Relationship.EQ) ||\n+                    (constraint.getRelationship() == Relationship.GEQ)) {\n+                matrix.setEntry(0, getArtificialVariableOffset() + artificialVar, 1);\n+                matrix.setEntry(row, getArtificialVariableOffset() + artificialVar++, 1);\n+                matrix.setRowVector(0, matrix.getRowVector(0).subtract(matrix.getRowVector(row)));\n+            }\n+        }\n+\n+        return matrix;\n+    }\n+\n+    /**\n+     * Get new versions of the constraints which have positive right hand sides.\n+     * @param originalConstraints original (not normalized) constraints\n+     * @return new versions of the constraints\n+     */\n+    public List<LinearConstraint> normalizeConstraints(Collection<LinearConstraint> originalConstraints) {\n+        List<LinearConstraint> normalized = new ArrayList<LinearConstraint>();\n+        for (LinearConstraint constraint : originalConstraints) {\n+            normalized.add(normalize(constraint));\n+        }\n+        return normalized;\n+    }\n+\n+    /**\n+     * Get a new equation equivalent to this one with a positive right hand side.\n+     * @param constraint reference constraint\n+     * @return new equation\n+     */\n+    private LinearConstraint normalize(final LinearConstraint constraint) {\n+        if (constraint.getValue() < 0) {\n+            return new LinearConstraint(constraint.getCoefficients().mapMultiply(-1),\n+                                        constraint.getRelationship().oppositeRelationship(),\n+                                        -1 * constraint.getValue());\n+        }\n+        return new LinearConstraint(constraint.getCoefficients(),\n+                                    constraint.getRelationship(), constraint.getValue());\n+    }\n+\n+    /**\n+     * Get the number of objective functions in this tableau.\n+     * @return 2 for Phase 1.  1 for Phase 2.\n+     */\n+    protected final int getNumObjectiveFunctions() {\n+        return this.numArtificialVariables > 0 ? 2 : 1;\n+    }\n+\n+    /**\n+     * Get a count of constraints corresponding to a specified relationship.\n+     * @param relationship relationship to count\n+     * @return number of constraint with the specified relationship\n+     */\n+    private int getConstraintTypeCounts(final Relationship relationship) {\n+        int count = 0;\n+        for (final LinearConstraint constraint : constraints) {\n+            if (constraint.getRelationship() == relationship) {\n+                ++count;\n+            }\n+        }\n+        return count;\n+    }\n+\n+    /**\n+     * Get the -1 times the sum of all coefficients in the given array.\n+     * @param coefficients coefficients to sum\n+     * @return the -1 times the sum of all coefficients in the given array.\n+     */\n+    protected static double getInvertedCoefficientSum(final RealVector coefficients) {\n+        double sum = 0;\n+        for (double coefficient : coefficients.toArray()) {\n+            sum -= coefficient;\n+        }\n+        return sum;\n+    }\n+\n+    /**\n+     * Checks whether the given column is basic.\n+     * @param col index of the column to check\n+     * @return the row that the variable is basic in.  null if the column is not basic\n+     */\n+    protected Integer getBasicRow(final int col) {\n+        Integer row = null;\n+        for (int i = 0; i < getHeight(); i++) {\n+            final double entry = getEntry(i, col);\n+            if (Precision.equals(entry, 1d, maxUlps) && (row == null)) {\n+                row = i;\n+            } else if (!Precision.equals(entry, 0d, maxUlps)) {\n+                return null;\n+            }\n+        }\n+        return row;\n+    }\n+\n+    /**\n+     * Removes the phase 1 objective function, positive cost non-artificial variables,\n+     * and the non-basic artificial variables from this tableau.\n+     */\n+    protected void dropPhase1Objective() {\n+        if (getNumObjectiveFunctions() == 1) {\n+            return;\n+        }\n+\n+        Set<Integer> columnsToDrop = new TreeSet<Integer>();\n+        columnsToDrop.add(0);\n+\n+        // positive cost non-artificial variables\n+        for (int i = getNumObjectiveFunctions(); i < getArtificialVariableOffset(); i++) {\n+            final double entry = tableau.getEntry(0, i);\n+            if (Precision.compareTo(entry, 0d, epsilon) > 0) {\n+                columnsToDrop.add(i);\n+            }\n+        }\n+\n+        // non-basic artificial variables\n+        for (int i = 0; i < getNumArtificialVariables(); i++) {\n+            int col = i + getArtificialVariableOffset();\n+            if (getBasicRow(col) == null) {\n+                columnsToDrop.add(col);\n+            }\n+        }\n+\n+        double[][] matrix = new double[getHeight() - 1][getWidth() - columnsToDrop.size()];\n+        for (int i = 1; i < getHeight(); i++) {\n+            int col = 0;\n+            for (int j = 0; j < getWidth(); j++) {\n+                if (!columnsToDrop.contains(j)) {\n+                    matrix[i - 1][col++] = tableau.getEntry(i, j);\n+                }\n+            }\n+        }\n+\n+        // remove the columns in reverse order so the indices are correct\n+        Integer[] drop = columnsToDrop.toArray(new Integer[columnsToDrop.size()]);\n+        for (int i = drop.length - 1; i >= 0; i--) {\n+            columnLabels.remove((int) drop[i]);\n+        }\n+\n+        this.tableau = new Array2DRowRealMatrix(matrix);\n+        this.numArtificialVariables = 0;\n+    }\n+\n+    /**\n+     * @param src the source array\n+     * @param dest the destination array\n+     */\n+    private void copyArray(final double[] src, final double[] dest) {\n+        System.arraycopy(src, 0, dest, getNumObjectiveFunctions(), src.length);\n+    }\n+\n+    /**\n+     * Returns whether the problem is at an optimal state.\n+     * @return whether the model has been solved\n+     */\n+    boolean isOptimal() {\n+        for (int i = getNumObjectiveFunctions(); i < getWidth() - 1; i++) {\n+            final double entry = tableau.getEntry(0, i);\n+            if (Precision.compareTo(entry, 0d, epsilon) < 0) {\n+                return false;\n+            }\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Get the current solution.\n+     * @return current solution\n+     */\n+    protected PointValuePair getSolution() {\n+        int negativeVarColumn = columnLabels.indexOf(NEGATIVE_VAR_COLUMN_LABEL);\n+        Integer negativeVarBasicRow = negativeVarColumn > 0 ? getBasicRow(negativeVarColumn) : null;\n+        double mostNegative = negativeVarBasicRow == null ? 0 : getEntry(negativeVarBasicRow, getRhsOffset());\n+\n+        Set<Integer> basicRows = new HashSet<Integer>();\n+        double[] coefficients = new double[getOriginalNumDecisionVariables()];\n+        for (int i = 0; i < coefficients.length; i++) {\n+            int colIndex = columnLabels.indexOf(\"x\" + i);\n+            if (colIndex < 0) {\n+                coefficients[i] = 0;\n+                continue;\n+            }\n+            Integer basicRow = getBasicRow(colIndex);\n+            if (basicRow != null && basicRow == 0) {\n+                // if the basic row is found to be the objective function row\n+                // set the coefficient to 0 -> this case handles unconstrained\n+                // variables that are still part of the objective function\n+                coefficients[i] = 0;\n+            } else if (basicRows.contains(basicRow)) {\n+                // if multiple variables can take a given value\n+                // then we choose the first and set the rest equal to 0\n+                coefficients[i] = 0 - (restrictToNonNegative ? 0 : mostNegative);\n+            } else {\n+                basicRows.add(basicRow);\n+                coefficients[i] =\n+                    (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) -\n+                    (restrictToNonNegative ? 0 : mostNegative);\n+            }\n+        }\n+        return new PointValuePair(coefficients, f.value(coefficients));\n+    }\n+\n+    /**\n+     * Subtracts a multiple of one row from another.\n+     * <p>\n+     * After application of this operation, the following will hold:\n+     * <pre>minuendRow = minuendRow - multiple * subtrahendRow</pre>\n+     *\n+     * @param dividendRow index of the row\n+     * @param divisor value of the divisor\n+     */\n+    protected void divideRow(final int dividendRow, final double divisor) {\n+        for (int j = 0; j < getWidth(); j++) {\n+            tableau.setEntry(dividendRow, j, tableau.getEntry(dividendRow, j) / divisor);\n+        }\n+    }\n+\n+    /**\n+     * Subtracts a multiple of one row from another.\n+     * <p>\n+     * After application of this operation, the following will hold:\n+     * <pre>minuendRow = minuendRow - multiple * subtrahendRow</pre>\n+     *\n+     * @param minuendRow row index\n+     * @param subtrahendRow row index\n+     * @param multiple multiplication factor\n+     */\n+    protected void subtractRow(final int minuendRow, final int subtrahendRow,\n+                               final double multiple) {\n+        for (int i = 0; i < getWidth(); i++) {\n+            double result = tableau.getEntry(minuendRow, i) - tableau.getEntry(subtrahendRow, i) * multiple;\n+            // cut-off values smaller than the CUTOFF_THRESHOLD, otherwise may lead to numerical instabilities\n+            if (FastMath.abs(result) < CUTOFF_THRESHOLD) {\n+                result = 0.0;\n+            }\n+            tableau.setEntry(minuendRow, i, result);\n+        }\n+    }\n+\n+    /**\n+     * Get the width of the tableau.\n+     * @return width of the tableau\n+     */\n+    protected final int getWidth() {\n+        return tableau.getColumnDimension();\n+    }\n+\n+    /**\n+     * Get the height of the tableau.\n+     * @return height of the tableau\n+     */\n+    protected final int getHeight() {\n+        return tableau.getRowDimension();\n+    }\n+\n+    /**\n+     * Get an entry of the tableau.\n+     * @param row row index\n+     * @param column column index\n+     * @return entry at (row, column)\n+     */\n+    protected final double getEntry(final int row, final int column) {\n+        return tableau.getEntry(row, column);\n+    }\n+\n+    /**\n+     * Set an entry of the tableau.\n+     * @param row row index\n+     * @param column column index\n+     * @param value for the entry\n+     */\n+    protected final void setEntry(final int row, final int column,\n+                                  final double value) {\n+        tableau.setEntry(row, column, value);\n+    }\n+\n+    /**\n+     * Get the offset of the first slack variable.\n+     * @return offset of the first slack variable\n+     */\n+    protected final int getSlackVariableOffset() {\n+        return getNumObjectiveFunctions() + numDecisionVariables;\n+    }\n+\n+    /**\n+     * Get the offset of the first artificial variable.\n+     * @return offset of the first artificial variable\n+     */\n+    protected final int getArtificialVariableOffset() {\n+        return getNumObjectiveFunctions() + numDecisionVariables + numSlackVariables;\n+    }\n+\n+    /**\n+     * Get the offset of the right hand side.\n+     * @return offset of the right hand side\n+     */\n+    protected final int getRhsOffset() {\n+        return getWidth() - 1;\n+    }\n+\n+    /**\n+     * Get the number of decision variables.\n+     * <p>\n+     * If variables are not restricted to positive values, this will include 1 extra decision variable to represent\n+     * the absolute value of the most negative variable.\n+     *\n+     * @return number of decision variables\n+     * @see #getOriginalNumDecisionVariables()\n+     */\n+    protected final int getNumDecisionVariables() {\n+        return numDecisionVariables;\n+    }\n+\n+    /**\n+     * Get the original number of decision variables.\n+     * @return original number of decision variables\n+     * @see #getNumDecisionVariables()\n+     */\n+    protected final int getOriginalNumDecisionVariables() {\n+        return f.getCoefficients().getDimension();\n+    }\n+\n+    /**\n+     * Get the number of slack variables.\n+     * @return number of slack variables\n+     */\n+    protected final int getNumSlackVariables() {\n+        return numSlackVariables;\n+    }\n+\n+    /**\n+     * Get the number of artificial variables.\n+     * @return number of artificial variables\n+     */\n+    protected final int getNumArtificialVariables() {\n+        return numArtificialVariables;\n+    }\n+\n+    /**\n+     * Get the tableau data.\n+     * @return tableau data\n+     */\n+    protected final double[][] getData() {\n+        return tableau.getData();\n+    }\n+\n+    @Override\n+    public boolean equals(Object other) {\n+\n+      if (this == other) {\n+        return true;\n+      }\n+\n+      if (other instanceof SimplexTableau) {\n+          SimplexTableau rhs = (SimplexTableau) other;\n+          return (restrictToNonNegative  == rhs.restrictToNonNegative) &&\n+                 (numDecisionVariables   == rhs.numDecisionVariables) &&\n+                 (numSlackVariables      == rhs.numSlackVariables) &&\n+                 (numArtificialVariables == rhs.numArtificialVariables) &&\n+                 (epsilon                == rhs.epsilon) &&\n+                 (maxUlps                == rhs.maxUlps) &&\n+                 f.equals(rhs.f) &&\n+                 constraints.equals(rhs.constraints) &&\n+                 tableau.equals(rhs.tableau);\n+      }\n+      return false;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Boolean.valueOf(restrictToNonNegative).hashCode() ^\n+               numDecisionVariables ^\n+               numSlackVariables ^\n+               numArtificialVariables ^\n+               Double.valueOf(epsilon).hashCode() ^\n+               maxUlps ^\n+               f.hashCode() ^\n+               constraints.hashCode() ^\n+               tableau.hashCode();\n+    }\n+\n+    /**\n+     * Serialize the instance.\n+     * @param oos stream where object should be written\n+     * @throws IOException if object cannot be written to stream\n+     */\n+    private void writeObject(ObjectOutputStream oos)\n+        throws IOException {\n+        oos.defaultWriteObject();\n+        MatrixUtils.serializeRealMatrix(tableau, oos);\n+    }\n+\n+    /**\n+     * Deserialize the instance.\n+     * @param ois stream from which the object should be read\n+     * @throws ClassNotFoundException if a class in the stream cannot be found\n+     * @throws IOException if object cannot be read from the stream\n+     */\n+    private void readObject(ObjectInputStream ois)\n+      throws ClassNotFoundException, IOException {\n+        ois.defaultReadObject();\n+        MatrixUtils.deserializeRealMatrix(this, \"tableau\", ois);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/UnboundedSolutionException.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+\n+/**\n+ * This class represents exceptions thrown by optimizers when a solution escapes to infinity.\n+ *\n+ * @version $Id: UnboundedSolutionException.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class UnboundedSolutionException extends MathIllegalStateException {\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = 940539497277290619L;\n+\n+    /**\n+     * Simple constructor using a default message.\n+     */\n+    public UnboundedSolutionException() {\n+        super(LocalizedFormats.UNBOUNDED_SOLUTION);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/linear/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+/**\n+ * Optimization algorithms for linear constrained problems.\n+ */\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/GradientMultivariateOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+\n+/**\n+ * Base class for implementing optimizers for multivariate scalar\n+ * differentiable functions.\n+ * It contains boiler-plate code for dealing with gradient evaluation.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class GradientMultivariateOptimizer\n+    extends MultivariateOptimizer {\n+    /**\n+     * Gradient of the objective function.\n+     */\n+    private MultivariateVectorFunction gradient;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected GradientMultivariateOptimizer(ConvergenceChecker<PointValuePair> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * Compute the gradient vector.\n+     *\n+     * @param params Point at which the gradient must be evaluated.\n+     * @return the gradient at the specified point.\n+     */\n+    protected double[] computeObjectiveGradient(final double[] params) {\n+        return gradient.value(params);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxEval}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.InitialGuess}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.SimpleBounds}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.GoalType}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.ObjectiveFunction}</li>\n+     *  <li>{@link ObjectiveFunctionGradient}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations (of the objective function) is exceeded.\n+     */\n+    @Override\n+    public PointValuePair optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException {\n+         // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link ObjectiveFunction}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if  (data instanceof ObjectiveFunctionGradient) {\n+                gradient = ((ObjectiveFunctionGradient) data).getObjectiveFunctionGradient();\n+                // If more data must be parsed, this statement _must_ be\n+                // changed to \"continue\".\n+                break;\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/LeastSquaresConverter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.linear.RealMatrix;\n+\n+/**\n+ * This class converts\n+ * {@link MultivariateVectorFunction vectorial objective functions} to\n+ * {@link MultivariateFunction scalar objective functions}\n+ * when the goal is to minimize them.\n+ * <br/>\n+ * This class is mostly used when the vectorial objective function represents\n+ * a theoretical result computed from a point set applied to a model and\n+ * the models point must be adjusted to fit the theoretical result to some\n+ * reference observations. The observations may be obtained for example from\n+ * physical measurements whether the model is built from theoretical\n+ * considerations.\n+ * <br/>\n+ * This class computes a possibly weighted squared sum of the residuals, which is\n+ * a scalar value. The residuals are the difference between the theoretical model\n+ * (i.e. the output of the vectorial objective function) and the observations. The\n+ * class implements the {@link MultivariateFunction} interface and can therefore be\n+ * minimized by any optimizer supporting scalar objectives functions.This is one way\n+ * to perform a least square estimation. There are other ways to do this without using\n+ * this converter, as some optimization algorithms directly support vectorial objective\n+ * functions.\n+ * <br/>\n+ * This class support combination of residuals with or without weights and correlations.\n+  *\n+ * @see MultivariateFunction\n+ * @see MultivariateVectorFunction\n+ * @version $Id: LeastSquaresConverter.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+\n+public class LeastSquaresConverter implements MultivariateFunction {\n+    /** Underlying vectorial function. */\n+    private final MultivariateVectorFunction function;\n+    /** Observations to be compared to objective function to compute residuals. */\n+    private final double[] observations;\n+    /** Optional weights for the residuals. */\n+    private final double[] weights;\n+    /** Optional scaling matrix (weight and correlations) for the residuals. */\n+    private final RealMatrix scale;\n+\n+    /**\n+     * Builds a simple converter for uncorrelated residuals with identical\n+     * weights.\n+     *\n+     * @param function vectorial residuals function to wrap\n+     * @param observations observations to be compared to objective function to compute residuals\n+     */\n+    public LeastSquaresConverter(final MultivariateVectorFunction function,\n+                                 final double[] observations) {\n+        this.function     = function;\n+        this.observations = observations.clone();\n+        this.weights      = null;\n+        this.scale        = null;\n+    }\n+\n+    /**\n+     * Builds a simple converter for uncorrelated residuals with the\n+     * specified weights.\n+     * <p>\n+     * The scalar objective function value is computed as:\n+     * <pre>\n+     * objective = &sum;weight<sub>i</sub>(observation<sub>i</sub>-objective<sub>i</sub>)<sup>2</sup>\n+     * </pre>\n+     * </p>\n+     * <p>\n+     * Weights can be used for example to combine residuals with different standard\n+     * deviations. As an example, consider a residuals array in which even elements\n+     * are angular measurements in degrees with a 0.01&deg; standard deviation and\n+     * odd elements are distance measurements in meters with a 15m standard deviation.\n+     * In this case, the weights array should be initialized with value\n+     * 1.0/(0.01<sup>2</sup>) in the even elements and 1.0/(15.0<sup>2</sup>) in the\n+     * odd elements (i.e. reciprocals of variances).\n+     * </p>\n+     * <p>\n+     * The array computed by the objective function, the observations array and the\n+     * weights array must have consistent sizes or a {@link DimensionMismatchException}\n+     * will be triggered while computing the scalar objective.\n+     * </p>\n+     *\n+     * @param function vectorial residuals function to wrap\n+     * @param observations observations to be compared to objective function to compute residuals\n+     * @param weights weights to apply to the residuals\n+     * @throws DimensionMismatchException if the observations vector and the weights\n+     * vector dimensions do not match (objective function dimension is checked only when\n+     * the {@link #value(double[])} method is called)\n+     */\n+    public LeastSquaresConverter(final MultivariateVectorFunction function,\n+                                 final double[] observations,\n+                                 final double[] weights) {\n+        if (observations.length != weights.length) {\n+            throw new DimensionMismatchException(observations.length, weights.length);\n+        }\n+        this.function     = function;\n+        this.observations = observations.clone();\n+        this.weights      = weights.clone();\n+        this.scale        = null;\n+    }\n+\n+    /**\n+     * Builds a simple converter for correlated residuals with the\n+     * specified weights.\n+     * <p>\n+     * The scalar objective function value is computed as:\n+     * <pre>\n+     * objective = y<sup>T</sup>y with y = scale&times;(observation-objective)\n+     * </pre>\n+     * </p>\n+     * <p>\n+     * The array computed by the objective function, the observations array and the\n+     * the scaling matrix must have consistent sizes or a {@link DimensionMismatchException}\n+     * will be triggered while computing the scalar objective.\n+     * </p>\n+     *\n+     * @param function vectorial residuals function to wrap\n+     * @param observations observations to be compared to objective function to compute residuals\n+     * @param scale scaling matrix\n+     * @throws DimensionMismatchException if the observations vector and the scale\n+     * matrix dimensions do not match (objective function dimension is checked only when\n+     * the {@link #value(double[])} method is called)\n+     */\n+    public LeastSquaresConverter(final MultivariateVectorFunction function,\n+                                 final double[] observations,\n+                                 final RealMatrix scale) {\n+        if (observations.length != scale.getColumnDimension()) {\n+            throw new DimensionMismatchException(observations.length, scale.getColumnDimension());\n+        }\n+        this.function     = function;\n+        this.observations = observations.clone();\n+        this.weights      = null;\n+        this.scale        = scale.copy();\n+    }\n+\n+    /** {@inheritDoc} */\n+    public double value(final double[] point) {\n+        // compute residuals\n+        final double[] residuals = function.value(point);\n+        if (residuals.length != observations.length) {\n+            throw new DimensionMismatchException(residuals.length, observations.length);\n+        }\n+        for (int i = 0; i < residuals.length; ++i) {\n+            residuals[i] -= observations[i];\n+        }\n+\n+        // compute sum of squares\n+        double sumSquares = 0;\n+        if (weights != null) {\n+            for (int i = 0; i < residuals.length; ++i) {\n+                final double ri = residuals[i];\n+                sumSquares +=  weights[i] * ri * ri;\n+            }\n+        } else if (scale != null) {\n+            for (final double yi : scale.operate(residuals)) {\n+                sumSquares += yi * yi;\n+            }\n+        } else {\n+            for (final double ri : residuals) {\n+                sumSquares += ri * ri;\n+            }\n+        }\n+\n+        return sumSquares;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/MultiStartMultivariateOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.exception.NullArgumentException;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+import org.apache.commons.math3.optim.BaseMultiStartMultivariateOptimizer;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.GoalType;\n+\n+/**\n+ * Multi-start optimizer.\n+ *\n+ * This class wraps an optimizer in order to use it several times in\n+ * turn with different starting points (trying to avoid being trapped\n+ * in a local extremum when looking for a global one).\n+ *\n+ * @version $Id$\n+ * @since 3.0\n+ */\n+public class MultiStartMultivariateOptimizer\n+    extends BaseMultiStartMultivariateOptimizer<PointValuePair> {\n+    /** Underlying optimizer. */\n+    private final MultivariateOptimizer optimizer;\n+    /** Found optima. */\n+    private final List<PointValuePair> optima = new ArrayList<PointValuePair>();\n+\n+    /**\n+     * Create a multi-start optimizer from a single-start optimizer.\n+     *\n+     * @param optimizer Single-start optimizer to wrap.\n+     * @param starts Number of starts to perform.\n+     * If {@code starts == 1}, the result will be same as if {@code optimizer}\n+     * is called directly.\n+     * @param generator Random vector generator to use for restarts.\n+     * @throws NullArgumentException if {@code optimizer} or {@code generator}\n+     * is {@code null}.\n+     * @throws NotStrictlyPositiveException if {@code starts < 1}.\n+     */\n+    public MultiStartMultivariateOptimizer(final MultivariateOptimizer optimizer,\n+                                           final int starts,\n+                                           final RandomVectorGenerator generator)\n+        throws NullArgumentException,\n+        NotStrictlyPositiveException {\n+        super(optimizer, starts, generator);\n+        this.optimizer = optimizer;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public PointValuePair[] getOptima() {\n+        Collections.sort(optima, getPairComparator());\n+        return optima.toArray(new PointValuePair[0]);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    protected void store(PointValuePair optimum) {\n+        optima.add(optimum);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    protected void clear() {\n+        optima.clear();\n+    }\n+\n+    /**\n+     * @return a comparator for sorting the optima.\n+     */\n+    private Comparator<PointValuePair> getPairComparator() {\n+        return new Comparator<PointValuePair>() {\n+            public int compare(final PointValuePair o1,\n+                               final PointValuePair o2) {\n+                if (o1 == null) {\n+                    return (o2 == null) ? 0 : 1;\n+                } else if (o2 == null) {\n+                    return -1;\n+                }\n+                final double v1 = o1.getValue();\n+                final double v2 = o2.getValue();\n+                return (optimizer.getGoalType() == GoalType.MINIMIZE) ?\n+                    Double.compare(v1, v2) : Double.compare(v2, v1);\n+            }\n+        };\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/MultivariateFunctionMappingAdapter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.analysis.function.Logit;\n+import org.apache.commons.math3.analysis.function.Sigmoid;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.util.MathUtils;\n+\n+/**\n+ * <p>Adapter for mapping bounded {@link MultivariateFunction} to unbounded ones.</p>\n+ *\n+ * <p>\n+ * This adapter can be used to wrap functions subject to simple bounds on\n+ * parameters so they can be used by optimizers that do <em>not</em> directly\n+ * support simple bounds.\n+ * </p>\n+ * <p>\n+ * The principle is that the user function that will be wrapped will see its\n+ * parameters bounded as required, i.e when its {@code value} method is called\n+ * with argument array {@code point}, the elements array will fulfill requirement\n+ * {@code lower[i] <= point[i] <= upper[i]} for all i. Some of the components\n+ * may be unbounded or bounded only on one side if the corresponding bound is\n+ * set to an infinite value. The optimizer will not manage the user function by\n+ * itself, but it will handle this adapter and it is this adapter that will take\n+ * care the bounds are fulfilled. The adapter {@link #value(double[])} method will\n+ * be called by the optimizer with unbound parameters, and the adapter will map\n+ * the unbounded value to the bounded range using appropriate functions like\n+ * {@link Sigmoid} for double bounded elements for example.\n+ * </p>\n+ * <p>\n+ * As the optimizer sees only unbounded parameters, it should be noted that the\n+ * start point or simplex expected by the optimizer should be unbounded, so the\n+ * user is responsible for converting his bounded point to unbounded by calling\n+ * {@link #boundedToUnbounded(double[])} before providing them to the optimizer.\n+ * For the same reason, the point returned by the {@link\n+ * org.apache.commons.math3.optimization.BaseMultivariateOptimizer#optimize(int,\n+ * MultivariateFunction, org.apache.commons.math3.optimization.GoalType, double[])}\n+ * method is unbounded. So to convert this point to bounded, users must call\n+ * {@link #unboundedToBounded(double[])} by themselves!</p>\n+ * <p>\n+ * This adapter is only a poor man solution to simple bounds optimization constraints\n+ * that can be used with simple optimizers like\n+ * {@link org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer\n+ * SimplexOptimizer}.\n+ * A better solution is to use an optimizer that directly supports simple bounds like\n+ * {@link org.apache.commons.math3.optim.nonlinear.scalar.noderiv.CMAESOptimizer\n+ * CMAESOptimizer} or\n+ * {@link org.apache.commons.math3.optim.nonlinear.scalar.noderiv.BOBYQAOptimizer\n+ * BOBYQAOptimizer}.\n+ * One caveat of this poor-man's solution is that behavior near the bounds may be\n+ * numerically unstable as bounds are mapped from infinite values.\n+ * Another caveat is that convergence values are evaluated by the optimizer with\n+ * respect to unbounded variables, so there will be scales differences when\n+ * converted to bounded variables.\n+ * </p>\n+ *\n+ * @see MultivariateFunctionPenaltyAdapter\n+ *\n+ * @version $Id: MultivariateFunctionMappingAdapter.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.0\n+ */\n+public class MultivariateFunctionMappingAdapter\n+    implements MultivariateFunction {\n+    /** Underlying bounded function. */\n+    private final MultivariateFunction bounded;\n+    /** Mapping functions. */\n+    private final Mapper[] mappers;\n+\n+    /** Simple constructor.\n+     * @param bounded bounded function\n+     * @param lower lower bounds for each element of the input parameters array\n+     * (some elements may be set to {@code Double.NEGATIVE_INFINITY} for\n+     * unbounded values)\n+     * @param upper upper bounds for each element of the input parameters array\n+     * (some elements may be set to {@code Double.POSITIVE_INFINITY} for\n+     * unbounded values)\n+     * @exception DimensionMismatchException if lower and upper bounds are not\n+     * consistent, either according to dimension or to values\n+     */\n+    public MultivariateFunctionMappingAdapter(final MultivariateFunction bounded,\n+                                              final double[] lower, final double[] upper) {\n+        // safety checks\n+        MathUtils.checkNotNull(lower);\n+        MathUtils.checkNotNull(upper);\n+        if (lower.length != upper.length) {\n+            throw new DimensionMismatchException(lower.length, upper.length);\n+        }\n+        for (int i = 0; i < lower.length; ++i) {\n+            // note the following test is written in such a way it also fails for NaN\n+            if (!(upper[i] >= lower[i])) {\n+                throw new NumberIsTooSmallException(upper[i], lower[i], true);\n+            }\n+        }\n+\n+        this.bounded = bounded;\n+        this.mappers = new Mapper[lower.length];\n+        for (int i = 0; i < mappers.length; ++i) {\n+            if (Double.isInfinite(lower[i])) {\n+                if (Double.isInfinite(upper[i])) {\n+                    // element is unbounded, no transformation is needed\n+                    mappers[i] = new NoBoundsMapper();\n+                } else {\n+                    // element is simple-bounded on the upper side\n+                    mappers[i] = new UpperBoundMapper(upper[i]);\n+                }\n+            } else {\n+                if (Double.isInfinite(upper[i])) {\n+                    // element is simple-bounded on the lower side\n+                    mappers[i] = new LowerBoundMapper(lower[i]);\n+                } else {\n+                    // element is double-bounded\n+                    mappers[i] = new LowerUpperBoundMapper(lower[i], upper[i]);\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Maps an array from unbounded to bounded.\n+     *\n+     * @param point Unbounded values.\n+     * @return the bounded values.\n+     */\n+    public double[] unboundedToBounded(double[] point) {\n+        // Map unbounded input point to bounded point.\n+        final double[] mapped = new double[mappers.length];\n+        for (int i = 0; i < mappers.length; ++i) {\n+            mapped[i] = mappers[i].unboundedToBounded(point[i]);\n+        }\n+\n+        return mapped;\n+    }\n+\n+    /**\n+     * Maps an array from bounded to unbounded.\n+     *\n+     * @param point Bounded values.\n+     * @return the unbounded values.\n+     */\n+    public double[] boundedToUnbounded(double[] point) {\n+        // Map bounded input point to unbounded point.\n+        final double[] mapped = new double[mappers.length];\n+        for (int i = 0; i < mappers.length; ++i) {\n+            mapped[i] = mappers[i].boundedToUnbounded(point[i]);\n+        }\n+\n+        return mapped;\n+    }\n+\n+    /**\n+     * Compute the underlying function value from an unbounded point.\n+     * <p>\n+     * This method simply bounds the unbounded point using the mappings\n+     * set up at construction and calls the underlying function using\n+     * the bounded point.\n+     * </p>\n+     * @param point unbounded value\n+     * @return underlying function value\n+     * @see #unboundedToBounded(double[])\n+     */\n+    public double value(double[] point) {\n+        return bounded.value(unboundedToBounded(point));\n+    }\n+\n+    /** Mapping interface. */\n+    private interface Mapper {\n+        /**\n+         * Maps a value from unbounded to bounded.\n+         *\n+         * @param y Unbounded value.\n+         * @return the bounded value.\n+         */\n+        double unboundedToBounded(double y);\n+\n+        /**\n+         * Maps a value from bounded to unbounded.\n+         *\n+         * @param x Bounded value.\n+         * @return the unbounded value.\n+         */\n+        double boundedToUnbounded(double x);\n+    }\n+\n+    /** Local class for no bounds mapping. */\n+    private static class NoBoundsMapper implements Mapper {\n+        /** {@inheritDoc} */\n+        public double unboundedToBounded(final double y) {\n+            return y;\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double boundedToUnbounded(final double x) {\n+            return x;\n+        }\n+    }\n+\n+    /** Local class for lower bounds mapping. */\n+    private static class LowerBoundMapper implements Mapper {\n+        /** Low bound. */\n+        private final double lower;\n+\n+        /**\n+         * Simple constructor.\n+         *\n+         * @param lower lower bound\n+         */\n+        public LowerBoundMapper(final double lower) {\n+            this.lower = lower;\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double unboundedToBounded(final double y) {\n+            return lower + FastMath.exp(y);\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double boundedToUnbounded(final double x) {\n+            return FastMath.log(x - lower);\n+        }\n+\n+    }\n+\n+    /** Local class for upper bounds mapping. */\n+    private static class UpperBoundMapper implements Mapper {\n+\n+        /** Upper bound. */\n+        private final double upper;\n+\n+        /** Simple constructor.\n+         * @param upper upper bound\n+         */\n+        public UpperBoundMapper(final double upper) {\n+            this.upper = upper;\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double unboundedToBounded(final double y) {\n+            return upper - FastMath.exp(-y);\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double boundedToUnbounded(final double x) {\n+            return -FastMath.log(upper - x);\n+        }\n+\n+    }\n+\n+    /** Local class for lower and bounds mapping. */\n+    private static class LowerUpperBoundMapper implements Mapper {\n+        /** Function from unbounded to bounded. */\n+        private final UnivariateFunction boundingFunction;\n+        /** Function from bounded to unbounded. */\n+        private final UnivariateFunction unboundingFunction;\n+\n+        /**\n+         * Simple constructor.\n+         *\n+         * @param lower lower bound\n+         * @param upper upper bound\n+         */\n+        public LowerUpperBoundMapper(final double lower, final double upper) {\n+            boundingFunction   = new Sigmoid(lower, upper);\n+            unboundingFunction = new Logit(lower, upper);\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double unboundedToBounded(final double y) {\n+            return boundingFunction.value(y);\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double boundedToUnbounded(final double x) {\n+            return unboundingFunction.value(x);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/MultivariateFunctionPenaltyAdapter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.util.MathUtils;\n+\n+/**\n+ * <p>Adapter extending bounded {@link MultivariateFunction} to an unbouded\n+ * domain using a penalty function.</p>\n+ *\n+ * <p>\n+ * This adapter can be used to wrap functions subject to simple bounds on\n+ * parameters so they can be used by optimizers that do <em>not</em> directly\n+ * support simple bounds.\n+ * </p>\n+ * <p>\n+ * The principle is that the user function that will be wrapped will see its\n+ * parameters bounded as required, i.e when its {@code value} method is called\n+ * with argument array {@code point}, the elements array will fulfill requirement\n+ * {@code lower[i] <= point[i] <= upper[i]} for all i. Some of the components\n+ * may be unbounded or bounded only on one side if the corresponding bound is\n+ * set to an infinite value. The optimizer will not manage the user function by\n+ * itself, but it will handle this adapter and it is this adapter that will take\n+ * care the bounds are fulfilled. The adapter {@link #value(double[])} method will\n+ * be called by the optimizer with unbound parameters, and the adapter will check\n+ * if the parameters is within range or not. If it is in range, then the underlying\n+ * user function will be called, and if it is not the value of a penalty function\n+ * will be returned instead.\n+ * </p>\n+ * <p>\n+ * This adapter is only a poor-man's solution to simple bounds optimization\n+ * constraints that can be used with simple optimizers like\n+ * {@link org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer\n+ * SimplexOptimizer}.\n+ * A better solution is to use an optimizer that directly supports simple bounds like\n+ * {@link org.apache.commons.math3.optim.nonlinear.scalar.noderiv.CMAESOptimizer\n+ * CMAESOptimizer} or\n+ * {@link org.apache.commons.math3.optim.nonlinear.scalar.noderiv.BOBYQAOptimizer\n+ * BOBYQAOptimizer}.\n+ * One caveat of this poor-man's solution is that if start point or start simplex\n+ * is completely outside of the allowed range, only the penalty function is used,\n+ * and the optimizer may converge without ever entering the range.\n+ * </p>\n+ *\n+ * @see MultivariateFunctionMappingAdapter\n+ *\n+ * @version $Id: MultivariateFunctionPenaltyAdapter.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.0\n+ */\n+public class MultivariateFunctionPenaltyAdapter\n+    implements MultivariateFunction {\n+    /** Underlying bounded function. */\n+    private final MultivariateFunction bounded;\n+    /** Lower bounds. */\n+    private final double[] lower;\n+    /** Upper bounds. */\n+    private final double[] upper;\n+    /** Penalty offset. */\n+    private final double offset;\n+    /** Penalty scales. */\n+    private final double[] scale;\n+\n+    /**\n+     * Simple constructor.\n+     * <p>\n+     * When the optimizer provided points are out of range, the value of the\n+     * penalty function will be used instead of the value of the underlying\n+     * function. In order for this penalty to be effective in rejecting this\n+     * point during the optimization process, the penalty function value should\n+     * be defined with care. This value is computed as:\n+     * <pre>\n+     *   penalty(point) = offset + &sum;<sub>i</sub>[scale[i] * &radic;|point[i]-boundary[i]|]\n+     * </pre>\n+     * where indices i correspond to all the components that violates their boundaries.\n+     * </p>\n+     * <p>\n+     * So when attempting a function minimization, offset should be larger than\n+     * the maximum expected value of the underlying function and scale components\n+     * should all be positive. When attempting a function maximization, offset\n+     * should be lesser than the minimum expected value of the underlying function\n+     * and scale components should all be negative.\n+     * minimization, and lesser than the minimum expected value of the underlying\n+     * function when attempting maximization.\n+     * </p>\n+     * <p>\n+     * These choices for the penalty function have two properties. First, all out\n+     * of range points will return a function value that is worse than the value\n+     * returned by any in range point. Second, the penalty is worse for large\n+     * boundaries violation than for small violations, so the optimizer has an hint\n+     * about the direction in which it should search for acceptable points.\n+     * </p>\n+     * @param bounded bounded function\n+     * @param lower lower bounds for each element of the input parameters array\n+     * (some elements may be set to {@code Double.NEGATIVE_INFINITY} for\n+     * unbounded values)\n+     * @param upper upper bounds for each element of the input parameters array\n+     * (some elements may be set to {@code Double.POSITIVE_INFINITY} for\n+     * unbounded values)\n+     * @param offset base offset of the penalty function\n+     * @param scale scale of the penalty function\n+     * @exception DimensionMismatchException if lower bounds, upper bounds and\n+     * scales are not consistent, either according to dimension or to bounadary\n+     * values\n+     */\n+    public MultivariateFunctionPenaltyAdapter(final MultivariateFunction bounded,\n+                                              final double[] lower, final double[] upper,\n+                                              final double offset, final double[] scale) {\n+\n+        // safety checks\n+        MathUtils.checkNotNull(lower);\n+        MathUtils.checkNotNull(upper);\n+        MathUtils.checkNotNull(scale);\n+        if (lower.length != upper.length) {\n+            throw new DimensionMismatchException(lower.length, upper.length);\n+        }\n+        if (lower.length != scale.length) {\n+            throw new DimensionMismatchException(lower.length, scale.length);\n+        }\n+        for (int i = 0; i < lower.length; ++i) {\n+            // note the following test is written in such a way it also fails for NaN\n+            if (!(upper[i] >= lower[i])) {\n+                throw new NumberIsTooSmallException(upper[i], lower[i], true);\n+            }\n+        }\n+\n+        this.bounded = bounded;\n+        this.lower   = lower.clone();\n+        this.upper   = upper.clone();\n+        this.offset  = offset;\n+        this.scale   = scale.clone();\n+    }\n+\n+    /**\n+     * Computes the underlying function value from an unbounded point.\n+     * <p>\n+     * This method simply returns the value of the underlying function\n+     * if the unbounded point already fulfills the bounds, and compute\n+     * a replacement value using the offset and scale if bounds are\n+     * violated, without calling the function at all.\n+     * </p>\n+     * @param point unbounded point\n+     * @return either underlying function value or penalty function value\n+     */\n+    public double value(double[] point) {\n+\n+        for (int i = 0; i < scale.length; ++i) {\n+            if ((point[i] < lower[i]) || (point[i] > upper[i])) {\n+                // bound violation starting at this component\n+                double sum = 0;\n+                for (int j = i; j < scale.length; ++j) {\n+                    final double overshoot;\n+                    if (point[j] < lower[j]) {\n+                        overshoot = scale[j] * (lower[j] - point[j]);\n+                    } else if (point[j] > upper[j]) {\n+                        overshoot = scale[j] * (point[j] - upper[j]);\n+                    } else {\n+                        overshoot = 0;\n+                    }\n+                    sum += FastMath.sqrt(overshoot);\n+                }\n+                return offset + sum;\n+            }\n+        }\n+\n+        // all boundaries are fulfilled, we are in the expected\n+        // domain of the underlying function\n+        return bounded.value(point);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/MultivariateOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.optim.BaseMultivariateOptimizer;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+\n+/**\n+ * Base class for a multivariate scalar function optimizer.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class MultivariateOptimizer\n+    extends BaseMultivariateOptimizer<PointValuePair> {\n+    /** Objective function. */\n+    private MultivariateFunction function;\n+    /** Type of optimization. */\n+    private GoalType goal;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected MultivariateOptimizer(ConvergenceChecker<PointValuePair> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxEval}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.InitialGuess}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.SimpleBounds}</li>\n+     *  <li>{@link ObjectiveFunction}</li>\n+     *  <li>{@link GoalType}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     */\n+    @Override\n+    public PointValuePair optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException {\n+         // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link ObjectiveFunction}</li>\n+     *  <li>{@link GoalType}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof GoalType) {\n+                goal = (GoalType) data;\n+                continue;\n+            }\n+            if  (data instanceof ObjectiveFunction) {\n+                function = ((ObjectiveFunction) data).getObjectiveFunction();\n+                continue;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * @return the optimization type.\n+     */\n+    public GoalType getGoalType() {\n+        return goal;\n+    }\n+\n+    /**\n+     * Computes the objective function value.\n+     * This method <em>must</em> be called by subclasses to enforce the\n+     * evaluation counter limit.\n+     *\n+     * @param params Point at which the objective function must be evaluated.\n+     * @return the objective function value at the specified point.\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     */\n+    protected double computeObjectiveValue(double[] params) {\n+        super.incrementEvaluationCount();\n+        return function.value(params);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/ObjectiveFunctionGradient.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * Gradient of the scalar function to be optimized.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class ObjectiveFunctionGradient implements OptimizationData {\n+    /** Function to be optimized. */\n+    private final MultivariateVectorFunction gradient;\n+\n+    /**\n+     * @param g Gradient of the function to be optimized.\n+     */\n+    public ObjectiveFunctionGradient(MultivariateVectorFunction g) {\n+        gradient = g;\n+    }\n+\n+    /**\n+     * Gets the gradient of the function to be optimized.\n+     *\n+     * @return the objective function gradient.\n+     */\n+    public MultivariateVectorFunction getObjectiveFunctionGradient() {\n+        return gradient;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar.gradient;\n+\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.analysis.solvers.BrentSolver;\n+import org.apache.commons.math3.analysis.solvers.UnivariateSolver;\n+import org.apache.commons.math3.exception.MathInternalError;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.nonlinear.scalar.GradientMultivariateOptimizer;\n+import org.apache.commons.math3.util.FastMath;\n+\n+/**\n+ * Non-linear conjugate gradient optimizer.\n+ * <p>\n+ * This class supports both the Fletcher-Reeves and the Polak-Ribi\u00e8re\n+ * update formulas for the conjugate search directions.\n+ * It also supports optional preconditioning.\n+ * </p>\n+ *\n+ * @version $Id: NonLinearConjugateGradientOptimizer.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class NonLinearConjugateGradientOptimizer\n+    extends GradientMultivariateOptimizer {\n+    /** Update formula for the beta parameter. */\n+    private final Formula updateFormula;\n+    /** Preconditioner (may be null). */\n+    private final Preconditioner preconditioner;\n+    /** solver to use in the line search (may be null). */\n+    private final UnivariateSolver solver;\n+    /** Initial step used to bracket the optimum in line search. */\n+    private double initialStep = 1;\n+\n+    /**\n+     * Constructor with default {@link BrentSolver line search solver} and\n+     * {@link IdentityPreconditioner preconditioner}.\n+     *\n+     * @param updateFormula formula to use for updating the &beta; parameter,\n+     * must be one of {@link Formula#FLETCHER_REEVES} or\n+     * {@link Formula#POLAK_RIBIERE}.\n+     * @param checker Convergence checker.\n+     */\n+    public NonLinearConjugateGradientOptimizer(final Formula updateFormula,\n+                                               ConvergenceChecker<PointValuePair> checker) {\n+        this(updateFormula,\n+             checker,\n+             new BrentSolver(),\n+             new IdentityPreconditioner());\n+    }\n+\n+    /**\n+     * Available choices of update formulas for the updating the parameter\n+     * that is used to compute the successive conjugate search directions.\n+     * For non-linear conjugate gradients, there are\n+     * two formulas:\n+     * <ul>\n+     *   <li>Fletcher-Reeves formula</li>\n+     *   <li>Polak-Ribi\u00e8re formula</li>\n+     * </ul>\n+     *\n+     * On the one hand, the Fletcher-Reeves formula is guaranteed to converge\n+     * if the start point is close enough of the optimum whether the\n+     * Polak-Ribi\u00e8re formula may not converge in rare cases. On the\n+     * other hand, the Polak-Ribi\u00e8re formula is often faster when it\n+     * does converge. Polak-Ribi\u00e8re is often used.\n+     *\n+     * @since 2.0\n+     */\n+    public static enum Formula {\n+        /** Fletcher-Reeves formula. */\n+        FLETCHER_REEVES,\n+        /** Polak-Ribi\u00e8re formula. */\n+        POLAK_RIBIERE\n+    }\n+\n+    /**\n+     * The initial step is a factor with respect to the search direction\n+     * (which itself is roughly related to the gradient of the function).\n+     * <br/>\n+     * It is used to find an interval that brackets the optimum in line\n+     * search.\n+     *\n+     * @since 3.1\n+     */\n+    public static class BracketingStep implements OptimizationData {\n+        /** Initial step. */\n+        private final double initialStep;\n+\n+        /**\n+         * @param step Initial step for the bracket search.\n+         */\n+        public BracketingStep(double step) {\n+            initialStep = step;\n+        }\n+\n+        /**\n+         * Gets the initial step.\n+         *\n+         * @return the initial step.\n+         */\n+        public double getBracketingStep() {\n+            return initialStep;\n+        }\n+    }\n+\n+    /**\n+     * Constructor with default {@link IdentityPreconditioner preconditioner}.\n+     *\n+     * @param updateFormula formula to use for updating the &beta; parameter,\n+     * must be one of {@link Formula#FLETCHER_REEVES} or\n+     * {@link Formula#POLAK_RIBIERE}.\n+     * @param checker Convergence checker.\n+     * @param lineSearchSolver Solver to use during line search.\n+     */\n+    public NonLinearConjugateGradientOptimizer(final Formula updateFormula,\n+                                               ConvergenceChecker<PointValuePair> checker,\n+                                               final UnivariateSolver lineSearchSolver) {\n+        this(updateFormula,\n+             checker,\n+             lineSearchSolver,\n+             new IdentityPreconditioner());\n+    }\n+\n+    /**\n+     * @param updateFormula formula to use for updating the &beta; parameter,\n+     * must be one of {@link Formula#FLETCHER_REEVES} or\n+     * {@link Formula#POLAK_RIBIERE}.\n+     * @param checker Convergence checker.\n+     * @param lineSearchSolver Solver to use during line search.\n+     * @param preconditioner Preconditioner.\n+     */\n+    public NonLinearConjugateGradientOptimizer(final Formula updateFormula,\n+                                               ConvergenceChecker<PointValuePair> checker,\n+                                               final UnivariateSolver lineSearchSolver,\n+                                               final Preconditioner preconditioner) {\n+        super(checker);\n+\n+        this.updateFormula = updateFormula;\n+        solver = lineSearchSolver;\n+        this.preconditioner = preconditioner;\n+        initialStep = 1;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxEval}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.InitialGuess}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.SimpleBounds}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.GoalType}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.ObjectiveFunction}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.nonlinear.scalar.ObjectiveFunctionGradient}</li>\n+     *  <li>{@link BracketingStep}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations (of the objective function) is exceeded.\n+     */\n+    @Override\n+    public PointValuePair optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException {\n+         // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected PointValuePair doOptimize() {\n+        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+        final double[] point = getStartPoint();\n+        final GoalType goal = getGoalType();\n+        final int n = point.length;\n+        double[] r = computeObjectiveGradient(point);\n+        if (goal == GoalType.MINIMIZE) {\n+            for (int i = 0; i < n; i++) {\n+                r[i] = -r[i];\n+            }\n+        }\n+\n+        // Initial search direction.\n+        double[] steepestDescent = preconditioner.precondition(point, r);\n+        double[] searchDirection = steepestDescent.clone();\n+\n+        double delta = 0;\n+        for (int i = 0; i < n; ++i) {\n+            delta += r[i] * searchDirection[i];\n+        }\n+\n+        PointValuePair current = null;\n+        int iter = 0;\n+        int maxEval = getMaxEvaluations();\n+        while (true) {\n+            ++iter;\n+\n+            final double objective = computeObjectiveValue(point);\n+            PointValuePair previous = current;\n+            current = new PointValuePair(point, objective);\n+            if (previous != null) {\n+                if (checker.converged(iter, previous, current)) {\n+                    // We have found an optimum.\n+                    return current;\n+                }\n+            }\n+\n+            // Find the optimal step in the search direction.\n+            final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n+            final double uB = findUpperBound(lsf, 0, initialStep);\n+            // XXX Last parameters is set to a value close to zero in order to\n+            // work around the divergence problem in the \"testCircleFitting\"\n+            // unit test (see MATH-439).\n+            final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n+            maxEval -= solver.getEvaluations(); // Subtract used up evaluations.\n+\n+            // Validate new point.\n+            for (int i = 0; i < point.length; ++i) {\n+                point[i] += step * searchDirection[i];\n+            }\n+\n+            r = computeObjectiveGradient(point);\n+            if (goal == GoalType.MINIMIZE) {\n+                for (int i = 0; i < n; ++i) {\n+                    r[i] = -r[i];\n+                }\n+            }\n+\n+            // Compute beta.\n+            final double deltaOld = delta;\n+            final double[] newSteepestDescent = preconditioner.precondition(point, r);\n+            delta = 0;\n+            for (int i = 0; i < n; ++i) {\n+                delta += r[i] * newSteepestDescent[i];\n+            }\n+\n+            final double beta;\n+            switch (updateFormula) {\n+            case FLETCHER_REEVES:\n+                beta = delta / deltaOld;\n+                break;\n+            case POLAK_RIBIERE:\n+                double deltaMid = 0;\n+                for (int i = 0; i < r.length; ++i) {\n+                    deltaMid += r[i] * steepestDescent[i];\n+                }\n+                beta = (delta - deltaMid) / deltaOld;\n+                break;\n+            default:\n+                // Should never happen.\n+                throw new MathInternalError();\n+            }\n+            steepestDescent = newSteepestDescent;\n+\n+            // Compute conjugate search direction.\n+            if (iter % n == 0 ||\n+                beta < 0) {\n+                // Break conjugation: reset search direction.\n+                searchDirection = steepestDescent.clone();\n+            } else {\n+                // Compute new conjugate search direction.\n+                for (int i = 0; i < n; ++i) {\n+                    searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link InitialStep}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if  (data instanceof BracketingStep) {\n+                initialStep = ((BracketingStep) data).getBracketingStep();\n+                // If more data must be parsed, this statement _must_ be\n+                // changed to \"continue\".\n+                break;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Finds the upper bound b ensuring bracketing of a root between a and b.\n+     *\n+     * @param f function whose root must be bracketed.\n+     * @param a lower bound of the interval.\n+     * @param h initial step to try.\n+     * @return b such that f(a) and f(b) have opposite signs.\n+     * @throws MathIllegalStateException if no bracket can be found.\n+     */\n+    private double findUpperBound(final UnivariateFunction f,\n+                                  final double a, final double h) {\n+        final double yA = f.value(a);\n+        double yB = yA;\n+        for (double step = h; step < Double.MAX_VALUE; step *= FastMath.max(2, yA / yB)) {\n+            final double b = a + step;\n+            yB = f.value(b);\n+            if (yA * yB <= 0) {\n+                return b;\n+            }\n+        }\n+        throw new MathIllegalStateException(LocalizedFormats.UNABLE_TO_BRACKET_OPTIMUM_IN_LINE_SEARCH);\n+    }\n+\n+    /** Default identity preconditioner. */\n+    public static class IdentityPreconditioner implements Preconditioner {\n+        /** {@inheritDoc} */\n+        public double[] precondition(double[] variables, double[] r) {\n+            return r.clone();\n+        }\n+    }\n+\n+    /**\n+     * Internal class for line search.\n+     * <p>\n+     * The function represented by this class is the dot product of\n+     * the objective function gradient and the search direction. Its\n+     * value is zero when the gradient is orthogonal to the search\n+     * direction, i.e. when the objective function value is a local\n+     * extremum along the search direction.\n+     * </p>\n+     */\n+    private class LineSearchFunction implements UnivariateFunction {\n+        /** Current point. */\n+        private final double[] currentPoint;\n+        /** Search direction. */\n+        private final double[] searchDirection;\n+\n+        /**\n+         * @param point Current point.\n+         * @param direction Search direction.\n+         */\n+        public LineSearchFunction(double[] point,\n+                                  double[] direction) {\n+            currentPoint = point.clone();\n+            searchDirection = direction.clone();\n+        }\n+\n+        /** {@inheritDoc} */\n+        public double value(double x) {\n+            // current point in the search direction\n+            final double[] shiftedPoint = currentPoint.clone();\n+            for (int i = 0; i < shiftedPoint.length; ++i) {\n+                shiftedPoint[i] += x * searchDirection[i];\n+            }\n+\n+            // gradient of the objective function\n+            final double[] gradient = computeObjectiveGradient(shiftedPoint);\n+\n+            // dot product with the search direction\n+            double dotProduct = 0;\n+            for (int i = 0; i < gradient.length; ++i) {\n+                dotProduct += gradient[i] * searchDirection[i];\n+            }\n+\n+            return dotProduct;\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/gradient/Preconditioner.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar.gradient;\n+\n+/**\n+ * This interface represents a preconditioner for differentiable scalar\n+ * objective function optimizers.\n+ * @version $Id: Preconditioner.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public interface Preconditioner {\n+    /**\n+     * Precondition a search direction.\n+     * <p>\n+     * The returned preconditioned search direction must be computed fast or\n+     * the algorithm performances will drop drastically. A classical approach\n+     * is to compute only the diagonal elements of the hessian and to divide\n+     * the raw search direction by these elements if they are all positive.\n+     * If at least one of them is negative, it is safer to return a clone of\n+     * the raw search direction as if the hessian was the identity matrix. The\n+     * rationale for this simplified choice is that a negative diagonal element\n+     * means the current point is far from the optimum and preconditioning will\n+     * not be efficient anyway in this case.\n+     * </p>\n+     * @param point current point at which the search direction was computed\n+     * @param r raw search direction (i.e. opposite of the gradient)\n+     * @return approximation of H<sup>-1</sup>r where H is the objective function hessian\n+     */\n+    double[] precondition(double[] point, double[] r);\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/gradient/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.gradient;\n+\n+/**\n+ * This package provides optimization algorithms that require derivatives.\n+ */\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/AbstractSimplex.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import java.util.Arrays;\n+import java.util.Comparator;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.ZeroException;\n+import org.apache.commons.math3.exception.OutOfRangeException;\n+import org.apache.commons.math3.exception.NullArgumentException;\n+import org.apache.commons.math3.exception.MathIllegalArgumentException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * This class implements the simplex concept.\n+ * It is intended to be used in conjunction with {@link SimplexOptimizer}.\n+ * <br/>\n+ * The initial configuration of the simplex is set by the constructors\n+ * {@link #AbstractSimplex(double[])} or {@link #AbstractSimplex(double[][])}.\n+ * The other {@link #AbstractSimplex(int) constructor} will set all steps\n+ * to 1, thus building a default configuration from a unit hypercube.\n+ * <br/>\n+ * Users <em>must</em> call the {@link #build(double[]) build} method in order\n+ * to create the data structure that will be acted on by the other methods of\n+ * this class.\n+ *\n+ * @see SimplexOptimizer\n+ * @version $Id: AbstractSimplex.java 1397759 2012-10-13 01:12:58Z erans $\n+ * @since 3.0\n+ */\n+public abstract class AbstractSimplex implements OptimizationData {\n+    /** Simplex. */\n+    private PointValuePair[] simplex;\n+    /** Start simplex configuration. */\n+    private double[][] startConfiguration;\n+    /** Simplex dimension (must be equal to {@code simplex.length - 1}). */\n+    private final int dimension;\n+\n+    /**\n+     * Build a unit hypercube simplex.\n+     *\n+     * @param n Dimension of the simplex.\n+     */\n+    protected AbstractSimplex(int n) {\n+        this(n, 1d);\n+    }\n+\n+    /**\n+     * Build a hypercube simplex with the given side length.\n+     *\n+     * @param n Dimension of the simplex.\n+     * @param sideLength Length of the sides of the hypercube.\n+     */\n+    protected AbstractSimplex(int n,\n+                              double sideLength) {\n+        this(createHypercubeSteps(n, sideLength));\n+    }\n+\n+    /**\n+     * The start configuration for simplex is built from a box parallel to\n+     * the canonical axes of the space. The simplex is the subset of vertices\n+     * of a box parallel to the canonical axes. It is built as the path followed\n+     * while traveling from one vertex of the box to the diagonally opposite\n+     * vertex moving only along the box edges. The first vertex of the box will\n+     * be located at the start point of the optimization.\n+     * As an example, in dimension 3 a simplex has 4 vertices. Setting the\n+     * steps to (1, 10, 2) and the start point to (1, 1, 1) would imply the\n+     * start simplex would be: { (1, 1, 1), (2, 1, 1), (2, 11, 1), (2, 11, 3) }.\n+     * The first vertex would be set to the start point at (1, 1, 1) and the\n+     * last vertex would be set to the diagonally opposite vertex at (2, 11, 3).\n+     *\n+     * @param steps Steps along the canonical axes representing box edges. They\n+     * may be negative but not zero.\n+     * @throws NullArgumentException if {@code steps} is {@code null}.\n+     * @throws ZeroException if one of the steps is zero.\n+     */\n+    protected AbstractSimplex(final double[] steps) {\n+        if (steps == null) {\n+            throw new NullArgumentException();\n+        }\n+        if (steps.length == 0) {\n+            throw new ZeroException();\n+        }\n+        dimension = steps.length;\n+\n+        // Only the relative position of the n final vertices with respect\n+        // to the first one are stored.\n+        startConfiguration = new double[dimension][dimension];\n+        for (int i = 0; i < dimension; i++) {\n+            final double[] vertexI = startConfiguration[i];\n+            for (int j = 0; j < i + 1; j++) {\n+                if (steps[j] == 0) {\n+                    throw new ZeroException(LocalizedFormats.EQUAL_VERTICES_IN_SIMPLEX);\n+                }\n+                System.arraycopy(steps, 0, vertexI, 0, j + 1);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * The real initial simplex will be set up by moving the reference\n+     * simplex such that its first point is located at the start point of the\n+     * optimization.\n+     *\n+     * @param referenceSimplex Reference simplex.\n+     * @throws NotStrictlyPositiveException if the reference simplex does not\n+     * contain at least one point.\n+     * @throws DimensionMismatchException if there is a dimension mismatch\n+     * in the reference simplex.\n+     * @throws IllegalArgumentException if one of its vertices is duplicated.\n+     */\n+    protected AbstractSimplex(final double[][] referenceSimplex) {\n+        if (referenceSimplex.length <= 0) {\n+            throw new NotStrictlyPositiveException(LocalizedFormats.SIMPLEX_NEED_ONE_POINT,\n+                                                   referenceSimplex.length);\n+        }\n+        dimension = referenceSimplex.length - 1;\n+\n+        // Only the relative position of the n final vertices with respect\n+        // to the first one are stored.\n+        startConfiguration = new double[dimension][dimension];\n+        final double[] ref0 = referenceSimplex[0];\n+\n+        // Loop over vertices.\n+        for (int i = 0; i < referenceSimplex.length; i++) {\n+            final double[] refI = referenceSimplex[i];\n+\n+            // Safety checks.\n+            if (refI.length != dimension) {\n+                throw new DimensionMismatchException(refI.length, dimension);\n+            }\n+            for (int j = 0; j < i; j++) {\n+                final double[] refJ = referenceSimplex[j];\n+                boolean allEquals = true;\n+                for (int k = 0; k < dimension; k++) {\n+                    if (refI[k] != refJ[k]) {\n+                        allEquals = false;\n+                        break;\n+                    }\n+                }\n+                if (allEquals) {\n+                    throw new MathIllegalArgumentException(LocalizedFormats.EQUAL_VERTICES_IN_SIMPLEX,\n+                                                           i, j);\n+                }\n+            }\n+\n+            // Store vertex i position relative to vertex 0 position.\n+            if (i > 0) {\n+                final double[] confI = startConfiguration[i - 1];\n+                for (int k = 0; k < dimension; k++) {\n+                    confI[k] = refI[k] - ref0[k];\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Get simplex dimension.\n+     *\n+     * @return the dimension of the simplex.\n+     */\n+    public int getDimension() {\n+        return dimension;\n+    }\n+\n+    /**\n+     * Get simplex size.\n+     * After calling the {@link #build(double[]) build} method, this method will\n+     * will be equivalent to {@code getDimension() + 1}.\n+     *\n+     * @return the size of the simplex.\n+     */\n+    public int getSize() {\n+        return simplex.length;\n+    }\n+\n+    /**\n+     * Compute the next simplex of the algorithm.\n+     *\n+     * @param evaluationFunction Evaluation function.\n+     * @param comparator Comparator to use to sort simplex vertices from best\n+     * to worst.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+     * if the algorithm fails to converge.\n+     */\n+    public abstract void iterate(final MultivariateFunction evaluationFunction,\n+                                 final Comparator<PointValuePair> comparator);\n+\n+    /**\n+     * Build an initial simplex.\n+     *\n+     * @param startPoint First point of the simplex.\n+     * @throws DimensionMismatchException if the start point does not match\n+     * simplex dimension.\n+     */\n+    public void build(final double[] startPoint) {\n+        if (dimension != startPoint.length) {\n+            throw new DimensionMismatchException(dimension, startPoint.length);\n+        }\n+\n+        // Set first vertex.\n+        simplex = new PointValuePair[dimension + 1];\n+        simplex[0] = new PointValuePair(startPoint, Double.NaN);\n+\n+        // Set remaining vertices.\n+        for (int i = 0; i < dimension; i++) {\n+            final double[] confI = startConfiguration[i];\n+            final double[] vertexI = new double[dimension];\n+            for (int k = 0; k < dimension; k++) {\n+                vertexI[k] = startPoint[k] + confI[k];\n+            }\n+            simplex[i + 1] = new PointValuePair(vertexI, Double.NaN);\n+        }\n+    }\n+\n+    /**\n+     * Evaluate all the non-evaluated points of the simplex.\n+     *\n+     * @param evaluationFunction Evaluation function.\n+     * @param comparator Comparator to use to sort simplex vertices from best to worst.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+     * if the maximal number of evaluations is exceeded.\n+     */\n+    public void evaluate(final MultivariateFunction evaluationFunction,\n+                         final Comparator<PointValuePair> comparator) {\n+        // Evaluate the objective function at all non-evaluated simplex points.\n+        for (int i = 0; i < simplex.length; i++) {\n+            final PointValuePair vertex = simplex[i];\n+            final double[] point = vertex.getPointRef();\n+            if (Double.isNaN(vertex.getValue())) {\n+                simplex[i] = new PointValuePair(point, evaluationFunction.value(point), false);\n+            }\n+        }\n+\n+        // Sort the simplex from best to worst.\n+        Arrays.sort(simplex, comparator);\n+    }\n+\n+    /**\n+     * Replace the worst point of the simplex by a new point.\n+     *\n+     * @param pointValuePair Point to insert.\n+     * @param comparator Comparator to use for sorting the simplex vertices\n+     * from best to worst.\n+     */\n+    protected void replaceWorstPoint(PointValuePair pointValuePair,\n+                                     final Comparator<PointValuePair> comparator) {\n+        for (int i = 0; i < dimension; i++) {\n+            if (comparator.compare(simplex[i], pointValuePair) > 0) {\n+                PointValuePair tmp = simplex[i];\n+                simplex[i] = pointValuePair;\n+                pointValuePair = tmp;\n+            }\n+        }\n+        simplex[dimension] = pointValuePair;\n+    }\n+\n+    /**\n+     * Get the points of the simplex.\n+     *\n+     * @return all the simplex points.\n+     */\n+    public PointValuePair[] getPoints() {\n+        final PointValuePair[] copy = new PointValuePair[simplex.length];\n+        System.arraycopy(simplex, 0, copy, 0, simplex.length);\n+        return copy;\n+    }\n+\n+    /**\n+     * Get the simplex point stored at the requested {@code index}.\n+     *\n+     * @param index Location.\n+     * @return the point at location {@code index}.\n+     */\n+    public PointValuePair getPoint(int index) {\n+        if (index < 0 ||\n+            index >= simplex.length) {\n+            throw new OutOfRangeException(index, 0, simplex.length - 1);\n+        }\n+        return simplex[index];\n+    }\n+\n+    /**\n+     * Store a new point at location {@code index}.\n+     * Note that no deep-copy of {@code point} is performed.\n+     *\n+     * @param index Location.\n+     * @param point New value.\n+     */\n+    protected void setPoint(int index, PointValuePair point) {\n+        if (index < 0 ||\n+            index >= simplex.length) {\n+            throw new OutOfRangeException(index, 0, simplex.length - 1);\n+        }\n+        simplex[index] = point;\n+    }\n+\n+    /**\n+     * Replace all points.\n+     * Note that no deep-copy of {@code points} is performed.\n+     *\n+     * @param points New Points.\n+     */\n+    protected void setPoints(PointValuePair[] points) {\n+        if (points.length != simplex.length) {\n+            throw new DimensionMismatchException(points.length, simplex.length);\n+        }\n+        simplex = points;\n+    }\n+\n+    /**\n+     * Create steps for a unit hypercube.\n+     *\n+     * @param n Dimension of the hypercube.\n+     * @param sideLength Length of the sides of the hypercube.\n+     * @return the steps.\n+     */\n+    private static double[] createHypercubeSteps(int n,\n+                                                 double sideLength) {\n+        final double[] steps = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            steps[i] = sideLength;\n+        }\n+        return steps;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/BOBYQAOptimizer.java\n+// CHECKSTYLE: stop all\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import java.util.Arrays;\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.OutOfRangeException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.linear.Array2DRowRealMatrix;\n+import org.apache.commons.math3.linear.ArrayRealVector;\n+import org.apache.commons.math3.linear.RealVector;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\n+\n+/**\n+ * Powell's BOBYQA algorithm. This implementation is translated and\n+ * adapted from the Fortran version available\n+ * <a href=\"http://plato.asu.edu/ftp/other_software/bobyqa.zip\">here</a>.\n+ * See <a href=\"http://www.optimization-online.org/DB_HTML/2010/05/2616.html\">\n+ * this paper</a> for an introduction.\n+ * <br/>\n+ * BOBYQA is particularly well suited for high dimensional problems\n+ * where derivatives are not available. In most cases it outperforms the\n+ * {@link PowellOptimizer} significantly. Stochastic algorithms like\n+ * {@link CMAESOptimizer} succeed more often than BOBYQA, but are more\n+ * expensive. BOBYQA could also be considered as a replacement of any\n+ * derivative-based optimizer when the derivatives are approximated by\n+ * finite differences.\n+ *\n+ * @version $Id: BOBYQAOptimizer.java 1413131 2012-11-24 04:44:02Z psteitz $\n+ * @since 3.0\n+ */\n+public class BOBYQAOptimizer\n+    extends MultivariateOptimizer {\n+    /** Minimum dimension of the problem: {@value} */\n+    public static final int MINIMUM_PROBLEM_DIMENSION = 2;\n+    /** Default value for {@link #initialTrustRegionRadius}: {@value} . */\n+    public static final double DEFAULT_INITIAL_RADIUS = 10.0;\n+    /** Default value for {@link #stoppingTrustRegionRadius}: {@value} . */\n+    public static final double DEFAULT_STOPPING_RADIUS = 1E-8;\n+\n+    private static final double ZERO = 0d;\n+    private static final double ONE = 1d;\n+    private static final double TWO = 2d;\n+    private static final double TEN = 10d;\n+    private static final double SIXTEEN = 16d;\n+    private static final double TWO_HUNDRED_FIFTY = 250d;\n+    private static final double MINUS_ONE = -ONE;\n+    private static final double HALF = ONE / 2;\n+    private static final double ONE_OVER_FOUR = ONE / 4;\n+    private static final double ONE_OVER_EIGHT = ONE / 8;\n+    private static final double ONE_OVER_TEN = ONE / 10;\n+    private static final double ONE_OVER_A_THOUSAND = ONE / 1000;\n+\n+    /**\n+     * numberOfInterpolationPoints XXX\n+     */\n+    private final int numberOfInterpolationPoints;\n+    /**\n+     * initialTrustRegionRadius XXX\n+     */\n+    private double initialTrustRegionRadius;\n+    /**\n+     * stoppingTrustRegionRadius XXX\n+     */\n+    private final double stoppingTrustRegionRadius;\n+    /** Goal type (minimize or maximize). */\n+    private boolean isMinimize;\n+    /**\n+     * Current best values for the variables to be optimized.\n+     * The vector will be changed in-place to contain the values of the least\n+     * calculated objective function values.\n+     */\n+    private ArrayRealVector currentBest;\n+    /** Differences between the upper and lower bounds. */\n+    private double[] boundDifference;\n+    /**\n+     * Index of the interpolation point at the trust region center.\n+     */\n+    private int trustRegionCenterInterpolationPointIndex;\n+    /**\n+     * Last <em>n</em> columns of matrix H (where <em>n</em> is the dimension\n+     * of the problem).\n+     * XXX \"bmat\" in the original code.\n+     */\n+    private Array2DRowRealMatrix bMatrix;\n+    /**\n+     * Factorization of the leading <em>npt</em> square submatrix of H, this\n+     * factorization being Z Z<sup>T</sup>, which provides both the correct\n+     * rank and positive semi-definiteness.\n+     * XXX \"zmat\" in the original code.\n+     */\n+    private Array2DRowRealMatrix zMatrix;\n+    /**\n+     * Coordinates of the interpolation points relative to {@link #originShift}.\n+     * XXX \"xpt\" in the original code.\n+     */\n+    private Array2DRowRealMatrix interpolationPoints;\n+    /**\n+     * Shift of origin that should reduce the contributions from rounding\n+     * errors to values of the model and Lagrange functions.\n+     * XXX \"xbase\" in the original code.\n+     */\n+    private ArrayRealVector originShift;\n+    /**\n+     * Values of the objective function at the interpolation points.\n+     * XXX \"fval\" in the original code.\n+     */\n+    private ArrayRealVector fAtInterpolationPoints;\n+    /**\n+     * Displacement from {@link #originShift} of the trust region center.\n+     * XXX \"xopt\" in the original code.\n+     */\n+    private ArrayRealVector trustRegionCenterOffset;\n+    /**\n+     * Gradient of the quadratic model at {@link #originShift} +\n+     * {@link #trustRegionCenterOffset}.\n+     * XXX \"gopt\" in the original code.\n+     */\n+    private ArrayRealVector gradientAtTrustRegionCenter;\n+    /**\n+     * Differences {@link #getLowerBound()} - {@link #originShift}.\n+     * All the components of every {@link #trustRegionCenterOffset} are going\n+     * to satisfy the bounds<br/>\n+     * {@link #getLowerBound() lowerBound}<sub>i</sub> &le;\n+     * {@link #trustRegionCenterOffset}<sub>i</sub>,<br/>\n+     * with appropriate equalities when {@link #trustRegionCenterOffset} is\n+     * on a constraint boundary.\n+     * XXX \"sl\" in the original code.\n+     */\n+    private ArrayRealVector lowerDifference;\n+    /**\n+     * Differences {@link #getUpperBound()} - {@link #originShift}\n+     * All the components of every {@link #trustRegionCenterOffset} are going\n+     * to satisfy the bounds<br/>\n+     *  {@link #trustRegionCenterOffset}<sub>i</sub> &le;\n+     *  {@link #getUpperBound() upperBound}<sub>i</sub>,<br/>\n+     * with appropriate equalities when {@link #trustRegionCenterOffset} is\n+     * on a constraint boundary.\n+     * XXX \"su\" in the original code.\n+     */\n+    private ArrayRealVector upperDifference;\n+    /**\n+     * Parameters of the implicit second derivatives of the quadratic model.\n+     * XXX \"pq\" in the original code.\n+     */\n+    private ArrayRealVector modelSecondDerivativesParameters;\n+    /**\n+     * Point chosen by function {@link #trsbox(double,ArrayRealVector,\n+     * ArrayRealVector, ArrayRealVector,ArrayRealVector,ArrayRealVector) trsbox}\n+     * or {@link #altmov(int,double) altmov}.\n+     * Usually {@link #originShift} + {@link #newPoint} is the vector of\n+     * variables for the next evaluation of the objective function.\n+     * It also satisfies the constraints indicated in {@link #lowerDifference}\n+     * and {@link #upperDifference}.\n+     * XXX \"xnew\" in the original code.\n+     */\n+    private ArrayRealVector newPoint;\n+    /**\n+     * Alternative to {@link #newPoint}, chosen by\n+     * {@link #altmov(int,double) altmov}.\n+     * It may replace {@link #newPoint} in order to increase the denominator\n+     * in the {@link #update(double, double, int) updating procedure}.\n+     * XXX \"xalt\" in the original code.\n+     */\n+    private ArrayRealVector alternativeNewPoint;\n+    /**\n+     * Trial step from {@link #trustRegionCenterOffset} which is usually\n+     * {@link #newPoint} - {@link #trustRegionCenterOffset}.\n+     * XXX \"d__\" in the original code.\n+     */\n+    private ArrayRealVector trialStepPoint;\n+    /**\n+     * Values of the Lagrange functions at a new point.\n+     * XXX \"vlag\" in the original code.\n+     */\n+    private ArrayRealVector lagrangeValuesAtNewPoint;\n+    /**\n+     * Explicit second derivatives of the quadratic model.\n+     * XXX \"hq\" in the original code.\n+     */\n+    private ArrayRealVector modelSecondDerivativesValues;\n+\n+    /**\n+     * @param numberOfInterpolationPoints Number of interpolation conditions.\n+     * For a problem of dimension {@code n}, its value must be in the interval\n+     * {@code [n+2, (n+1)(n+2)/2]}.\n+     * Choices that exceed {@code 2n+1} are not recommended.\n+     */\n+    public BOBYQAOptimizer(int numberOfInterpolationPoints) {\n+        this(numberOfInterpolationPoints,\n+             DEFAULT_INITIAL_RADIUS,\n+             DEFAULT_STOPPING_RADIUS);\n+    }\n+\n+    /**\n+     * @param numberOfInterpolationPoints Number of interpolation conditions.\n+     * For a problem of dimension {@code n}, its value must be in the interval\n+     * {@code [n+2, (n+1)(n+2)/2]}.\n+     * Choices that exceed {@code 2n+1} are not recommended.\n+     * @param initialTrustRegionRadius Initial trust region radius.\n+     * @param stoppingTrustRegionRadius Stopping trust region radius.\n+     */\n+    public BOBYQAOptimizer(int numberOfInterpolationPoints,\n+                           double initialTrustRegionRadius,\n+                           double stoppingTrustRegionRadius) {\n+        super(null); // No custom convergence criterion.\n+        this.numberOfInterpolationPoints = numberOfInterpolationPoints;\n+        this.initialTrustRegionRadius = initialTrustRegionRadius;\n+        this.stoppingTrustRegionRadius = stoppingTrustRegionRadius;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected PointValuePair doOptimize() {\n+        final double[] lowerBound = getLowerBound();\n+        final double[] upperBound = getUpperBound();\n+\n+        // Validity checks.\n+        setup(lowerBound, upperBound);\n+\n+        isMinimize = (getGoalType() == GoalType.MINIMIZE);\n+        currentBest = new ArrayRealVector(getStartPoint());\n+\n+        final double value = bobyqa(lowerBound, upperBound);\n+\n+        return new PointValuePair(currentBest.getDataRef(),\n+                                  isMinimize ? value : -value);\n+    }\n+\n+    /**\n+     *     This subroutine seeks the least value of a function of many variables,\n+     *     by applying a trust region method that forms quadratic models by\n+     *     interpolation. There is usually some freedom in the interpolation\n+     *     conditions, which is taken up by minimizing the Frobenius norm of\n+     *     the change to the second derivative of the model, beginning with the\n+     *     zero matrix. The values of the variables are constrained by upper and\n+     *     lower bounds. The arguments of the subroutine are as follows.\n+     *\n+     *     N must be set to the number of variables and must be at least two.\n+     *     NPT is the number of interpolation conditions. Its value must be in\n+     *       the interval [N+2,(N+1)(N+2)/2]. Choices that exceed 2*N+1 are not\n+     *       recommended.\n+     *     Initial values of the variables must be set in X(1),X(2),...,X(N). They\n+     *       will be changed to the values that give the least calculated F.\n+     *     For I=1,2,...,N, XL(I) and XU(I) must provide the lower and upper\n+     *       bounds, respectively, on X(I). The construction of quadratic models\n+     *       requires XL(I) to be strictly less than XU(I) for each I. Further,\n+     *       the contribution to a model from changes to the I-th variable is\n+     *       damaged severely by rounding errors if XU(I)-XL(I) is too small.\n+     *     RHOBEG and RHOEND must be set to the initial and final values of a trust\n+     *       region radius, so both must be positive with RHOEND no greater than\n+     *       RHOBEG. Typically, RHOBEG should be about one tenth of the greatest\n+     *       expected change to a variable, while RHOEND should indicate the\n+     *       accuracy that is required in the final values of the variables. An\n+     *       error return occurs if any of the differences XU(I)-XL(I), I=1,...,N,\n+     *       is less than 2*RHOBEG.\n+     *     MAXFUN must be set to an upper bound on the number of calls of CALFUN.\n+     *     The array W will be used for working space. Its length must be at least\n+     *       (NPT+5)*(NPT+N)+3*N*(N+5)/2.\n+     *\n+     * @param lowerBound Lower bounds.\n+     * @param upperBound Upper bounds.\n+     * @return the value of the objective at the optimum.\n+     */\n+    private double bobyqa(double[] lowerBound,\n+                          double[] upperBound) {\n+        printMethod(); // XXX\n+\n+        final int n = currentBest.getDimension();\n+\n+        // Return if there is insufficient space between the bounds. Modify the\n+        // initial X if necessary in order to avoid conflicts between the bounds\n+        // and the construction of the first quadratic model. The lower and upper\n+        // bounds on moves from the updated X are set now, in the ISL and ISU\n+        // partitions of W, in order to provide useful and exact information about\n+        // components of X that become within distance RHOBEG from their bounds.\n+\n+        for (int j = 0; j < n; j++) {\n+            final double boundDiff = boundDifference[j];\n+            lowerDifference.setEntry(j, lowerBound[j] - currentBest.getEntry(j));\n+            upperDifference.setEntry(j, upperBound[j] - currentBest.getEntry(j));\n+            if (lowerDifference.getEntry(j) >= -initialTrustRegionRadius) {\n+                if (lowerDifference.getEntry(j) >= ZERO) {\n+                    currentBest.setEntry(j, lowerBound[j]);\n+                    lowerDifference.setEntry(j, ZERO);\n+                    upperDifference.setEntry(j, boundDiff);\n+                } else {\n+                    currentBest.setEntry(j, lowerBound[j] + initialTrustRegionRadius);\n+                    lowerDifference.setEntry(j, -initialTrustRegionRadius);\n+                    // Computing MAX\n+                    final double deltaOne = upperBound[j] - currentBest.getEntry(j);\n+                    upperDifference.setEntry(j, Math.max(deltaOne, initialTrustRegionRadius));\n+                }\n+            } else if (upperDifference.getEntry(j) <= initialTrustRegionRadius) {\n+                if (upperDifference.getEntry(j) <= ZERO) {\n+                    currentBest.setEntry(j, upperBound[j]);\n+                    lowerDifference.setEntry(j, -boundDiff);\n+                    upperDifference.setEntry(j, ZERO);\n+                } else {\n+                    currentBest.setEntry(j, upperBound[j] - initialTrustRegionRadius);\n+                    // Computing MIN\n+                    final double deltaOne = lowerBound[j] - currentBest.getEntry(j);\n+                    final double deltaTwo = -initialTrustRegionRadius;\n+                    lowerDifference.setEntry(j, Math.min(deltaOne, deltaTwo));\n+                    upperDifference.setEntry(j, initialTrustRegionRadius);\n+                }\n+            }\n+        }\n+\n+        // Make the call of BOBYQB.\n+\n+        return bobyqb(lowerBound, upperBound);\n+    } // bobyqa\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    /**\n+     *     The arguments N, NPT, X, XL, XU, RHOBEG, RHOEND, IPRINT and MAXFUN\n+     *       are identical to the corresponding arguments in SUBROUTINE BOBYQA.\n+     *     XBASE holds a shift of origin that should reduce the contributions\n+     *       from rounding errors to values of the model and Lagrange functions.\n+     *     XPT is a two-dimensional array that holds the coordinates of the\n+     *       interpolation points relative to XBASE.\n+     *     FVAL holds the values of F at the interpolation points.\n+     *     XOPT is set to the displacement from XBASE of the trust region centre.\n+     *     GOPT holds the gradient of the quadratic model at XBASE+XOPT.\n+     *     HQ holds the explicit second derivatives of the quadratic model.\n+     *     PQ contains the parameters of the implicit second derivatives of the\n+     *       quadratic model.\n+     *     BMAT holds the last N columns of H.\n+     *     ZMAT holds the factorization of the leading NPT by NPT submatrix of H,\n+     *       this factorization being ZMAT times ZMAT^T, which provides both the\n+     *       correct rank and positive semi-definiteness.\n+     *     NDIM is the first dimension of BMAT and has the value NPT+N.\n+     *     SL and SU hold the differences XL-XBASE and XU-XBASE, respectively.\n+     *       All the components of every XOPT are going to satisfy the bounds\n+     *       SL(I) .LEQ. XOPT(I) .LEQ. SU(I), with appropriate equalities when\n+     *       XOPT is on a constraint boundary.\n+     *     XNEW is chosen by SUBROUTINE TRSBOX or ALTMOV. Usually XBASE+XNEW is the\n+     *       vector of variables for the next call of CALFUN. XNEW also satisfies\n+     *       the SL and SU constraints in the way that has just been mentioned.\n+     *     XALT is an alternative to XNEW, chosen by ALTMOV, that may replace XNEW\n+     *       in order to increase the denominator in the updating of UPDATE.\n+     *     D is reserved for a trial step from XOPT, which is usually XNEW-XOPT.\n+     *     VLAG contains the values of the Lagrange functions at a new point X.\n+     *       They are part of a product that requires VLAG to be of length NDIM.\n+     *     W is a one-dimensional array that is used for working space. Its length\n+     *       must be at least 3*NDIM = 3*(NPT+N).\n+     *\n+     * @param lowerBound Lower bounds.\n+     * @param upperBound Upper bounds.\n+     * @return the value of the objective at the optimum.\n+     */\n+    private double bobyqb(double[] lowerBound,\n+                          double[] upperBound) {\n+        printMethod(); // XXX\n+\n+        final int n = currentBest.getDimension();\n+        final int npt = numberOfInterpolationPoints;\n+        final int np = n + 1;\n+        final int nptm = npt - np;\n+        final int nh = n * np / 2;\n+\n+        final ArrayRealVector work1 = new ArrayRealVector(n);\n+        final ArrayRealVector work2 = new ArrayRealVector(npt);\n+        final ArrayRealVector work3 = new ArrayRealVector(npt);\n+\n+        double cauchy = Double.NaN;\n+        double alpha = Double.NaN;\n+        double dsq = Double.NaN;\n+        double crvmin = Double.NaN;\n+\n+        // Set some constants.\n+        // Parameter adjustments\n+\n+        // Function Body\n+\n+        // The call of PRELIM sets the elements of XBASE, XPT, FVAL, GOPT, HQ, PQ,\n+        // BMAT and ZMAT for the first iteration, with the corresponding values of\n+        // of NF and KOPT, which are the number of calls of CALFUN so far and the\n+        // index of the interpolation point at the trust region centre. Then the\n+        // initial XOPT is set too. The branch to label 720 occurs if MAXFUN is\n+        // less than NPT. GOPT will be updated if KOPT is different from KBASE.\n+\n+        trustRegionCenterInterpolationPointIndex = 0;\n+\n+        prelim(lowerBound, upperBound);\n+        double xoptsq = ZERO;\n+        for (int i = 0; i < n; i++) {\n+            trustRegionCenterOffset.setEntry(i, interpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex, i));\n+            // Computing 2nd power\n+            final double deltaOne = trustRegionCenterOffset.getEntry(i);\n+            xoptsq += deltaOne * deltaOne;\n+        }\n+        double fsave = fAtInterpolationPoints.getEntry(0);\n+        final int kbase = 0;\n+\n+        // Complete the settings that are required for the iterative procedure.\n+\n+        int ntrits = 0;\n+        int itest = 0;\n+        int knew = 0;\n+        int nfsav = getEvaluations();\n+        double rho = initialTrustRegionRadius;\n+        double delta = rho;\n+        double diffa = ZERO;\n+        double diffb = ZERO;\n+        double diffc = ZERO;\n+        double f = ZERO;\n+        double beta = ZERO;\n+        double adelt = ZERO;\n+        double denom = ZERO;\n+        double ratio = ZERO;\n+        double dnorm = ZERO;\n+        double scaden = ZERO;\n+        double biglsq = ZERO;\n+        double distsq = ZERO;\n+\n+        // Update GOPT if necessary before the first iteration and after each\n+        // call of RESCUE that makes a call of CALFUN.\n+\n+        int state = 20;\n+        for(;;) switch (state) {\n+        case 20: {\n+            printState(20); // XXX\n+            if (trustRegionCenterInterpolationPointIndex != kbase) {\n+                int ih = 0;\n+                for (int j = 0; j < n; j++) {\n+                    for (int i = 0; i <= j; i++) {\n+                        if (i < j) {\n+                            gradientAtTrustRegionCenter.setEntry(j, gradientAtTrustRegionCenter.getEntry(j) + modelSecondDerivativesValues.getEntry(ih) * trustRegionCenterOffset.getEntry(i));\n+                        }\n+                        gradientAtTrustRegionCenter.setEntry(i, gradientAtTrustRegionCenter.getEntry(i) + modelSecondDerivativesValues.getEntry(ih) * trustRegionCenterOffset.getEntry(j));\n+                        ih++;\n+                    }\n+                }\n+                if (getEvaluations() > npt) {\n+                    for (int k = 0; k < npt; k++) {\n+                        double temp = ZERO;\n+                        for (int j = 0; j < n; j++) {\n+                            temp += interpolationPoints.getEntry(k, j) * trustRegionCenterOffset.getEntry(j);\n+                        }\n+                        temp *= modelSecondDerivativesParameters.getEntry(k);\n+                        for (int i = 0; i < n; i++) {\n+                            gradientAtTrustRegionCenter.setEntry(i, gradientAtTrustRegionCenter.getEntry(i) + temp * interpolationPoints.getEntry(k, i));\n+                        }\n+                    }\n+                    // throw new PathIsExploredException(); // XXX\n+                }\n+            }\n+\n+            // Generate the next point in the trust region that provides a small value\n+            // of the quadratic model subject to the constraints on the variables.\n+            // The int NTRITS is set to the number \"trust region\" iterations that\n+            // have occurred since the last \"alternative\" iteration. If the length\n+            // of XNEW-XOPT is less than HALF*RHO, however, then there is a branch to\n+            // label 650 or 680 with NTRITS=-1, instead of calculating F at XNEW.\n+\n+        }\n+        case 60: {\n+            printState(60); // XXX\n+            final ArrayRealVector gnew = new ArrayRealVector(n);\n+            final ArrayRealVector xbdi = new ArrayRealVector(n);\n+            final ArrayRealVector s = new ArrayRealVector(n);\n+            final ArrayRealVector hs = new ArrayRealVector(n);\n+            final ArrayRealVector hred = new ArrayRealVector(n);\n+\n+            final double[] dsqCrvmin = trsbox(delta, gnew, xbdi, s,\n+                                              hs, hred);\n+            dsq = dsqCrvmin[0];\n+            crvmin = dsqCrvmin[1];\n+\n+            // Computing MIN\n+            double deltaOne = delta;\n+            double deltaTwo = Math.sqrt(dsq);\n+            dnorm = Math.min(deltaOne, deltaTwo);\n+            if (dnorm < HALF * rho) {\n+                ntrits = -1;\n+                // Computing 2nd power\n+                deltaOne = TEN * rho;\n+                distsq = deltaOne * deltaOne;\n+                if (getEvaluations() <= nfsav + 2) {\n+                    state = 650; break;\n+                }\n+\n+                // The following choice between labels 650 and 680 depends on whether or\n+                // not our work with the current RHO seems to be complete. Either RHO is\n+                // decreased or termination occurs if the errors in the quadratic model at\n+                // the last three interpolation points compare favourably with predictions\n+                // of likely improvements to the model within distance HALF*RHO of XOPT.\n+\n+                // Computing MAX\n+                deltaOne = Math.max(diffa, diffb);\n+                final double errbig = Math.max(deltaOne, diffc);\n+                final double frhosq = rho * ONE_OVER_EIGHT * rho;\n+                if (crvmin > ZERO &&\n+                    errbig > frhosq * crvmin) {\n+                    state = 650; break;\n+                }\n+                final double bdtol = errbig / rho;\n+                for (int j = 0; j < n; j++) {\n+                    double bdtest = bdtol;\n+                    if (newPoint.getEntry(j) == lowerDifference.getEntry(j)) {\n+                        bdtest = work1.getEntry(j);\n+                    }\n+                    if (newPoint.getEntry(j) == upperDifference.getEntry(j)) {\n+                        bdtest = -work1.getEntry(j);\n+                    }\n+                    if (bdtest < bdtol) {\n+                        double curv = modelSecondDerivativesValues.getEntry((j + j * j) / 2);\n+                        for (int k = 0; k < npt; k++) {\n+                            // Computing 2nd power\n+                            final double d1 = interpolationPoints.getEntry(k, j);\n+                            curv += modelSecondDerivativesParameters.getEntry(k) * (d1 * d1);\n+                        }\n+                        bdtest += HALF * curv * rho;\n+                        if (bdtest < bdtol) {\n+                            state = 650; break;\n+                        }\n+                        // throw new PathIsExploredException(); // XXX\n+                    }\n+                }\n+                state = 680; break;\n+            }\n+            ++ntrits;\n+\n+            // Severe cancellation is likely to occur if XOPT is too far from XBASE.\n+            // If the following test holds, then XBASE is shifted so that XOPT becomes\n+            // zero. The appropriate changes are made to BMAT and to the second\n+            // derivatives of the current model, beginning with the changes to BMAT\n+            // that do not depend on ZMAT. VLAG is used temporarily for working space.\n+\n+        }\n+        case 90: {\n+            printState(90); // XXX\n+            if (dsq <= xoptsq * ONE_OVER_A_THOUSAND) {\n+                final double fracsq = xoptsq * ONE_OVER_FOUR;\n+                double sumpq = ZERO;\n+                // final RealVector sumVector\n+                //     = new ArrayRealVector(npt, -HALF * xoptsq).add(interpolationPoints.operate(trustRegionCenter));\n+                for (int k = 0; k < npt; k++) {\n+                    sumpq += modelSecondDerivativesParameters.getEntry(k);\n+                    double sum = -HALF * xoptsq;\n+                    for (int i = 0; i < n; i++) {\n+                        sum += interpolationPoints.getEntry(k, i) * trustRegionCenterOffset.getEntry(i);\n+                    }\n+                    // sum = sumVector.getEntry(k); // XXX \"testAckley\" and \"testDiffPow\" fail.\n+                    work2.setEntry(k, sum);\n+                    final double temp = fracsq - HALF * sum;\n+                    for (int i = 0; i < n; i++) {\n+                        work1.setEntry(i, bMatrix.getEntry(k, i));\n+                        lagrangeValuesAtNewPoint.setEntry(i, sum * interpolationPoints.getEntry(k, i) + temp * trustRegionCenterOffset.getEntry(i));\n+                        final int ip = npt + i;\n+                        for (int j = 0; j <= i; j++) {\n+                            bMatrix.setEntry(ip, j,\n+                                          bMatrix.getEntry(ip, j)\n+                                          + work1.getEntry(i) * lagrangeValuesAtNewPoint.getEntry(j)\n+                                          + lagrangeValuesAtNewPoint.getEntry(i) * work1.getEntry(j));\n+                        }\n+                    }\n+                }\n+\n+                // Then the revisions of BMAT that depend on ZMAT are calculated.\n+\n+                for (int m = 0; m < nptm; m++) {\n+                    double sumz = ZERO;\n+                    double sumw = ZERO;\n+                    for (int k = 0; k < npt; k++) {\n+                        sumz += zMatrix.getEntry(k, m);\n+                        lagrangeValuesAtNewPoint.setEntry(k, work2.getEntry(k) * zMatrix.getEntry(k, m));\n+                        sumw += lagrangeValuesAtNewPoint.getEntry(k);\n+                    }\n+                    for (int j = 0; j < n; j++) {\n+                        double sum = (fracsq * sumz - HALF * sumw) * trustRegionCenterOffset.getEntry(j);\n+                        for (int k = 0; k < npt; k++) {\n+                            sum += lagrangeValuesAtNewPoint.getEntry(k) * interpolationPoints.getEntry(k, j);\n+                        }\n+                        work1.setEntry(j, sum);\n+                        for (int k = 0; k < npt; k++) {\n+                            bMatrix.setEntry(k, j,\n+                                          bMatrix.getEntry(k, j)\n+                                          + sum * zMatrix.getEntry(k, m));\n+                        }\n+                    }\n+                    for (int i = 0; i < n; i++) {\n+                        final int ip = i + npt;\n+                        final double temp = work1.getEntry(i);\n+                        for (int j = 0; j <= i; j++) {\n+                            bMatrix.setEntry(ip, j,\n+                                          bMatrix.getEntry(ip, j)\n+                                          + temp * work1.getEntry(j));\n+                        }\n+                    }\n+                }\n+\n+                // The following instructions complete the shift, including the changes\n+                // to the second derivative parameters of the quadratic model.\n+\n+                int ih = 0;\n+                for (int j = 0; j < n; j++) {\n+                    work1.setEntry(j, -HALF * sumpq * trustRegionCenterOffset.getEntry(j));\n+                    for (int k = 0; k < npt; k++) {\n+                        work1.setEntry(j, work1.getEntry(j) + modelSecondDerivativesParameters.getEntry(k) * interpolationPoints.getEntry(k, j));\n+                        interpolationPoints.setEntry(k, j, interpolationPoints.getEntry(k, j) - trustRegionCenterOffset.getEntry(j));\n+                    }\n+                    for (int i = 0; i <= j; i++) {\n+                         modelSecondDerivativesValues.setEntry(ih,\n+                                    modelSecondDerivativesValues.getEntry(ih)\n+                                    + work1.getEntry(i) * trustRegionCenterOffset.getEntry(j)\n+                                    + trustRegionCenterOffset.getEntry(i) * work1.getEntry(j));\n+                        bMatrix.setEntry(npt + i, j, bMatrix.getEntry(npt + j, i));\n+                        ih++;\n+                    }\n+                }\n+                for (int i = 0; i < n; i++) {\n+                    originShift.setEntry(i, originShift.getEntry(i) + trustRegionCenterOffset.getEntry(i));\n+                    newPoint.setEntry(i, newPoint.getEntry(i) - trustRegionCenterOffset.getEntry(i));\n+                    lowerDifference.setEntry(i, lowerDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i));\n+                    upperDifference.setEntry(i, upperDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i));\n+                    trustRegionCenterOffset.setEntry(i, ZERO);\n+                }\n+                xoptsq = ZERO;\n+            }\n+            if (ntrits == 0) {\n+                state = 210; break;\n+            }\n+            state = 230; break;\n+\n+            // XBASE is also moved to XOPT by a call of RESCUE. This calculation is\n+            // more expensive than the previous shift, because new matrices BMAT and\n+            // ZMAT are generated from scratch, which may include the replacement of\n+            // interpolation points whose positions seem to be causing near linear\n+            // dependence in the interpolation conditions. Therefore RESCUE is called\n+            // only if rounding errors have reduced by at least a factor of two the\n+            // denominator of the formula for updating the H matrix. It provides a\n+            // useful safeguard, but is not invoked in most applications of BOBYQA.\n+\n+        }\n+        case 210: {\n+            printState(210); // XXX\n+            // Pick two alternative vectors of variables, relative to XBASE, that\n+            // are suitable as new positions of the KNEW-th interpolation point.\n+            // Firstly, XNEW is set to the point on a line through XOPT and another\n+            // interpolation point that minimizes the predicted value of the next\n+            // denominator, subject to ||XNEW - XOPT|| .LEQ. ADELT and to the SL\n+            // and SU bounds. Secondly, XALT is set to the best feasible point on\n+            // a constrained version of the Cauchy step of the KNEW-th Lagrange\n+            // function, the corresponding value of the square of this function\n+            // being returned in CAUCHY. The choice between these alternatives is\n+            // going to be made when the denominator is calculated.\n+\n+            final double[] alphaCauchy = altmov(knew, adelt);\n+            alpha = alphaCauchy[0];\n+            cauchy = alphaCauchy[1];\n+\n+            for (int i = 0; i < n; i++) {\n+                trialStepPoint.setEntry(i, newPoint.getEntry(i) - trustRegionCenterOffset.getEntry(i));\n+            }\n+\n+            // Calculate VLAG and BETA for the current choice of D. The scalar\n+            // product of D with XPT(K,.) is going to be held in W(NPT+K) for\n+            // use when VQUAD is calculated.\n+\n+        }\n+        case 230: {\n+            printState(230); // XXX\n+            for (int k = 0; k < npt; k++) {\n+                double suma = ZERO;\n+                double sumb = ZERO;\n+                double sum = ZERO;\n+                for (int j = 0; j < n; j++) {\n+                    suma += interpolationPoints.getEntry(k, j) * trialStepPoint.getEntry(j);\n+                    sumb += interpolationPoints.getEntry(k, j) * trustRegionCenterOffset.getEntry(j);\n+                    sum += bMatrix.getEntry(k, j) * trialStepPoint.getEntry(j);\n+                }\n+                work3.setEntry(k, suma * (HALF * suma + sumb));\n+                lagrangeValuesAtNewPoint.setEntry(k, sum);\n+                work2.setEntry(k, suma);\n+            }\n+            beta = ZERO;\n+            for (int m = 0; m < nptm; m++) {\n+                double sum = ZERO;\n+                for (int k = 0; k < npt; k++) {\n+                    sum += zMatrix.getEntry(k, m) * work3.getEntry(k);\n+                }\n+                beta -= sum * sum;\n+                for (int k = 0; k < npt; k++) {\n+                    lagrangeValuesAtNewPoint.setEntry(k, lagrangeValuesAtNewPoint.getEntry(k) + sum * zMatrix.getEntry(k, m));\n+                }\n+            }\n+            dsq = ZERO;\n+            double bsum = ZERO;\n+            double dx = ZERO;\n+            for (int j = 0; j < n; j++) {\n+                // Computing 2nd power\n+                final double d1 = trialStepPoint.getEntry(j);\n+                dsq += d1 * d1;\n+                double sum = ZERO;\n+                for (int k = 0; k < npt; k++) {\n+                    sum += work3.getEntry(k) * bMatrix.getEntry(k, j);\n+                }\n+                bsum += sum * trialStepPoint.getEntry(j);\n+                final int jp = npt + j;\n+                for (int i = 0; i < n; i++) {\n+                    sum += bMatrix.getEntry(jp, i) * trialStepPoint.getEntry(i);\n+                }\n+                lagrangeValuesAtNewPoint.setEntry(jp, sum);\n+                bsum += sum * trialStepPoint.getEntry(j);\n+                dx += trialStepPoint.getEntry(j) * trustRegionCenterOffset.getEntry(j);\n+            }\n+\n+            beta = dx * dx + dsq * (xoptsq + dx + dx + HALF * dsq) + beta - bsum; // Original\n+            // beta += dx * dx + dsq * (xoptsq + dx + dx + HALF * dsq) - bsum; // XXX \"testAckley\" and \"testDiffPow\" fail.\n+            // beta = dx * dx + dsq * (xoptsq + 2 * dx + HALF * dsq) + beta - bsum; // XXX \"testDiffPow\" fails.\n+\n+            lagrangeValuesAtNewPoint.setEntry(trustRegionCenterInterpolationPointIndex,\n+                          lagrangeValuesAtNewPoint.getEntry(trustRegionCenterInterpolationPointIndex) + ONE);\n+\n+            // If NTRITS is zero, the denominator may be increased by replacing\n+            // the step D of ALTMOV by a Cauchy step. Then RESCUE may be called if\n+            // rounding errors have damaged the chosen denominator.\n+\n+            if (ntrits == 0) {\n+                // Computing 2nd power\n+                final double d1 = lagrangeValuesAtNewPoint.getEntry(knew);\n+                denom = d1 * d1 + alpha * beta;\n+                if (denom < cauchy && cauchy > ZERO) {\n+                    for (int i = 0; i < n; i++) {\n+                        newPoint.setEntry(i, alternativeNewPoint.getEntry(i));\n+                        trialStepPoint.setEntry(i, newPoint.getEntry(i) - trustRegionCenterOffset.getEntry(i));\n+                    }\n+                    cauchy = ZERO; // XXX Useful statement?\n+                    state = 230; break;\n+                }\n+                // Alternatively, if NTRITS is positive, then set KNEW to the index of\n+                // the next interpolation point to be deleted to make room for a trust\n+                // region step. Again RESCUE may be called if rounding errors have damaged_\n+                // the chosen denominator, which is the reason for attempting to select\n+                // KNEW before calculating the next value of the objective function.\n+\n+            } else {\n+                final double delsq = delta * delta;\n+                scaden = ZERO;\n+                biglsq = ZERO;\n+                knew = 0;\n+                for (int k = 0; k < npt; k++) {\n+                    if (k == trustRegionCenterInterpolationPointIndex) {\n+                        continue;\n+                    }\n+                    double hdiag = ZERO;\n+                    for (int m = 0; m < nptm; m++) {\n+                        // Computing 2nd power\n+                        final double d1 = zMatrix.getEntry(k, m);\n+                        hdiag += d1 * d1;\n+                    }\n+                    // Computing 2nd power\n+                    final double d2 = lagrangeValuesAtNewPoint.getEntry(k);\n+                    final double den = beta * hdiag + d2 * d2;\n+                    distsq = ZERO;\n+                    for (int j = 0; j < n; j++) {\n+                        // Computing 2nd power\n+                        final double d3 = interpolationPoints.getEntry(k, j) - trustRegionCenterOffset.getEntry(j);\n+                        distsq += d3 * d3;\n+                    }\n+                    // Computing MAX\n+                    // Computing 2nd power\n+                    final double d4 = distsq / delsq;\n+                    final double temp = Math.max(ONE, d4 * d4);\n+                    if (temp * den > scaden) {\n+                        scaden = temp * den;\n+                        knew = k;\n+                        denom = den;\n+                    }\n+                    // Computing MAX\n+                    // Computing 2nd power\n+                    final double d5 = lagrangeValuesAtNewPoint.getEntry(k);\n+                    biglsq = Math.max(biglsq, temp * (d5 * d5));\n+                }\n+            }\n+\n+            // Put the variables for the next calculation of the objective function\n+            //   in XNEW, with any adjustments for the bounds.\n+\n+            // Calculate the value of the objective function at XBASE+XNEW, unless\n+            //   the limit on the number of calculations of F has been reached.\n+\n+        }\n+        case 360: {\n+            printState(360); // XXX\n+            for (int i = 0; i < n; i++) {\n+                // Computing MIN\n+                // Computing MAX\n+                final double d3 = lowerBound[i];\n+                final double d4 = originShift.getEntry(i) + newPoint.getEntry(i);\n+                final double d1 = Math.max(d3, d4);\n+                final double d2 = upperBound[i];\n+                currentBest.setEntry(i, Math.min(d1, d2));\n+                if (newPoint.getEntry(i) == lowerDifference.getEntry(i)) {\n+                    currentBest.setEntry(i, lowerBound[i]);\n+                }\n+                if (newPoint.getEntry(i) == upperDifference.getEntry(i)) {\n+                    currentBest.setEntry(i, upperBound[i]);\n+                }\n+            }\n+\n+            f = computeObjectiveValue(currentBest.toArray());\n+\n+            if (!isMinimize)\n+                f = -f;\n+            if (ntrits == -1) {\n+                fsave = f;\n+                state = 720; break;\n+            }\n+\n+            // Use the quadratic model to predict the change in F due to the step D,\n+            //   and set DIFF to the error of this prediction.\n+\n+            final double fopt = fAtInterpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex);\n+            double vquad = ZERO;\n+            int ih = 0;\n+            for (int j = 0; j < n; j++) {\n+                vquad += trialStepPoint.getEntry(j) * gradientAtTrustRegionCenter.getEntry(j);\n+                for (int i = 0; i <= j; i++) {\n+                    double temp = trialStepPoint.getEntry(i) * trialStepPoint.getEntry(j);\n+                    if (i == j) {\n+                        temp *= HALF;\n+                    }\n+                    vquad += modelSecondDerivativesValues.getEntry(ih) * temp;\n+                    ih++;\n+               }\n+            }\n+            for (int k = 0; k < npt; k++) {\n+                // Computing 2nd power\n+                final double d1 = work2.getEntry(k);\n+                final double d2 = d1 * d1; // \"d1\" must be squared first to prevent test failures.\n+                vquad += HALF * modelSecondDerivativesParameters.getEntry(k) * d2;\n+            }\n+            final double diff = f - fopt - vquad;\n+            diffc = diffb;\n+            diffb = diffa;\n+            diffa = Math.abs(diff);\n+            if (dnorm > rho) {\n+                nfsav = getEvaluations();\n+            }\n+\n+            // Pick the next value of DELTA after a trust region step.\n+\n+            if (ntrits > 0) {\n+                if (vquad >= ZERO) {\n+                    throw new MathIllegalStateException(LocalizedFormats.TRUST_REGION_STEP_FAILED, vquad);\n+                }\n+                ratio = (f - fopt) / vquad;\n+                final double hDelta = HALF * delta;\n+                if (ratio <= ONE_OVER_TEN) {\n+                    // Computing MIN\n+                    delta = Math.min(hDelta, dnorm);\n+                } else if (ratio <= .7) {\n+                    // Computing MAX\n+                    delta = Math.max(hDelta, dnorm);\n+                } else {\n+                    // Computing MAX\n+                    delta = Math.max(hDelta, 2 * dnorm);\n+                }\n+                if (delta <= rho * 1.5) {\n+                    delta = rho;\n+                }\n+\n+                // Recalculate KNEW and DENOM if the new F is less than FOPT.\n+\n+                if (f < fopt) {\n+                    final int ksav = knew;\n+                    final double densav = denom;\n+                    final double delsq = delta * delta;\n+                    scaden = ZERO;\n+                    biglsq = ZERO;\n+                    knew = 0;\n+                    for (int k = 0; k < npt; k++) {\n+                        double hdiag = ZERO;\n+                        for (int m = 0; m < nptm; m++) {\n+                            // Computing 2nd power\n+                            final double d1 = zMatrix.getEntry(k, m);\n+                            hdiag += d1 * d1;\n+                        }\n+                        // Computing 2nd power\n+                        final double d1 = lagrangeValuesAtNewPoint.getEntry(k);\n+                        final double den = beta * hdiag + d1 * d1;\n+                        distsq = ZERO;\n+                        for (int j = 0; j < n; j++) {\n+                            // Computing 2nd power\n+                            final double d2 = interpolationPoints.getEntry(k, j) - newPoint.getEntry(j);\n+                            distsq += d2 * d2;\n+                        }\n+                        // Computing MAX\n+                        // Computing 2nd power\n+                        final double d3 = distsq / delsq;\n+                        final double temp = Math.max(ONE, d3 * d3);\n+                        if (temp * den > scaden) {\n+                            scaden = temp * den;\n+                            knew = k;\n+                            denom = den;\n+                        }\n+                        // Computing MAX\n+                        // Computing 2nd power\n+                        final double d4 = lagrangeValuesAtNewPoint.getEntry(k);\n+                        final double d5 = temp * (d4 * d4);\n+                        biglsq = Math.max(biglsq, d5);\n+                    }\n+                    if (scaden <= HALF * biglsq) {\n+                        knew = ksav;\n+                        denom = densav;\n+                    }\n+                }\n+            }\n+\n+            // Update BMAT and ZMAT, so that the KNEW-th interpolation point can be\n+            // moved. Also update the second derivative terms of the model.\n+\n+            update(beta, denom, knew);\n+\n+            ih = 0;\n+            final double pqold = modelSecondDerivativesParameters.getEntry(knew);\n+            modelSecondDerivativesParameters.setEntry(knew, ZERO);\n+            for (int i = 0; i < n; i++) {\n+                final double temp = pqold * interpolationPoints.getEntry(knew, i);\n+                for (int j = 0; j <= i; j++) {\n+                    modelSecondDerivativesValues.setEntry(ih, modelSecondDerivativesValues.getEntry(ih) + temp * interpolationPoints.getEntry(knew, j));\n+                    ih++;\n+                }\n+            }\n+            for (int m = 0; m < nptm; m++) {\n+                final double temp = diff * zMatrix.getEntry(knew, m);\n+                for (int k = 0; k < npt; k++) {\n+                    modelSecondDerivativesParameters.setEntry(k, modelSecondDerivativesParameters.getEntry(k) + temp * zMatrix.getEntry(k, m));\n+                }\n+            }\n+\n+            // Include the new interpolation point, and make the changes to GOPT at\n+            // the old XOPT that are caused by the updating of the quadratic model.\n+\n+            fAtInterpolationPoints.setEntry(knew,  f);\n+            for (int i = 0; i < n; i++) {\n+                interpolationPoints.setEntry(knew, i, newPoint.getEntry(i));\n+                work1.setEntry(i, bMatrix.getEntry(knew, i));\n+            }\n+            for (int k = 0; k < npt; k++) {\n+                double suma = ZERO;\n+                for (int m = 0; m < nptm; m++) {\n+                    suma += zMatrix.getEntry(knew, m) * zMatrix.getEntry(k, m);\n+                }\n+                double sumb = ZERO;\n+                for (int j = 0; j < n; j++) {\n+                    sumb += interpolationPoints.getEntry(k, j) * trustRegionCenterOffset.getEntry(j);\n+                }\n+                final double temp = suma * sumb;\n+                for (int i = 0; i < n; i++) {\n+                    work1.setEntry(i, work1.getEntry(i) + temp * interpolationPoints.getEntry(k, i));\n+                }\n+            }\n+            for (int i = 0; i < n; i++) {\n+                gradientAtTrustRegionCenter.setEntry(i, gradientAtTrustRegionCenter.getEntry(i) + diff * work1.getEntry(i));\n+            }\n+\n+            // Update XOPT, GOPT and KOPT if the new calculated F is less than FOPT.\n+\n+            if (f < fopt) {\n+                trustRegionCenterInterpolationPointIndex = knew;\n+                xoptsq = ZERO;\n+                ih = 0;\n+                for (int j = 0; j < n; j++) {\n+                    trustRegionCenterOffset.setEntry(j, newPoint.getEntry(j));\n+                    // Computing 2nd power\n+                    final double d1 = trustRegionCenterOffset.getEntry(j);\n+                    xoptsq += d1 * d1;\n+                    for (int i = 0; i <= j; i++) {\n+                        if (i < j) {\n+                            gradientAtTrustRegionCenter.setEntry(j, gradientAtTrustRegionCenter.getEntry(j) + modelSecondDerivativesValues.getEntry(ih) * trialStepPoint.getEntry(i));\n+                        }\n+                        gradientAtTrustRegionCenter.setEntry(i, gradientAtTrustRegionCenter.getEntry(i) + modelSecondDerivativesValues.getEntry(ih) * trialStepPoint.getEntry(j));\n+                        ih++;\n+                    }\n+                }\n+                for (int k = 0; k < npt; k++) {\n+                    double temp = ZERO;\n+                    for (int j = 0; j < n; j++) {\n+                        temp += interpolationPoints.getEntry(k, j) * trialStepPoint.getEntry(j);\n+                    }\n+                    temp *= modelSecondDerivativesParameters.getEntry(k);\n+                    for (int i = 0; i < n; i++) {\n+                        gradientAtTrustRegionCenter.setEntry(i, gradientAtTrustRegionCenter.getEntry(i) + temp * interpolationPoints.getEntry(k, i));\n+                    }\n+                }\n+            }\n+\n+            // Calculate the parameters of the least Frobenius norm interpolant to\n+            // the current data, the gradient of this interpolant at XOPT being put\n+            // into VLAG(NPT+I), I=1,2,...,N.\n+\n+            if (ntrits > 0) {\n+                for (int k = 0; k < npt; k++) {\n+                    lagrangeValuesAtNewPoint.setEntry(k, fAtInterpolationPoints.getEntry(k) - fAtInterpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex));\n+                    work3.setEntry(k, ZERO);\n+                }\n+                for (int j = 0; j < nptm; j++) {\n+                    double sum = ZERO;\n+                    for (int k = 0; k < npt; k++) {\n+                        sum += zMatrix.getEntry(k, j) * lagrangeValuesAtNewPoint.getEntry(k);\n+                    }\n+                    for (int k = 0; k < npt; k++) {\n+                        work3.setEntry(k, work3.getEntry(k) + sum * zMatrix.getEntry(k, j));\n+                    }\n+                }\n+                for (int k = 0; k < npt; k++) {\n+                    double sum = ZERO;\n+                    for (int j = 0; j < n; j++) {\n+                        sum += interpolationPoints.getEntry(k, j) * trustRegionCenterOffset.getEntry(j);\n+                    }\n+                    work2.setEntry(k, work3.getEntry(k));\n+                    work3.setEntry(k, sum * work3.getEntry(k));\n+                }\n+                double gqsq = ZERO;\n+                double gisq = ZERO;\n+                for (int i = 0; i < n; i++) {\n+                    double sum = ZERO;\n+                    for (int k = 0; k < npt; k++) {\n+                        sum += bMatrix.getEntry(k, i) *\n+                            lagrangeValuesAtNewPoint.getEntry(k) + interpolationPoints.getEntry(k, i) * work3.getEntry(k);\n+                    }\n+                    if (trustRegionCenterOffset.getEntry(i) == lowerDifference.getEntry(i)) {\n+                        // Computing MIN\n+                        // Computing 2nd power\n+                        final double d1 = Math.min(ZERO, gradientAtTrustRegionCenter.getEntry(i));\n+                        gqsq += d1 * d1;\n+                        // Computing 2nd power\n+                        final double d2 = Math.min(ZERO, sum);\n+                        gisq += d2 * d2;\n+                    } else if (trustRegionCenterOffset.getEntry(i) == upperDifference.getEntry(i)) {\n+                        // Computing MAX\n+                        // Computing 2nd power\n+                        final double d1 = Math.max(ZERO, gradientAtTrustRegionCenter.getEntry(i));\n+                        gqsq += d1 * d1;\n+                        // Computing 2nd power\n+                        final double d2 = Math.max(ZERO, sum);\n+                        gisq += d2 * d2;\n+                    } else {\n+                        // Computing 2nd power\n+                        final double d1 = gradientAtTrustRegionCenter.getEntry(i);\n+                        gqsq += d1 * d1;\n+                        gisq += sum * sum;\n+                    }\n+                    lagrangeValuesAtNewPoint.setEntry(npt + i, sum);\n+                }\n+\n+                // Test whether to replace the new quadratic model by the least Frobenius\n+                // norm interpolant, making the replacement if the test is satisfied.\n+\n+                ++itest;\n+                if (gqsq < TEN * gisq) {\n+                    itest = 0;\n+                }\n+                if (itest >= 3) {\n+                    for (int i = 0, max = Math.max(npt, nh); i < max; i++) {\n+                        if (i < n) {\n+                            gradientAtTrustRegionCenter.setEntry(i, lagrangeValuesAtNewPoint.getEntry(npt + i));\n+                        }\n+                        if (i < npt) {\n+                            modelSecondDerivativesParameters.setEntry(i, work2.getEntry(i));\n+                        }\n+                        if (i < nh) {\n+                            modelSecondDerivativesValues.setEntry(i, ZERO);\n+                        }\n+                        itest = 0;\n+                    }\n+                }\n+            }\n+\n+            // If a trust region step has provided a sufficient decrease in F, then\n+            // branch for another trust region calculation. The case NTRITS=0 occurs\n+            // when the new interpolation point was reached by an alternative step.\n+\n+            if (ntrits == 0) {\n+                state = 60; break;\n+            }\n+            if (f <= fopt + ONE_OVER_TEN * vquad) {\n+                state = 60; break;\n+            }\n+\n+            // Alternatively, find out if the interpolation points are close enough\n+            //   to the best point so far.\n+\n+            // Computing MAX\n+            // Computing 2nd power\n+            final double d1 = TWO * delta;\n+            // Computing 2nd power\n+            final double d2 = TEN * rho;\n+            distsq = Math.max(d1 * d1, d2 * d2);\n+        }\n+        case 650: {\n+            printState(650); // XXX\n+            knew = -1;\n+            for (int k = 0; k < npt; k++) {\n+                double sum = ZERO;\n+                for (int j = 0; j < n; j++) {\n+                    // Computing 2nd power\n+                    final double d1 = interpolationPoints.getEntry(k, j) - trustRegionCenterOffset.getEntry(j);\n+                    sum += d1 * d1;\n+                }\n+                if (sum > distsq) {\n+                    knew = k;\n+                    distsq = sum;\n+                }\n+            }\n+\n+            // If KNEW is positive, then ALTMOV finds alternative new positions for\n+            // the KNEW-th interpolation point within distance ADELT of XOPT. It is\n+            // reached via label 90. Otherwise, there is a branch to label 60 for\n+            // another trust region iteration, unless the calculations with the\n+            // current RHO are complete.\n+\n+            if (knew >= 0) {\n+                final double dist = Math.sqrt(distsq);\n+                if (ntrits == -1) {\n+                    // Computing MIN\n+                    delta = Math.min(ONE_OVER_TEN * delta, HALF * dist);\n+                    if (delta <= rho * 1.5) {\n+                        delta = rho;\n+                    }\n+                }\n+                ntrits = 0;\n+                // Computing MAX\n+                // Computing MIN\n+                final double d1 = Math.min(ONE_OVER_TEN * dist, delta);\n+                adelt = Math.max(d1, rho);\n+                dsq = adelt * adelt;\n+                state = 90; break;\n+            }\n+            if (ntrits == -1) {\n+                state = 680; break;\n+            }\n+            if (ratio > ZERO) {\n+                state = 60; break;\n+            }\n+            if (Math.max(delta, dnorm) > rho) {\n+                state = 60; break;\n+            }\n+\n+            // The calculations with the current value of RHO are complete. Pick the\n+            //   next values of RHO and DELTA.\n+        }\n+        case 680: {\n+            printState(680); // XXX\n+            if (rho > stoppingTrustRegionRadius) {\n+                delta = HALF * rho;\n+                ratio = rho / stoppingTrustRegionRadius;\n+                if (ratio <= SIXTEEN) {\n+                    rho = stoppingTrustRegionRadius;\n+                } else if (ratio <= TWO_HUNDRED_FIFTY) {\n+                    rho = Math.sqrt(ratio) * stoppingTrustRegionRadius;\n+                } else {\n+                    rho *= ONE_OVER_TEN;\n+                }\n+                delta = Math.max(delta, rho);\n+                ntrits = 0;\n+                nfsav = getEvaluations();\n+                state = 60; break;\n+            }\n+\n+            // Return from the calculation, after another Newton-Raphson step, if\n+            //   it is too short to have been tried before.\n+\n+            if (ntrits == -1) {\n+                state = 360; break;\n+            }\n+        }\n+        case 720: {\n+            printState(720); // XXX\n+            if (fAtInterpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex) <= fsave) {\n+                for (int i = 0; i < n; i++) {\n+                    // Computing MIN\n+                    // Computing MAX\n+                    final double d3 = lowerBound[i];\n+                    final double d4 = originShift.getEntry(i) + trustRegionCenterOffset.getEntry(i);\n+                    final double d1 = Math.max(d3, d4);\n+                    final double d2 = upperBound[i];\n+                    currentBest.setEntry(i, Math.min(d1, d2));\n+                    if (trustRegionCenterOffset.getEntry(i) == lowerDifference.getEntry(i)) {\n+                        currentBest.setEntry(i, lowerBound[i]);\n+                    }\n+                    if (trustRegionCenterOffset.getEntry(i) == upperDifference.getEntry(i)) {\n+                        currentBest.setEntry(i, upperBound[i]);\n+                    }\n+                }\n+                f = fAtInterpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex);\n+            }\n+            return f;\n+        }\n+        default: {\n+            throw new MathIllegalStateException(LocalizedFormats.SIMPLE_MESSAGE, \"bobyqb\");\n+        }}\n+    } // bobyqb\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    /**\n+     *     The arguments N, NPT, XPT, XOPT, BMAT, ZMAT, NDIM, SL and SU all have\n+     *       the same meanings as the corresponding arguments of BOBYQB.\n+     *     KOPT is the index of the optimal interpolation point.\n+     *     KNEW is the index of the interpolation point that is going to be moved.\n+     *     ADELT is the current trust region bound.\n+     *     XNEW will be set to a suitable new position for the interpolation point\n+     *       XPT(KNEW,.). Specifically, it satisfies the SL, SU and trust region\n+     *       bounds and it should provide a large denominator in the next call of\n+     *       UPDATE. The step XNEW-XOPT from XOPT is restricted to moves along the\n+     *       straight lines through XOPT and another interpolation point.\n+     *     XALT also provides a large value of the modulus of the KNEW-th Lagrange\n+     *       function subject to the constraints that have been mentioned, its main\n+     *       difference from XNEW being that XALT-XOPT is a constrained version of\n+     *       the Cauchy step within the trust region. An exception is that XALT is\n+     *       not calculated if all components of GLAG (see below) are zero.\n+     *     ALPHA will be set to the KNEW-th diagonal element of the H matrix.\n+     *     CAUCHY will be set to the square of the KNEW-th Lagrange function at\n+     *       the step XALT-XOPT from XOPT for the vector XALT that is returned,\n+     *       except that CAUCHY is set to zero if XALT is not calculated.\n+     *     GLAG is a working space vector of length N for the gradient of the\n+     *       KNEW-th Lagrange function at XOPT.\n+     *     HCOL is a working space vector of length NPT for the second derivative\n+     *       coefficients of the KNEW-th Lagrange function.\n+     *     W is a working space vector of length 2N that is going to hold the\n+     *       constrained Cauchy step from XOPT of the Lagrange function, followed\n+     *       by the downhill version of XALT when the uphill step is calculated.\n+     *\n+     *     Set the first NPT components of W to the leading elements of the\n+     *     KNEW-th column of the H matrix.\n+     * @param knew\n+     * @param adelt\n+     */\n+    private double[] altmov(\n+            int knew,\n+            double adelt\n+    ) {\n+        printMethod(); // XXX\n+\n+        final int n = currentBest.getDimension();\n+        final int npt = numberOfInterpolationPoints;\n+\n+        final ArrayRealVector glag = new ArrayRealVector(n);\n+        final ArrayRealVector hcol = new ArrayRealVector(npt);\n+\n+        final ArrayRealVector work1 = new ArrayRealVector(n);\n+        final ArrayRealVector work2 = new ArrayRealVector(n);\n+\n+        for (int k = 0; k < npt; k++) {\n+            hcol.setEntry(k, ZERO);\n+        }\n+        for (int j = 0, max = npt - n - 1; j < max; j++) {\n+            final double tmp = zMatrix.getEntry(knew, j);\n+            for (int k = 0; k < npt; k++) {\n+                hcol.setEntry(k, hcol.getEntry(k) + tmp * zMatrix.getEntry(k, j));\n+            }\n+        }\n+        final double alpha = hcol.getEntry(knew);\n+        final double ha = HALF * alpha;\n+\n+        // Calculate the gradient of the KNEW-th Lagrange function at XOPT.\n+\n+        for (int i = 0; i < n; i++) {\n+            glag.setEntry(i, bMatrix.getEntry(knew, i));\n+        }\n+        for (int k = 0; k < npt; k++) {\n+            double tmp = ZERO;\n+            for (int j = 0; j < n; j++) {\n+                tmp += interpolationPoints.getEntry(k, j) * trustRegionCenterOffset.getEntry(j);\n+            }\n+            tmp *= hcol.getEntry(k);\n+            for (int i = 0; i < n; i++) {\n+                glag.setEntry(i, glag.getEntry(i) + tmp * interpolationPoints.getEntry(k, i));\n+            }\n+        }\n+\n+        // Search for a large denominator along the straight lines through XOPT\n+        // and another interpolation point. SLBD and SUBD will be lower and upper\n+        // bounds on the step along each of these lines in turn. PREDSQ will be\n+        // set to the square of the predicted denominator for each line. PRESAV\n+        // will be set to the largest admissible value of PREDSQ that occurs.\n+\n+        double presav = ZERO;\n+        double step = Double.NaN;\n+        int ksav = 0;\n+        int ibdsav = 0;\n+        double stpsav = 0;\n+        for (int k = 0; k < npt; k++) {\n+            if (k == trustRegionCenterInterpolationPointIndex) {\n+                continue;\n+            }\n+            double dderiv = ZERO;\n+            double distsq = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                final double tmp = interpolationPoints.getEntry(k, i) - trustRegionCenterOffset.getEntry(i);\n+                dderiv += glag.getEntry(i) * tmp;\n+                distsq += tmp * tmp;\n+            }\n+            double subd = adelt / Math.sqrt(distsq);\n+            double slbd = -subd;\n+            int ilbd = 0;\n+            int iubd = 0;\n+            final double sumin = Math.min(ONE, subd);\n+\n+            // Revise SLBD and SUBD if necessary because of the bounds in SL and SU.\n+\n+            for (int i = 0; i < n; i++) {\n+                final double tmp = interpolationPoints.getEntry(k, i) - trustRegionCenterOffset.getEntry(i);\n+                if (tmp > ZERO) {\n+                    if (slbd * tmp < lowerDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i)) {\n+                        slbd = (lowerDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i)) / tmp;\n+                        ilbd = -i - 1;\n+                    }\n+                    if (subd * tmp > upperDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i)) {\n+                        // Computing MAX\n+                        subd = Math.max(sumin,\n+                                        (upperDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i)) / tmp);\n+                        iubd = i + 1;\n+                    }\n+                } else if (tmp < ZERO) {\n+                    if (slbd * tmp > upperDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i)) {\n+                        slbd = (upperDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i)) / tmp;\n+                        ilbd = i + 1;\n+                    }\n+                    if (subd * tmp < lowerDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i)) {\n+                        // Computing MAX\n+                        subd = Math.max(sumin,\n+                                        (lowerDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i)) / tmp);\n+                        iubd = -i - 1;\n+                    }\n+                }\n+            }\n+\n+            // Seek a large modulus of the KNEW-th Lagrange function when the index\n+            // of the other interpolation point on the line through XOPT is KNEW.\n+\n+            step = slbd;\n+            int isbd = ilbd;\n+            double vlag = Double.NaN;\n+            if (k == knew) {\n+                final double diff = dderiv - ONE;\n+                vlag = slbd * (dderiv - slbd * diff);\n+                final double d1 = subd * (dderiv - subd * diff);\n+                if (Math.abs(d1) > Math.abs(vlag)) {\n+                    step = subd;\n+                    vlag = d1;\n+                    isbd = iubd;\n+                }\n+                final double d2 = HALF * dderiv;\n+                final double d3 = d2 - diff * slbd;\n+                final double d4 = d2 - diff * subd;\n+                if (d3 * d4 < ZERO) {\n+                    final double d5 = d2 * d2 / diff;\n+                    if (Math.abs(d5) > Math.abs(vlag)) {\n+                        step = d2 / diff;\n+                        vlag = d5;\n+                        isbd = 0;\n+                    }\n+                }\n+\n+                // Search along each of the other lines through XOPT and another point.\n+\n+            } else {\n+                vlag = slbd * (ONE - slbd);\n+                final double tmp = subd * (ONE - subd);\n+                if (Math.abs(tmp) > Math.abs(vlag)) {\n+                    step = subd;\n+                    vlag = tmp;\n+                    isbd = iubd;\n+                }\n+                if (subd > HALF) {\n+                    if (Math.abs(vlag) < ONE_OVER_FOUR) {\n+                        step = HALF;\n+                        vlag = ONE_OVER_FOUR;\n+                        isbd = 0;\n+                    }\n+                }\n+                vlag *= dderiv;\n+            }\n+\n+            // Calculate PREDSQ for the current line search and maintain PRESAV.\n+\n+            final double tmp = step * (ONE - step) * distsq;\n+            final double predsq = vlag * vlag * (vlag * vlag + ha * tmp * tmp);\n+            if (predsq > presav) {\n+                presav = predsq;\n+                ksav = k;\n+                stpsav = step;\n+                ibdsav = isbd;\n+            }\n+        }\n+\n+        // Construct XNEW in a way that satisfies the bound constraints exactly.\n+\n+        for (int i = 0; i < n; i++) {\n+            final double tmp = trustRegionCenterOffset.getEntry(i) + stpsav * (interpolationPoints.getEntry(ksav, i) - trustRegionCenterOffset.getEntry(i));\n+            newPoint.setEntry(i, Math.max(lowerDifference.getEntry(i),\n+                                      Math.min(upperDifference.getEntry(i), tmp)));\n+        }\n+        if (ibdsav < 0) {\n+            newPoint.setEntry(-ibdsav - 1, lowerDifference.getEntry(-ibdsav - 1));\n+        }\n+        if (ibdsav > 0) {\n+            newPoint.setEntry(ibdsav - 1, upperDifference.getEntry(ibdsav - 1));\n+        }\n+\n+        // Prepare for the iterative method that assembles the constrained Cauchy\n+        // step in W. The sum of squares of the fixed components of W is formed in\n+        // WFIXSQ, and the free components of W are set to BIGSTP.\n+\n+        final double bigstp = adelt + adelt;\n+        int iflag = 0;\n+        double cauchy = Double.NaN;\n+        double csave = ZERO;\n+        while (true) {\n+            double wfixsq = ZERO;\n+            double ggfree = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                final double glagValue = glag.getEntry(i);\n+                work1.setEntry(i, ZERO);\n+                if (Math.min(trustRegionCenterOffset.getEntry(i) - lowerDifference.getEntry(i), glagValue) > ZERO ||\n+                    Math.max(trustRegionCenterOffset.getEntry(i) - upperDifference.getEntry(i), glagValue) < ZERO) {\n+                    work1.setEntry(i, bigstp);\n+                    // Computing 2nd power\n+                    ggfree += glagValue * glagValue;\n+                }\n+            }\n+            if (ggfree == ZERO) {\n+                return new double[] { alpha, ZERO };\n+            }\n+\n+            // Investigate whether more components of W can be fixed.\n+            final double tmp1 = adelt * adelt - wfixsq;\n+            if (tmp1 > ZERO) {\n+                step = Math.sqrt(tmp1 / ggfree);\n+                ggfree = ZERO;\n+                for (int i = 0; i < n; i++) {\n+                    if (work1.getEntry(i) == bigstp) {\n+                        final double tmp2 = trustRegionCenterOffset.getEntry(i) - step * glag.getEntry(i);\n+                        if (tmp2 <= lowerDifference.getEntry(i)) {\n+                            work1.setEntry(i, lowerDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i));\n+                            // Computing 2nd power\n+                            final double d1 = work1.getEntry(i);\n+                            wfixsq += d1 * d1;\n+                        } else if (tmp2 >= upperDifference.getEntry(i)) {\n+                            work1.setEntry(i, upperDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i));\n+                            // Computing 2nd power\n+                            final double d1 = work1.getEntry(i);\n+                            wfixsq += d1 * d1;\n+                        } else {\n+                            // Computing 2nd power\n+                            final double d1 = glag.getEntry(i);\n+                            ggfree += d1 * d1;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Set the remaining free components of W and all components of XALT,\n+            // except that W may be scaled later.\n+\n+            double gw = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                final double glagValue = glag.getEntry(i);\n+                if (work1.getEntry(i) == bigstp) {\n+                    work1.setEntry(i, -step * glagValue);\n+                    final double min = Math.min(upperDifference.getEntry(i),\n+                                                trustRegionCenterOffset.getEntry(i) + work1.getEntry(i));\n+                    alternativeNewPoint.setEntry(i, Math.max(lowerDifference.getEntry(i), min));\n+                } else if (work1.getEntry(i) == ZERO) {\n+                    alternativeNewPoint.setEntry(i, trustRegionCenterOffset.getEntry(i));\n+                } else if (glagValue > ZERO) {\n+                    alternativeNewPoint.setEntry(i, lowerDifference.getEntry(i));\n+                } else {\n+                    alternativeNewPoint.setEntry(i, upperDifference.getEntry(i));\n+                }\n+                gw += glagValue * work1.getEntry(i);\n+            }\n+\n+            // Set CURV to the curvature of the KNEW-th Lagrange function along W.\n+            // Scale W by a factor less than one if that can reduce the modulus of\n+            // the Lagrange function at XOPT+W. Set CAUCHY to the final value of\n+            // the square of this function.\n+\n+            double curv = ZERO;\n+            for (int k = 0; k < npt; k++) {\n+                double tmp = ZERO;\n+                for (int j = 0; j < n; j++) {\n+                    tmp += interpolationPoints.getEntry(k, j) * work1.getEntry(j);\n+                }\n+                curv += hcol.getEntry(k) * tmp * tmp;\n+            }\n+            if (iflag == 1) {\n+                curv = -curv;\n+            }\n+            if (curv > -gw &&\n+                curv < -gw * (ONE + Math.sqrt(TWO))) {\n+                final double scale = -gw / curv;\n+                for (int i = 0; i < n; i++) {\n+                    final double tmp = trustRegionCenterOffset.getEntry(i) + scale * work1.getEntry(i);\n+                    alternativeNewPoint.setEntry(i, Math.max(lowerDifference.getEntry(i),\n+                                              Math.min(upperDifference.getEntry(i), tmp)));\n+                }\n+                // Computing 2nd power\n+                final double d1 = HALF * gw * scale;\n+                cauchy = d1 * d1;\n+            } else {\n+                // Computing 2nd power\n+                final double d1 = gw + HALF * curv;\n+                cauchy = d1 * d1;\n+            }\n+\n+            // If IFLAG is zero, then XALT is calculated as before after reversing\n+            // the sign of GLAG. Thus two XALT vectors become available. The one that\n+            // is chosen is the one that gives the larger value of CAUCHY.\n+\n+            if (iflag == 0) {\n+                for (int i = 0; i < n; i++) {\n+                    glag.setEntry(i, -glag.getEntry(i));\n+                    work2.setEntry(i, alternativeNewPoint.getEntry(i));\n+                }\n+                csave = cauchy;\n+                iflag = 1;\n+            } else {\n+                break;\n+            }\n+        }\n+        if (csave > cauchy) {\n+            for (int i = 0; i < n; i++) {\n+                alternativeNewPoint.setEntry(i, work2.getEntry(i));\n+            }\n+            cauchy = csave;\n+        }\n+\n+        return new double[] { alpha, cauchy };\n+    } // altmov\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    /**\n+     *     SUBROUTINE PRELIM sets the elements of XBASE, XPT, FVAL, GOPT, HQ, PQ,\n+     *     BMAT and ZMAT for the first iteration, and it maintains the values of\n+     *     NF and KOPT. The vector X is also changed by PRELIM.\n+     *\n+     *     The arguments N, NPT, X, XL, XU, RHOBEG, IPRINT and MAXFUN are the\n+     *       same as the corresponding arguments in SUBROUTINE BOBYQA.\n+     *     The arguments XBASE, XPT, FVAL, HQ, PQ, BMAT, ZMAT, NDIM, SL and SU\n+     *       are the same as the corresponding arguments in BOBYQB, the elements\n+     *       of SL and SU being set in BOBYQA.\n+     *     GOPT is usually the gradient of the quadratic model at XOPT+XBASE, but\n+     *       it is set by PRELIM to the gradient of the quadratic model at XBASE.\n+     *       If XOPT is nonzero, BOBYQB will change it to its usual value later.\n+     *     NF is maintaned as the number of calls of CALFUN so far.\n+     *     KOPT will be such that the least calculated value of F so far is at\n+     *       the point XPT(KOPT,.)+XBASE in the space of the variables.\n+     *\n+     * @param lowerBound Lower bounds.\n+     * @param upperBound Upper bounds.\n+     */\n+    private void prelim(double[] lowerBound,\n+                        double[] upperBound) {\n+        printMethod(); // XXX\n+\n+        final int n = currentBest.getDimension();\n+        final int npt = numberOfInterpolationPoints;\n+        final int ndim = bMatrix.getRowDimension();\n+\n+        final double rhosq = initialTrustRegionRadius * initialTrustRegionRadius;\n+        final double recip = 1d / rhosq;\n+        final int np = n + 1;\n+\n+        // Set XBASE to the initial vector of variables, and set the initial\n+        // elements of XPT, BMAT, HQ, PQ and ZMAT to zero.\n+\n+        for (int j = 0; j < n; j++) {\n+            originShift.setEntry(j, currentBest.getEntry(j));\n+            for (int k = 0; k < npt; k++) {\n+                interpolationPoints.setEntry(k, j, ZERO);\n+            }\n+            for (int i = 0; i < ndim; i++) {\n+                bMatrix.setEntry(i, j, ZERO);\n+            }\n+        }\n+        for (int i = 0, max = n * np / 2; i < max; i++) {\n+            modelSecondDerivativesValues.setEntry(i, ZERO);\n+        }\n+        for (int k = 0; k < npt; k++) {\n+            modelSecondDerivativesParameters.setEntry(k, ZERO);\n+            for (int j = 0, max = npt - np; j < max; j++) {\n+                zMatrix.setEntry(k, j, ZERO);\n+            }\n+        }\n+\n+        // Begin the initialization procedure. NF becomes one more than the number\n+        // of function values so far. The coordinates of the displacement of the\n+        // next initial interpolation point from XBASE are set in XPT(NF+1,.).\n+\n+        int ipt = 0;\n+        int jpt = 0;\n+        double fbeg = Double.NaN;\n+        do {\n+            final int nfm = getEvaluations();\n+            final int nfx = nfm - n;\n+            final int nfmm = nfm - 1;\n+            final int nfxm = nfx - 1;\n+            double stepa = 0;\n+            double stepb = 0;\n+            if (nfm <= 2 * n) {\n+                if (nfm >= 1 &&\n+                    nfm <= n) {\n+                    stepa = initialTrustRegionRadius;\n+                    if (upperDifference.getEntry(nfmm) == ZERO) {\n+                        stepa = -stepa;\n+                        // throw new PathIsExploredException(); // XXX\n+                    }\n+                    interpolationPoints.setEntry(nfm, nfmm, stepa);\n+                } else if (nfm > n) {\n+                    stepa = interpolationPoints.getEntry(nfx, nfxm);\n+                    stepb = -initialTrustRegionRadius;\n+                    if (lowerDifference.getEntry(nfxm) == ZERO) {\n+                        stepb = Math.min(TWO * initialTrustRegionRadius, upperDifference.getEntry(nfxm));\n+                        // throw new PathIsExploredException(); // XXX\n+                    }\n+                    if (upperDifference.getEntry(nfxm) == ZERO) {\n+                        stepb = Math.max(-TWO * initialTrustRegionRadius, lowerDifference.getEntry(nfxm));\n+                        // throw new PathIsExploredException(); // XXX\n+                    }\n+                    interpolationPoints.setEntry(nfm, nfxm, stepb);\n+                }\n+            } else {\n+                final int tmp1 = (nfm - np) / n;\n+                jpt = nfm - tmp1 * n - n;\n+                ipt = jpt + tmp1;\n+                if (ipt > n) {\n+                    final int tmp2 = jpt;\n+                    jpt = ipt - n;\n+                    ipt = tmp2;\n+//                     throw new PathIsExploredException(); // XXX\n+                }\n+                final int iptMinus1 = ipt - 1;\n+                final int jptMinus1 = jpt - 1;\n+                interpolationPoints.setEntry(nfm, iptMinus1, interpolationPoints.getEntry(ipt, iptMinus1));\n+                interpolationPoints.setEntry(nfm, jptMinus1, interpolationPoints.getEntry(jpt, jptMinus1));\n+            }\n+\n+            // Calculate the next value of F. The least function value so far and\n+            // its index are required.\n+\n+            for (int j = 0; j < n; j++) {\n+                currentBest.setEntry(j, Math.min(Math.max(lowerBound[j],\n+                                                          originShift.getEntry(j) + interpolationPoints.getEntry(nfm, j)),\n+                                                 upperBound[j]));\n+                if (interpolationPoints.getEntry(nfm, j) == lowerDifference.getEntry(j)) {\n+                    currentBest.setEntry(j, lowerBound[j]);\n+                }\n+                if (interpolationPoints.getEntry(nfm, j) == upperDifference.getEntry(j)) {\n+                    currentBest.setEntry(j, upperBound[j]);\n+                }\n+            }\n+\n+            final double objectiveValue = computeObjectiveValue(currentBest.toArray());\n+            final double f = isMinimize ? objectiveValue : -objectiveValue;\n+            final int numEval = getEvaluations(); // nfm + 1\n+            fAtInterpolationPoints.setEntry(nfm, f);\n+\n+            if (numEval == 1) {\n+                fbeg = f;\n+                trustRegionCenterInterpolationPointIndex = 0;\n+            } else if (f < fAtInterpolationPoints.getEntry(trustRegionCenterInterpolationPointIndex)) {\n+                trustRegionCenterInterpolationPointIndex = nfm;\n+            }\n+\n+            // Set the nonzero initial elements of BMAT and the quadratic model in the\n+            // cases when NF is at most 2*N+1. If NF exceeds N+1, then the positions\n+            // of the NF-th and (NF-N)-th interpolation points may be switched, in\n+            // order that the function value at the first of them contributes to the\n+            // off-diagonal second derivative terms of the initial quadratic model.\n+\n+            if (numEval <= 2 * n + 1) {\n+                if (numEval >= 2 &&\n+                    numEval <= n + 1) {\n+                    gradientAtTrustRegionCenter.setEntry(nfmm, (f - fbeg) / stepa);\n+                    if (npt < numEval + n) {\n+                        final double oneOverStepA = ONE / stepa;\n+                        bMatrix.setEntry(0, nfmm, -oneOverStepA);\n+                        bMatrix.setEntry(nfm, nfmm, oneOverStepA);\n+                        bMatrix.setEntry(npt + nfmm, nfmm, -HALF * rhosq);\n+                        // throw new PathIsExploredException(); // XXX\n+                    }\n+                } else if (numEval >= n + 2) {\n+                    final int ih = nfx * (nfx + 1) / 2 - 1;\n+                    final double tmp = (f - fbeg) / stepb;\n+                    final double diff = stepb - stepa;\n+                    modelSecondDerivativesValues.setEntry(ih, TWO * (tmp - gradientAtTrustRegionCenter.getEntry(nfxm)) / diff);\n+                    gradientAtTrustRegionCenter.setEntry(nfxm, (gradientAtTrustRegionCenter.getEntry(nfxm) * stepb - tmp * stepa) / diff);\n+                    if (stepa * stepb < ZERO) {\n+                        if (f < fAtInterpolationPoints.getEntry(nfm - n)) {\n+                            fAtInterpolationPoints.setEntry(nfm, fAtInterpolationPoints.getEntry(nfm - n));\n+                            fAtInterpolationPoints.setEntry(nfm - n, f);\n+                            if (trustRegionCenterInterpolationPointIndex == nfm) {\n+                                trustRegionCenterInterpolationPointIndex = nfm - n;\n+                            }\n+                            interpolationPoints.setEntry(nfm - n, nfxm, stepb);\n+                            interpolationPoints.setEntry(nfm, nfxm, stepa);\n+                        }\n+                    }\n+                    bMatrix.setEntry(0, nfxm, -(stepa + stepb) / (stepa * stepb));\n+                    bMatrix.setEntry(nfm, nfxm, -HALF / interpolationPoints.getEntry(nfm - n, nfxm));\n+                    bMatrix.setEntry(nfm - n, nfxm,\n+                                  -bMatrix.getEntry(0, nfxm) - bMatrix.getEntry(nfm, nfxm));\n+                    zMatrix.setEntry(0, nfxm, Math.sqrt(TWO) / (stepa * stepb));\n+                    zMatrix.setEntry(nfm, nfxm, Math.sqrt(HALF) / rhosq);\n+                    // zMatrix.setEntry(nfm, nfxm, Math.sqrt(HALF) * recip); // XXX \"testAckley\" and \"testDiffPow\" fail.\n+                    zMatrix.setEntry(nfm - n, nfxm,\n+                                  -zMatrix.getEntry(0, nfxm) - zMatrix.getEntry(nfm, nfxm));\n+                }\n+\n+                // Set the off-diagonal second derivatives of the Lagrange functions and\n+                // the initial quadratic model.\n+\n+            } else {\n+                zMatrix.setEntry(0, nfxm, recip);\n+                zMatrix.setEntry(nfm, nfxm, recip);\n+                zMatrix.setEntry(ipt, nfxm, -recip);\n+                zMatrix.setEntry(jpt, nfxm, -recip);\n+\n+                final int ih = ipt * (ipt - 1) / 2 + jpt - 1;\n+                final double tmp = interpolationPoints.getEntry(nfm, ipt - 1) * interpolationPoints.getEntry(nfm, jpt - 1);\n+                modelSecondDerivativesValues.setEntry(ih, (fbeg - fAtInterpolationPoints.getEntry(ipt) - fAtInterpolationPoints.getEntry(jpt) + f) / tmp);\n+//                 throw new PathIsExploredException(); // XXX\n+            }\n+        } while (getEvaluations() < npt);\n+    } // prelim\n+\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    /**\n+     *     A version of the truncated conjugate gradient is applied. If a line\n+     *     search is restricted by a constraint, then the procedure is restarted,\n+     *     the values of the variables that are at their bounds being fixed. If\n+     *     the trust region boundary is reached, then further changes may be made\n+     *     to D, each one being in the two dimensional space that is spanned\n+     *     by the current D and the gradient of Q at XOPT+D, staying on the trust\n+     *     region boundary. Termination occurs when the reduction in Q seems to\n+     *     be close to the greatest reduction that can be achieved.\n+     *     The arguments N, NPT, XPT, XOPT, GOPT, HQ, PQ, SL and SU have the same\n+     *       meanings as the corresponding arguments of BOBYQB.\n+     *     DELTA is the trust region radius for the present calculation, which\n+     *       seeks a small value of the quadratic model within distance DELTA of\n+     *       XOPT subject to the bounds on the variables.\n+     *     XNEW will be set to a new vector of variables that is approximately\n+     *       the one that minimizes the quadratic model within the trust region\n+     *       subject to the SL and SU constraints on the variables. It satisfies\n+     *       as equations the bounds that become active during the calculation.\n+     *     D is the calculated trial step from XOPT, generated iteratively from an\n+     *       initial value of zero. Thus XNEW is XOPT+D after the final iteration.\n+     *     GNEW holds the gradient of the quadratic model at XOPT+D. It is updated\n+     *       when D is updated.\n+     *     xbdi.get( is a working space vector. For I=1,2,...,N, the element xbdi.get((I) is\n+     *       set to -1.0, 0.0, or 1.0, the value being nonzero if and only if the\n+     *       I-th variable has become fixed at a bound, the bound being SL(I) or\n+     *       SU(I) in the case xbdi.get((I)=-1.0 or xbdi.get((I)=1.0, respectively. This\n+     *       information is accumulated during the construction of XNEW.\n+     *     The arrays S, HS and HRED are also used for working space. They hold the\n+     *       current search direction, and the changes in the gradient of Q along S\n+     *       and the reduced D, respectively, where the reduced D is the same as D,\n+     *       except that the components of the fixed variables are zero.\n+     *     DSQ will be set to the square of the length of XNEW-XOPT.\n+     *     CRVMIN is set to zero if D reaches the trust region boundary. Otherwise\n+     *       it is set to the least curvature of H that occurs in the conjugate\n+     *       gradient searches that are not restricted by any constraints. The\n+     *       value CRVMIN=-1.0D0 is set, however, if all of these searches are\n+     *       constrained.\n+     * @param delta\n+     * @param gnew\n+     * @param xbdi\n+     * @param s\n+     * @param hs\n+     * @param hred\n+     */\n+    private double[] trsbox(\n+            double delta,\n+            ArrayRealVector gnew,\n+            ArrayRealVector xbdi,\n+            ArrayRealVector s,\n+            ArrayRealVector hs,\n+            ArrayRealVector hred\n+    ) {\n+        printMethod(); // XXX\n+\n+        final int n = currentBest.getDimension();\n+        final int npt = numberOfInterpolationPoints;\n+\n+        double dsq = Double.NaN;\n+        double crvmin = Double.NaN;\n+\n+        // Local variables\n+        double ds;\n+        int iu;\n+        double dhd, dhs, cth, shs, sth, ssq, beta=0, sdec, blen;\n+        int iact = -1;\n+        int nact = 0;\n+        double angt = 0, qred;\n+        int isav;\n+        double temp = 0, xsav = 0, xsum = 0, angbd = 0, dredg = 0, sredg = 0;\n+        int iterc;\n+        double resid = 0, delsq = 0, ggsav = 0, tempa = 0, tempb = 0,\n+        redmax = 0, dredsq = 0, redsav = 0, gredsq = 0, rednew = 0;\n+        int itcsav = 0;\n+        double rdprev = 0, rdnext = 0, stplen = 0, stepsq = 0;\n+        int itermax = 0;\n+\n+        // Set some constants.\n+\n+        // Function Body\n+\n+        // The sign of GOPT(I) gives the sign of the change to the I-th variable\n+        // that will reduce Q from its value at XOPT. Thus xbdi.get((I) shows whether\n+        // or not to fix the I-th variable at one of its bounds initially, with\n+        // NACT being set to the number of fixed variables. D and GNEW are also\n+        // set for the first iteration. DELSQ is the upper bound on the sum of\n+        // squares of the free variables. QRED is the reduction in Q so far.\n+\n+        iterc = 0;\n+        nact = 0;\n+        for (int i = 0; i < n; i++) {\n+            xbdi.setEntry(i, ZERO);\n+            if (trustRegionCenterOffset.getEntry(i) <= lowerDifference.getEntry(i)) {\n+                if (gradientAtTrustRegionCenter.getEntry(i) >= ZERO) {\n+                    xbdi.setEntry(i, MINUS_ONE);\n+                }\n+            } else if (trustRegionCenterOffset.getEntry(i) >= upperDifference.getEntry(i)) {\n+                if (gradientAtTrustRegionCenter.getEntry(i) <= ZERO) {\n+                    xbdi.setEntry(i, ONE);\n+                }\n+            }\n+            if (xbdi.getEntry(i) != ZERO) {\n+                ++nact;\n+            }\n+            trialStepPoint.setEntry(i, ZERO);\n+            gnew.setEntry(i, gradientAtTrustRegionCenter.getEntry(i));\n+        }\n+        delsq = delta * delta;\n+        qred = ZERO;\n+        crvmin = MINUS_ONE;\n+\n+        // Set the next search direction of the conjugate gradient method. It is\n+        // the steepest descent direction initially and when the iterations are\n+        // restarted because a variable has just been fixed by a bound, and of\n+        // course the components of the fixed variables are zero. ITERMAX is an\n+        // upper bound on the indices of the conjugate gradient iterations.\n+\n+        int state = 20;\n+        for(;;) {\n+            switch (state) {\n+        case 20: {\n+            printState(20); // XXX\n+            beta = ZERO;\n+        }\n+        case 30: {\n+            printState(30); // XXX\n+            stepsq = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                if (xbdi.getEntry(i) != ZERO) {\n+                    s.setEntry(i, ZERO);\n+                } else if (beta == ZERO) {\n+                    s.setEntry(i, -gnew.getEntry(i));\n+                } else {\n+                    s.setEntry(i, beta * s.getEntry(i) - gnew.getEntry(i));\n+                }\n+                // Computing 2nd power\n+                final double d1 = s.getEntry(i);\n+                stepsq += d1 * d1;\n+            }\n+            if (stepsq == ZERO) {\n+                state = 190; break;\n+            }\n+            if (beta == ZERO) {\n+                gredsq = stepsq;\n+                itermax = iterc + n - nact;\n+            }\n+            if (gredsq * delsq <= qred * 1e-4 * qred) {\n+                state = 190; break;\n+            }\n+\n+            // Multiply the search direction by the second derivative matrix of Q and\n+            // calculate some scalars for the choice of steplength. Then set BLEN to\n+            // the length of the the step to the trust region boundary and STPLEN to\n+            // the steplength, ignoring the simple bounds.\n+\n+            state = 210; break;\n+        }\n+        case 50: {\n+            printState(50); // XXX\n+            resid = delsq;\n+            ds = ZERO;\n+            shs = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                if (xbdi.getEntry(i) == ZERO) {\n+                    // Computing 2nd power\n+                    final double d1 = trialStepPoint.getEntry(i);\n+                    resid -= d1 * d1;\n+                    ds += s.getEntry(i) * trialStepPoint.getEntry(i);\n+                    shs += s.getEntry(i) * hs.getEntry(i);\n+                }\n+            }\n+            if (resid <= ZERO) {\n+                state = 90; break;\n+            }\n+            temp = Math.sqrt(stepsq * resid + ds * ds);\n+            if (ds < ZERO) {\n+                blen = (temp - ds) / stepsq;\n+            } else {\n+                blen = resid / (temp + ds);\n+            }\n+            stplen = blen;\n+            if (shs > ZERO) {\n+                // Computing MIN\n+                stplen = Math.min(blen, gredsq / shs);\n+            }\n+\n+            // Reduce STPLEN if necessary in order to preserve the simple bounds,\n+            // letting IACT be the index of the new constrained variable.\n+\n+            iact = -1;\n+            for (int i = 0; i < n; i++) {\n+                if (s.getEntry(i) != ZERO) {\n+                    xsum = trustRegionCenterOffset.getEntry(i) + trialStepPoint.getEntry(i);\n+                    if (s.getEntry(i) > ZERO) {\n+                        temp = (upperDifference.getEntry(i) - xsum) / s.getEntry(i);\n+                    } else {\n+                        temp = (lowerDifference.getEntry(i) - xsum) / s.getEntry(i);\n+                    }\n+                    if (temp < stplen) {\n+                        stplen = temp;\n+                        iact = i;\n+                    }\n+                }\n+            }\n+\n+            // Update CRVMIN, GNEW and D. Set SDEC to the decrease that occurs in Q.\n+\n+            sdec = ZERO;\n+            if (stplen > ZERO) {\n+                ++iterc;\n+                temp = shs / stepsq;\n+                if (iact == -1 && temp > ZERO) {\n+                    crvmin = Math.min(crvmin,temp);\n+                    if (crvmin == MINUS_ONE) {\n+                        crvmin = temp;\n+                    }\n+                }\n+                ggsav = gredsq;\n+                gredsq = ZERO;\n+                for (int i = 0; i < n; i++) {\n+                    gnew.setEntry(i, gnew.getEntry(i) + stplen * hs.getEntry(i));\n+                    if (xbdi.getEntry(i) == ZERO) {\n+                        // Computing 2nd power\n+                        final double d1 = gnew.getEntry(i);\n+                        gredsq += d1 * d1;\n+                    }\n+                    trialStepPoint.setEntry(i, trialStepPoint.getEntry(i) + stplen * s.getEntry(i));\n+                }\n+                // Computing MAX\n+                final double d1 = stplen * (ggsav - HALF * stplen * shs);\n+                sdec = Math.max(d1, ZERO);\n+                qred += sdec;\n+            }\n+\n+            // Restart the conjugate gradient method if it has hit a new bound.\n+\n+            if (iact >= 0) {\n+                ++nact;\n+                xbdi.setEntry(iact, ONE);\n+                if (s.getEntry(iact) < ZERO) {\n+                    xbdi.setEntry(iact, MINUS_ONE);\n+                }\n+                // Computing 2nd power\n+                final double d1 = trialStepPoint.getEntry(iact);\n+                delsq -= d1 * d1;\n+                if (delsq <= ZERO) {\n+                    state = 190; break;\n+                }\n+                state = 20; break;\n+            }\n+\n+            // If STPLEN is less than BLEN, then either apply another conjugate\n+            // gradient iteration or RETURN.\n+\n+            if (stplen < blen) {\n+                if (iterc == itermax) {\n+                    state = 190; break;\n+                }\n+                if (sdec <= qred * .01) {\n+                    state = 190; break;\n+                }\n+                beta = gredsq / ggsav;\n+                state = 30; break;\n+            }\n+        }\n+        case 90: {\n+            printState(90); // XXX\n+            crvmin = ZERO;\n+\n+            // Prepare for the alternative iteration by calculating some scalars\n+            // and by multiplying the reduced D by the second derivative matrix of\n+            // Q, where S holds the reduced D in the call of GGMULT.\n+\n+        }\n+        case 100: {\n+            printState(100); // XXX\n+            if (nact >= n - 1) {\n+                state = 190; break;\n+            }\n+            dredsq = ZERO;\n+            dredg = ZERO;\n+            gredsq = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                if (xbdi.getEntry(i) == ZERO) {\n+                    // Computing 2nd power\n+                    double d1 = trialStepPoint.getEntry(i);\n+                    dredsq += d1 * d1;\n+                    dredg += trialStepPoint.getEntry(i) * gnew.getEntry(i);\n+                    // Computing 2nd power\n+                    d1 = gnew.getEntry(i);\n+                    gredsq += d1 * d1;\n+                    s.setEntry(i, trialStepPoint.getEntry(i));\n+                } else {\n+                    s.setEntry(i, ZERO);\n+                }\n+            }\n+            itcsav = iterc;\n+            state = 210; break;\n+            // Let the search direction S be a linear combination of the reduced D\n+            // and the reduced G that is orthogonal to the reduced D.\n+        }\n+        case 120: {\n+            printState(120); // XXX\n+            ++iterc;\n+            temp = gredsq * dredsq - dredg * dredg;\n+            if (temp <= qred * 1e-4 * qred) {\n+                state = 190; break;\n+            }\n+            temp = Math.sqrt(temp);\n+            for (int i = 0; i < n; i++) {\n+                if (xbdi.getEntry(i) == ZERO) {\n+                    s.setEntry(i, (dredg * trialStepPoint.getEntry(i) - dredsq * gnew.getEntry(i)) / temp);\n+                } else {\n+                    s.setEntry(i, ZERO);\n+                }\n+            }\n+            sredg = -temp;\n+\n+            // By considering the simple bounds on the variables, calculate an upper\n+            // bound on the tangent of half the angle of the alternative iteration,\n+            // namely ANGBD, except that, if already a free variable has reached a\n+            // bound, there is a branch back to label 100 after fixing that variable.\n+\n+            angbd = ONE;\n+            iact = -1;\n+            for (int i = 0; i < n; i++) {\n+                if (xbdi.getEntry(i) == ZERO) {\n+                    tempa = trustRegionCenterOffset.getEntry(i) + trialStepPoint.getEntry(i) - lowerDifference.getEntry(i);\n+                    tempb = upperDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i) - trialStepPoint.getEntry(i);\n+                    if (tempa <= ZERO) {\n+                        ++nact;\n+                        xbdi.setEntry(i, MINUS_ONE);\n+                        state = 100; break;\n+                    } else if (tempb <= ZERO) {\n+                        ++nact;\n+                        xbdi.setEntry(i, ONE);\n+                        state = 100; break;\n+                    }\n+                    // Computing 2nd power\n+                    double d1 = trialStepPoint.getEntry(i);\n+                    // Computing 2nd power\n+                    double d2 = s.getEntry(i);\n+                    ssq = d1 * d1 + d2 * d2;\n+                    // Computing 2nd power\n+                    d1 = trustRegionCenterOffset.getEntry(i) - lowerDifference.getEntry(i);\n+                    temp = ssq - d1 * d1;\n+                    if (temp > ZERO) {\n+                        temp = Math.sqrt(temp) - s.getEntry(i);\n+                        if (angbd * temp > tempa) {\n+                            angbd = tempa / temp;\n+                            iact = i;\n+                            xsav = MINUS_ONE;\n+                        }\n+                    }\n+                    // Computing 2nd power\n+                    d1 = upperDifference.getEntry(i) - trustRegionCenterOffset.getEntry(i);\n+                    temp = ssq - d1 * d1;\n+                    if (temp > ZERO) {\n+                        temp = Math.sqrt(temp) + s.getEntry(i);\n+                        if (angbd * temp > tempb) {\n+                            angbd = tempb / temp;\n+                            iact = i;\n+                            xsav = ONE;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // Calculate HHD and some curvatures for the alternative iteration.\n+\n+            state = 210; break;\n+        }\n+        case 150: {\n+            printState(150); // XXX\n+            shs = ZERO;\n+            dhs = ZERO;\n+            dhd = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                if (xbdi.getEntry(i) == ZERO) {\n+                    shs += s.getEntry(i) * hs.getEntry(i);\n+                    dhs += trialStepPoint.getEntry(i) * hs.getEntry(i);\n+                    dhd += trialStepPoint.getEntry(i) * hred.getEntry(i);\n+                }\n+            }\n+\n+            // Seek the greatest reduction in Q for a range of equally spaced values\n+            // of ANGT in [0,ANGBD], where ANGT is the tangent of half the angle of\n+            // the alternative iteration.\n+\n+            redmax = ZERO;\n+            isav = -1;\n+            redsav = ZERO;\n+            iu = (int) (angbd * 17. + 3.1);\n+            for (int i = 0; i < iu; i++) {\n+                angt = angbd * i / iu;\n+                sth = (angt + angt) / (ONE + angt * angt);\n+                temp = shs + angt * (angt * dhd - dhs - dhs);\n+                rednew = sth * (angt * dredg - sredg - HALF * sth * temp);\n+                if (rednew > redmax) {\n+                    redmax = rednew;\n+                    isav = i;\n+                    rdprev = redsav;\n+                } else if (i == isav + 1) {\n+                    rdnext = rednew;\n+                }\n+                redsav = rednew;\n+            }\n+\n+            // Return if the reduction is zero. Otherwise, set the sine and cosine\n+            // of the angle of the alternative iteration, and calculate SDEC.\n+\n+            if (isav < 0) {\n+                state = 190; break;\n+            }\n+            if (isav < iu) {\n+                temp = (rdnext - rdprev) / (redmax + redmax - rdprev - rdnext);\n+                angt = angbd * (isav + HALF * temp) / iu;\n+            }\n+            cth = (ONE - angt * angt) / (ONE + angt * angt);\n+            sth = (angt + angt) / (ONE + angt * angt);\n+            temp = shs + angt * (angt * dhd - dhs - dhs);\n+            sdec = sth * (angt * dredg - sredg - HALF * sth * temp);\n+            if (sdec <= ZERO) {\n+                state = 190; break;\n+            }\n+\n+            // Update GNEW, D and HRED. If the angle of the alternative iteration\n+            // is restricted by a bound on a free variable, that variable is fixed\n+            // at the bound.\n+\n+            dredg = ZERO;\n+            gredsq = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                gnew.setEntry(i, gnew.getEntry(i) + (cth - ONE) * hred.getEntry(i) + sth * hs.getEntry(i));\n+                if (xbdi.getEntry(i) == ZERO) {\n+                    trialStepPoint.setEntry(i, cth * trialStepPoint.getEntry(i) + sth * s.getEntry(i));\n+                    dredg += trialStepPoint.getEntry(i) * gnew.getEntry(i);\n+                    // Computing 2nd power\n+                    final double d1 = gnew.getEntry(i);\n+                    gredsq += d1 * d1;\n+                }\n+                hred.setEntry(i, cth * hred.getEntry(i) + sth * hs.getEntry(i));\n+            }\n+            qred += sdec;\n+            if (iact >= 0 && isav == iu) {\n+                ++nact;\n+                xbdi.setEntry(iact, xsav);\n+                state = 100; break;\n+            }\n+\n+            // If SDEC is sufficiently small, then RETURN after setting XNEW to\n+            // XOPT+D, giving careful attention to the bounds.\n+\n+            if (sdec > qred * .01) {\n+                state = 120; break;\n+            }\n+        }\n+        case 190: {\n+            printState(190); // XXX\n+            dsq = ZERO;\n+            for (int i = 0; i < n; i++) {\n+                // Computing MAX\n+                // Computing MIN\n+                final double min = Math.min(trustRegionCenterOffset.getEntry(i) + trialStepPoint.getEntry(i),\n+                                            upperDifference.getEntry(i));\n+                newPoint.setEntry(i, Math.max(min, lowerDifference.getEntry(i)));\n+                if (xbdi.getEntry(i) == MINUS_ONE) {\n+                    newPoint.setEntry(i, lowerDifference.getEntry(i));\n+                }\n+                if (xbdi.getEntry(i) == ONE) {\n+                    newPoint.setEntry(i, upperDifference.getEntry(i));\n+                }\n+                trialStepPoint.setEntry(i, newPoint.getEntry(i) - trustRegionCenterOffset.getEntry(i));\n+                // Computing 2nd power\n+                final double d1 = trialStepPoint.getEntry(i);\n+                dsq += d1 * d1;\n+            }\n+            return new double[] { dsq, crvmin };\n+            // The following instructions multiply the current S-vector by the second\n+            // derivative matrix of the quadratic model, putting the product in HS.\n+            // They are reached from three different parts of the software above and\n+            // they can be regarded as an external subroutine.\n+        }\n+        case 210: {\n+            printState(210); // XXX\n+            int ih = 0;\n+            for (int j = 0; j < n; j++) {\n+                hs.setEntry(j, ZERO);\n+                for (int i = 0; i <= j; i++) {\n+                    if (i < j) {\n+                        hs.setEntry(j, hs.getEntry(j) + modelSecondDerivativesValues.getEntry(ih) * s.getEntry(i));\n+                    }\n+                    hs.setEntry(i, hs.getEntry(i) + modelSecondDerivativesValues.getEntry(ih) * s.getEntry(j));\n+                    ih++;\n+                }\n+            }\n+            final RealVector tmp = interpolationPoints.operate(s).ebeMultiply(modelSecondDerivativesParameters);\n+            for (int k = 0; k < npt; k++) {\n+                if (modelSecondDerivativesParameters.getEntry(k) != ZERO) {\n+                    for (int i = 0; i < n; i++) {\n+                        hs.setEntry(i, hs.getEntry(i) + tmp.getEntry(k) * interpolationPoints.getEntry(k, i));\n+                    }\n+                }\n+            }\n+            if (crvmin != ZERO) {\n+                state = 50; break;\n+            }\n+            if (iterc > itcsav) {\n+                state = 150; break;\n+            }\n+            for (int i = 0; i < n; i++) {\n+                hred.setEntry(i, hs.getEntry(i));\n+            }\n+            state = 120; break;\n+        }\n+        default: {\n+            throw new MathIllegalStateException(LocalizedFormats.SIMPLE_MESSAGE, \"trsbox\");\n+        }}\n+        }\n+    } // trsbox\n+\n+    // ----------------------------------------------------------------------------------------\n+\n+    /**\n+     *     The arrays BMAT and ZMAT are updated, as required by the new position\n+     *     of the interpolation point that has the index KNEW. The vector VLAG has\n+     *     N+NPT components, set on entry to the first NPT and last N components\n+     *     of the product Hw in equation (4.11) of the Powell (2006) paper on\n+     *     NEWUOA. Further, BETA is set on entry to the value of the parameter\n+     *     with that name, and DENOM is set to the denominator of the updating\n+     *     formula. Elements of ZMAT may be treated as zero if their moduli are\n+     *     at most ZTEST. The first NDIM elements of W are used for working space.\n+     * @param beta\n+     * @param denom\n+     * @param knew\n+     */\n+    private void update(\n+            double beta,\n+            double denom,\n+            int knew\n+    ) {\n+        printMethod(); // XXX\n+\n+        final int n = currentBest.getDimension();\n+        final int npt = numberOfInterpolationPoints;\n+        final int nptm = npt - n - 1;\n+\n+        // XXX Should probably be split into two arrays.\n+        final ArrayRealVector work = new ArrayRealVector(npt + n);\n+\n+        double ztest = ZERO;\n+        for (int k = 0; k < npt; k++) {\n+            for (int j = 0; j < nptm; j++) {\n+                // Computing MAX\n+                ztest = Math.max(ztest, Math.abs(zMatrix.getEntry(k, j)));\n+            }\n+        }\n+        ztest *= 1e-20;\n+\n+        // Apply the rotations that put zeros in the KNEW-th row of ZMAT.\n+\n+        for (int j = 1; j < nptm; j++) {\n+            final double d1 = zMatrix.getEntry(knew, j);\n+            if (Math.abs(d1) > ztest) {\n+                // Computing 2nd power\n+                final double d2 = zMatrix.getEntry(knew, 0);\n+                // Computing 2nd power\n+                final double d3 = zMatrix.getEntry(knew, j);\n+                final double d4 = Math.sqrt(d2 * d2 + d3 * d3);\n+                final double d5 = zMatrix.getEntry(knew, 0) / d4;\n+                final double d6 = zMatrix.getEntry(knew, j) / d4;\n+                for (int i = 0; i < npt; i++) {\n+                    final double d7 = d5 * zMatrix.getEntry(i, 0) + d6 * zMatrix.getEntry(i, j);\n+                    zMatrix.setEntry(i, j, d5 * zMatrix.getEntry(i, j) - d6 * zMatrix.getEntry(i, 0));\n+                    zMatrix.setEntry(i, 0, d7);\n+                }\n+            }\n+            zMatrix.setEntry(knew, j, ZERO);\n+        }\n+\n+        // Put the first NPT components of the KNEW-th column of HLAG into W,\n+        // and calculate the parameters of the updating formula.\n+\n+        for (int i = 0; i < npt; i++) {\n+            work.setEntry(i, zMatrix.getEntry(knew, 0) * zMatrix.getEntry(i, 0));\n+        }\n+        final double alpha = work.getEntry(knew);\n+        final double tau = lagrangeValuesAtNewPoint.getEntry(knew);\n+        lagrangeValuesAtNewPoint.setEntry(knew, lagrangeValuesAtNewPoint.getEntry(knew) - ONE);\n+\n+        // Complete the updating of ZMAT.\n+\n+        final double sqrtDenom = Math.sqrt(denom);\n+        final double d1 = tau / sqrtDenom;\n+        final double d2 = zMatrix.getEntry(knew, 0) / sqrtDenom;\n+        for (int i = 0; i < npt; i++) {\n+            zMatrix.setEntry(i, 0,\n+                          d1 * zMatrix.getEntry(i, 0) - d2 * lagrangeValuesAtNewPoint.getEntry(i));\n+        }\n+\n+        // Finally, update the matrix BMAT.\n+\n+        for (int j = 0; j < n; j++) {\n+            final int jp = npt + j;\n+            work.setEntry(jp, bMatrix.getEntry(knew, j));\n+            final double d3 = (alpha * lagrangeValuesAtNewPoint.getEntry(jp) - tau * work.getEntry(jp)) / denom;\n+            final double d4 = (-beta * work.getEntry(jp) - tau * lagrangeValuesAtNewPoint.getEntry(jp)) / denom;\n+            for (int i = 0; i <= jp; i++) {\n+                bMatrix.setEntry(i, j,\n+                              bMatrix.getEntry(i, j) + d3 * lagrangeValuesAtNewPoint.getEntry(i) + d4 * work.getEntry(i));\n+                if (i >= npt) {\n+                    bMatrix.setEntry(jp, (i - npt), bMatrix.getEntry(i, j));\n+                }\n+            }\n+        }\n+    } // update\n+\n+    /**\n+     * Performs validity checks.\n+     *\n+     * @param lowerBound Lower bounds (constraints) of the objective variables.\n+     * @param upperBound Upperer bounds (constraints) of the objective variables.\n+     */\n+    private void setup(double[] lowerBound,\n+                       double[] upperBound) {\n+        printMethod(); // XXX\n+\n+        double[] init = getStartPoint();\n+        final int dimension = init.length;\n+\n+        // Check problem dimension.\n+        if (dimension < MINIMUM_PROBLEM_DIMENSION) {\n+            throw new NumberIsTooSmallException(dimension, MINIMUM_PROBLEM_DIMENSION, true);\n+        }\n+        // Check number of interpolation points.\n+        final int[] nPointsInterval = { dimension + 2, (dimension + 2) * (dimension + 1) / 2 };\n+        if (numberOfInterpolationPoints < nPointsInterval[0] ||\n+            numberOfInterpolationPoints > nPointsInterval[1]) {\n+            throw new OutOfRangeException(LocalizedFormats.NUMBER_OF_INTERPOLATION_POINTS,\n+                                          numberOfInterpolationPoints,\n+                                          nPointsInterval[0],\n+                                          nPointsInterval[1]);\n+        }\n+\n+        // Initialize bound differences.\n+        boundDifference = new double[dimension];\n+\n+        double requiredMinDiff = 2 * initialTrustRegionRadius;\n+        double minDiff = Double.POSITIVE_INFINITY;\n+        for (int i = 0; i < dimension; i++) {\n+            boundDifference[i] = upperBound[i] - lowerBound[i];\n+            minDiff = Math.min(minDiff, boundDifference[i]);\n+        }\n+        if (minDiff < requiredMinDiff) {\n+            initialTrustRegionRadius = minDiff / 3.0;\n+        }\n+\n+        // Initialize the data structures used by the \"bobyqa\" method.\n+        bMatrix = new Array2DRowRealMatrix(dimension + numberOfInterpolationPoints,\n+                                           dimension);\n+        zMatrix = new Array2DRowRealMatrix(numberOfInterpolationPoints,\n+                                           numberOfInterpolationPoints - dimension - 1);\n+        interpolationPoints = new Array2DRowRealMatrix(numberOfInterpolationPoints,\n+                                                       dimension);\n+        originShift = new ArrayRealVector(dimension);\n+        fAtInterpolationPoints = new ArrayRealVector(numberOfInterpolationPoints);\n+        trustRegionCenterOffset = new ArrayRealVector(dimension);\n+        gradientAtTrustRegionCenter = new ArrayRealVector(dimension);\n+        lowerDifference = new ArrayRealVector(dimension);\n+        upperDifference = new ArrayRealVector(dimension);\n+        modelSecondDerivativesParameters = new ArrayRealVector(numberOfInterpolationPoints);\n+        newPoint = new ArrayRealVector(dimension);\n+        alternativeNewPoint = new ArrayRealVector(dimension);\n+        trialStepPoint = new ArrayRealVector(dimension);\n+        lagrangeValuesAtNewPoint = new ArrayRealVector(dimension + numberOfInterpolationPoints);\n+        modelSecondDerivativesValues = new ArrayRealVector(dimension * (dimension + 1) / 2);\n+    }\n+\n+    /**\n+     * Creates a new array.\n+     *\n+     * @param n Dimension of the returned array.\n+     * @param value Value for each element.\n+     * @return an array containing {@code n} elements set to the given\n+     * {@code value}.\n+     */\n+    private static double[] fillNewArray(int n,\n+                                         double value) {\n+        double[] ds = new double[n];\n+        Arrays.fill(ds, value);\n+        return ds;\n+    }\n+\n+    // XXX utility for figuring out call sequence.\n+    private static String caller(int n) {\n+        final Throwable t = new Throwable();\n+        final StackTraceElement[] elements = t.getStackTrace();\n+        final StackTraceElement e = elements[n];\n+        return e.getMethodName() + \" (at line \" + e.getLineNumber() + \")\";\n+    }\n+    // XXX utility for figuring out call sequence.\n+    private static void printState(int s) {\n+        //        System.out.println(caller(2) + \": state \" + s);\n+    }\n+    // XXX utility for figuring out call sequence.\n+    private static void printMethod() {\n+        //        System.out.println(caller(2));\n+    }\n+\n+    /**\n+     * Marker for code paths that are not explored with the current unit tests.\n+     * If the path becomes explored, it should just be removed from the code.\n+     */\n+    private static class PathIsExploredException extends RuntimeException {\n+        private static final long serialVersionUID = 745350979634801853L;\n+\n+        private static final String PATH_IS_EXPLORED\n+            = \"If this exception is thrown, just remove it from the code\";\n+\n+        PathIsExploredException() {\n+            super(PATH_IS_EXPLORED + \" \" + BOBYQAOptimizer.caller(3));\n+        }\n+    }\n+}\n+//CHECKSTYLE: resume all\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.NotPositiveException;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.exception.OutOfRangeException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.linear.Array2DRowRealMatrix;\n+import org.apache.commons.math3.linear.EigenDecomposition;\n+import org.apache.commons.math3.linear.MatrixUtils;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\n+import org.apache.commons.math3.random.RandomGenerator;\n+import org.apache.commons.math3.util.MathArrays;\n+\n+/**\n+ * <p>An implementation of the active Covariance Matrix Adaptation Evolution Strategy (CMA-ES)\n+ * for non-linear, non-convex, non-smooth, global function minimization.\n+ * The CMA-Evolution Strategy (CMA-ES) is a reliable stochastic optimization method\n+ * which should be applied if derivative-based methods, e.g. quasi-Newton BFGS or\n+ * conjugate gradient, fail due to a rugged search landscape (e.g. noise, local\n+ * optima, outlier, etc.) of the objective function. Like a\n+ * quasi-Newton method, the CMA-ES learns and applies a variable metric\n+ * on the underlying search space. Unlike a quasi-Newton method, the\n+ * CMA-ES neither estimates nor uses gradients, making it considerably more\n+ * reliable in terms of finding a good, or even close to optimal, solution.</p>\n+ *\n+ * <p>In general, on smooth objective functions the CMA-ES is roughly ten times\n+ * slower than BFGS (counting objective function evaluations, no gradients provided).\n+ * For up to <math>N=10</math> variables also the derivative-free simplex\n+ * direct search method (Nelder and Mead) can be faster, but it is\n+ * far less reliable than CMA-ES.</p>\n+ *\n+ * <p>The CMA-ES is particularly well suited for non-separable\n+ * and/or badly conditioned problems. To observe the advantage of CMA compared\n+ * to a conventional evolution strategy, it will usually take about\n+ * <math>30 N</math> function evaluations. On difficult problems the complete\n+ * optimization (a single run) is expected to take <em>roughly</em> between\n+ * <math>30 N</math> and <math>300 N<sup>2</sup></math>\n+ * function evaluations.</p>\n+ *\n+ * <p>This implementation is translated and adapted from the Matlab version\n+ * of the CMA-ES algorithm as implemented in module {@code cmaes.m} version 3.51.</p>\n+ *\n+ * For more information, please refer to the following links:\n+ * <ul>\n+ *  <li><a href=\"http://www.lri.fr/~hansen/cmaes.m\">Matlab code</a></li>\n+ *  <li><a href=\"http://www.lri.fr/~hansen/cmaesintro.html\">Introduction to CMA-ES</a></li>\n+ *  <li><a href=\"http://en.wikipedia.org/wiki/CMA-ES\">Wikipedia</a></li>\n+ * </ul>\n+ *\n+ * @version $Id: CMAESOptimizer.java 1400108 2012-10-19 14:20:16Z erans $\n+ * @since 3.0\n+ */\n+public class CMAESOptimizer\n+    extends MultivariateOptimizer {\n+    // global search parameters\n+    /**\n+     * Population size, offspring number. The primary strategy parameter to play\n+     * with, which can be increased from its default value. Increasing the\n+     * population size improves global search properties in exchange to speed.\n+     * Speed decreases, as a rule, at most linearly with increasing population\n+     * size. It is advisable to begin with the default small population size.\n+     */\n+    private int lambda; // population size\n+    /**\n+     * Covariance update mechanism, default is active CMA. isActiveCMA = true\n+     * turns on \"active CMA\" with a negative update of the covariance matrix and\n+     * checks for positive definiteness. OPTS.CMA.active = 2 does not check for\n+     * pos. def. and is numerically faster. Active CMA usually speeds up the\n+     * adaptation.\n+     */\n+    private final boolean isActiveCMA;\n+    /**\n+     * Determines how often a new random offspring is generated in case it is\n+     * not feasible / beyond the defined limits, default is 0.\n+     */\n+    private final int checkFeasableCount;\n+    /**\n+     * @see Sigma\n+     */\n+    private double[] inputSigma;\n+    /** Number of objective variables/problem dimension */\n+    private int dimension;\n+    /**\n+     * Defines the number of initial iterations, where the covariance matrix\n+     * remains diagonal and the algorithm has internally linear time complexity.\n+     * diagonalOnly = 1 means keeping the covariance matrix always diagonal and\n+     * this setting also exhibits linear space complexity. This can be\n+     * particularly useful for dimension > 100.\n+     * @see <a href=\"http://hal.archives-ouvertes.fr/inria-00287367/en\">A Simple Modification in CMA-ES</a>\n+     */\n+    private int diagonalOnly;\n+    /** Number of objective variables/problem dimension */\n+    private boolean isMinimize = true;\n+    /** Indicates whether statistic data is collected. */\n+    private final boolean generateStatistics;\n+\n+    // termination criteria\n+    /** Maximal number of iterations allowed. */\n+    private final int maxIterations;\n+    /** Limit for fitness value. */\n+    private final double stopFitness;\n+    /** Stop if x-changes larger stopTolUpX. */\n+    private double stopTolUpX;\n+    /** Stop if x-change smaller stopTolX. */\n+    private double stopTolX;\n+    /** Stop if fun-changes smaller stopTolFun. */\n+    private double stopTolFun;\n+    /** Stop if back fun-changes smaller stopTolHistFun. */\n+    private double stopTolHistFun;\n+\n+    // selection strategy parameters\n+    /** Number of parents/points for recombination. */\n+    private int mu; //\n+    /** log(mu + 0.5), stored for efficiency. */\n+    private double logMu2;\n+    /** Array for weighted recombination. */\n+    private RealMatrix weights;\n+    /** Variance-effectiveness of sum w_i x_i. */\n+    private double mueff; //\n+\n+    // dynamic strategy parameters and constants\n+    /** Overall standard deviation - search volume. */\n+    private double sigma;\n+    /** Cumulation constant. */\n+    private double cc;\n+    /** Cumulation constant for step-size. */\n+    private double cs;\n+    /** Damping for step-size. */\n+    private double damps;\n+    /** Learning rate for rank-one update. */\n+    private double ccov1;\n+    /** Learning rate for rank-mu update' */\n+    private double ccovmu;\n+    /** Expectation of ||N(0,I)|| == norm(randn(N,1)). */\n+    private double chiN;\n+    /** Learning rate for rank-one update - diagonalOnly */\n+    private double ccov1Sep;\n+    /** Learning rate for rank-mu update - diagonalOnly */\n+    private double ccovmuSep;\n+\n+    // CMA internal values - updated each generation\n+    /** Objective variables. */\n+    private RealMatrix xmean;\n+    /** Evolution path. */\n+    private RealMatrix pc;\n+    /** Evolution path for sigma. */\n+    private RealMatrix ps;\n+    /** Norm of ps, stored for efficiency. */\n+    private double normps;\n+    /** Coordinate system. */\n+    private RealMatrix B;\n+    /** Scaling. */\n+    private RealMatrix D;\n+    /** B*D, stored for efficiency. */\n+    private RealMatrix BD;\n+    /** Diagonal of sqrt(D), stored for efficiency. */\n+    private RealMatrix diagD;\n+    /** Covariance matrix. */\n+    private RealMatrix C;\n+    /** Diagonal of C, used for diagonalOnly. */\n+    private RealMatrix diagC;\n+    /** Number of iterations already performed. */\n+    private int iterations;\n+\n+    /** History queue of best values. */\n+    private double[] fitnessHistory;\n+    /** Size of history queue of best values. */\n+    private int historySize;\n+\n+    /** Random generator. */\n+    private final RandomGenerator random;\n+\n+    /** History of sigma values. */\n+    private final List<Double> statisticsSigmaHistory = new ArrayList<Double>();\n+    /** History of mean matrix. */\n+    private final List<RealMatrix> statisticsMeanHistory = new ArrayList<RealMatrix>();\n+    /** History of fitness values. */\n+    private final List<Double> statisticsFitnessHistory = new ArrayList<Double>();\n+    /** History of D matrix. */\n+    private final List<RealMatrix> statisticsDHistory = new ArrayList<RealMatrix>();\n+\n+    /**\n+     * @param maxIterations Maximal number of iterations.\n+     * @param stopFitness Whether to stop if objective function value is smaller than\n+     * {@code stopFitness}.\n+     * @param isActiveCMA Chooses the covariance matrix update method.\n+     * @param diagonalOnly Number of initial iterations, where the covariance matrix\n+     * remains diagonal.\n+     * @param checkFeasableCount Determines how often new random objective variables are\n+     * generated in case they are out of bounds.\n+     * @param random Random generator.\n+     * @param generateStatistics Whether statistic data is collected.\n+     * @param checker Convergence checker.\n+     *\n+     * @since 3.1\n+     */\n+    public CMAESOptimizer(int maxIterations,\n+                          double stopFitness,\n+                          boolean isActiveCMA,\n+                          int diagonalOnly,\n+                          int checkFeasableCount,\n+                          RandomGenerator random,\n+                          boolean generateStatistics,\n+                          ConvergenceChecker<PointValuePair> checker) {\n+        super(checker);\n+        this.maxIterations = maxIterations;\n+        this.stopFitness = stopFitness;\n+        this.isActiveCMA = isActiveCMA;\n+        this.diagonalOnly = diagonalOnly;\n+        this.checkFeasableCount = checkFeasableCount;\n+        this.random = random;\n+        this.generateStatistics = generateStatistics;\n+    }\n+\n+    /**\n+     * @return History of sigma values.\n+     */\n+    public List<Double> getStatisticsSigmaHistory() {\n+        return statisticsSigmaHistory;\n+    }\n+\n+    /**\n+     * @return History of mean matrix.\n+     */\n+    public List<RealMatrix> getStatisticsMeanHistory() {\n+        return statisticsMeanHistory;\n+    }\n+\n+    /**\n+     * @return History of fitness values.\n+     */\n+    public List<Double> getStatisticsFitnessHistory() {\n+        return statisticsFitnessHistory;\n+    }\n+\n+    /**\n+     * @return History of D matrix.\n+     */\n+    public List<RealMatrix> getStatisticsDHistory() {\n+        return statisticsDHistory;\n+    }\n+\n+    /**\n+     * Input sigma values.\n+     * They define the initial coordinate-wise standard deviations for\n+     * sampling new search points around the initial guess.\n+     * It is suggested to set them to the estimated distance from the\n+     * initial to the desired optimum.\n+     * Small values induce the search to be more local (and very small\n+     * values are more likely to find a local optimum close to the initial\n+     * guess).\n+     * Too small values might however lead to early termination.\n+     */\n+    public static class Sigma implements OptimizationData {\n+        /** Sigma values. */\n+        private final double[] sigma;\n+\n+        /**\n+         * @param s Sigma values.\n+         * @throws NotPositiveException if any of the array entries is smaller\n+         * than zero.\n+         */\n+        public Sigma(double[] s)\n+            throws NotPositiveException {\n+            for (int i = 0; i < s.length; i++) {\n+                if (s[i] < 0) {\n+                    throw new NotPositiveException(s[i]);\n+                }\n+            }\n+\n+            sigma = s.clone();\n+        }\n+\n+        /**\n+         * @return the sigma values.\n+         */\n+        public double[] getSigma() {\n+            return sigma.clone();\n+        }\n+    }\n+\n+    /**\n+     * Population size.\n+     * The number of offspring is the primary strategy parameter.\n+     * In the absence of better clues, a good default could be an\n+     * integer close to {@code 4 + 3 ln(n)}, where {@code n} is the\n+     * number of optimized parameters.\n+     * Increasing the population size improves global search properties\n+     * at the expense of speed (which in general decreases at most\n+     * linearly with increasing population size).\n+     */\n+    public static class PopulationSize implements OptimizationData {\n+        /** Population size. */\n+        private final int lambda;\n+\n+        /**\n+         * @param size Population size.\n+         * @throws NotStrictlyPositiveException if {@code size <= 0}.\n+         */\n+        public PopulationSize(int size)\n+            throws NotStrictlyPositiveException {\n+            if (size <= 0) {\n+                throw new NotStrictlyPositiveException(size);\n+            }\n+            lambda = size;\n+        }\n+\n+        /**\n+         * @return the population size.\n+         */\n+        public int getPopulationSize() {\n+            return lambda;\n+        }\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxEval}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.InitialGuess}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.SimpleBounds}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.ObjectiveFunction}</li>\n+     *  <li>{@link Sigma}</li>\n+     *  <li>{@link PopulationSize}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     * @throws DimensionMismatchException if the initial guess, target, and weight\n+     * arguments have inconsistent dimensions.\n+     */\n+    @Override\n+    public PointValuePair optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException,\n+               DimensionMismatchException {\n+        // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected PointValuePair doOptimize() {\n+        checkParameters();\n+         // -------------------- Initialization --------------------------------\n+        isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n+        final FitnessFunction fitfun = new FitnessFunction();\n+        final double[] guess = getStartPoint();\n+        // number of objective variables/problem dimension\n+        dimension = guess.length;\n+        initializeCMA(guess);\n+        iterations = 0;\n+        double bestValue = fitfun.value(guess);\n+        push(fitnessHistory, bestValue);\n+        PointValuePair optimum\n+            = new PointValuePair(getStartPoint(),\n+                                 isMinimize ? bestValue : -bestValue);\n+        PointValuePair lastResult = null;\n+\n+        // -------------------- Generation Loop --------------------------------\n+\n+        generationLoop:\n+        for (iterations = 1; iterations <= maxIterations; iterations++) {\n+            // Generate and evaluate lambda offspring\n+            final RealMatrix arz = randn1(dimension, lambda);\n+            final RealMatrix arx = zeros(dimension, lambda);\n+            final double[] fitness = new double[lambda];\n+            // generate random offspring\n+            for (int k = 0; k < lambda; k++) {\n+                RealMatrix arxk = null;\n+                for (int i = 0; i < checkFeasableCount + 1; i++) {\n+                    if (diagonalOnly <= 0) {\n+                        arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\n+                                         .scalarMultiply(sigma)); // m + sig * Normal(0,C)\n+                    } else {\n+                        arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))\n+                                         .scalarMultiply(sigma));\n+                    }\n+                    if (i >= checkFeasableCount ||\n+                        fitfun.isFeasible(arxk.getColumn(0))) {\n+                        break;\n+                    }\n+                    // regenerate random arguments for row\n+                    arz.setColumn(k, randn(dimension));\n+                }\n+                copyColumn(arxk, 0, arx, k);\n+                try {\n+                    fitness[k] = fitfun.value(arx.getColumn(k)); // compute fitness\n+                } catch (TooManyEvaluationsException e) {\n+                    break generationLoop;\n+                }\n+            }\n+            // Sort by fitness and compute weighted mean into xmean\n+            final int[] arindex = sortedIndices(fitness);\n+            // Calculate new xmean, this is selection and recombination\n+            final RealMatrix xold = xmean; // for speed up of Eq. (2) and (3)\n+            final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n+            xmean = bestArx.multiply(weights);\n+            final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n+            final RealMatrix zmean = bestArz.multiply(weights);\n+            final boolean hsig = updateEvolutionPaths(zmean, xold);\n+            if (diagonalOnly <= 0) {\n+                updateCovariance(hsig, bestArx, arz, arindex, xold);\n+            } else {\n+                updateCovarianceDiagonalOnly(hsig, bestArz, xold);\n+            }\n+            // Adapt step size sigma - Eq. (5)\n+            sigma *= Math.exp(Math.min(1, (normps/chiN - 1) * cs / damps));\n+            final double bestFitness = fitness[arindex[0]];\n+            final double worstFitness = fitness[arindex[arindex.length - 1]];\n+            if (bestValue > bestFitness) {\n+                bestValue = bestFitness;\n+                lastResult = optimum;\n+                optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)),\n+                                             isMinimize ? bestFitness : -bestFitness);\n+                if (getConvergenceChecker() != null &&\n+                    lastResult != null) {\n+                    if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n+                        break generationLoop;\n+                    }\n+                }\n+            }\n+            // handle termination criteria\n+            // Break, if fitness is good enough\n+            if (stopFitness != 0) { // only if stopFitness is defined\n+                if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n+                    break generationLoop;\n+                }\n+            }\n+            final double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n+            final double[] pcCol = pc.getColumn(0);\n+            for (int i = 0; i < dimension; i++) {\n+                if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {\n+                    break;\n+                }\n+                if (i >= dimension - 1) {\n+                    break generationLoop;\n+                }\n+            }\n+            for (int i = 0; i < dimension; i++) {\n+                if (sigma * sqrtDiagC[i] > stopTolUpX) {\n+                    break generationLoop;\n+                }\n+            }\n+            final double historyBest = min(fitnessHistory);\n+            final double historyWorst = max(fitnessHistory);\n+            if (iterations > 2 &&\n+                Math.max(historyWorst, worstFitness) -\n+                Math.min(historyBest, bestFitness) < stopTolFun) {\n+                break generationLoop;\n+            }\n+            if (iterations > fitnessHistory.length &&\n+                historyWorst - historyBest < stopTolHistFun) {\n+                break generationLoop;\n+            }\n+            // condition number of the covariance matrix exceeds 1e14\n+            if (max(diagD) / min(diagD) > 1e7) {\n+                break generationLoop;\n+            }\n+            // user defined termination\n+            if (getConvergenceChecker() != null) {\n+                final PointValuePair current\n+                    = new PointValuePair(bestArx.getColumn(0),\n+                                         isMinimize ? bestFitness : -bestFitness);\n+                if (lastResult != null &&\n+                    getConvergenceChecker().converged(iterations, current, lastResult)) {\n+                    break generationLoop;\n+                    }\n+                lastResult = current;\n+            }\n+            // Adjust step size in case of equal function values (flat fitness)\n+            if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\n+                sigma = sigma * Math.exp(0.2 + cs / damps);\n+            }\n+            if (iterations > 2 && Math.max(historyWorst, bestFitness) -\n+                Math.min(historyBest, bestFitness) == 0) {\n+                sigma = sigma * Math.exp(0.2 + cs / damps);\n+            }\n+            // store best in history\n+            push(fitnessHistory,bestFitness);\n+            fitfun.setValueRange(worstFitness-bestFitness);\n+            if (generateStatistics) {\n+                statisticsSigmaHistory.add(sigma);\n+                statisticsFitnessHistory.add(bestFitness);\n+                statisticsMeanHistory.add(xmean.transpose());\n+                statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n+            }\n+        }\n+        return optimum;\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link Sigma}</li>\n+     *  <li>{@link PopulationSize}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof Sigma) {\n+                inputSigma = ((Sigma) data).getSigma();\n+                continue;\n+            }\n+            if (data instanceof PopulationSize) {\n+                lambda = ((PopulationSize) data).getPopulationSize();\n+                continue;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks dimensions and values of boundaries and inputSigma if defined.\n+     */\n+    private void checkParameters() {\n+        final double[] init = getStartPoint();\n+        final double[] lB = getLowerBound();\n+        final double[] uB = getUpperBound();\n+\n+        if (inputSigma != null) {\n+            if (inputSigma.length != init.length) {\n+                throw new DimensionMismatchException(inputSigma.length, init.length);\n+            }\n+            for (int i = 0; i < init.length; i++) {\n+                if (inputSigma[i] > uB[i] - lB[i]) {\n+                    throw new OutOfRangeException(inputSigma[i], 0, uB[i] - lB[i]);\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Initialization of the dynamic search parameters\n+     *\n+     * @param guess Initial guess for the arguments of the fitness function.\n+     */\n+    private void initializeCMA(double[] guess) {\n+        if (lambda <= 0) {\n+            throw new NotStrictlyPositiveException(lambda);\n+        }\n+        // initialize sigma\n+        final double[][] sigmaArray = new double[guess.length][1];\n+        for (int i = 0; i < guess.length; i++) {\n+            sigmaArray[i][0] = inputSigma[i];\n+        }\n+        final RealMatrix insigma = new Array2DRowRealMatrix(sigmaArray, false);\n+        sigma = max(insigma); // overall standard deviation\n+\n+        // initialize termination criteria\n+        stopTolUpX = 1e3 * max(insigma);\n+        stopTolX = 1e-11 * max(insigma);\n+        stopTolFun = 1e-12;\n+        stopTolHistFun = 1e-13;\n+\n+        // initialize selection strategy parameters\n+        mu = lambda / 2; // number of parents/points for recombination\n+        logMu2 = Math.log(mu + 0.5);\n+        weights = log(sequence(1, mu, 1)).scalarMultiply(-1).scalarAdd(logMu2);\n+        double sumw = 0;\n+        double sumwq = 0;\n+        for (int i = 0; i < mu; i++) {\n+            double w = weights.getEntry(i, 0);\n+            sumw += w;\n+            sumwq += w * w;\n+        }\n+        weights = weights.scalarMultiply(1 / sumw);\n+        mueff = sumw * sumw / sumwq; // variance-effectiveness of sum w_i x_i\n+\n+        // initialize dynamic strategy parameters and constants\n+        cc = (4 + mueff / dimension) /\n+                (dimension + 4 + 2 * mueff / dimension);\n+        cs = (mueff + 2) / (dimension + mueff + 3.);\n+        damps = (1 + 2 * Math.max(0, Math.sqrt((mueff - 1) /\n+                                               (dimension + 1)) - 1)) *\n+            Math.max(0.3,\n+                     1 - dimension / (1e-6 + maxIterations)) + cs; // minor increment\n+        ccov1 = 2 / ((dimension + 1.3) * (dimension + 1.3) + mueff);\n+        ccovmu = Math.min(1 - ccov1, 2 * (mueff - 2 + 1 / mueff) /\n+                          ((dimension + 2) * (dimension + 2) + mueff));\n+        ccov1Sep = Math.min(1, ccov1 * (dimension + 1.5) / 3);\n+        ccovmuSep = Math.min(1 - ccov1, ccovmu * (dimension + 1.5) / 3);\n+        chiN = Math.sqrt(dimension) *\n+            (1 - 1 / ((double) 4 * dimension) + 1 / ((double) 21 * dimension * dimension));\n+        // intialize CMA internal values - updated each generation\n+        xmean = MatrixUtils.createColumnRealMatrix(guess); // objective variables\n+        diagD = insigma.scalarMultiply(1 / sigma);\n+        diagC = square(diagD);\n+        pc = zeros(dimension, 1); // evolution paths for C and sigma\n+        ps = zeros(dimension, 1); // B defines the coordinate system\n+        normps = ps.getFrobeniusNorm();\n+\n+        B = eye(dimension, dimension);\n+        D = ones(dimension, 1); // diagonal D defines the scaling\n+        BD = times(B, repmat(diagD.transpose(), dimension, 1));\n+        C = B.multiply(diag(square(D)).multiply(B.transpose())); // covariance\n+        historySize = 10 + (int) (3 * 10 * dimension / (double) lambda);\n+        fitnessHistory = new double[historySize]; // history of fitness values\n+        for (int i = 0; i < historySize; i++) {\n+            fitnessHistory[i] = Double.MAX_VALUE;\n+        }\n+    }\n+\n+    /**\n+     * Update of the evolution paths ps and pc.\n+     *\n+     * @param zmean Weighted row matrix of the gaussian random numbers generating\n+     * the current offspring.\n+     * @param xold xmean matrix of the previous generation.\n+     * @return hsig flag indicating a small correction.\n+     */\n+    private boolean updateEvolutionPaths(RealMatrix zmean, RealMatrix xold) {\n+        ps = ps.scalarMultiply(1 - cs).add(\n+                B.multiply(zmean).scalarMultiply(\n+                        Math.sqrt(cs * (2 - cs) * mueff)));\n+        normps = ps.getFrobeniusNorm();\n+        final boolean hsig = normps /\n+            Math.sqrt(1 - Math.pow(1 - cs, 2 * iterations)) /\n+            chiN < 1.4 + 2 / ((double) dimension + 1);\n+        pc = pc.scalarMultiply(1 - cc);\n+        if (hsig) {\n+            pc = pc.add(xmean.subtract(xold).scalarMultiply(Math.sqrt(cc * (2 - cc) * mueff) / sigma));\n+        }\n+        return hsig;\n+    }\n+\n+    /**\n+     * Update of the covariance matrix C for diagonalOnly > 0\n+     *\n+     * @param hsig Flag indicating a small correction.\n+     * @param bestArz Fitness-sorted matrix of the gaussian random values of the\n+     * current offspring.\n+     * @param xold xmean matrix of the previous generation.\n+     */\n+    private void updateCovarianceDiagonalOnly(boolean hsig,\n+                                              final RealMatrix bestArz,\n+                                              final RealMatrix xold) {\n+        // minor correction if hsig==false\n+        double oldFac = hsig ? 0 : ccov1Sep * cc * (2 - cc);\n+        oldFac += 1 - ccov1Sep - ccovmuSep;\n+        diagC = diagC.scalarMultiply(oldFac) // regard old matrix\n+            .add(square(pc).scalarMultiply(ccov1Sep)) // plus rank one update\n+            .add((times(diagC, square(bestArz).multiply(weights))) // plus rank mu update\n+                 .scalarMultiply(ccovmuSep));\n+        diagD = sqrt(diagC); // replaces eig(C)\n+        if (diagonalOnly > 1 &&\n+            iterations > diagonalOnly) {\n+            // full covariance matrix from now on\n+            diagonalOnly = 0;\n+            B = eye(dimension, dimension);\n+            BD = diag(diagD);\n+            C = diag(diagC);\n+        }\n+    }\n+\n+    /**\n+     * Update of the covariance matrix C.\n+     *\n+     * @param hsig Flag indicating a small correction.\n+     * @param bestArx Fitness-sorted matrix of the argument vectors producing the\n+     * current offspring.\n+     * @param arz Unsorted matrix containing the gaussian random values of the\n+     * current offspring.\n+     * @param arindex Indices indicating the fitness-order of the current offspring.\n+     * @param xold xmean matrix of the previous generation.\n+     */\n+    private void updateCovariance(boolean hsig, final RealMatrix bestArx,\n+                                  final RealMatrix arz, final int[] arindex,\n+                                  final RealMatrix xold) {\n+        double negccov = 0;\n+        if (ccov1 + ccovmu > 0) {\n+            final RealMatrix arpos = bestArx.subtract(repmat(xold, 1, mu))\n+                .scalarMultiply(1 / sigma); // mu difference vectors\n+            final RealMatrix roneu = pc.multiply(pc.transpose())\n+                .scalarMultiply(ccov1); // rank one update\n+            // minor correction if hsig==false\n+            double oldFac = hsig ? 0 : ccov1 * cc * (2 - cc);\n+            oldFac += 1 - ccov1 - ccovmu;\n+            if (isActiveCMA) {\n+                // Adapt covariance matrix C active CMA\n+                negccov = (1 - ccovmu) * 0.25 * mueff /\n+                    (Math.pow(dimension + 2, 1.5) + 2 * mueff);\n+                // keep at least 0.66 in all directions, small popsize are most\n+                // critical\n+                final double negminresidualvariance = 0.66;\n+                // where to make up for the variance loss\n+                final double negalphaold = 0.5;\n+                // prepare vectors, compute negative updating matrix Cneg\n+                final int[] arReverseIndex = reverse(arindex);\n+                RealMatrix arzneg = selectColumns(arz, MathArrays.copyOf(arReverseIndex, mu));\n+                RealMatrix arnorms = sqrt(sumRows(square(arzneg)));\n+                final int[] idxnorms = sortedIndices(arnorms.getRow(0));\n+                final RealMatrix arnormsSorted = selectColumns(arnorms, idxnorms);\n+                final int[] idxReverse = reverse(idxnorms);\n+                final RealMatrix arnormsReverse = selectColumns(arnorms, idxReverse);\n+                arnorms = divide(arnormsReverse, arnormsSorted);\n+                final int[] idxInv = inverse(idxnorms);\n+                final RealMatrix arnormsInv = selectColumns(arnorms, idxInv);\n+                // check and set learning rate negccov\n+                final double negcovMax = (1 - negminresidualvariance) /\n+                    square(arnormsInv).multiply(weights).getEntry(0, 0);\n+                if (negccov > negcovMax) {\n+                    negccov = negcovMax;\n+                }\n+                arzneg = times(arzneg, repmat(arnormsInv, dimension, 1));\n+                final RealMatrix artmp = BD.multiply(arzneg);\n+                final RealMatrix Cneg = artmp.multiply(diag(weights)).multiply(artmp.transpose());\n+                oldFac += negalphaold * negccov;\n+                C = C.scalarMultiply(oldFac)\n+                    .add(roneu) // regard old matrix\n+                    .add(arpos.scalarMultiply( // plus rank one update\n+                                              ccovmu + (1 - negalphaold) * negccov) // plus rank mu update\n+                         .multiply(times(repmat(weights, 1, dimension),\n+                                         arpos.transpose())))\n+                    .subtract(Cneg.scalarMultiply(negccov));\n+            } else {\n+                // Adapt covariance matrix C - nonactive\n+                C = C.scalarMultiply(oldFac) // regard old matrix\n+                    .add(roneu) // plus rank one update\n+                    .add(arpos.scalarMultiply(ccovmu) // plus rank mu update\n+                         .multiply(times(repmat(weights, 1, dimension),\n+                                         arpos.transpose())));\n+            }\n+        }\n+        updateBD(negccov);\n+    }\n+\n+    /**\n+     * Update B and D from C.\n+     *\n+     * @param negccov Negative covariance factor.\n+     */\n+    private void updateBD(double negccov) {\n+        if (ccov1 + ccovmu + negccov > 0 &&\n+            (iterations % 1. / (ccov1 + ccovmu + negccov) / dimension / 10.) < 1) {\n+            // to achieve O(N^2)\n+            C = triu(C, 0).add(triu(C, 1).transpose());\n+            // enforce symmetry to prevent complex numbers\n+            final EigenDecomposition eig = new EigenDecomposition(C);\n+            B = eig.getV(); // eigen decomposition, B==normalized eigenvectors\n+            D = eig.getD();\n+            diagD = diag(D);\n+            if (min(diagD) <= 0) {\n+                for (int i = 0; i < dimension; i++) {\n+                    if (diagD.getEntry(i, 0) < 0) {\n+                        diagD.setEntry(i, 0, 0);\n+                    }\n+                }\n+                final double tfac = max(diagD) / 1e14;\n+                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));\n+                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));\n+            }\n+            if (max(diagD) > 1e14 * min(diagD)) {\n+                final double tfac = max(diagD) / 1e14 - min(diagD);\n+                C = C.add(eye(dimension, dimension).scalarMultiply(tfac));\n+                diagD = diagD.add(ones(dimension, 1).scalarMultiply(tfac));\n+            }\n+            diagC = diag(C);\n+            diagD = sqrt(diagD); // D contains standard deviations now\n+            BD = times(B, repmat(diagD.transpose(), dimension, 1)); // O(n^2)\n+        }\n+    }\n+\n+    /**\n+     * Pushes the current best fitness value in a history queue.\n+     *\n+     * @param vals History queue.\n+     * @param val Current best fitness value.\n+     */\n+    private static void push(double[] vals, double val) {\n+        for (int i = vals.length-1; i > 0; i--) {\n+            vals[i] = vals[i-1];\n+        }\n+        vals[0] = val;\n+    }\n+\n+    /**\n+     * Sorts fitness values.\n+     *\n+     * @param doubles Array of values to be sorted.\n+     * @return a sorted array of indices pointing into doubles.\n+     */\n+    private int[] sortedIndices(final double[] doubles) {\n+        final DoubleIndex[] dis = new DoubleIndex[doubles.length];\n+        for (int i = 0; i < doubles.length; i++) {\n+            dis[i] = new DoubleIndex(doubles[i], i);\n+        }\n+        Arrays.sort(dis);\n+        final int[] indices = new int[doubles.length];\n+        for (int i = 0; i < doubles.length; i++) {\n+            indices[i] = dis[i].index;\n+        }\n+        return indices;\n+    }\n+\n+    /**\n+     * Used to sort fitness values. Sorting is always in lower value first\n+     * order.\n+     */\n+    private static class DoubleIndex implements Comparable<DoubleIndex> {\n+        /** Value to compare. */\n+        private final double value;\n+        /** Index into sorted array. */\n+        private final int index;\n+\n+        /**\n+         * @param value Value to compare.\n+         * @param index Index into sorted array.\n+         */\n+        DoubleIndex(double value, int index) {\n+            this.value = value;\n+            this.index = index;\n+        }\n+\n+        /** {@inheritDoc} */\n+        public int compareTo(DoubleIndex o) {\n+            return Double.compare(value, o.value);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override\n+        public boolean equals(Object other) {\n+\n+            if (this == other) {\n+                return true;\n+            }\n+\n+            if (other instanceof DoubleIndex) {\n+                return Double.compare(value, ((DoubleIndex) other).value) == 0;\n+            }\n+\n+            return false;\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override\n+        public int hashCode() {\n+            long bits = Double.doubleToLongBits(value);\n+            return (int) ((1438542 ^ (bits >>> 32) ^ bits) & 0xffffffff);\n+        }\n+    }\n+\n+    /**\n+     * Normalizes fitness values to the range [0,1]. Adds a penalty to the\n+     * fitness value if out of range. The penalty is adjusted by calling\n+     * setValueRange().\n+     */\n+    private class FitnessFunction {\n+        /** Determines the penalty for boundary violations */\n+        private double valueRange;\n+        /**\n+         * Flag indicating whether the objective variables are forced into their\n+         * bounds if defined\n+         */\n+        private final boolean isRepairMode;\n+\n+        /** Simple constructor.\n+         */\n+        public FitnessFunction() {\n+            valueRange = 1;\n+            isRepairMode = true;\n+        }\n+\n+        /**\n+         * @param point Normalized objective variables.\n+         * @return the objective value + penalty for violated bounds.\n+         */\n+        public double value(final double[] point) {\n+            double value;\n+            if (isRepairMode) {\n+                double[] repaired = repair(point);\n+                value = CMAESOptimizer.this.computeObjectiveValue(repaired) +\n+                    penalty(point, repaired);\n+            } else {\n+                value = CMAESOptimizer.this.computeObjectiveValue(point);\n+            }\n+            return isMinimize ? value : -value;\n+        }\n+\n+        /**\n+         * @param x Normalized objective variables.\n+         * @return {@code true} if in bounds.\n+         */\n+        public boolean isFeasible(final double[] x) {\n+            final double[] lB = CMAESOptimizer.this.getLowerBound();\n+            final double[] uB = CMAESOptimizer.this.getUpperBound();\n+\n+            for (int i = 0; i < x.length; i++) {\n+                if (x[i] < lB[i]) {\n+                    return false;\n+                }\n+                if (x[i] > uB[i]) {\n+                    return false;\n+                }\n+            }\n+            return true;\n+        }\n+\n+        /**\n+         * @param valueRange Adjusts the penalty computation.\n+         */\n+        public void setValueRange(double valueRange) {\n+            this.valueRange = valueRange;\n+        }\n+\n+        /**\n+         * @param x Normalized objective variables.\n+         * @return the repaired (i.e. all in bounds) objective variables.\n+         */\n+        private double[] repair(final double[] x) {\n+            final double[] lB = CMAESOptimizer.this.getLowerBound();\n+            final double[] uB = CMAESOptimizer.this.getUpperBound();\n+\n+            final double[] repaired = new double[x.length];\n+            for (int i = 0; i < x.length; i++) {\n+                if (x[i] < lB[i]) {\n+                    repaired[i] = lB[i];\n+                } else if (x[i] > uB[i]) {\n+                    repaired[i] = uB[i];\n+                } else {\n+                    repaired[i] = x[i];\n+                }\n+            }\n+            return repaired;\n+        }\n+\n+        /**\n+         * @param x Normalized objective variables.\n+         * @param repaired Repaired objective variables.\n+         * @return Penalty value according to the violation of the bounds.\n+         */\n+        private double penalty(final double[] x, final double[] repaired) {\n+            double penalty = 0;\n+            for (int i = 0; i < x.length; i++) {\n+                double diff = Math.abs(x[i] - repaired[i]);\n+                penalty += diff * valueRange;\n+            }\n+            return isMinimize ? penalty : -penalty;\n+        }\n+    }\n+\n+    // -----Matrix utility functions similar to the Matlab build in functions------\n+\n+    /**\n+     * @param m Input matrix\n+     * @return Matrix representing the element-wise logarithm of m.\n+     */\n+    private static RealMatrix log(final RealMatrix m) {\n+        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < m.getColumnDimension(); c++) {\n+                d[r][c] = Math.log(m.getEntry(r, c));\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix.\n+     * @return Matrix representing the element-wise square root of m.\n+     */\n+    private static RealMatrix sqrt(final RealMatrix m) {\n+        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < m.getColumnDimension(); c++) {\n+                d[r][c] = Math.sqrt(m.getEntry(r, c));\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix.\n+     * @return Matrix representing the element-wise square of m.\n+     */\n+    private static RealMatrix square(final RealMatrix m) {\n+        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < m.getColumnDimension(); c++) {\n+                double e = m.getEntry(r, c);\n+                d[r][c] = e * e;\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix 1.\n+     * @param n Input matrix 2.\n+     * @return the matrix where the elements of m and n are element-wise multiplied.\n+     */\n+    private static RealMatrix times(final RealMatrix m, final RealMatrix n) {\n+        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < m.getColumnDimension(); c++) {\n+                d[r][c] = m.getEntry(r, c) * n.getEntry(r, c);\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix 1.\n+     * @param n Input matrix 2.\n+     * @return Matrix where the elements of m and n are element-wise divided.\n+     */\n+    private static RealMatrix divide(final RealMatrix m, final RealMatrix n) {\n+        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < m.getColumnDimension(); c++) {\n+                d[r][c] = m.getEntry(r, c) / n.getEntry(r, c);\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix.\n+     * @param cols Columns to select.\n+     * @return Matrix representing the selected columns.\n+     */\n+    private static RealMatrix selectColumns(final RealMatrix m, final int[] cols) {\n+        final double[][] d = new double[m.getRowDimension()][cols.length];\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < cols.length; c++) {\n+                d[r][c] = m.getEntry(r, cols[c]);\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix.\n+     * @param k Diagonal position.\n+     * @return Upper triangular part of matrix.\n+     */\n+    private static RealMatrix triu(final RealMatrix m, int k) {\n+        final double[][] d = new double[m.getRowDimension()][m.getColumnDimension()];\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < m.getColumnDimension(); c++) {\n+                d[r][c] = r <= c - k ? m.getEntry(r, c) : 0;\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix.\n+     * @return Row matrix representing the sums of the rows.\n+     */\n+    private static RealMatrix sumRows(final RealMatrix m) {\n+        final double[][] d = new double[1][m.getColumnDimension()];\n+        for (int c = 0; c < m.getColumnDimension(); c++) {\n+            double sum = 0;\n+            for (int r = 0; r < m.getRowDimension(); r++) {\n+                sum += m.getEntry(r, c);\n+            }\n+            d[0][c] = sum;\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix.\n+     * @return the diagonal n-by-n matrix if m is a column matrix or the column\n+     * matrix representing the diagonal if m is a n-by-n matrix.\n+     */\n+    private static RealMatrix diag(final RealMatrix m) {\n+        if (m.getColumnDimension() == 1) {\n+            final double[][] d = new double[m.getRowDimension()][m.getRowDimension()];\n+            for (int i = 0; i < m.getRowDimension(); i++) {\n+                d[i][i] = m.getEntry(i, 0);\n+            }\n+            return new Array2DRowRealMatrix(d, false);\n+        } else {\n+            final double[][] d = new double[m.getRowDimension()][1];\n+            for (int i = 0; i < m.getColumnDimension(); i++) {\n+                d[i][0] = m.getEntry(i, i);\n+            }\n+            return new Array2DRowRealMatrix(d, false);\n+        }\n+    }\n+\n+    /**\n+     * Copies a column from m1 to m2.\n+     *\n+     * @param m1 Source matrix.\n+     * @param col1 Source column.\n+     * @param m2 Target matrix.\n+     * @param col2 Target column.\n+     */\n+    private static void copyColumn(final RealMatrix m1, int col1,\n+                                   RealMatrix m2, int col2) {\n+        for (int i = 0; i < m1.getRowDimension(); i++) {\n+            m2.setEntry(i, col2, m1.getEntry(i, col1));\n+        }\n+    }\n+\n+    /**\n+     * @param n Number of rows.\n+     * @param m Number of columns.\n+     * @return n-by-m matrix filled with 1.\n+     */\n+    private static RealMatrix ones(int n, int m) {\n+        final double[][] d = new double[n][m];\n+        for (int r = 0; r < n; r++) {\n+            Arrays.fill(d[r], 1);\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param n Number of rows.\n+     * @param m Number of columns.\n+     * @return n-by-m matrix of 0 values out of diagonal, and 1 values on\n+     * the diagonal.\n+     */\n+    private static RealMatrix eye(int n, int m) {\n+        final double[][] d = new double[n][m];\n+        for (int r = 0; r < n; r++) {\n+            if (r < m) {\n+                d[r][r] = 1;\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param n Number of rows.\n+     * @param m Number of columns.\n+     * @return n-by-m matrix of zero values.\n+     */\n+    private static RealMatrix zeros(int n, int m) {\n+        return new Array2DRowRealMatrix(n, m);\n+    }\n+\n+    /**\n+     * @param mat Input matrix.\n+     * @param n Number of row replicates.\n+     * @param m Number of column replicates.\n+     * @return a matrix which replicates the input matrix in both directions.\n+     */\n+    private static RealMatrix repmat(final RealMatrix mat, int n, int m) {\n+        final int rd = mat.getRowDimension();\n+        final int cd = mat.getColumnDimension();\n+        final double[][] d = new double[n * rd][m * cd];\n+        for (int r = 0; r < n * rd; r++) {\n+            for (int c = 0; c < m * cd; c++) {\n+                d[r][c] = mat.getEntry(r % rd, c % cd);\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param start Start value.\n+     * @param end End value.\n+     * @param step Step size.\n+     * @return a sequence as column matrix.\n+     */\n+    private static RealMatrix sequence(double start, double end, double step) {\n+        final int size = (int) ((end - start) / step + 1);\n+        final double[][] d = new double[size][1];\n+        double value = start;\n+        for (int r = 0; r < size; r++) {\n+            d[r][0] = value;\n+            value += step;\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+\n+    /**\n+     * @param m Input matrix.\n+     * @return the maximum of the matrix element values.\n+     */\n+    private static double max(final RealMatrix m) {\n+        double max = -Double.MAX_VALUE;\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < m.getColumnDimension(); c++) {\n+                double e = m.getEntry(r, c);\n+                if (max < e) {\n+                    max = e;\n+                }\n+            }\n+        }\n+        return max;\n+    }\n+\n+    /**\n+     * @param m Input matrix.\n+     * @return the minimum of the matrix element values.\n+     */\n+    private static double min(final RealMatrix m) {\n+        double min = Double.MAX_VALUE;\n+        for (int r = 0; r < m.getRowDimension(); r++) {\n+            for (int c = 0; c < m.getColumnDimension(); c++) {\n+                double e = m.getEntry(r, c);\n+                if (min > e) {\n+                    min = e;\n+                }\n+            }\n+        }\n+        return min;\n+    }\n+\n+    /**\n+     * @param m Input array.\n+     * @return the maximum of the array values.\n+     */\n+    private static double max(final double[] m) {\n+        double max = -Double.MAX_VALUE;\n+        for (int r = 0; r < m.length; r++) {\n+            if (max < m[r]) {\n+                max = m[r];\n+            }\n+        }\n+        return max;\n+    }\n+\n+    /**\n+     * @param m Input array.\n+     * @return the minimum of the array values.\n+     */\n+    private static double min(final double[] m) {\n+        double min = Double.MAX_VALUE;\n+        for (int r = 0; r < m.length; r++) {\n+            if (min > m[r]) {\n+                min = m[r];\n+            }\n+        }\n+        return min;\n+    }\n+\n+    /**\n+     * @param indices Input index array.\n+     * @return the inverse of the mapping defined by indices.\n+     */\n+    private static int[] inverse(final int[] indices) {\n+        final int[] inverse = new int[indices.length];\n+        for (int i = 0; i < indices.length; i++) {\n+            inverse[indices[i]] = i;\n+        }\n+        return inverse;\n+    }\n+\n+    /**\n+     * @param indices Input index array.\n+     * @return the indices in inverse order (last is first).\n+     */\n+    private static int[] reverse(final int[] indices) {\n+        final int[] reverse = new int[indices.length];\n+        for (int i = 0; i < indices.length; i++) {\n+            reverse[i] = indices[indices.length - i - 1];\n+        }\n+        return reverse;\n+    }\n+\n+    /**\n+     * @param size Length of random array.\n+     * @return an array of Gaussian random numbers.\n+     */\n+    private double[] randn(int size) {\n+        final double[] randn = new double[size];\n+        for (int i = 0; i < size; i++) {\n+            randn[i] = random.nextGaussian();\n+        }\n+        return randn;\n+    }\n+\n+    /**\n+     * @param size Number of rows.\n+     * @param popSize Population size.\n+     * @return a 2-dimensional matrix of Gaussian random numbers.\n+     */\n+    private RealMatrix randn1(int size, int popSize) {\n+        final double[][] d = new double[size][popSize];\n+        for (int r = 0; r < size; r++) {\n+            for (int c = 0; c < popSize; c++) {\n+                d[r][c] = random.nextGaussian();\n+            }\n+        }\n+        return new Array2DRowRealMatrix(d, false);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/MultiDirectionalSimplex.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import java.util.Comparator;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.optim.PointValuePair;\n+\n+/**\n+ * This class implements the multi-directional direct search method.\n+ *\n+ * @version $Id: MultiDirectionalSimplex.java 1364392 2012-07-22 18:27:12Z tn $\n+ * @since 3.0\n+ */\n+public class MultiDirectionalSimplex extends AbstractSimplex {\n+    /** Default value for {@link #khi}: {@value}. */\n+    private static final double DEFAULT_KHI = 2;\n+    /** Default value for {@link #gamma}: {@value}. */\n+    private static final double DEFAULT_GAMMA = 0.5;\n+    /** Expansion coefficient. */\n+    private final double khi;\n+    /** Contraction coefficient. */\n+    private final double gamma;\n+\n+    /**\n+     * Build a multi-directional simplex with default coefficients.\n+     * The default values are 2.0 for khi and 0.5 for gamma.\n+     *\n+     * @param n Dimension of the simplex.\n+     */\n+    public MultiDirectionalSimplex(final int n) {\n+        this(n, 1d);\n+    }\n+\n+    /**\n+     * Build a multi-directional simplex with default coefficients.\n+     * The default values are 2.0 for khi and 0.5 for gamma.\n+     *\n+     * @param n Dimension of the simplex.\n+     * @param sideLength Length of the sides of the default (hypercube)\n+     * simplex. See {@link AbstractSimplex#AbstractSimplex(int,double)}.\n+     */\n+    public MultiDirectionalSimplex(final int n, double sideLength) {\n+        this(n, sideLength, DEFAULT_KHI, DEFAULT_GAMMA);\n+    }\n+\n+    /**\n+     * Build a multi-directional simplex with specified coefficients.\n+     *\n+     * @param n Dimension of the simplex. See\n+     * {@link AbstractSimplex#AbstractSimplex(int,double)}.\n+     * @param khi Expansion coefficient.\n+     * @param gamma Contraction coefficient.\n+     */\n+    public MultiDirectionalSimplex(final int n,\n+                                   final double khi, final double gamma) {\n+        this(n, 1d, khi, gamma);\n+    }\n+\n+    /**\n+     * Build a multi-directional simplex with specified coefficients.\n+     *\n+     * @param n Dimension of the simplex. See\n+     * {@link AbstractSimplex#AbstractSimplex(int,double)}.\n+     * @param sideLength Length of the sides of the default (hypercube)\n+     * simplex. See {@link AbstractSimplex#AbstractSimplex(int,double)}.\n+     * @param khi Expansion coefficient.\n+     * @param gamma Contraction coefficient.\n+     */\n+    public MultiDirectionalSimplex(final int n, double sideLength,\n+                                   final double khi, final double gamma) {\n+        super(n, sideLength);\n+\n+        this.khi   = khi;\n+        this.gamma = gamma;\n+    }\n+\n+    /**\n+     * Build a multi-directional simplex with default coefficients.\n+     * The default values are 2.0 for khi and 0.5 for gamma.\n+     *\n+     * @param steps Steps along the canonical axes representing box edges.\n+     * They may be negative but not zero. See\n+     */\n+    public MultiDirectionalSimplex(final double[] steps) {\n+        this(steps, DEFAULT_KHI, DEFAULT_GAMMA);\n+    }\n+\n+    /**\n+     * Build a multi-directional simplex with specified coefficients.\n+     *\n+     * @param steps Steps along the canonical axes representing box edges.\n+     * They may be negative but not zero. See\n+     * {@link AbstractSimplex#AbstractSimplex(double[])}.\n+     * @param khi Expansion coefficient.\n+     * @param gamma Contraction coefficient.\n+     */\n+    public MultiDirectionalSimplex(final double[] steps,\n+                                   final double khi, final double gamma) {\n+        super(steps);\n+\n+        this.khi   = khi;\n+        this.gamma = gamma;\n+    }\n+\n+    /**\n+     * Build a multi-directional simplex with default coefficients.\n+     * The default values are 2.0 for khi and 0.5 for gamma.\n+     *\n+     * @param referenceSimplex Reference simplex. See\n+     * {@link AbstractSimplex#AbstractSimplex(double[][])}.\n+     */\n+    public MultiDirectionalSimplex(final double[][] referenceSimplex) {\n+        this(referenceSimplex, DEFAULT_KHI, DEFAULT_GAMMA);\n+    }\n+\n+    /**\n+     * Build a multi-directional simplex with specified coefficients.\n+     *\n+     * @param referenceSimplex Reference simplex. See\n+     * {@link AbstractSimplex#AbstractSimplex(double[][])}.\n+     * @param khi Expansion coefficient.\n+     * @param gamma Contraction coefficient.\n+     * @throws org.apache.commons.math3.exception.NotStrictlyPositiveException\n+     * if the reference simplex does not contain at least one point.\n+     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n+     * if there is a dimension mismatch in the reference simplex.\n+     */\n+    public MultiDirectionalSimplex(final double[][] referenceSimplex,\n+                                   final double khi, final double gamma) {\n+        super(referenceSimplex);\n+\n+        this.khi   = khi;\n+        this.gamma = gamma;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public void iterate(final MultivariateFunction evaluationFunction,\n+                        final Comparator<PointValuePair> comparator) {\n+        // Save the original simplex.\n+        final PointValuePair[] original = getPoints();\n+        final PointValuePair best = original[0];\n+\n+        // Perform a reflection step.\n+        final PointValuePair reflected = evaluateNewSimplex(evaluationFunction,\n+                                                                original, 1, comparator);\n+        if (comparator.compare(reflected, best) < 0) {\n+            // Compute the expanded simplex.\n+            final PointValuePair[] reflectedSimplex = getPoints();\n+            final PointValuePair expanded = evaluateNewSimplex(evaluationFunction,\n+                                                                   original, khi, comparator);\n+            if (comparator.compare(reflected, expanded) <= 0) {\n+                // Keep the reflected simplex.\n+                setPoints(reflectedSimplex);\n+            }\n+            // Keep the expanded simplex.\n+            return;\n+        }\n+\n+        // Compute the contracted simplex.\n+        evaluateNewSimplex(evaluationFunction, original, gamma, comparator);\n+\n+    }\n+\n+    /**\n+     * Compute and evaluate a new simplex.\n+     *\n+     * @param evaluationFunction Evaluation function.\n+     * @param original Original simplex (to be preserved).\n+     * @param coeff Linear coefficient.\n+     * @param comparator Comparator to use to sort simplex vertices from best\n+     * to poorest.\n+     * @return the best point in the transformed simplex.\n+     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+     * if the maximal number of evaluations is exceeded.\n+     */\n+    private PointValuePair evaluateNewSimplex(final MultivariateFunction evaluationFunction,\n+                                                  final PointValuePair[] original,\n+                                                  final double coeff,\n+                                                  final Comparator<PointValuePair> comparator) {\n+        final double[] xSmallest = original[0].getPointRef();\n+        // Perform a linear transformation on all the simplex points,\n+        // except the first one.\n+        setPoint(0, original[0]);\n+        final int dim = getDimension();\n+        for (int i = 1; i < getSize(); i++) {\n+            final double[] xOriginal = original[i].getPointRef();\n+            final double[] xTransformed = new double[dim];\n+            for (int j = 0; j < dim; j++) {\n+                xTransformed[j] = xSmallest[j] + coeff * (xSmallest[j] - xOriginal[j]);\n+            }\n+            setPoint(i, new PointValuePair(xTransformed, Double.NaN, false));\n+        }\n+\n+        // Evaluate the simplex.\n+        evaluate(evaluationFunction, comparator);\n+\n+        return getPoint(0);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/NelderMeadSimplex.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import java.util.Comparator;\n+\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+\n+/**\n+ * This class implements the Nelder-Mead simplex algorithm.\n+ *\n+ * @version $Id: NelderMeadSimplex.java 1364392 2012-07-22 18:27:12Z tn $\n+ * @since 3.0\n+ */\n+public class NelderMeadSimplex extends AbstractSimplex {\n+    /** Default value for {@link #rho}: {@value}. */\n+    private static final double DEFAULT_RHO = 1;\n+    /** Default value for {@link #khi}: {@value}. */\n+    private static final double DEFAULT_KHI = 2;\n+    /** Default value for {@link #gamma}: {@value}. */\n+    private static final double DEFAULT_GAMMA = 0.5;\n+    /** Default value for {@link #sigma}: {@value}. */\n+    private static final double DEFAULT_SIGMA = 0.5;\n+    /** Reflection coefficient. */\n+    private final double rho;\n+    /** Expansion coefficient. */\n+    private final double khi;\n+    /** Contraction coefficient. */\n+    private final double gamma;\n+    /** Shrinkage coefficient. */\n+    private final double sigma;\n+\n+    /**\n+     * Build a Nelder-Mead simplex with default coefficients.\n+     * The default coefficients are 1.0 for rho, 2.0 for khi and 0.5\n+     * for both gamma and sigma.\n+     *\n+     * @param n Dimension of the simplex.\n+     */\n+    public NelderMeadSimplex(final int n) {\n+        this(n, 1d);\n+    }\n+\n+    /**\n+     * Build a Nelder-Mead simplex with default coefficients.\n+     * The default coefficients are 1.0 for rho, 2.0 for khi and 0.5\n+     * for both gamma and sigma.\n+     *\n+     * @param n Dimension of the simplex.\n+     * @param sideLength Length of the sides of the default (hypercube)\n+     * simplex. See {@link AbstractSimplex#AbstractSimplex(int,double)}.\n+     */\n+    public NelderMeadSimplex(final int n, double sideLength) {\n+        this(n, sideLength,\n+             DEFAULT_RHO, DEFAULT_KHI, DEFAULT_GAMMA, DEFAULT_SIGMA);\n+    }\n+\n+    /**\n+     * Build a Nelder-Mead simplex with specified coefficients.\n+     *\n+     * @param n Dimension of the simplex. See\n+     * {@link AbstractSimplex#AbstractSimplex(int,double)}.\n+     * @param sideLength Length of the sides of the default (hypercube)\n+     * simplex. See {@link AbstractSimplex#AbstractSimplex(int,double)}.\n+     * @param rho Reflection coefficient.\n+     * @param khi Expansion coefficient.\n+     * @param gamma Contraction coefficient.\n+     * @param sigma Shrinkage coefficient.\n+     */\n+    public NelderMeadSimplex(final int n, double sideLength,\n+                             final double rho, final double khi,\n+                             final double gamma, final double sigma) {\n+        super(n, sideLength);\n+\n+        this.rho = rho;\n+        this.khi = khi;\n+        this.gamma = gamma;\n+        this.sigma = sigma;\n+    }\n+\n+    /**\n+     * Build a Nelder-Mead simplex with specified coefficients.\n+     *\n+     * @param n Dimension of the simplex. See\n+     * {@link AbstractSimplex#AbstractSimplex(int)}.\n+     * @param rho Reflection coefficient.\n+     * @param khi Expansion coefficient.\n+     * @param gamma Contraction coefficient.\n+     * @param sigma Shrinkage coefficient.\n+     */\n+    public NelderMeadSimplex(final int n,\n+                             final double rho, final double khi,\n+                             final double gamma, final double sigma) {\n+        this(n, 1d, rho, khi, gamma, sigma);\n+    }\n+\n+    /**\n+     * Build a Nelder-Mead simplex with default coefficients.\n+     * The default coefficients are 1.0 for rho, 2.0 for khi and 0.5\n+     * for both gamma and sigma.\n+     *\n+     * @param steps Steps along the canonical axes representing box edges.\n+     * They may be negative but not zero. See\n+     */\n+    public NelderMeadSimplex(final double[] steps) {\n+        this(steps, DEFAULT_RHO, DEFAULT_KHI, DEFAULT_GAMMA, DEFAULT_SIGMA);\n+    }\n+\n+    /**\n+     * Build a Nelder-Mead simplex with specified coefficients.\n+     *\n+     * @param steps Steps along the canonical axes representing box edges.\n+     * They may be negative but not zero. See\n+     * {@link AbstractSimplex#AbstractSimplex(double[])}.\n+     * @param rho Reflection coefficient.\n+     * @param khi Expansion coefficient.\n+     * @param gamma Contraction coefficient.\n+     * @param sigma Shrinkage coefficient.\n+     * @throws IllegalArgumentException if one of the steps is zero.\n+     */\n+    public NelderMeadSimplex(final double[] steps,\n+                             final double rho, final double khi,\n+                             final double gamma, final double sigma) {\n+        super(steps);\n+\n+        this.rho = rho;\n+        this.khi = khi;\n+        this.gamma = gamma;\n+        this.sigma = sigma;\n+    }\n+\n+    /**\n+     * Build a Nelder-Mead simplex with default coefficients.\n+     * The default coefficients are 1.0 for rho, 2.0 for khi and 0.5\n+     * for both gamma and sigma.\n+     *\n+     * @param referenceSimplex Reference simplex. See\n+     * {@link AbstractSimplex#AbstractSimplex(double[][])}.\n+     */\n+    public NelderMeadSimplex(final double[][] referenceSimplex) {\n+        this(referenceSimplex, DEFAULT_RHO, DEFAULT_KHI, DEFAULT_GAMMA, DEFAULT_SIGMA);\n+    }\n+\n+    /**\n+     * Build a Nelder-Mead simplex with specified coefficients.\n+     *\n+     * @param referenceSimplex Reference simplex. See\n+     * {@link AbstractSimplex#AbstractSimplex(double[][])}.\n+     * @param rho Reflection coefficient.\n+     * @param khi Expansion coefficient.\n+     * @param gamma Contraction coefficient.\n+     * @param sigma Shrinkage coefficient.\n+     * @throws org.apache.commons.math3.exception.NotStrictlyPositiveException\n+     * if the reference simplex does not contain at least one point.\n+     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n+     * if there is a dimension mismatch in the reference simplex.\n+     */\n+    public NelderMeadSimplex(final double[][] referenceSimplex,\n+                             final double rho, final double khi,\n+                             final double gamma, final double sigma) {\n+        super(referenceSimplex);\n+\n+        this.rho = rho;\n+        this.khi = khi;\n+        this.gamma = gamma;\n+        this.sigma = sigma;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public void iterate(final MultivariateFunction evaluationFunction,\n+                        final Comparator<PointValuePair> comparator) {\n+        // The simplex has n + 1 points if dimension is n.\n+        final int n = getDimension();\n+\n+        // Interesting values.\n+        final PointValuePair best = getPoint(0);\n+        final PointValuePair secondBest = getPoint(n - 1);\n+        final PointValuePair worst = getPoint(n);\n+        final double[] xWorst = worst.getPointRef();\n+\n+        // Compute the centroid of the best vertices (dismissing the worst\n+        // point at index n).\n+        final double[] centroid = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            final double[] x = getPoint(i).getPointRef();\n+            for (int j = 0; j < n; j++) {\n+                centroid[j] += x[j];\n+            }\n+        }\n+        final double scaling = 1.0 / n;\n+        for (int j = 0; j < n; j++) {\n+            centroid[j] *= scaling;\n+        }\n+\n+        // compute the reflection point\n+        final double[] xR = new double[n];\n+        for (int j = 0; j < n; j++) {\n+            xR[j] = centroid[j] + rho * (centroid[j] - xWorst[j]);\n+        }\n+        final PointValuePair reflected\n+            = new PointValuePair(xR, evaluationFunction.value(xR), false);\n+\n+        if (comparator.compare(best, reflected) <= 0 &&\n+            comparator.compare(reflected, secondBest) < 0) {\n+            // Accept the reflected point.\n+            replaceWorstPoint(reflected, comparator);\n+        } else if (comparator.compare(reflected, best) < 0) {\n+            // Compute the expansion point.\n+            final double[] xE = new double[n];\n+            for (int j = 0; j < n; j++) {\n+                xE[j] = centroid[j] + khi * (xR[j] - centroid[j]);\n+            }\n+            final PointValuePair expanded\n+                = new PointValuePair(xE, evaluationFunction.value(xE), false);\n+\n+            if (comparator.compare(expanded, reflected) < 0) {\n+                // Accept the expansion point.\n+                replaceWorstPoint(expanded, comparator);\n+            } else {\n+                // Accept the reflected point.\n+                replaceWorstPoint(reflected, comparator);\n+            }\n+        } else {\n+            if (comparator.compare(reflected, worst) < 0) {\n+                // Perform an outside contraction.\n+                final double[] xC = new double[n];\n+                for (int j = 0; j < n; j++) {\n+                    xC[j] = centroid[j] + gamma * (xR[j] - centroid[j]);\n+                }\n+                final PointValuePair outContracted\n+                    = new PointValuePair(xC, evaluationFunction.value(xC), false);\n+                if (comparator.compare(outContracted, reflected) <= 0) {\n+                    // Accept the contraction point.\n+                    replaceWorstPoint(outContracted, comparator);\n+                    return;\n+                }\n+            } else {\n+                // Perform an inside contraction.\n+                final double[] xC = new double[n];\n+                for (int j = 0; j < n; j++) {\n+                    xC[j] = centroid[j] - gamma * (centroid[j] - xWorst[j]);\n+                }\n+                final PointValuePair inContracted\n+                    = new PointValuePair(xC, evaluationFunction.value(xC), false);\n+\n+                if (comparator.compare(inContracted, worst) < 0) {\n+                    // Accept the contraction point.\n+                    replaceWorstPoint(inContracted, comparator);\n+                    return;\n+                }\n+            }\n+\n+            // Perform a shrink.\n+            final double[] xSmallest = getPoint(0).getPointRef();\n+            for (int i = 1; i <= n; i++) {\n+                final double[] x = getPoint(i).getPoint();\n+                for (int j = 0; j < n; j++) {\n+                    x[j] = xSmallest[j] + sigma * (x[j] - xSmallest[j]);\n+                }\n+                setPoint(i, new PointValuePair(x, Double.NaN, false));\n+            }\n+            evaluate(evaluationFunction, comparator);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.util.MathArrays;\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\n+import org.apache.commons.math3.optim.univariate.BracketFinder;\n+import org.apache.commons.math3.optim.univariate.BrentOptimizer;\n+import org.apache.commons.math3.optim.univariate.UnivariatePointValuePair;\n+import org.apache.commons.math3.optim.univariate.SimpleUnivariateValueChecker;\n+import org.apache.commons.math3.optim.univariate.SearchInterval;\n+import org.apache.commons.math3.optim.univariate.UnivariateObjectiveFunction;\n+\n+/**\n+ * Powell algorithm.\n+ * This code is translated and adapted from the Python version of this\n+ * algorithm (as implemented in module {@code optimize.py} v0.5 of\n+ * <em>SciPy</em>).\n+ * <br/>\n+ * The default stopping criterion is based on the differences of the\n+ * function value between two successive iterations. It is however possible\n+ * to define a custom convergence checker that might terminate the algorithm\n+ * earlier.\n+ * <br/>\n+ * The internal line search optimizer is a {@link BrentOptimizer} with a\n+ * convergence checker set to {@link SimpleUnivariateValueChecker}.\n+ *\n+ * @version $Id: PowellOptimizer.java 1413594 2012-11-26 13:16:39Z erans $\n+ * @since 2.2\n+ */\n+public class PowellOptimizer\n+    extends MultivariateOptimizer {\n+    /**\n+     * Minimum relative tolerance.\n+     */\n+    private static final double MIN_RELATIVE_TOLERANCE = 2 * FastMath.ulp(1d);\n+    /**\n+     * Relative threshold.\n+     */\n+    private final double relativeThreshold;\n+    /**\n+     * Absolute threshold.\n+     */\n+    private final double absoluteThreshold;\n+    /**\n+     * Line search.\n+     */\n+    private final LineSearch line;\n+\n+    /**\n+     * This constructor allows to specify a user-defined convergence checker,\n+     * in addition to the parameters that control the default convergence\n+     * checking procedure.\n+     * <br/>\n+     * The internal line search tolerances are set to the square-root of their\n+     * corresponding value in the multivariate optimizer.\n+     *\n+     * @param rel Relative threshold.\n+     * @param abs Absolute threshold.\n+     * @param checker Convergence checker.\n+     * @throws NotStrictlyPositiveException if {@code abs <= 0}.\n+     * @throws NumberIsTooSmallException if {@code rel < 2 * Math.ulp(1d)}.\n+     */\n+    public PowellOptimizer(double rel,\n+                           double abs,\n+                           ConvergenceChecker<PointValuePair> checker) {\n+        this(rel, abs, FastMath.sqrt(rel), FastMath.sqrt(abs), checker);\n+    }\n+\n+    /**\n+     * This constructor allows to specify a user-defined convergence checker,\n+     * in addition to the parameters that control the default convergence\n+     * checking procedure and the line search tolerances.\n+     *\n+     * @param rel Relative threshold for this optimizer.\n+     * @param abs Absolute threshold for this optimizer.\n+     * @param lineRel Relative threshold for the internal line search optimizer.\n+     * @param lineAbs Absolute threshold for the internal line search optimizer.\n+     * @param checker Convergence checker.\n+     * @throws NotStrictlyPositiveException if {@code abs <= 0}.\n+     * @throws NumberIsTooSmallException if {@code rel < 2 * Math.ulp(1d)}.\n+     */\n+    public PowellOptimizer(double rel,\n+                           double abs,\n+                           double lineRel,\n+                           double lineAbs,\n+                           ConvergenceChecker<PointValuePair> checker) {\n+        super(checker);\n+\n+        if (rel < MIN_RELATIVE_TOLERANCE) {\n+            throw new NumberIsTooSmallException(rel, MIN_RELATIVE_TOLERANCE, true);\n+        }\n+        if (abs <= 0) {\n+            throw new NotStrictlyPositiveException(abs);\n+        }\n+        relativeThreshold = rel;\n+        absoluteThreshold = abs;\n+\n+        // Create the line search optimizer.\n+        line = new LineSearch(lineRel,\n+                              lineAbs);\n+    }\n+\n+    /**\n+     * The parameters control the default convergence checking procedure.\n+     * <br/>\n+     * The internal line search tolerances are set to the square-root of their\n+     * corresponding value in the multivariate optimizer.\n+     *\n+     * @param rel Relative threshold.\n+     * @param abs Absolute threshold.\n+     * @throws NotStrictlyPositiveException if {@code abs <= 0}.\n+     * @throws NumberIsTooSmallException if {@code rel < 2 * Math.ulp(1d)}.\n+     */\n+    public PowellOptimizer(double rel,\n+                           double abs) {\n+        this(rel, abs, null);\n+    }\n+\n+    /**\n+     * Builds an instance with the default convergence checking procedure.\n+     *\n+     * @param rel Relative threshold.\n+     * @param abs Absolute threshold.\n+     * @param lineRel Relative threshold for the internal line search optimizer.\n+     * @param lineAbs Absolute threshold for the internal line search optimizer.\n+     * @throws NotStrictlyPositiveException if {@code abs <= 0}.\n+     * @throws NumberIsTooSmallException if {@code rel < 2 * Math.ulp(1d)}.\n+     */\n+    public PowellOptimizer(double rel,\n+                           double abs,\n+                           double lineRel,\n+                           double lineAbs) {\n+        this(rel, abs, lineRel, lineAbs, null);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected PointValuePair doOptimize() {\n+        final GoalType goal = getGoalType();\n+        final double[] guess = getStartPoint();\n+        final int n = guess.length;\n+\n+        final double[][] direc = new double[n][n];\n+        for (int i = 0; i < n; i++) {\n+            direc[i][i] = 1;\n+        }\n+\n+        final ConvergenceChecker<PointValuePair> checker\n+            = getConvergenceChecker();\n+\n+        double[] x = guess;\n+        double fVal = computeObjectiveValue(x);\n+        double[] x1 = x.clone();\n+        int iter = 0;\n+        while (true) {\n+            ++iter;\n+\n+            double fX = fVal;\n+            double fX2 = 0;\n+            double delta = 0;\n+            int bigInd = 0;\n+            double alphaMin = 0;\n+\n+            for (int i = 0; i < n; i++) {\n+                final double[] d = MathArrays.copyOf(direc[i]);\n+\n+                fX2 = fVal;\n+\n+                final UnivariatePointValuePair optimum = line.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+\n+                if ((fX2 - fVal) > delta) {\n+                    delta = fX2 - fVal;\n+                    bigInd = i;\n+                }\n+            }\n+\n+            // Default convergence check.\n+            boolean stop = 2 * (fX - fVal) <=\n+                (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) +\n+                 absoluteThreshold);\n+\n+            final PointValuePair previous = new PointValuePair(x1, fX);\n+            final PointValuePair current = new PointValuePair(x, fVal);\n+            if (!stop) { // User-defined stopping criteria.\n+                if (checker != null) {\n+                    stop = checker.converged(iter, previous, current);\n+                }\n+            }\n+            if (stop) {\n+                if (goal == GoalType.MINIMIZE) {\n+                    return (fVal < fX) ? current : previous;\n+                } else {\n+                    return (fVal > fX) ? current : previous;\n+                }\n+            }\n+\n+            final double[] d = new double[n];\n+            final double[] x2 = new double[n];\n+            for (int i = 0; i < n; i++) {\n+                d[i] = x[i] - x1[i];\n+                x2[i] = 2 * x[i] - x1[i];\n+            }\n+\n+            x1 = x.clone();\n+            fX2 = computeObjectiveValue(x2);\n+\n+            if (fX > fX2) {\n+                double t = 2 * (fX + fX2 - 2 * fVal);\n+                double temp = fX - fVal - delta;\n+                t *= temp * temp;\n+                temp = fX - fX2;\n+                t -= delta * temp * temp;\n+\n+                if (t < 0.0) {\n+                    final UnivariatePointValuePair optimum = line.search(x, d);\n+                    fVal = optimum.getValue();\n+                    alphaMin = optimum.getPoint();\n+                    final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                    x = result[0];\n+\n+                    final int lastInd = n - 1;\n+                    direc[bigInd] = direc[lastInd];\n+                    direc[lastInd] = result[1];\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Compute a new point (in the original space) and a new direction\n+     * vector, resulting from the line search.\n+     *\n+     * @param p Point used in the line search.\n+     * @param d Direction used in the line search.\n+     * @param optimum Optimum found by the line search.\n+     * @return a 2-element array containing the new point (at index 0) and\n+     * the new direction (at index 1).\n+     */\n+    private double[][] newPointAndDirection(double[] p,\n+                                            double[] d,\n+                                            double optimum) {\n+        final int n = p.length;\n+        final double[] nP = new double[n];\n+        final double[] nD = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            nD[i] = d[i] * optimum;\n+            nP[i] = p[i] + nD[i];\n+        }\n+\n+        final double[][] result = new double[2][];\n+        result[0] = nP;\n+        result[1] = nD;\n+\n+        return result;\n+    }\n+\n+    /**\n+     * Class for finding the minimum of the objective function along a given\n+     * direction.\n+     */\n+    private class LineSearch extends BrentOptimizer {\n+        /**\n+         * Value that will pass the precondition check for {@link BrentOptimizer}\n+         * but will not pass the convergence check, so that the custom checker\n+         * will always decide when to stop the line search.\n+         */\n+        private static final double REL_TOL_UNUSED = 1e-15;\n+        /**\n+         * Value that will pass the precondition check for {@link BrentOptimizer}\n+         * but will not pass the convergence check, so that the custom checker\n+         * will always decide when to stop the line search.\n+         */\n+        private static final double ABS_TOL_UNUSED = Double.MIN_VALUE;\n+        /**\n+         * Automatic bracketing.\n+         */\n+        private final BracketFinder bracket = new BracketFinder();\n+\n+        /**\n+         * The \"BrentOptimizer\" default stopping criterion uses the tolerances\n+         * to check the domain (point) values, not the function values.\n+         * We thus create a custom checker to use function values.\n+         *\n+         * @param rel Relative threshold.\n+         * @param abs Absolute threshold.\n+         */\n+        LineSearch(double rel,\n+                   double abs) {\n+            super(REL_TOL_UNUSED,\n+                  ABS_TOL_UNUSED,\n+                  new SimpleUnivariateValueChecker(rel, abs));\n+        }\n+\n+        /**\n+         * Find the minimum of the function {@code f(p + alpha * d)}.\n+         *\n+         * @param p Starting point.\n+         * @param d Search direction.\n+         * @return the optimum.\n+         * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n+         * if the number of evaluations is exceeded.\n+         */\n+        public UnivariatePointValuePair search(final double[] p, final double[] d) {\n+            final int n = p.length;\n+            final UnivariateFunction f = new UnivariateFunction() {\n+                    public double value(double alpha) {\n+                        final double[] x = new double[n];\n+                        for (int i = 0; i < n; i++) {\n+                            x[i] = p[i] + alpha * d[i];\n+                        }\n+                        final double obj = PowellOptimizer.this.computeObjectiveValue(x);\n+                        return obj;\n+                    }\n+                };\n+\n+            final GoalType goal = PowellOptimizer.this.getGoalType();\n+            bracket.search(f, goal, 0, 1);\n+            // Passing \"MAX_VALUE\" as a dummy value because it is the enclosing\n+            // class that counts the number of evaluations (and will eventually\n+            // generate the exception).\n+            return optimize(new MaxEval(Integer.MAX_VALUE),\n+                            new UnivariateObjectiveFunction(f),\n+                            goal,\n+                            new SearchInterval(bracket.getLo(),\n+                                               bracket.getHi(),\n+                                               bracket.getMid()));\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import java.util.Comparator;\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.exception.NullArgumentException;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.SimpleValueChecker;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\n+\n+/**\n+ * This class implements simplex-based direct search optimization.\n+ *\n+ * <p>\n+ *  Direct search methods only use objective function values, they do\n+ *  not need derivatives and don't either try to compute approximation\n+ *  of the derivatives. According to a 1996 paper by Margaret H. Wright\n+ *  (<a href=\"http://cm.bell-labs.com/cm/cs/doc/96/4-02.ps.gz\">Direct\n+ *  Search Methods: Once Scorned, Now Respectable</a>), they are used\n+ *  when either the computation of the derivative is impossible (noisy\n+ *  functions, unpredictable discontinuities) or difficult (complexity,\n+ *  computation cost). In the first cases, rather than an optimum, a\n+ *  <em>not too bad</em> point is desired. In the latter cases, an\n+ *  optimum is desired but cannot be reasonably found. In all cases\n+ *  direct search methods can be useful.\n+ * </p>\n+ * <p>\n+ *  Simplex-based direct search methods are based on comparison of\n+ *  the objective function values at the vertices of a simplex (which is a\n+ *  set of n+1 points in dimension n) that is updated by the algorithms\n+ *  steps.\n+ * <p>\n+ * <p>\n+ *  The simplex update procedure ({@link NelderMeadSimplex} or\n+ * {@link MultiDirectionalSimplex})  must be passed to the\n+ * {@code optimize} method.\n+ * </p>\n+ * <p>\n+ *  Each call to {@code optimize} will re-use the start configuration of\n+ *  the current simplex and move it such that its first vertex is at the\n+ *  provided start point of the optimization.\n+ *  If the {@code optimize} method is called to solve a different problem\n+ *  and the number of parameters change, the simplex must be re-initialized\n+ *  to one with the appropriate dimensions.\n+ * </p>\n+ * <p>\n+ *  Convergence is checked by providing the <em>worst</em> points of\n+ *  previous and current simplex to the convergence checker, not the best\n+ *  ones.\n+ * </p>\n+ * <p>\n+ *  This simplex optimizer implementation does not directly support constrained\n+ *  optimization with simple bounds; so, for such optimizations, either a more\n+ *  dedicated algorithm must be used like\n+ *  {@link CMAESOptimizer} or {@link BOBYQAOptimizer}, or the objective\n+ *  function must be wrapped in an adapter like\n+ *  {@link org.apache.commons.math3.optim.nonlinear.scalar.MultivariateFunctionMappingAdapter\n+ *  MultivariateFunctionMappingAdapter} or\n+ *  {@link org.apache.commons.math3.optim.nonlinear.scalar.MultivariateFunctionPenaltyAdapter\n+ *  MultivariateFunctionPenaltyAdapter}.\n+ * </p>\n+ *\n+ * @version $Id: SimplexOptimizer.java 1397759 2012-10-13 01:12:58Z erans $\n+ * @since 3.0\n+ */\n+public class SimplexOptimizer extends MultivariateOptimizer {\n+    /** Simplex update rule. */\n+    private AbstractSimplex simplex;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    public SimplexOptimizer(ConvergenceChecker<PointValuePair> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * @param rel Relative threshold.\n+     * @param abs Absolute threshold.\n+     */\n+    public SimplexOptimizer(double rel, double abs) {\n+        this(new SimpleValueChecker(rel, abs));\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxEval}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.InitialGuess}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.SimpleBounds}</li>\n+     *  <li>{@link AbstractSimplex}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     */\n+    @Override\n+    public PointValuePair optimize(OptimizationData... optData) {\n+        // Retrieve settings\n+        parseOptimizationData(optData);\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected PointValuePair doOptimize() {\n+        if (simplex == null) {\n+            throw new NullArgumentException();\n+        }\n+\n+        // Indirect call to \"computeObjectiveValue\" in order to update the\n+        // evaluations counter.\n+        final MultivariateFunction evalFunc\n+            = new MultivariateFunction() {\n+                public double value(double[] point) {\n+                    return computeObjectiveValue(point);\n+                }\n+            };\n+\n+        final boolean isMinim = getGoalType() == GoalType.MINIMIZE;\n+        final Comparator<PointValuePair> comparator\n+            = new Comparator<PointValuePair>() {\n+            public int compare(final PointValuePair o1,\n+                               final PointValuePair o2) {\n+                final double v1 = o1.getValue();\n+                final double v2 = o2.getValue();\n+                return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);\n+            }\n+        };\n+\n+        // Initialize search.\n+        simplex.build(getStartPoint());\n+        simplex.evaluate(evalFunc, comparator);\n+\n+        PointValuePair[] previous = null;\n+        int iteration = 0;\n+        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+        while (true) {\n+            if (iteration > 0) {\n+                boolean converged = true;\n+                for (int i = 0; i < simplex.getSize(); i++) {\n+                    PointValuePair prev = previous[i];\n+                    converged = converged &&\n+                        checker.converged(iteration, prev, simplex.getPoint(i));\n+                }\n+                if (converged) {\n+                    // We have found an optimum.\n+                    return simplex.getPoint(0);\n+                }\n+            }\n+\n+            // We still need to search.\n+            previous = simplex.getPoints();\n+            simplex.iterate(evalFunc, comparator);\n+            ++iteration;\n+        }\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link AbstractSimplex}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof AbstractSimplex) {\n+                simplex = (AbstractSimplex) data;\n+                // If more data must be parsed, this statement _must_ be\n+                // changed to \"continue\".\n+                break;\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+/**\n+ * This package provides optimization algorithms that do not require derivatives.\n+ */\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+/**\n+ * Algorithms for optimizing a scalar function.\n+ */\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/JacobianMultivariateVectorOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+\n+/**\n+ * Base class for implementing optimizers for multivariate vector\n+ * differentiable functions.\n+ * It contains boiler-plate code for dealing with Jacobian evaluation.\n+ * It assumes that the rows of the Jacobian matrix iterate on the model\n+ * functions while the columns iterate on the parameters; thus, the numbers\n+ * of rows is equal to the dimension of the {@link Target} while the\n+ * number of columns is equal to the dimension of the\n+ * {@link org.apache.commons.math3.optim.InitialGuess InitialGuess}.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class JacobianMultivariateVectorOptimizer\n+    extends MultivariateVectorOptimizer {\n+    /**\n+     * Jacobian of the model function.\n+     */\n+    private MultivariateMatrixFunction jacobian;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected JacobianMultivariateVectorOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * Computes the Jacobian matrix.\n+     *\n+     * @param params Point at which the Jacobian must be evaluated.\n+     * @return the Jacobian at the specified point.\n+     */\n+    protected double[][] computeJacobian(final double[] params) {\n+        return jacobian.value(params);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxEval}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.InitialGuess}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.SimpleBounds}</li>\n+     *  <li>{@link Target}</li>\n+     *  <li>{@link Weight}</li>\n+     *  <li>{@link ModelFunction}</li>\n+     *  <li>{@link ModelFunctionJacobian}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     * @throws DimensionMismatchException if the initial guess, target, and weight\n+     * arguments have inconsistent dimensions.\n+     */\n+    @Override\n+    public PointVectorValuePair optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException,\n+               DimensionMismatchException {\n+        // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link ModelFunctionJacobian}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof ModelFunctionJacobian) {\n+                jacobian = ((ModelFunctionJacobian) data).getModelFunctionJacobian();\n+                // If more data must be parsed, this statement _must_ be\n+                // changed to \"continue\".\n+                break;\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/ModelFunction.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * Model (vector) function to be optimized.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class ModelFunction implements OptimizationData {\n+    /** Function to be optimized. */\n+    private final MultivariateVectorFunction model;\n+\n+    /**\n+     * @param m Model function to be optimized.\n+     */\n+    public ModelFunction(MultivariateVectorFunction m) {\n+        model = m;\n+    }\n+\n+    /**\n+     * Gets the model function to be optimized.\n+     *\n+     * @return the model function.\n+     */\n+    public MultivariateVectorFunction getModelFunction() {\n+        return model;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/ModelFunctionJacobian.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * Jacobian of the model (vector) function to be optimized.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class ModelFunctionJacobian implements OptimizationData {\n+    /** Function to be optimized. */\n+    private final MultivariateMatrixFunction jacobian;\n+\n+    /**\n+     * @param j Jacobian of the model function to be optimized.\n+     */\n+    public ModelFunctionJacobian(MultivariateMatrixFunction j) {\n+        jacobian = j;\n+    }\n+\n+    /**\n+     * Gets the Jacobian of the model function to be optimized.\n+     *\n+     * @return the model function Jacobian.\n+     */\n+    public MultivariateMatrixFunction getModelFunctionJacobian() {\n+        return jacobian;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/MultiStartMultivariateVectorOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.exception.NullArgumentException;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.linear.RealVector;\n+import org.apache.commons.math3.linear.ArrayRealVector;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+import org.apache.commons.math3.optim.BaseMultiStartMultivariateOptimizer;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+\n+/**\n+ * Multi-start optimizer for a (vector) model function.\n+ *\n+ * This class wraps an optimizer in order to use it several times in\n+ * turn with different starting points (trying to avoid being trapped\n+ * in a local extremum when looking for a global one).\n+ *\n+ * @version $Id$\n+ * @since 3.0\n+ */\n+public class MultiStartMultivariateVectorOptimizer\n+    extends BaseMultiStartMultivariateOptimizer<PointVectorValuePair> {\n+    /** Underlying optimizer. */\n+    private final MultivariateVectorOptimizer optimizer;\n+    /** Found optima. */\n+    private final List<PointVectorValuePair> optima = new ArrayList<PointVectorValuePair>();\n+\n+    /**\n+     * Create a multi-start optimizer from a single-start optimizer.\n+     *\n+     * @param optimizer Single-start optimizer to wrap.\n+     * @param starts Number of starts to perform.\n+     * If {@code starts == 1}, the result will be same as if {@code optimizer}\n+     * is called directly.\n+     * @param generator Random vector generator to use for restarts.\n+     * @throws NullArgumentException if {@code optimizer} or {@code generator}\n+     * is {@code null}.\n+     * @throws NotStrictlyPositiveException if {@code starts < 1}.\n+     */\n+    public MultiStartMultivariateVectorOptimizer(final MultivariateVectorOptimizer optimizer,\n+                                                 final int starts,\n+                                                 final RandomVectorGenerator generator)\n+        throws NullArgumentException,\n+        NotStrictlyPositiveException {\n+        super(optimizer, starts, generator);\n+        this.optimizer = optimizer;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public PointVectorValuePair[] getOptima() {\n+        Collections.sort(optima, getPairComparator());\n+        return optima.toArray(new PointVectorValuePair[0]);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    protected void store(PointVectorValuePair optimum) {\n+        optima.add(optimum);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    protected void clear() {\n+        optima.clear();\n+    }\n+\n+    /**\n+     * @return a comparator for sorting the optima.\n+     */\n+    private Comparator<PointVectorValuePair> getPairComparator() {\n+        return new Comparator<PointVectorValuePair>() {\n+            private final RealVector target = new ArrayRealVector(optimizer.getTarget(), false);\n+            private final RealMatrix weight = optimizer.getWeight();\n+\n+            public int compare(final PointVectorValuePair o1,\n+                               final PointVectorValuePair o2) {\n+                if (o1 == null) {\n+                    return (o2 == null) ? 0 : 1;\n+                } else if (o2 == null) {\n+                    return -1;\n+                }\n+                return Double.compare(weightedResidual(o1),\n+                                      weightedResidual(o2));\n+            }\n+\n+            private double weightedResidual(final PointVectorValuePair pv) {\n+                final RealVector v = new ArrayRealVector(pv.getValueRef(), false);\n+                final RealVector r = target.subtract(v);\n+                return r.dotProduct(weight.operate(r));\n+            }\n+        };\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/MultivariateVectorOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.BaseMultivariateOptimizer;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.linear.RealMatrix;\n+\n+/**\n+ * Base class for a multivariate vector function optimizer.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class MultivariateVectorOptimizer\n+    extends BaseMultivariateOptimizer<PointVectorValuePair> {\n+    /** Target values for the model function at optimum. */\n+    private double[] target;\n+    /** Weight matrix. */\n+    private RealMatrix weightMatrix;\n+    /** Model function. */\n+    private MultivariateVectorFunction model;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected MultivariateVectorOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * Computes the objective function value.\n+     * This method <em>must</em> be called by subclasses to enforce the\n+     * evaluation counter limit.\n+     *\n+     * @param params Point at which the objective function must be evaluated.\n+     * @return the objective function value at the specified point.\n+     * @throws TooManyEvaluationsException if the maximal number of evaluations\n+     * (of the model vector function) is exceeded.\n+     */\n+    protected double[] computeObjectiveValue(double[] params) {\n+        super.incrementEvaluationCount();\n+        return model.value(params);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxEval}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.InitialGuess}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.SimpleBounds}</li>\n+     *  <li>{@link Target}</li>\n+     *  <li>{@link Weight}</li>\n+     *  <li>{@link ModelFunction}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     * @throws DimensionMismatchException if the initial guess, target, and weight\n+     * arguments have inconsistent dimensions.\n+     */\n+    public PointVectorValuePair optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException,\n+               DimensionMismatchException {\n+        // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Check input consistency.\n+        checkParameters();\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /**\n+     * Gets the weight matrix of the observations.\n+     *\n+     * @return the weight matrix.\n+     */\n+    public RealMatrix getWeight() {\n+        return weightMatrix.copy();\n+    }\n+    /**\n+     * Gets the observed values to be matched by the objective vector\n+     * function.\n+     *\n+     * @return the target values.\n+     */\n+    public double[] getTarget() {\n+        return target.clone();\n+    }\n+\n+    /**\n+     * Gets the number of observed values.\n+     *\n+     * @return the length of the target vector.\n+     */\n+    public int getTargetSize() {\n+        return target.length;\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link Target}</li>\n+     *  <li>{@link Weight}</li>\n+     *  <li>{@link ModelFunction}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof ModelFunction) {\n+                model = ((ModelFunction) data).getModelFunction();\n+                continue;\n+            }\n+            if (data instanceof Target) {\n+                target = ((Target) data).getTarget();\n+                continue;\n+            }\n+            if (data instanceof Weight) {\n+                weightMatrix = ((Weight) data).getWeight();\n+                continue;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Check parameters consistency.\n+     *\n+     * @throws DimensionMismatchException if {@link #target} and\n+     * {@link #weightMatrix} have inconsistent dimensions.\n+     */\n+    private void checkParameters() {\n+        if (target.length != weightMatrix.getColumnDimension()) {\n+            throw new DimensionMismatchException(target.length,\n+                                                 weightMatrix.getColumnDimension());\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/Target.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * Target of the optimization procedure.\n+ * They are the values which the objective vector function must reproduce\n+ * When the parameters of the model have been optimized.\n+ * <br/>\n+ * Immutable class.\n+ *\n+ * @version $Id: Target.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.1\n+ */\n+public class Target implements OptimizationData {\n+    /** Target values (of the objective vector function). */\n+    private final double[] target;\n+\n+    /**\n+     * @param observations Target values.\n+     */\n+    public Target(double[] observations) {\n+        target = observations.clone();\n+    }\n+\n+    /**\n+     * Gets the initial guess.\n+     *\n+     * @return the initial guess.\n+     */\n+    public double[] getTarget() {\n+        return target.clone();\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/Weight.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.linear.MatrixUtils;\n+import org.apache.commons.math3.linear.NonSquareMatrixException;\n+\n+/**\n+ * Weight matrix of the residuals between model and observations.\n+ * <br/>\n+ * Immutable class.\n+ *\n+ * @version $Id: Weight.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 3.1\n+ */\n+public class Weight implements OptimizationData {\n+    /** Weight matrix. */\n+    private final RealMatrix weightMatrix;\n+\n+    /**\n+     * Creates a diagonal weight matrix.\n+     *\n+     * @param weight List of the values of the diagonal.\n+     */\n+    public Weight(double[] weight) {\n+        final int dim = weight.length;\n+        weightMatrix = MatrixUtils.createRealMatrix(dim, dim);\n+        for (int i = 0; i < dim; i++) {\n+            weightMatrix.setEntry(i, i, weight[i]);\n+        }\n+    }\n+\n+    /**\n+     * @param weight Weight matrix.\n+     * @throws NonSquareMatrixException if the argument is not\n+     * a square matrix.\n+     */\n+    public Weight(RealMatrix weight) {\n+        if (weight.getColumnDimension() != weight.getRowDimension()) {\n+            throw new NonSquareMatrixException(weight.getColumnDimension(),\n+                                               weight.getRowDimension());\n+        }\n+\n+        weightMatrix = weight.copy();\n+    }\n+\n+    /**\n+     * Gets the initial guess.\n+     *\n+     * @return the initial guess.\n+     */\n+    public RealMatrix getWeight() {\n+        return weightMatrix.copy();\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/AbstractLeastSquaresOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.linear.ArrayRealVector;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.linear.DecompositionSolver;\n+import org.apache.commons.math3.linear.MatrixUtils;\n+import org.apache.commons.math3.linear.QRDecomposition;\n+import org.apache.commons.math3.linear.EigenDecomposition;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+import org.apache.commons.math3.optim.nonlinear.vector.JacobianMultivariateVectorOptimizer;\n+import org.apache.commons.math3.util.FastMath;\n+\n+/**\n+ * Base class for implementing least-squares optimizers.\n+ * It provides methods for error estimation.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class AbstractLeastSquaresOptimizer\n+    extends JacobianMultivariateVectorOptimizer {\n+    /** Square-root of the weight matrix. */\n+    private RealMatrix weightMatrixSqrt;\n+    /** Cost value (square root of the sum of the residuals). */\n+    private double cost;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected AbstractLeastSquaresOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * Computes the weighted Jacobian matrix.\n+     *\n+     * @param params Model parameters at which to compute the Jacobian.\n+     * @return the weighted Jacobian: W<sup>1/2</sup> J.\n+     * @throws DimensionMismatchException if the Jacobian dimension does not\n+     * match problem dimension.\n+     */\n+    protected RealMatrix computeWeightedJacobian(double[] params) {\n+        return weightMatrixSqrt.multiply(MatrixUtils.createRealMatrix(computeJacobian(params)));\n+    }\n+\n+    /**\n+     * Computes the cost.\n+     *\n+     * @param residuals Residuals.\n+     * @return the cost.\n+     * @see #computeResiduals(double[])\n+     */\n+    protected double computeCost(double[] residuals) {\n+        final ArrayRealVector r = new ArrayRealVector(residuals);\n+        return FastMath.sqrt(r.dotProduct(getWeight().operate(r)));\n+    }\n+\n+    /**\n+     * Gets the root-mean-square (RMS) value.\n+     *\n+     * The RMS the root of the arithmetic mean of the square of all weighted\n+     * residuals.\n+     * This is related to the criterion that is minimized by the optimizer\n+     * as follows: If <em>c</em> if the criterion, and <em>n</em> is the\n+     * number of measurements, then the RMS is <em>sqrt (c/n)</em>.\n+     *\n+     * @return the RMS value.\n+     */\n+    public double getRMS() {\n+        return FastMath.sqrt(getChiSquare() / getTargetSize());\n+    }\n+\n+    /**\n+     * Get a Chi-Square-like value assuming the N residuals follow N\n+     * distinct normal distributions centered on 0 and whose variances are\n+     * the reciprocal of the weights.\n+     * @return chi-square value\n+     */\n+    public double getChiSquare() {\n+        return cost * cost;\n+    }\n+\n+    /**\n+     * Gets the square-root of the weight matrix.\n+     *\n+     * @return the square-root of the weight matrix.\n+     */\n+    public RealMatrix getWeightSquareRoot() {\n+        return weightMatrixSqrt.copy();\n+    }\n+\n+    /**\n+     * Sets the cost.\n+     *\n+     * @param cost Cost value.\n+     */\n+    protected void setCost(double cost) {\n+        this.cost = cost;\n+    }\n+\n+    /**\n+     * Get the covariance matrix of the optimized parameters.\n+     * <br/>\n+     * Note that this operation involves the inversion of the\n+     * <code>J<sup>T</sup>J</code> matrix, where {@code J} is the\n+     * Jacobian matrix.\n+     * The {@code threshold} parameter is a way for the caller to specify\n+     * that the result of this computation should be considered meaningless,\n+     * and thus trigger an exception.\n+     *\n+     * @param params Model parameters.\n+     * @param threshold Singularity threshold.\n+     * @return the covariance matrix.\n+     * @throws org.apache.commons.math3.linear.SingularMatrixException\n+     * if the covariance matrix cannot be computed (singular problem).\n+     */\n+    public double[][] computeCovariances(double[] params,\n+                                         double threshold) {\n+        // Set up the Jacobian.\n+        final RealMatrix j = computeWeightedJacobian(params);\n+\n+        // Compute transpose(J)J.\n+        final RealMatrix jTj = j.transpose().multiply(j);\n+\n+        // Compute the covariances matrix.\n+        final DecompositionSolver solver\n+            = new QRDecomposition(jTj, threshold).getSolver();\n+        return solver.getInverse().getData();\n+    }\n+\n+    /**\n+     * Computes an estimate of the standard deviation of the parameters. The\n+     * returned values are the square root of the diagonal coefficients of the\n+     * covariance matrix, {@code sd(a[i]) ~= sqrt(C[i][i])}, where {@code a[i]}\n+     * is the optimized value of the {@code i}-th parameter, and {@code C} is\n+     * the covariance matrix.\n+     *\n+     * @param params Model parameters.\n+     * @param covarianceSingularityThreshold Singularity threshold (see\n+     * {@link #computeCovariances(double[],double) computeCovariances}).\n+     * @return an estimate of the standard deviation of the optimized parameters\n+     * @throws org.apache.commons.math3.linear.SingularMatrixException\n+     * if the covariance matrix cannot be computed.\n+     */\n+    public double[] computeSigma(double[] params,\n+                                 double covarianceSingularityThreshold) {\n+        final int nC = params.length;\n+        final double[] sig = new double[nC];\n+        final double[][] cov = computeCovariances(params, covarianceSingularityThreshold);\n+        for (int i = 0; i < nC; ++i) {\n+            sig[i] = FastMath.sqrt(cov[i][i]);\n+        }\n+        return sig;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link org.apache.commons.math3.optim.MaxEval}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.InitialGuess}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.SimpleBounds}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.nonlinear.vector.Target}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.nonlinear.vector.Weight}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.nonlinear.vector.ModelFunction}</li>\n+     *  <li>{@link org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     * @throws DimensionMismatchException if the initial guess, target, and weight\n+     * arguments have inconsistent dimensions.\n+     */\n+    @Override\n+    public PointVectorValuePair optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException {\n+        // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Set up base class and perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /**\n+     * Computes the residuals.\n+     * The residual is the difference between the observed (target)\n+     * values and the model (objective function) value.\n+     * There is one residual for each element of the vector-valued\n+     * function.\n+     *\n+     * @param objectiveValue Value of the the objective function. This is\n+     * the value returned from a call to\n+     * {@link #computeObjectiveValue(double[]) computeObjectiveValue}\n+     * (whose array argument contains the model parameters).\n+     * @return the residuals.\n+     * @throws DimensionMismatchException if {@code params} has a wrong\n+     * length.\n+     */\n+    protected double[] computeResiduals(double[] objectiveValue) {\n+        final double[] target = getTarget();\n+        if (objectiveValue.length != target.length) {\n+            throw new DimensionMismatchException(target.length,\n+                                                 objectiveValue.length);\n+        }\n+\n+        final double[] residuals = new double[target.length];\n+        for (int i = 0; i < target.length; i++) {\n+            residuals[i] = target[i] - objectiveValue[i];\n+        }\n+\n+        return residuals;\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     * If the weight matrix is specified, the {@link #weightMatrixSqrt}\n+     * field is recomputed.\n+     *\n+     * @param optData Optimization data. The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link Weight}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof Weight) {\n+                weightMatrixSqrt = squareRoot(((Weight) data).getWeight());\n+                // If more data must be parsed, this statement _must_ be\n+                // changed to \"continue\".\n+                break;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Computes the square-root of the weight matrix.\n+     *\n+     * @param m Symmetric, positive-definite (weight) matrix.\n+     * @return the square-root of the weight matrix.\n+     */\n+    private RealMatrix squareRoot(RealMatrix m) {\n+        final EigenDecomposition dec = new EigenDecomposition(m);\n+        return dec.getSquareRoot();\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import org.apache.commons.math3.exception.ConvergenceException;\n+import org.apache.commons.math3.exception.NullArgumentException;\n+import org.apache.commons.math3.exception.MathInternalError;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.linear.ArrayRealVector;\n+import org.apache.commons.math3.linear.BlockRealMatrix;\n+import org.apache.commons.math3.linear.DecompositionSolver;\n+import org.apache.commons.math3.linear.LUDecomposition;\n+import org.apache.commons.math3.linear.QRDecomposition;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.linear.SingularMatrixException;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+\n+/**\n+ * Gauss-Newton least-squares solver.\n+ * <p>\n+ * This class solve a least-square problem by solving the normal equations\n+ * of the linearized problem at each iteration. Either LU decomposition or\n+ * QR decomposition can be used to solve the normal equations. LU decomposition\n+ * is faster but QR decomposition is more robust for difficult problems.\n+ * </p>\n+ *\n+ * @version $Id: GaussNewtonOptimizer.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ *\n+ */\n+public class GaussNewtonOptimizer extends AbstractLeastSquaresOptimizer {\n+    /** Indicator for using LU decomposition. */\n+    private final boolean useLU;\n+\n+    /**\n+     * Simple constructor with default settings.\n+     * The normal equations will be solved using LU decomposition.\n+     *\n+     * @param checker Convergence checker.\n+     */\n+    public GaussNewtonOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n+        this(true, checker);\n+    }\n+\n+    /**\n+     * @param useLU If {@code true}, the normal equations will be solved\n+     * using LU decomposition, otherwise they will be solved using QR\n+     * decomposition.\n+     * @param checker Convergence checker.\n+     */\n+    public GaussNewtonOptimizer(final boolean useLU,\n+                                ConvergenceChecker<PointVectorValuePair> checker) {\n+        super(checker);\n+        this.useLU = useLU;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public PointVectorValuePair doOptimize() {\n+        final ConvergenceChecker<PointVectorValuePair> checker\n+            = getConvergenceChecker();\n+\n+        // Computation will be useless without a checker (see \"for-loop\").\n+        if (checker == null) {\n+            throw new NullArgumentException();\n+        }\n+\n+        final double[] targetValues = getTarget();\n+        final int nR = targetValues.length; // Number of observed data.\n+\n+        final RealMatrix weightMatrix = getWeight();\n+        // Diagonal of the weight matrix.\n+        final double[] residualsWeights = new double[nR];\n+        for (int i = 0; i < nR; i++) {\n+            residualsWeights[i] = weightMatrix.getEntry(i, i);\n+        }\n+\n+        final double[] currentPoint = getStartPoint();\n+        final int nC = currentPoint.length;\n+\n+        // iterate until convergence is reached\n+        PointVectorValuePair current = null;\n+        int iter = 0;\n+        for (boolean converged = false; !converged;) {\n+            ++iter;\n+\n+            // evaluate the objective function and its jacobian\n+            PointVectorValuePair previous = current;\n+            // Value of the objective function at \"currentPoint\".\n+            final double[] currentObjective = computeObjectiveValue(currentPoint);\n+            final double[] currentResiduals = computeResiduals(currentObjective);\n+            final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);\n+            current = new PointVectorValuePair(currentPoint, currentObjective);\n+\n+            // build the linear problem\n+            final double[]   b = new double[nC];\n+            final double[][] a = new double[nC][nC];\n+            for (int i = 0; i < nR; ++i) {\n+\n+                final double[] grad   = weightedJacobian.getRow(i);\n+                final double weight   = residualsWeights[i];\n+                final double residual = currentResiduals[i];\n+\n+                // compute the normal equation\n+                final double wr = weight * residual;\n+                for (int j = 0; j < nC; ++j) {\n+                    b[j] += wr * grad[j];\n+                }\n+\n+                // build the contribution matrix for measurement i\n+                for (int k = 0; k < nC; ++k) {\n+                    double[] ak = a[k];\n+                    double wgk = weight * grad[k];\n+                    for (int l = 0; l < nC; ++l) {\n+                        ak[l] += wgk * grad[l];\n+                    }\n+                }\n+            }\n+\n+            try {\n+                // solve the linearized least squares problem\n+                RealMatrix mA = new BlockRealMatrix(a);\n+                DecompositionSolver solver = useLU ?\n+                        new LUDecomposition(mA).getSolver() :\n+                        new QRDecomposition(mA).getSolver();\n+                final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();\n+                // update the estimated parameters\n+                for (int i = 0; i < nC; ++i) {\n+                    currentPoint[i] += dX[i];\n+                }\n+            } catch (SingularMatrixException e) {\n+                throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);\n+            }\n+\n+            // Check convergence.\n+            if (previous != null) {\n+                converged = checker.converged(iter, previous, current);\n+                if (converged) {\n+                    setCost(computeCost(currentResiduals));\n+                    return current;\n+                }\n+            }\n+        }\n+        // Must never happen.\n+        throw new MathInternalError();\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.util.Arrays;\n+import org.apache.commons.math3.exception.ConvergenceException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.util.Precision;\n+import org.apache.commons.math3.util.FastMath;\n+\n+\n+/**\n+ * This class solves a least-squares problem using the Levenberg-Marquardt algorithm.\n+ *\n+ * <p>This implementation <em>should</em> work even for over-determined systems\n+ * (i.e. systems having more point than equations). Over-determined systems\n+ * are solved by ignoring the point which have the smallest impact according\n+ * to their jacobian column norm. Only the rank of the matrix and some loop bounds\n+ * are changed to implement this.</p>\n+ *\n+ * <p>The resolution engine is a simple translation of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/lmder.f\">lmder</a> routine with minor\n+ * changes. The changes include the over-determined resolution, the use of\n+ * inherited convergence checker and the Q.R. decomposition which has been\n+ * rewritten following the algorithm described in the\n+ * P. Lascaux and R. Theodor book <i>Analyse num&eacute;rique matricielle\n+ * appliqu&eacute;e &agrave; l'art de l'ing&eacute;nieur</i>, Masson 1986.</p>\n+ * <p>The authors of the original fortran version are:\n+ * <ul>\n+ * <li>Argonne National Laboratory. MINPACK project. March 1980</li>\n+ * <li>Burton S. Garbow</li>\n+ * <li>Kenneth E. Hillstrom</li>\n+ * <li>Jorge J. More</li>\n+ * </ul>\n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for convenience, it\n+ * is reproduced below.</p>\n+ *\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+ *\n+ * @version $Id: LevenbergMarquardtOptimizer.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class LevenbergMarquardtOptimizer\n+    extends AbstractLeastSquaresOptimizer {\n+    /** Number of solved point. */\n+    private int solvedCols;\n+    /** Diagonal elements of the R matrix in the Q.R. decomposition. */\n+    private double[] diagR;\n+    /** Norms of the columns of the jacobian matrix. */\n+    private double[] jacNorm;\n+    /** Coefficients of the Householder transforms vectors. */\n+    private double[] beta;\n+    /** Columns permutation array. */\n+    private int[] permutation;\n+    /** Rank of the jacobian matrix. */\n+    private int rank;\n+    /** Levenberg-Marquardt parameter. */\n+    private double lmPar;\n+    /** Parameters evolution direction associated with lmPar. */\n+    private double[] lmDir;\n+    /** Positive input variable used in determining the initial step bound. */\n+    private final double initialStepBoundFactor;\n+    /** Desired relative error in the sum of squares. */\n+    private final double costRelativeTolerance;\n+    /**  Desired relative error in the approximate solution parameters. */\n+    private final double parRelativeTolerance;\n+    /** Desired max cosine on the orthogonality between the function vector\n+     * and the columns of the jacobian. */\n+    private final double orthoTolerance;\n+    /** Threshold for QR ranking. */\n+    private final double qrRankingThreshold;\n+    /** Weighted residuals. */\n+    private double[] weightedResidual;\n+    /** Weighted Jacobian. */\n+    private double[][] weightedJacobian;\n+\n+    /**\n+     * Build an optimizer for least squares problems with default values\n+     * for all the tuning parameters (see the {@link\n+     * #LevenbergMarquardtOptimizer(double,double,double,double,double)\n+     * other contructor}.\n+     * The default values for the algorithm settings are:\n+     * <ul>\n+     *  <li>Initial step bound factor: 100</li>\n+     *  <li>Cost relative tolerance: 1e-10</li>\n+     *  <li>Parameters relative tolerance: 1e-10</li>\n+     *  <li>Orthogonality tolerance: 1e-10</li>\n+     *  <li>QR ranking threshold: {@link Precision#SAFE_MIN}</li>\n+     * </ul>\n+     */\n+    public LevenbergMarquardtOptimizer() {\n+        this(100, 1e-10, 1e-10, 1e-10, Precision.SAFE_MIN);\n+    }\n+\n+    /**\n+     * Constructor that allows the specification of a custom convergence\n+     * checker.\n+     * Note that all the usual convergence checks will be <em>disabled</em>.\n+     * The default values for the algorithm settings are:\n+     * <ul>\n+     *  <li>Initial step bound factor: 100</li>\n+     *  <li>Cost relative tolerance: 1e-10</li>\n+     *  <li>Parameters relative tolerance: 1e-10</li>\n+     *  <li>Orthogonality tolerance: 1e-10</li>\n+     *  <li>QR ranking threshold: {@link Precision#SAFE_MIN}</li>\n+     * </ul>\n+     *\n+     * @param checker Convergence checker.\n+     */\n+    public LevenbergMarquardtOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {\n+        this(100, checker, 1e-10, 1e-10, 1e-10, Precision.SAFE_MIN);\n+    }\n+\n+    /**\n+     * Constructor that allows the specification of a custom convergence\n+     * checker, in addition to the standard ones.\n+     *\n+     * @param initialStepBoundFactor Positive input variable used in\n+     * determining the initial step bound. This bound is set to the\n+     * product of initialStepBoundFactor and the euclidean norm of\n+     * {@code diag * x} if non-zero, or else to {@code initialStepBoundFactor}\n+     * itself. In most cases factor should lie in the interval\n+     * {@code (0.1, 100.0)}. {@code 100} is a generally recommended value.\n+     * @param checker Convergence checker.\n+     * @param costRelativeTolerance Desired relative error in the sum of\n+     * squares.\n+     * @param parRelativeTolerance Desired relative error in the approximate\n+     * solution parameters.\n+     * @param orthoTolerance Desired max cosine on the orthogonality between\n+     * the function vector and the columns of the Jacobian.\n+     * @param threshold Desired threshold for QR ranking. If the squared norm\n+     * of a column vector is smaller or equal to this threshold during QR\n+     * decomposition, it is considered to be a zero vector and hence the rank\n+     * of the matrix is reduced.\n+     */\n+    public LevenbergMarquardtOptimizer(double initialStepBoundFactor,\n+                                       ConvergenceChecker<PointVectorValuePair> checker,\n+                                       double costRelativeTolerance,\n+                                       double parRelativeTolerance,\n+                                       double orthoTolerance,\n+                                       double threshold) {\n+        super(checker);\n+        this.initialStepBoundFactor = initialStepBoundFactor;\n+        this.costRelativeTolerance = costRelativeTolerance;\n+        this.parRelativeTolerance = parRelativeTolerance;\n+        this.orthoTolerance = orthoTolerance;\n+        this.qrRankingThreshold = threshold;\n+    }\n+\n+    /**\n+     * Build an optimizer for least squares problems with default values\n+     * for some of the tuning parameters (see the {@link\n+     * #LevenbergMarquardtOptimizer(double,double,double,double,double)\n+     * other contructor}.\n+     * The default values for the algorithm settings are:\n+     * <ul>\n+     *  <li>Initial step bound factor}: 100</li>\n+     *  <li>QR ranking threshold}: {@link Precision#SAFE_MIN}</li>\n+     * </ul>\n+     *\n+     * @param costRelativeTolerance Desired relative error in the sum of\n+     * squares.\n+     * @param parRelativeTolerance Desired relative error in the approximate\n+     * solution parameters.\n+     * @param orthoTolerance Desired max cosine on the orthogonality between\n+     * the function vector and the columns of the Jacobian.\n+     */\n+    public LevenbergMarquardtOptimizer(double costRelativeTolerance,\n+                                       double parRelativeTolerance,\n+                                       double orthoTolerance) {\n+        this(100,\n+             costRelativeTolerance, parRelativeTolerance, orthoTolerance,\n+             Precision.SAFE_MIN);\n+    }\n+\n+    /**\n+     * The arguments control the behaviour of the default convergence checking\n+     * procedure.\n+     * Additional criteria can defined through the setting of a {@link\n+     * ConvergenceChecker}.\n+     *\n+     * @param initialStepBoundFactor Positive input variable used in\n+     * determining the initial step bound. This bound is set to the\n+     * product of initialStepBoundFactor and the euclidean norm of\n+     * {@code diag * x} if non-zero, or else to {@code initialStepBoundFactor}\n+     * itself. In most cases factor should lie in the interval\n+     * {@code (0.1, 100.0)}. {@code 100} is a generally recommended value.\n+     * @param costRelativeTolerance Desired relative error in the sum of\n+     * squares.\n+     * @param parRelativeTolerance Desired relative error in the approximate\n+     * solution parameters.\n+     * @param orthoTolerance Desired max cosine on the orthogonality between\n+     * the function vector and the columns of the Jacobian.\n+     * @param threshold Desired threshold for QR ranking. If the squared norm\n+     * of a column vector is smaller or equal to this threshold during QR\n+     * decomposition, it is considered to be a zero vector and hence the rank\n+     * of the matrix is reduced.\n+     */\n+    public LevenbergMarquardtOptimizer(double initialStepBoundFactor,\n+                                       double costRelativeTolerance,\n+                                       double parRelativeTolerance,\n+                                       double orthoTolerance,\n+                                       double threshold) {\n+        super(null); // No custom convergence criterion.\n+        this.initialStepBoundFactor = initialStepBoundFactor;\n+        this.costRelativeTolerance = costRelativeTolerance;\n+        this.parRelativeTolerance = parRelativeTolerance;\n+        this.orthoTolerance = orthoTolerance;\n+        this.qrRankingThreshold = threshold;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected PointVectorValuePair doOptimize() {\n+        final int nR = getTarget().length; // Number of observed data.\n+        final double[] currentPoint = getStartPoint();\n+        final int nC = currentPoint.length; // Number of parameters.\n+\n+        // arrays shared with the other private methods\n+        solvedCols  = FastMath.min(nR, nC);\n+        diagR       = new double[nC];\n+        jacNorm     = new double[nC];\n+        beta        = new double[nC];\n+        permutation = new int[nC];\n+        lmDir       = new double[nC];\n+\n+        // local point\n+        double   delta   = 0;\n+        double   xNorm   = 0;\n+        double[] diag    = new double[nC];\n+        double[] oldX    = new double[nC];\n+        double[] oldRes  = new double[nR];\n+        double[] oldObj  = new double[nR];\n+        double[] qtf     = new double[nR];\n+        double[] work1   = new double[nC];\n+        double[] work2   = new double[nC];\n+        double[] work3   = new double[nC];\n+\n+        final RealMatrix weightMatrixSqrt = getWeightSquareRoot();\n+\n+        // Evaluate the function at the starting point and calculate its norm.\n+        double[] currentObjective = computeObjectiveValue(currentPoint);\n+        double[] currentResiduals = computeResiduals(currentObjective);\n+        PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);\n+        double currentCost = computeCost(currentResiduals);\n+\n+        // Outer loop.\n+        lmPar = 0;\n+        boolean firstIteration = true;\n+        int iter = 0;\n+        final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n+        while (true) {\n+            ++iter;\n+            final PointVectorValuePair previous = current;\n+\n+            // QR decomposition of the jacobian matrix\n+            qrDecomposition(computeWeightedJacobian(currentPoint));\n+\n+            weightedResidual = weightMatrixSqrt.operate(currentResiduals);\n+            for (int i = 0; i < nR; i++) {\n+                qtf[i] = weightedResidual[i];\n+            }\n+\n+            // compute Qt.res\n+            qTy(qtf);\n+\n+            // now we don't need Q anymore,\n+            // so let jacobian contain the R matrix with its diagonal elements\n+            for (int k = 0; k < solvedCols; ++k) {\n+                int pk = permutation[k];\n+                weightedJacobian[k][pk] = diagR[pk];\n+            }\n+\n+            if (firstIteration) {\n+                // scale the point according to the norms of the columns\n+                // of the initial jacobian\n+                xNorm = 0;\n+                for (int k = 0; k < nC; ++k) {\n+                    double dk = jacNorm[k];\n+                    if (dk == 0) {\n+                        dk = 1.0;\n+                    }\n+                    double xk = dk * currentPoint[k];\n+                    xNorm  += xk * xk;\n+                    diag[k] = dk;\n+                }\n+                xNorm = FastMath.sqrt(xNorm);\n+\n+                // initialize the step bound delta\n+                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n+            }\n+\n+            // check orthogonality between function vector and jacobian columns\n+            double maxCosine = 0;\n+            if (currentCost != 0) {\n+                for (int j = 0; j < solvedCols; ++j) {\n+                    int    pj = permutation[j];\n+                    double s  = jacNorm[pj];\n+                    if (s != 0) {\n+                        double sum = 0;\n+                        for (int i = 0; i <= j; ++i) {\n+                            sum += weightedJacobian[i][pj] * qtf[i];\n+                        }\n+                        maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));\n+                    }\n+                }\n+            }\n+            if (maxCosine <= orthoTolerance) {\n+                // Convergence has been reached.\n+                setCost(currentCost);\n+                return current;\n+            }\n+\n+            // rescale if necessary\n+            for (int j = 0; j < nC; ++j) {\n+                diag[j] = FastMath.max(diag[j], jacNorm[j]);\n+            }\n+\n+            // Inner loop.\n+            for (double ratio = 0; ratio < 1.0e-4;) {\n+\n+                // save the state\n+                for (int j = 0; j < solvedCols; ++j) {\n+                    int pj = permutation[j];\n+                    oldX[pj] = currentPoint[pj];\n+                }\n+                final double previousCost = currentCost;\n+                double[] tmpVec = weightedResidual;\n+                weightedResidual = oldRes;\n+                oldRes    = tmpVec;\n+                tmpVec    = currentObjective;\n+                currentObjective = oldObj;\n+                oldObj    = tmpVec;\n+\n+                // determine the Levenberg-Marquardt parameter\n+                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+\n+                // compute the new point and the norm of the evolution direction\n+                double lmNorm = 0;\n+                for (int j = 0; j < solvedCols; ++j) {\n+                    int pj = permutation[j];\n+                    lmDir[pj] = -lmDir[pj];\n+                    currentPoint[pj] = oldX[pj] + lmDir[pj];\n+                    double s = diag[pj] * lmDir[pj];\n+                    lmNorm  += s * s;\n+                }\n+                lmNorm = FastMath.sqrt(lmNorm);\n+                // on the first iteration, adjust the initial step bound.\n+                if (firstIteration) {\n+                    delta = FastMath.min(delta, lmNorm);\n+                }\n+\n+                // Evaluate the function at x + p and calculate its norm.\n+                currentObjective = computeObjectiveValue(currentPoint);\n+                currentResiduals = computeResiduals(currentObjective);\n+                current = new PointVectorValuePair(currentPoint, currentObjective);\n+                currentCost = computeCost(currentResiduals);\n+\n+                // compute the scaled actual reduction\n+                double actRed = -1.0;\n+                if (0.1 * currentCost < previousCost) {\n+                    double r = currentCost / previousCost;\n+                    actRed = 1.0 - r * r;\n+                }\n+\n+                // compute the scaled predicted reduction\n+                // and the scaled directional derivative\n+                for (int j = 0; j < solvedCols; ++j) {\n+                    int pj = permutation[j];\n+                    double dirJ = lmDir[pj];\n+                    work1[j] = 0;\n+                    for (int i = 0; i <= j; ++i) {\n+                        work1[i] += weightedJacobian[i][pj] * dirJ;\n+                    }\n+                }\n+                double coeff1 = 0;\n+                for (int j = 0; j < solvedCols; ++j) {\n+                    coeff1 += work1[j] * work1[j];\n+                }\n+                double pc2 = previousCost * previousCost;\n+                coeff1 = coeff1 / pc2;\n+                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n+                double preRed = coeff1 + 2 * coeff2;\n+                double dirDer = -(coeff1 + coeff2);\n+\n+                // ratio of the actual to the predicted reduction\n+                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n+\n+                // update the step bound\n+                if (ratio <= 0.25) {\n+                    double tmp =\n+                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n+                        if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {\n+                            tmp = 0.1;\n+                        }\n+                        delta = tmp * FastMath.min(delta, 10.0 * lmNorm);\n+                        lmPar /= tmp;\n+                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n+                    delta = 2 * lmNorm;\n+                    lmPar *= 0.5;\n+                }\n+\n+                // test for successful iteration.\n+                if (ratio >= 1.0e-4) {\n+                    // successful iteration, update the norm\n+                    firstIteration = false;\n+                    xNorm = 0;\n+                    for (int k = 0; k < nC; ++k) {\n+                        double xK = diag[k] * currentPoint[k];\n+                        xNorm += xK * xK;\n+                    }\n+                    xNorm = FastMath.sqrt(xNorm);\n+\n+                    // tests for convergence.\n+                    if (checker != null) {\n+                        // we use the vectorial convergence checker\n+                        if (checker.converged(iter, previous, current)) {\n+                            setCost(currentCost);\n+                            return current;\n+                        }\n+                    }\n+                } else {\n+                    // failed iteration, reset the previous values\n+                    currentCost = previousCost;\n+                    for (int j = 0; j < solvedCols; ++j) {\n+                        int pj = permutation[j];\n+                        currentPoint[pj] = oldX[pj];\n+                    }\n+                    tmpVec    = weightedResidual;\n+                    weightedResidual = oldRes;\n+                    oldRes    = tmpVec;\n+                    tmpVec    = currentObjective;\n+                    currentObjective = oldObj;\n+                    oldObj    = tmpVec;\n+                    // Reset \"current\" to previous values.\n+                    current = new PointVectorValuePair(currentPoint, currentObjective);\n+                }\n+\n+                // Default convergence criteria.\n+                if ((FastMath.abs(actRed) <= costRelativeTolerance &&\n+                     preRed <= costRelativeTolerance &&\n+                     ratio <= 2.0) ||\n+                    delta <= parRelativeTolerance * xNorm) {\n+                    setCost(currentCost);\n+                    return current;\n+                }\n+\n+                // tests for termination and stringent tolerances\n+                // (2.2204e-16 is the machine epsilon for IEEE754)\n+                if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n+                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n+                                                   costRelativeTolerance);\n+                } else if (delta <= 2.2204e-16 * xNorm) {\n+                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n+                                                   parRelativeTolerance);\n+                } else if (maxCosine <= 2.2204e-16)  {\n+                    throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n+                                                   orthoTolerance);\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Determine the Levenberg-Marquardt parameter.\n+     * <p>This implementation is a translation in Java of the MINPACK\n+     * <a href=\"http://www.netlib.org/minpack/lmpar.f\">lmpar</a>\n+     * routine.</p>\n+     * <p>This method sets the lmPar and lmDir attributes.</p>\n+     * <p>The authors of the original fortran function are:</p>\n+     * <ul>\n+     *   <li>Argonne National Laboratory. MINPACK project. March 1980</li>\n+     *   <li>Burton  S. Garbow</li>\n+     *   <li>Kenneth E. Hillstrom</li>\n+     *   <li>Jorge   J. More</li>\n+     * </ul>\n+     * <p>Luc Maisonobe did the Java translation.</p>\n+     *\n+     * @param qy array containing qTy\n+     * @param delta upper bound on the euclidean norm of diagR * lmDir\n+     * @param diag diagonal matrix\n+     * @param work1 work array\n+     * @param work2 work array\n+     * @param work3 work array\n+     */\n+    private void determineLMParameter(double[] qy, double delta, double[] diag,\n+                                      double[] work1, double[] work2, double[] work3) {\n+        final int nC = weightedJacobian[0].length;\n+\n+        // compute and store in x the gauss-newton direction, if the\n+        // jacobian is rank-deficient, obtain a least squares solution\n+        for (int j = 0; j < rank; ++j) {\n+            lmDir[permutation[j]] = qy[j];\n+        }\n+        for (int j = rank; j < nC; ++j) {\n+            lmDir[permutation[j]] = 0;\n+        }\n+        for (int k = rank - 1; k >= 0; --k) {\n+            int pk = permutation[k];\n+            double ypk = lmDir[pk] / diagR[pk];\n+            for (int i = 0; i < k; ++i) {\n+                lmDir[permutation[i]] -= ypk * weightedJacobian[i][pk];\n+            }\n+            lmDir[pk] = ypk;\n+        }\n+\n+        // evaluate the function at the origin, and test\n+        // for acceptance of the Gauss-Newton direction\n+        double dxNorm = 0;\n+        for (int j = 0; j < solvedCols; ++j) {\n+            int pj = permutation[j];\n+            double s = diag[pj] * lmDir[pj];\n+            work1[pj] = s;\n+            dxNorm += s * s;\n+        }\n+        dxNorm = FastMath.sqrt(dxNorm);\n+        double fp = dxNorm - delta;\n+        if (fp <= 0.1 * delta) {\n+            lmPar = 0;\n+            return;\n+        }\n+\n+        // if the jacobian is not rank deficient, the Newton step provides\n+        // a lower bound, parl, for the zero of the function,\n+        // otherwise set this bound to zero\n+        double sum2;\n+        double parl = 0;\n+        if (rank == solvedCols) {\n+            for (int j = 0; j < solvedCols; ++j) {\n+                int pj = permutation[j];\n+                work1[pj] *= diag[pj] / dxNorm;\n+            }\n+            sum2 = 0;\n+            for (int j = 0; j < solvedCols; ++j) {\n+                int pj = permutation[j];\n+                double sum = 0;\n+                for (int i = 0; i < j; ++i) {\n+                    sum += weightedJacobian[i][pj] * work1[permutation[i]];\n+                }\n+                double s = (work1[pj] - sum) / diagR[pj];\n+                work1[pj] = s;\n+                sum2 += s * s;\n+            }\n+            parl = fp / (delta * sum2);\n+        }\n+\n+        // calculate an upper bound, paru, for the zero of the function\n+        sum2 = 0;\n+        for (int j = 0; j < solvedCols; ++j) {\n+            int pj = permutation[j];\n+            double sum = 0;\n+            for (int i = 0; i <= j; ++i) {\n+                sum += weightedJacobian[i][pj] * qy[i];\n+            }\n+            sum /= diag[pj];\n+            sum2 += sum * sum;\n+        }\n+        double gNorm = FastMath.sqrt(sum2);\n+        double paru = gNorm / delta;\n+        if (paru == 0) {\n+            // 2.2251e-308 is the smallest positive real for IEE754\n+            paru = 2.2251e-308 / FastMath.min(delta, 0.1);\n+        }\n+\n+        // if the input par lies outside of the interval (parl,paru),\n+        // set par to the closer endpoint\n+        lmPar = FastMath.min(paru, FastMath.max(lmPar, parl));\n+        if (lmPar == 0) {\n+            lmPar = gNorm / dxNorm;\n+        }\n+\n+        for (int countdown = 10; countdown >= 0; --countdown) {\n+\n+            // evaluate the function at the current value of lmPar\n+            if (lmPar == 0) {\n+                lmPar = FastMath.max(2.2251e-308, 0.001 * paru);\n+            }\n+            double sPar = FastMath.sqrt(lmPar);\n+            for (int j = 0; j < solvedCols; ++j) {\n+                int pj = permutation[j];\n+                work1[pj] = sPar * diag[pj];\n+            }\n+            determineLMDirection(qy, work1, work2, work3);\n+\n+            dxNorm = 0;\n+            for (int j = 0; j < solvedCols; ++j) {\n+                int pj = permutation[j];\n+                double s = diag[pj] * lmDir[pj];\n+                work3[pj] = s;\n+                dxNorm += s * s;\n+            }\n+            dxNorm = FastMath.sqrt(dxNorm);\n+            double previousFP = fp;\n+            fp = dxNorm - delta;\n+\n+            // if the function is small enough, accept the current value\n+            // of lmPar, also test for the exceptional cases where parl is zero\n+            if ((FastMath.abs(fp) <= 0.1 * delta) ||\n+                    ((parl == 0) && (fp <= previousFP) && (previousFP < 0))) {\n+                return;\n+            }\n+\n+            // compute the Newton correction\n+            for (int j = 0; j < solvedCols; ++j) {\n+                int pj = permutation[j];\n+                work1[pj] = work3[pj] * diag[pj] / dxNorm;\n+            }\n+            for (int j = 0; j < solvedCols; ++j) {\n+                int pj = permutation[j];\n+                work1[pj] /= work2[j];\n+                double tmp = work1[pj];\n+                for (int i = j + 1; i < solvedCols; ++i) {\n+                    work1[permutation[i]] -= weightedJacobian[i][pj] * tmp;\n+                }\n+            }\n+            sum2 = 0;\n+            for (int j = 0; j < solvedCols; ++j) {\n+                double s = work1[permutation[j]];\n+                sum2 += s * s;\n+            }\n+            double correction = fp / (delta * sum2);\n+\n+            // depending on the sign of the function, update parl or paru.\n+            if (fp > 0) {\n+                parl = FastMath.max(parl, lmPar);\n+            } else if (fp < 0) {\n+                paru = FastMath.min(paru, lmPar);\n+            }\n+\n+            // compute an improved estimate for lmPar\n+            lmPar = FastMath.max(parl, lmPar + correction);\n+\n+        }\n+    }\n+\n+    /**\n+     * Solve a*x = b and d*x = 0 in the least squares sense.\n+     * <p>This implementation is a translation in Java of the MINPACK\n+     * <a href=\"http://www.netlib.org/minpack/qrsolv.f\">qrsolv</a>\n+     * routine.</p>\n+     * <p>This method sets the lmDir and lmDiag attributes.</p>\n+     * <p>The authors of the original fortran function are:</p>\n+     * <ul>\n+     *   <li>Argonne National Laboratory. MINPACK project. March 1980</li>\n+     *   <li>Burton  S. Garbow</li>\n+     *   <li>Kenneth E. Hillstrom</li>\n+     *   <li>Jorge   J. More</li>\n+     * </ul>\n+     * <p>Luc Maisonobe did the Java translation.</p>\n+     *\n+     * @param qy array containing qTy\n+     * @param diag diagonal matrix\n+     * @param lmDiag diagonal elements associated with lmDir\n+     * @param work work array\n+     */\n+    private void determineLMDirection(double[] qy, double[] diag,\n+                                      double[] lmDiag, double[] work) {\n+\n+        // copy R and Qty to preserve input and initialize s\n+        //  in particular, save the diagonal elements of R in lmDir\n+        for (int j = 0; j < solvedCols; ++j) {\n+            int pj = permutation[j];\n+            for (int i = j + 1; i < solvedCols; ++i) {\n+                weightedJacobian[i][pj] = weightedJacobian[j][permutation[i]];\n+            }\n+            lmDir[j] = diagR[pj];\n+            work[j]  = qy[j];\n+        }\n+\n+        // eliminate the diagonal matrix d using a Givens rotation\n+        for (int j = 0; j < solvedCols; ++j) {\n+\n+            // prepare the row of d to be eliminated, locating the\n+            // diagonal element using p from the Q.R. factorization\n+            int pj = permutation[j];\n+            double dpj = diag[pj];\n+            if (dpj != 0) {\n+                Arrays.fill(lmDiag, j + 1, lmDiag.length, 0);\n+            }\n+            lmDiag[j] = dpj;\n+\n+            //  the transformations to eliminate the row of d\n+            // modify only a single element of Qty\n+            // beyond the first n, which is initially zero.\n+            double qtbpj = 0;\n+            for (int k = j; k < solvedCols; ++k) {\n+                int pk = permutation[k];\n+\n+                // determine a Givens rotation which eliminates the\n+                // appropriate element in the current row of d\n+                if (lmDiag[k] != 0) {\n+\n+                    final double sin;\n+                    final double cos;\n+                    double rkk = weightedJacobian[k][pk];\n+                    if (FastMath.abs(rkk) < FastMath.abs(lmDiag[k])) {\n+                        final double cotan = rkk / lmDiag[k];\n+                        sin   = 1.0 / FastMath.sqrt(1.0 + cotan * cotan);\n+                        cos   = sin * cotan;\n+                    } else {\n+                        final double tan = lmDiag[k] / rkk;\n+                        cos = 1.0 / FastMath.sqrt(1.0 + tan * tan);\n+                        sin = cos * tan;\n+                    }\n+\n+                    // compute the modified diagonal element of R and\n+                    // the modified element of (Qty,0)\n+                    weightedJacobian[k][pk] = cos * rkk + sin * lmDiag[k];\n+                    final double temp = cos * work[k] + sin * qtbpj;\n+                    qtbpj = -sin * work[k] + cos * qtbpj;\n+                    work[k] = temp;\n+\n+                    // accumulate the tranformation in the row of s\n+                    for (int i = k + 1; i < solvedCols; ++i) {\n+                        double rik = weightedJacobian[i][pk];\n+                        final double temp2 = cos * rik + sin * lmDiag[i];\n+                        lmDiag[i] = -sin * rik + cos * lmDiag[i];\n+                        weightedJacobian[i][pk] = temp2;\n+                    }\n+                }\n+            }\n+\n+            // store the diagonal element of s and restore\n+            // the corresponding diagonal element of R\n+            lmDiag[j] = weightedJacobian[j][permutation[j]];\n+            weightedJacobian[j][permutation[j]] = lmDir[j];\n+        }\n+\n+        // solve the triangular system for z, if the system is\n+        // singular, then obtain a least squares solution\n+        int nSing = solvedCols;\n+        for (int j = 0; j < solvedCols; ++j) {\n+            if ((lmDiag[j] == 0) && (nSing == solvedCols)) {\n+                nSing = j;\n+            }\n+            if (nSing < solvedCols) {\n+                work[j] = 0;\n+            }\n+        }\n+        if (nSing > 0) {\n+            for (int j = nSing - 1; j >= 0; --j) {\n+                int pj = permutation[j];\n+                double sum = 0;\n+                for (int i = j + 1; i < nSing; ++i) {\n+                    sum += weightedJacobian[i][pj] * work[i];\n+                }\n+                work[j] = (work[j] - sum) / lmDiag[j];\n+            }\n+        }\n+\n+        // permute the components of z back to components of lmDir\n+        for (int j = 0; j < lmDir.length; ++j) {\n+            lmDir[permutation[j]] = work[j];\n+        }\n+    }\n+\n+    /**\n+     * Decompose a matrix A as A.P = Q.R using Householder transforms.\n+     * <p>As suggested in the P. Lascaux and R. Theodor book\n+     * <i>Analyse num&eacute;rique matricielle appliqu&eacute;e &agrave;\n+     * l'art de l'ing&eacute;nieur</i> (Masson, 1986), instead of representing\n+     * the Householder transforms with u<sub>k</sub> unit vectors such that:\n+     * <pre>\n+     * H<sub>k</sub> = I - 2u<sub>k</sub>.u<sub>k</sub><sup>t</sup>\n+     * </pre>\n+     * we use <sub>k</sub> non-unit vectors such that:\n+     * <pre>\n+     * H<sub>k</sub> = I - beta<sub>k</sub>v<sub>k</sub>.v<sub>k</sub><sup>t</sup>\n+     * </pre>\n+     * where v<sub>k</sub> = a<sub>k</sub> - alpha<sub>k</sub> e<sub>k</sub>.\n+     * The beta<sub>k</sub> coefficients are provided upon exit as recomputing\n+     * them from the v<sub>k</sub> vectors would be costly.</p>\n+     * <p>This decomposition handles rank deficient cases since the tranformations\n+     * are performed in non-increasing columns norms order thanks to columns\n+     * pivoting. The diagonal elements of the R matrix are therefore also in\n+     * non-increasing absolute values order.</p>\n+     *\n+     * @param jacobian Weighted Jacobian matrix at the current point.\n+     * @exception ConvergenceException if the decomposition cannot be performed\n+     */\n+    private void qrDecomposition(RealMatrix jacobian) throws ConvergenceException {\n+        // Code in this class assumes that the weighted Jacobian is -(W^(1/2) J),\n+        // hence the multiplication by -1.\n+        weightedJacobian = jacobian.scalarMultiply(-1).getData();\n+\n+        final int nR = weightedJacobian.length;\n+        final int nC = weightedJacobian[0].length;\n+\n+        // initializations\n+        for (int k = 0; k < nC; ++k) {\n+            permutation[k] = k;\n+            double norm2 = 0;\n+            for (int i = 0; i < nR; ++i) {\n+                double akk = weightedJacobian[i][k];\n+                norm2 += akk * akk;\n+            }\n+            jacNorm[k] = FastMath.sqrt(norm2);\n+        }\n+\n+        // transform the matrix column after column\n+        for (int k = 0; k < nC; ++k) {\n+\n+            // select the column with the greatest norm on active components\n+            int nextColumn = -1;\n+            double ak2 = Double.NEGATIVE_INFINITY;\n+            for (int i = k; i < nC; ++i) {\n+                double norm2 = 0;\n+                for (int j = k; j < nR; ++j) {\n+                    double aki = weightedJacobian[j][permutation[i]];\n+                    norm2 += aki * aki;\n+                }\n+                if (Double.isInfinite(norm2) || Double.isNaN(norm2)) {\n+                    throw new ConvergenceException(LocalizedFormats.UNABLE_TO_PERFORM_QR_DECOMPOSITION_ON_JACOBIAN,\n+                                                   nR, nC);\n+                }\n+                if (norm2 > ak2) {\n+                    nextColumn = i;\n+                    ak2        = norm2;\n+                }\n+            }\n+            if (ak2 <= qrRankingThreshold) {\n+                rank = k;\n+                return;\n+            }\n+            int pk                  = permutation[nextColumn];\n+            permutation[nextColumn] = permutation[k];\n+            permutation[k]          = pk;\n+\n+            // choose alpha such that Hk.u = alpha ek\n+            double akk   = weightedJacobian[k][pk];\n+            double alpha = (akk > 0) ? -FastMath.sqrt(ak2) : FastMath.sqrt(ak2);\n+            double betak = 1.0 / (ak2 - akk * alpha);\n+            beta[pk]     = betak;\n+\n+            // transform the current column\n+            diagR[pk]        = alpha;\n+            weightedJacobian[k][pk] -= alpha;\n+\n+            // transform the remaining columns\n+            for (int dk = nC - 1 - k; dk > 0; --dk) {\n+                double gamma = 0;\n+                for (int j = k; j < nR; ++j) {\n+                    gamma += weightedJacobian[j][pk] * weightedJacobian[j][permutation[k + dk]];\n+                }\n+                gamma *= betak;\n+                for (int j = k; j < nR; ++j) {\n+                    weightedJacobian[j][permutation[k + dk]] -= gamma * weightedJacobian[j][pk];\n+                }\n+            }\n+        }\n+        rank = solvedCols;\n+    }\n+\n+    /**\n+     * Compute the product Qt.y for some Q.R. decomposition.\n+     *\n+     * @param y vector to multiply (will be overwritten with the result)\n+     */\n+    private void qTy(double[] y) {\n+        final int nR = weightedJacobian.length;\n+        final int nC = weightedJacobian[0].length;\n+\n+        for (int k = 0; k < nC; ++k) {\n+            int pk = permutation[k];\n+            double gamma = 0;\n+            for (int i = k; i < nR; ++i) {\n+                gamma += weightedJacobian[i][pk] * y[i];\n+            }\n+            gamma *= beta[pk];\n+            for (int i = k; i < nR; ++i) {\n+                y[i] -= gamma * weightedJacobian[i][pk];\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+/**\n+ * This package provides optimization algorithms that require derivatives.\n+ */\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/nonlinear/vector/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+/**\n+ * Algorithms for optimizing a vector function.\n+ */\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+/**\n+ * <p>\n+ *  Generally, optimizers are algorithms that will either\n+ *  {@link GoalType#MINIMIZE minimize} or {@link GoalType#MAXIMIZE maximize}\n+ *  a scalar function, called the {@link ObjectiveFunction <em>objective\n+ *  function</em>}.\n+ *  <br/>\n+ *  For some scalar objective functions the gradient can be computed (analytically\n+ *  or numerically). Algorithms that use this knowledge are defined in the\n+ *  {@link org.apache.commons.math3.optim.nonlinear.scalar.gradient} package.\n+ *  The algorithms that do not need this additional information are located in\n+ *  the {@link org.apache.commons.math3.optim.nonlinear.scalar.noderiv} package.\n+ * </p>\n+ *\n+ * <p>\n+ *  Some problems are solved more efficiently by algorithms that, instead of an\n+ *  objective function, need access to a\n+ *  {@link org.apache.commons.math3.optim.nonlinear.vector.ModelFunction\n+ *  <em>model function</em>}: such a model predicts a set of values which the\n+ *  algorithm tries to match with a set of given\n+ *  {@link org.apache.commons.math3.optim.nonlinear.vector.Target target values}.\n+ *  Those algorithms are located in the\n+ *  {@link org.apache.commons.math3.optim.nonlinear.vector} package.\n+ *  <br/>\n+ *  Algorithms that also require the\n+ *  {@link org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian\n+ *  Jacobian matrix of the model} are located in the\n+ *  {@link org.apache.commons.math3.optim.nonlinear.vector.jacobian} package.\n+ *  <br/>\n+ *  The {@link org.apache.commons.math3.optim.nonlinear.vector.jacobian.AbstractLeastSquaresOptimizer\n+ *  non-linear least-squares optimizers} are a specialization of the the latter,\n+ *  that minimize the distance (called <em>cost</em> or <em>&chi;<sup>2</sup></em>)\n+ *  between model and observations.\n+ *  <br/>\n+ *  For cases where the Jacobian cannot be provided, a utility class will\n+ *  {@link org.apache.commons.math3.optim.nonlinear.scalar.LeastSquaresConverter\n+ *  convert} a (vector) model into a (scalar) objective function.\n+ * </p>\n+ *\n+ * <p>\n+ *  This package provides common functionality for the optimization algorithms.\n+ *  Abstract classes ({@link BaseOptimizer} and {@link BaseMultivariateOptimizer})\n+ *  define boiler-plate code for storing {@link MaxEval evaluations} and\n+ *  {@link MaxIter iterations} counters and a user-defined\n+ *  {@link ConvergenceChecker convergence checker}.\n+ * </p>\n+ *\n+ * <p>\n+ *  For each of the optimizer types, there is a special implementation that\n+ *  wraps an optimizer instance and provides a \"multi-start\" feature: it calls\n+ *  the underlying optimizer several times with different starting points and\n+ *  returns the best optimum found, or all optima if so desired.\n+ *  This could be useful to avoid being trapped in a local extremum.\n+ * </p>\n+ */\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/BracketFinder.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.util.Incrementor;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.exception.MaxCountExceededException;\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.optim.GoalType;\n+\n+/**\n+ * Provide an interval that brackets a local optimum of a function.\n+ * This code is based on a Python implementation (from <em>SciPy</em>,\n+ * module {@code optimize.py} v0.5).\n+ *\n+ * @version $Id: BracketFinder.java 1413186 2012-11-24 13:47:59Z erans $\n+ * @since 2.2\n+ */\n+public class BracketFinder {\n+    /** Tolerance to avoid division by zero. */\n+    private static final double EPS_MIN = 1e-21;\n+    /**\n+     * Golden section.\n+     */\n+    private static final double GOLD = 1.618034;\n+    /**\n+     * Factor for expanding the interval.\n+     */\n+    private final double growLimit;\n+    /**\n+     * Counter for function evaluations.\n+     */\n+    private final Incrementor evaluations = new Incrementor();\n+    /**\n+     * Lower bound of the bracket.\n+     */\n+    private double lo;\n+    /**\n+     * Higher bound of the bracket.\n+     */\n+    private double hi;\n+    /**\n+     * Point inside the bracket.\n+     */\n+    private double mid;\n+    /**\n+     * Function value at {@link #lo}.\n+     */\n+    private double fLo;\n+    /**\n+     * Function value at {@link #hi}.\n+     */\n+    private double fHi;\n+    /**\n+     * Function value at {@link #mid}.\n+     */\n+    private double fMid;\n+\n+    /**\n+     * Constructor with default values {@code 100, 50} (see the\n+     * {@link #BracketFinder(double,int) other constructor}).\n+     */\n+    public BracketFinder() {\n+        this(100, 50);\n+    }\n+\n+    /**\n+     * Create a bracketing interval finder.\n+     *\n+     * @param growLimit Expanding factor.\n+     * @param maxEvaluations Maximum number of evaluations allowed for finding\n+     * a bracketing interval.\n+     */\n+    public BracketFinder(double growLimit,\n+                         int maxEvaluations) {\n+        if (growLimit <= 0) {\n+            throw new NotStrictlyPositiveException(growLimit);\n+        }\n+        if (maxEvaluations <= 0) {\n+            throw new NotStrictlyPositiveException(maxEvaluations);\n+        }\n+\n+        this.growLimit = growLimit;\n+        evaluations.setMaximalCount(maxEvaluations);\n+    }\n+\n+    /**\n+     * Search new points that bracket a local optimum of the function.\n+     *\n+     * @param func Function whose optimum should be bracketed.\n+     * @param goal {@link GoalType Goal type}.\n+     * @param xA Initial point.\n+     * @param xB Initial point.\n+     * @throws TooManyEvaluationsException if the maximum number of evaluations\n+     * is exceeded.\n+     */\n+    public void search(UnivariateFunction func, GoalType goal, double xA, double xB) {\n+        evaluations.resetCount();\n+        final boolean isMinim = goal == GoalType.MINIMIZE;\n+\n+        double fA = eval(func, xA);\n+        double fB = eval(func, xB);\n+        if (isMinim ?\n+            fA < fB :\n+            fA > fB) {\n+\n+            double tmp = xA;\n+            xA = xB;\n+            xB = tmp;\n+\n+            tmp = fA;\n+            fA = fB;\n+            fB = tmp;\n+        }\n+\n+        double xC = xB + GOLD * (xB - xA);\n+        double fC = eval(func, xC);\n+\n+        while (isMinim ? fC < fB : fC > fB) {\n+            double tmp1 = (xB - xA) * (fB - fC);\n+            double tmp2 = (xB - xC) * (fB - fA);\n+\n+            double val = tmp2 - tmp1;\n+            double denom = Math.abs(val) < EPS_MIN ? 2 * EPS_MIN : 2 * val;\n+\n+            double w = xB - ((xB - xC) * tmp2 - (xB - xA) * tmp1) / denom;\n+            double wLim = xB + growLimit * (xC - xB);\n+\n+            double fW;\n+            if ((w - xC) * (xB - w) > 0) {\n+                fW = eval(func, w);\n+                if (isMinim ?\n+                    fW < fC :\n+                    fW > fC) {\n+                    xA = xB;\n+                    xB = w;\n+                    fA = fB;\n+                    fB = fW;\n+                    break;\n+                } else if (isMinim ?\n+                           fW > fB :\n+                           fW < fB) {\n+                    xC = w;\n+                    fC = fW;\n+                    break;\n+                }\n+                w = xC + GOLD * (xC - xB);\n+                fW = eval(func, w);\n+            } else if ((w - wLim) * (wLim - xC) >= 0) {\n+                w = wLim;\n+                fW = eval(func, w);\n+            } else if ((w - wLim) * (xC - w) > 0) {\n+                fW = eval(func, w);\n+                if (isMinim ?\n+                    fW < fC :\n+                    fW > fC) {\n+                    xB = xC;\n+                    xC = w;\n+                    w = xC + GOLD * (xC - xB);\n+                    fB = fC;\n+                    fC =fW;\n+                    fW = eval(func, w);\n+                }\n+            } else {\n+                w = xC + GOLD * (xC - xB);\n+                fW = eval(func, w);\n+            }\n+\n+            xA = xB;\n+            fA = fB;\n+            xB = xC;\n+            fB = fC;\n+            xC = w;\n+            fC = fW;\n+        }\n+\n+        lo = xA;\n+        fLo = fA;\n+        mid = xB;\n+        fMid = fB;\n+        hi = xC;\n+        fHi = fC;\n+\n+        if (lo > hi) {\n+            double tmp = lo;\n+            lo = hi;\n+            hi = tmp;\n+\n+            tmp = fLo;\n+            fLo = fHi;\n+            fHi = tmp;\n+        }\n+    }\n+\n+    /**\n+     * @return the number of evalutations.\n+     */\n+    public int getMaxEvaluations() {\n+        return evaluations.getMaximalCount();\n+    }\n+\n+    /**\n+     * @return the number of evalutations.\n+     */\n+    public int getEvaluations() {\n+        return evaluations.getCount();\n+    }\n+\n+    /**\n+     * @return the lower bound of the bracket.\n+     * @see #getFLo()\n+     */\n+    public double getLo() {\n+        return lo;\n+    }\n+\n+    /**\n+     * Get function value at {@link #getLo()}.\n+     * @return function value at {@link #getLo()}\n+     */\n+    public double getFLo() {\n+        return fLo;\n+    }\n+\n+    /**\n+     * @return the higher bound of the bracket.\n+     * @see #getFHi()\n+     */\n+    public double getHi() {\n+        return hi;\n+    }\n+\n+    /**\n+     * Get function value at {@link #getHi()}.\n+     * @return function value at {@link #getHi()}\n+     */\n+    public double getFHi() {\n+        return fHi;\n+    }\n+\n+    /**\n+     * @return a point in the middle of the bracket.\n+     * @see #getFMid()\n+     */\n+    public double getMid() {\n+        return mid;\n+    }\n+\n+    /**\n+     * Get function value at {@link #getMid()}.\n+     * @return function value at {@link #getMid()}\n+     */\n+    public double getFMid() {\n+        return fMid;\n+    }\n+\n+    /**\n+     * @param f Function.\n+     * @param x Argument.\n+     * @return {@code f(x)}\n+     * @throws TooManyEvaluationsException if the maximal number of evaluations is\n+     * exceeded.\n+     */\n+    private double eval(UnivariateFunction f, double x) {\n+        try {\n+            evaluations.incrementCount();\n+        } catch (MaxCountExceededException e) {\n+            throw new TooManyEvaluationsException(e.getMax());\n+        }\n+        return f.value(x);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/BrentOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.util.Precision;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.GoalType;\n+\n+/**\n+ * For a function defined on some interval {@code (lo, hi)}, this class\n+ * finds an approximation {@code x} to the point at which the function\n+ * attains its minimum.\n+ * It implements Richard Brent's algorithm (from his book \"Algorithms for\n+ * Minimization without Derivatives\", p. 79) for finding minima of real\n+ * univariate functions.\n+ * <br/>\n+ * This code is an adaptation, partly based on the Python code from SciPy\n+ * (module \"optimize.py\" v0.5); the original algorithm is also modified\n+ * <ul>\n+ *  <li>to use an initial guess provided by the user,</li>\n+ *  <li>to ensure that the best point encountered is the one returned.</li>\n+ * </ul>\n+ *\n+ * @version $Id: BrentOptimizer.java 1416643 2012-12-03 19:37:14Z tn $\n+ * @since 2.0\n+ */\n+public class BrentOptimizer extends UnivariateOptimizer {\n+    /**\n+     * Golden section.\n+     */\n+    private static final double GOLDEN_SECTION = 0.5 * (3 - FastMath.sqrt(5));\n+    /**\n+     * Minimum relative tolerance.\n+     */\n+    private static final double MIN_RELATIVE_TOLERANCE = 2 * FastMath.ulp(1d);\n+    /**\n+     * Relative threshold.\n+     */\n+    private final double relativeThreshold;\n+    /**\n+     * Absolute threshold.\n+     */\n+    private final double absoluteThreshold;\n+\n+    /**\n+     * The arguments are used implement the original stopping criterion\n+     * of Brent's algorithm.\n+     * {@code abs} and {@code rel} define a tolerance\n+     * {@code tol = rel |x| + abs}. {@code rel} should be no smaller than\n+     * <em>2 macheps</em> and preferably not much less than <em>sqrt(macheps)</em>,\n+     * where <em>macheps</em> is the relative machine precision. {@code abs} must\n+     * be positive.\n+     *\n+     * @param rel Relative threshold.\n+     * @param abs Absolute threshold.\n+     * @param checker Additional, user-defined, convergence checking\n+     * procedure.\n+     * @throws NotStrictlyPositiveException if {@code abs <= 0}.\n+     * @throws NumberIsTooSmallException if {@code rel < 2 * Math.ulp(1d)}.\n+     */\n+    public BrentOptimizer(double rel,\n+                          double abs,\n+                          ConvergenceChecker<UnivariatePointValuePair> checker) {\n+        super(checker);\n+\n+        if (rel < MIN_RELATIVE_TOLERANCE) {\n+            throw new NumberIsTooSmallException(rel, MIN_RELATIVE_TOLERANCE, true);\n+        }\n+        if (abs <= 0) {\n+            throw new NotStrictlyPositiveException(abs);\n+        }\n+\n+        relativeThreshold = rel;\n+        absoluteThreshold = abs;\n+    }\n+\n+    /**\n+     * The arguments are used for implementing the original stopping criterion\n+     * of Brent's algorithm.\n+     * {@code abs} and {@code rel} define a tolerance\n+     * {@code tol = rel |x| + abs}. {@code rel} should be no smaller than\n+     * <em>2 macheps</em> and preferably not much less than <em>sqrt(macheps)</em>,\n+     * where <em>macheps</em> is the relative machine precision. {@code abs} must\n+     * be positive.\n+     *\n+     * @param rel Relative threshold.\n+     * @param abs Absolute threshold.\n+     * @throws NotStrictlyPositiveException if {@code abs <= 0}.\n+     * @throws NumberIsTooSmallException if {@code rel < 2 * Math.ulp(1d)}.\n+     */\n+    public BrentOptimizer(double rel,\n+                          double abs) {\n+        this(rel, abs, null);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected UnivariatePointValuePair doOptimize() {\n+        final boolean isMinim = getGoalType() == GoalType.MINIMIZE;\n+        final double lo = getMin();\n+        final double mid = getStartValue();\n+        final double hi = getMax();\n+\n+        // Optional additional convergence criteria.\n+        final ConvergenceChecker<UnivariatePointValuePair> checker\n+            = getConvergenceChecker();\n+\n+        double a;\n+        double b;\n+        if (lo < hi) {\n+            a = lo;\n+            b = hi;\n+        } else {\n+            a = hi;\n+            b = lo;\n+        }\n+\n+        double x = mid;\n+        double v = x;\n+        double w = x;\n+        double d = 0;\n+        double e = 0;\n+        double fx = computeObjectiveValue(x);\n+        if (!isMinim) {\n+            fx = -fx;\n+        }\n+        double fv = fx;\n+        double fw = fx;\n+\n+        UnivariatePointValuePair previous = null;\n+        UnivariatePointValuePair current\n+            = new UnivariatePointValuePair(x, isMinim ? fx : -fx);\n+        // Best point encountered so far (which is the initial guess).\n+        UnivariatePointValuePair best = current;\n+\n+        int iter = 0;\n+        while (true) {\n+            final double m = 0.5 * (a + b);\n+            final double tol1 = relativeThreshold * FastMath.abs(x) + absoluteThreshold;\n+            final double tol2 = 2 * tol1;\n+\n+            // Default stopping criterion.\n+            final boolean stop = FastMath.abs(x - m) <= tol2 - 0.5 * (b - a);\n+            if (!stop) {\n+                double p = 0;\n+                double q = 0;\n+                double r = 0;\n+                double u = 0;\n+\n+                if (FastMath.abs(e) > tol1) { // Fit parabola.\n+                    r = (x - w) * (fx - fv);\n+                    q = (x - v) * (fx - fw);\n+                    p = (x - v) * q - (x - w) * r;\n+                    q = 2 * (q - r);\n+\n+                    if (q > 0) {\n+                        p = -p;\n+                    } else {\n+                        q = -q;\n+                    }\n+\n+                    r = e;\n+                    e = d;\n+\n+                    if (p > q * (a - x) &&\n+                        p < q * (b - x) &&\n+                        FastMath.abs(p) < FastMath.abs(0.5 * q * r)) {\n+                        // Parabolic interpolation step.\n+                        d = p / q;\n+                        u = x + d;\n+\n+                        // f must not be evaluated too close to a or b.\n+                        if (u - a < tol2 || b - u < tol2) {\n+                            if (x <= m) {\n+                                d = tol1;\n+                            } else {\n+                                d = -tol1;\n+                            }\n+                        }\n+                    } else {\n+                        // Golden section step.\n+                        if (x < m) {\n+                            e = b - x;\n+                        } else {\n+                            e = a - x;\n+                        }\n+                        d = GOLDEN_SECTION * e;\n+                    }\n+                } else {\n+                    // Golden section step.\n+                    if (x < m) {\n+                        e = b - x;\n+                    } else {\n+                        e = a - x;\n+                    }\n+                    d = GOLDEN_SECTION * e;\n+                }\n+\n+                // Update by at least \"tol1\".\n+                if (FastMath.abs(d) < tol1) {\n+                    if (d >= 0) {\n+                        u = x + tol1;\n+                    } else {\n+                        u = x - tol1;\n+                    }\n+                } else {\n+                    u = x + d;\n+                }\n+\n+                double fu = computeObjectiveValue(u);\n+                if (!isMinim) {\n+                    fu = -fu;\n+                }\n+\n+                // User-defined convergence checker.\n+                previous = current;\n+                current = new UnivariatePointValuePair(u, isMinim ? fu : -fu);\n+                best = best(best,\n+                            best(previous,\n+                                 current,\n+                                 isMinim),\n+                            isMinim);\n+\n+                if (checker != null) {\n+                    if (checker.converged(iter, previous, current)) {\n+                        return best;\n+                    }\n+                }\n+\n+                // Update a, b, v, w and x.\n+                if (fu <= fx) {\n+                    if (u < x) {\n+                        b = x;\n+                    } else {\n+                        a = x;\n+                    }\n+                    v = w;\n+                    fv = fw;\n+                    w = x;\n+                    fw = fx;\n+                    x = u;\n+                    fx = fu;\n+                } else {\n+                    if (u < x) {\n+                        a = u;\n+                    } else {\n+                        b = u;\n+                    }\n+                    if (fu <= fw ||\n+                        Precision.equals(w, x)) {\n+                        v = w;\n+                        fv = fw;\n+                        w = u;\n+                        fw = fu;\n+                    } else if (fu <= fv ||\n+                               Precision.equals(v, x) ||\n+                               Precision.equals(v, w)) {\n+                        v = u;\n+                        fv = fu;\n+                    }\n+                }\n+            } else { // Default termination (Brent's criterion).\n+                return best(best,\n+                            best(previous,\n+                                 current,\n+                                 isMinim),\n+                            isMinim);\n+            }\n+            ++iter;\n+        }\n+    }\n+\n+    /**\n+     * Selects the best of two points.\n+     *\n+     * @param a Point and value.\n+     * @param b Point and value.\n+     * @param isMinim {@code true} if the selected point must be the one with\n+     * the lowest value.\n+     * @return the best point, or {@code null} if {@code a} and {@code b} are\n+     * both {@code null}. When {@code a} and {@code b} have the same function\n+     * value, {@code a} is returned.\n+     */\n+    private UnivariatePointValuePair best(UnivariatePointValuePair a,\n+                                          UnivariatePointValuePair b,\n+                                          boolean isMinim) {\n+        if (a == null) {\n+            return b;\n+        }\n+        if (b == null) {\n+            return a;\n+        }\n+\n+        if (isMinim) {\n+            return a.getValue() <= b.getValue() ? a : b;\n+        } else {\n+            return a.getValue() >= b.getValue() ? a : b;\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/MultiStartUnivariateOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.univariate;\n+\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.exception.NullArgumentException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.random.RandomGenerator;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * Special implementation of the {@link UnivariateOptimizer} interface\n+ * adding multi-start features to an existing optimizer.\n+ * <br/>\n+ * This class wraps an optimizer in order to use it several times in\n+ * turn with different starting points (trying to avoid being trapped\n+ * in a local extremum when looking for a global one).\n+ *\n+ * @version $Id$\n+ * @since 3.0\n+ */\n+public class MultiStartUnivariateOptimizer\n+    extends UnivariateOptimizer {\n+    /** Underlying classical optimizer. */\n+    private final UnivariateOptimizer optimizer;\n+    /** Number of evaluations already performed for all starts. */\n+    private int totalEvaluations;\n+    /** Number of starts to go. */\n+    private int starts;\n+    /** Random generator for multi-start. */\n+    private RandomGenerator generator;\n+    /** Found optima. */\n+    private UnivariatePointValuePair[] optima;\n+    /** Optimization data. */\n+    private OptimizationData[] optimData;\n+    /**\n+     * Location in {@link #optimData} where the updated maximum\n+     * number of evaluations will be stored.\n+     */\n+    private int maxEvalIndex = -1;\n+    /**\n+     * Location in {@link #optimData} where the updated start value\n+     * will be stored.\n+     */\n+    private int searchIntervalIndex = -1;\n+\n+    /**\n+     * Create a multi-start optimizer from a single-start optimizer.\n+     *\n+     * @param optimizer Single-start optimizer to wrap.\n+     * @param starts Number of starts to perform. If {@code starts == 1},\n+     * the {@code optimize} methods will return the same solution as\n+     * {@code optimizer} would.\n+     * @param generator Random generator to use for restarts.\n+     * @throws NullArgumentException if {@code optimizer} or {@code generator}\n+     * is {@code null}.\n+     * @throws NotStrictlyPositiveException if {@code starts < 1}.\n+     */\n+    public MultiStartUnivariateOptimizer(final UnivariateOptimizer optimizer,\n+                                         final int starts,\n+                                         final RandomGenerator generator) {\n+        super(optimizer.getConvergenceChecker());\n+\n+        if (optimizer == null ||\n+            generator == null) {\n+            throw new NullArgumentException();\n+        }\n+        if (starts < 1) {\n+            throw new NotStrictlyPositiveException(starts);\n+        }\n+\n+        this.optimizer = optimizer;\n+        this.starts = starts;\n+        this.generator = generator;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    public int getEvaluations() {\n+        return totalEvaluations;\n+    }\n+\n+    /**\n+     * Gets all the optima found during the last call to {@code optimize}.\n+     * The optimizer stores all the optima found during a set of\n+     * restarts. The {@code optimize} method returns the best point only.\n+     * This method returns all the points found at the end of each starts,\n+     * including the best one already returned by the {@code optimize} method.\n+     * <br/>\n+     * The returned array as one element for each start as specified\n+     * in the constructor. It is ordered with the results from the\n+     * runs that did converge first, sorted from best to worst\n+     * objective value (i.e in ascending order if minimizing and in\n+     * descending order if maximizing), followed by {@code null} elements\n+     * corresponding to the runs that did not converge. This means all\n+     * elements will be {@code null} if the {@code optimize} method did throw\n+     * an exception.\n+     * This also means that if the first element is not {@code null}, it is\n+     * the best point found across all starts.\n+     *\n+     * @return an array containing the optima.\n+     * @throws MathIllegalStateException if {@link #optimize(OptimizationData[])\n+     * optimize} has not been called.\n+     */\n+    public UnivariatePointValuePair[] getOptima() {\n+        if (optima == null) {\n+            throw new MathIllegalStateException(LocalizedFormats.NO_OPTIMUM_COMPUTED_YET);\n+        }\n+        return optima.clone();\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @throws MathIllegalStateException if {@code optData} does not contain an\n+     * instance of {@link MaxEval} or {@link SearchInterval}.\n+     */\n+    @Override\n+    public UnivariatePointValuePair optimize(OptimizationData... optData) {\n+        // Store arguments in order to pass them to the internal optimizer.\n+       optimData = optData;\n+        // Set up base class and perform computations.\n+        return super.optimize(optData);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override\n+    protected UnivariatePointValuePair doOptimize() {\n+        // Remove all instances of \"MaxEval\" and \"SearchInterval\" from the\n+        // array that will be passed to the internal optimizer.\n+        // The former is to enforce smaller numbers of allowed evaluations\n+        // (according to how many have been used up already), and the latter\n+        // to impose a different start value for each start.\n+        for (int i = 0; i < optimData.length; i++) {\n+            if (optimData[i] instanceof MaxEval) {\n+                optimData[i] = null;\n+                maxEvalIndex = i;\n+                continue;\n+            }\n+            if (optimData[i] instanceof SearchInterval) {\n+                optimData[i] = null;\n+                searchIntervalIndex = i;\n+                continue;\n+            }\n+        }\n+        if (maxEvalIndex == -1) {\n+            throw new MathIllegalStateException();\n+        }\n+        if (searchIntervalIndex == -1) {\n+            throw new MathIllegalStateException();\n+        }\n+\n+        RuntimeException lastException = null;\n+        optima = new UnivariatePointValuePair[starts];\n+        totalEvaluations = 0;\n+\n+        final int maxEval = getMaxEvaluations();\n+        final double min = getMin();\n+        final double max = getMax();\n+        final double startValue = getStartValue();\n+\n+        // Multi-start loop.\n+        for (int i = 0; i < starts; i++) {\n+            // CHECKSTYLE: stop IllegalCatch\n+            try {\n+                // Decrease number of allowed evaluations.\n+                optimData[maxEvalIndex] = new MaxEval(maxEval - totalEvaluations);\n+                // New start value.\n+                final double s = (i == 0) ?\n+                    startValue :\n+                    min + generator.nextDouble() * (max - min);\n+                optimData[searchIntervalIndex] = new SearchInterval(min, max, s);\n+                // Optimize.\n+                optima[i] = optimizer.optimize(optimData);\n+            } catch (RuntimeException mue) {\n+                lastException = mue;\n+                optima[i] = null;\n+            }\n+            // CHECKSTYLE: resume IllegalCatch\n+\n+            totalEvaluations += optimizer.getEvaluations();\n+        }\n+\n+        sortPairs(getGoalType());\n+\n+        if (optima[0] == null) {\n+            throw lastException; // Cannot be null if starts >= 1.\n+        }\n+\n+        // Return the point with the best objective function value.\n+        return optima[0];\n+    }\n+\n+    /**\n+     * Sort the optima from best to worst, followed by {@code null} elements.\n+     *\n+     * @param goal Goal type.\n+     */\n+    private void sortPairs(final GoalType goal) {\n+        Arrays.sort(optima, new Comparator<UnivariatePointValuePair>() {\n+                public int compare(final UnivariatePointValuePair o1,\n+                                   final UnivariatePointValuePair o2) {\n+                    if (o1 == null) {\n+                        return (o2 == null) ? 0 : 1;\n+                    } else if (o2 == null) {\n+                        return -1;\n+                    }\n+                    final double v1 = o1.getValue();\n+                    final double v2 = o2.getValue();\n+                    return (goal == GoalType.MINIMIZE) ?\n+                        Double.compare(v1, v2) : Double.compare(v2, v1);\n+                }\n+            });\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/SearchInterval.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.exception.NumberIsTooLargeException;\n+import org.apache.commons.math3.exception.OutOfRangeException;\n+\n+/**\n+ * Search interval and (optional) start value.\n+ * <br/>\n+ * Immutable class.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class SearchInterval implements OptimizationData {\n+    /** Lower bound. */\n+    private final double lower;\n+    /** Upper bound. */\n+    private final double upper;\n+    /** Start value. */\n+    private final double start;\n+\n+    /**\n+     * @param lo Lower bound.\n+     * @param hi Upper bound.\n+     * @param init Start value.\n+     * @throws NumberIsTooLargeException if {@code lo >= hi}.\n+     * @throws OutOfRangeException if {@code init < lo} or {@code init > hi}.\n+     */\n+    public SearchInterval(double lo,\n+                          double hi,\n+                          double init) {\n+        if (lo >= hi) {\n+            throw new NumberIsTooLargeException(lo, hi, false);\n+        }\n+        if (init < lo ||\n+            init > hi) {\n+            throw new OutOfRangeException(init, lo, hi);\n+        }\n+\n+        lower = lo;\n+        upper = hi;\n+        start = init;\n+    }\n+\n+    /**\n+     * @param lo Lower bound.\n+     * @param hi Upper bound.\n+     * @throws NumberIsTooLargeException if {@code lo >= hi}.\n+     */\n+    public SearchInterval(double lo,\n+                          double hi) {\n+        this(lo, hi, 0.5 * (lo + hi));\n+    }\n+\n+    /**\n+     * Gets the lower bound.\n+     *\n+     * @return the lower bound.\n+     */\n+    public double getMin() {\n+        return lower;\n+    }\n+    /**\n+     * Gets the upper bound.\n+     *\n+     * @return the upper bound.\n+     */\n+    public double getMax() {\n+        return upper;\n+    }\n+    /**\n+     * Gets the start value.\n+     *\n+     * @return the start value.\n+     */\n+    public double getStartValue() {\n+        return start;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/SimpleUnivariateValueChecker.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.apache.commons.math3.optim.AbstractConvergenceChecker;\n+\n+/**\n+ * Simple implementation of the\n+ * {@link org.apache.commons.math3.optimization.ConvergenceChecker} interface\n+ * that uses only objective function values.\n+ *\n+ * Convergence is considered to have been reached if either the relative\n+ * difference between the objective function values is smaller than a\n+ * threshold or if either the absolute difference between the objective\n+ * function values is smaller than another threshold.\n+ * <br/>\n+ * The {@link #converged(int,UnivariatePointValuePair,UnivariatePointValuePair)\n+ * converged} method will also return {@code true} if the number of iterations\n+ * has been set (see {@link #SimpleUnivariateValueChecker(double,double,int)\n+ * this constructor}).\n+ *\n+ * @version $Id: SimpleUnivariateValueChecker.java 1413171 2012-11-24 11:11:10Z erans $\n+ * @since 3.1\n+ */\n+public class SimpleUnivariateValueChecker\n+    extends AbstractConvergenceChecker<UnivariatePointValuePair> {\n+    /**\n+     * If {@link #maxIterationCount} is set to this value, the number of\n+     * iterations will never cause\n+     * {@link #converged(int,UnivariatePointValuePair,UnivariatePointValuePair)}\n+     * to return {@code true}.\n+     */\n+    private static final int ITERATION_CHECK_DISABLED = -1;\n+    /**\n+     * Number of iterations after which the\n+     * {@link #converged(int,UnivariatePointValuePair,UnivariatePointValuePair)}\n+     * method will return true (unless the check is disabled).\n+     */\n+    private final int maxIterationCount;\n+\n+    /** Build an instance with specified thresholds.\n+     *\n+     * In order to perform only relative checks, the absolute tolerance\n+     * must be set to a negative value. In order to perform only absolute\n+     * checks, the relative tolerance must be set to a negative value.\n+     *\n+     * @param relativeThreshold relative tolerance threshold\n+     * @param absoluteThreshold absolute tolerance threshold\n+     */\n+    public SimpleUnivariateValueChecker(final double relativeThreshold,\n+                                        final double absoluteThreshold) {\n+        super(relativeThreshold, absoluteThreshold);\n+        maxIterationCount = ITERATION_CHECK_DISABLED;\n+    }\n+\n+    /**\n+     * Builds an instance with specified thresholds.\n+     *\n+     * In order to perform only relative checks, the absolute tolerance\n+     * must be set to a negative value. In order to perform only absolute\n+     * checks, the relative tolerance must be set to a negative value.\n+     *\n+     * @param relativeThreshold relative tolerance threshold\n+     * @param absoluteThreshold absolute tolerance threshold\n+     * @param maxIter Maximum iteration count.\n+     * @throws NotStrictlyPositiveException if {@code maxIter <= 0}.\n+     *\n+     * @since 3.1\n+     */\n+    public SimpleUnivariateValueChecker(final double relativeThreshold,\n+                                        final double absoluteThreshold,\n+                                        final int maxIter) {\n+        super(relativeThreshold, absoluteThreshold);\n+\n+        if (maxIter <= 0) {\n+            throw new NotStrictlyPositiveException(maxIter);\n+        }\n+        maxIterationCount = maxIter;\n+    }\n+\n+    /**\n+     * Check if the optimization algorithm has converged considering the\n+     * last two points.\n+     * This method may be called several time from the same algorithm\n+     * iteration with different points. This can be detected by checking the\n+     * iteration number at each call if needed. Each time this method is\n+     * called, the previous and current point correspond to points with the\n+     * same role at each iteration, so they can be compared. As an example,\n+     * simplex-based algorithms call this method for all points of the simplex,\n+     * not only for the best or worst ones.\n+     *\n+     * @param iteration Index of current iteration\n+     * @param previous Best point in the previous iteration.\n+     * @param current Best point in the current iteration.\n+     * @return {@code true} if the algorithm has converged.\n+     */\n+    @Override\n+    public boolean converged(final int iteration,\n+                             final UnivariatePointValuePair previous,\n+                             final UnivariatePointValuePair current) {\n+        if (maxIterationCount != ITERATION_CHECK_DISABLED) {\n+            if (iteration >= maxIterationCount) {\n+                return true;\n+            }\n+        }\n+\n+        final double p = previous.getValue();\n+        final double c = current.getValue();\n+        final double difference = FastMath.abs(p - c);\n+        final double size = FastMath.max(FastMath.abs(p), FastMath.abs(c));\n+        return difference <= size * getRelativeThreshold() ||\n+            difference <= getAbsoluteThreshold();\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/UnivariateObjectiveFunction.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.optim.OptimizationData;\n+\n+/**\n+ * Scalar function to be optimized.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public class UnivariateObjectiveFunction implements OptimizationData {\n+    /** Function to be optimized. */\n+    private final UnivariateFunction function;\n+\n+    /**\n+     * @param f Function to be optimized.\n+     */\n+    public UnivariateObjectiveFunction(UnivariateFunction f) {\n+        function = f;\n+    }\n+\n+    /**\n+     * Gets the function to be optimized.\n+     *\n+     * @return the objective function.\n+     */\n+    public UnivariateFunction getObjectiveFunction() {\n+        return function;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/UnivariateOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.optim.BaseOptimizer;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+\n+/**\n+ * Base class for a univariate scalar function optimizer.\n+ *\n+ * @version $Id$\n+ * @since 3.1\n+ */\n+public abstract class UnivariateOptimizer\n+    extends BaseOptimizer<UnivariatePointValuePair> {\n+    /** Objective function. */\n+    private UnivariateFunction function;\n+    /** Type of optimization. */\n+    private GoalType goal;\n+    /** Initial guess. */\n+    private double start;\n+    /** Lower bound. */\n+    private double min;\n+    /** Upper bound. */\n+    private double max;\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    protected UnivariateOptimizer(ConvergenceChecker<UnivariatePointValuePair> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link GoalType}</li>\n+     *  <li>{@link SearchInterval}</li>\n+     *  <li>{@link UnivariateObjectiveFunction}</li>\n+     * </ul>\n+     * @return {@inheritDoc}\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     */\n+    public UnivariatePointValuePair optimize(OptimizationData... optData)\n+        throws TooManyEvaluationsException {\n+        // Retrieve settings.\n+        parseOptimizationData(optData);\n+        // Perform computation.\n+        return super.optimize(optData);\n+    }\n+\n+    /**\n+     * @return the optimization type.\n+     */\n+    public GoalType getGoalType() {\n+        return goal;\n+    }\n+\n+    /**\n+     * Scans the list of (required and optional) optimization data that\n+     * characterize the problem.\n+     *\n+     * @param optData Optimization data.\n+     * The following data will be looked for:\n+     * <ul>\n+     *  <li>{@link GoalType}</li>\n+     *  <li>{@link SearchInterval}</li>\n+     *  <li>{@link UnivariateObjectiveFunction}</li>\n+     * </ul>\n+     */\n+    private void parseOptimizationData(OptimizationData... optData) {\n+        // The existing values (as set by the previous call) are reused if\n+        // not provided in the argument list.\n+        for (OptimizationData data : optData) {\n+            if (data instanceof SearchInterval) {\n+                final SearchInterval interval = (SearchInterval) data;\n+                min = interval.getMin();\n+                max = interval.getMax();\n+                start = interval.getStartValue();\n+                continue;\n+            }\n+            if (data instanceof UnivariateObjectiveFunction) {\n+                function = ((UnivariateObjectiveFunction) data).getObjectiveFunction();\n+                continue;\n+            }\n+            if (data instanceof GoalType) {\n+                goal = (GoalType) data;\n+                continue;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * @return the initial guess.\n+     */\n+    public double getStartValue() {\n+        return start;\n+    }\n+    /**\n+     * @return the lower bounds.\n+     */\n+    public double getMin() {\n+        return min;\n+    }\n+    /**\n+     * @return the upper bounds.\n+     */\n+    public double getMax() {\n+        return max;\n+    }\n+\n+    /**\n+     * Computes the objective function value.\n+     * This method <em>must</em> be called by subclasses to enforce the\n+     * evaluation counter limit.\n+     *\n+     * @param x Point at which the objective function must be evaluated.\n+     * @return the objective function value at the specified point.\n+     * @throws TooManyEvaluationsException if the maximal number of\n+     * evaluations is exceeded.\n+     */\n+    protected double computeObjectiveValue(double x) {\n+        super.incrementEvaluationCount();\n+        return function.value(x);\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/UnivariatePointValuePair.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.univariate;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * This class holds a point and the value of an objective function at this\n+ * point.\n+ * This is a simple immutable container.\n+ *\n+ * @version $Id: UnivariatePointValuePair.java 1364392 2012-07-22 18:27:12Z tn $\n+ * @since 3.0\n+ */\n+public class UnivariatePointValuePair implements Serializable {\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = 1003888396256744753L;\n+    /** Point. */\n+    private final double point;\n+    /** Value of the objective function at the point. */\n+    private final double value;\n+\n+    /**\n+     * Build a point/objective function value pair.\n+     *\n+     * @param point Point.\n+     * @param value Value of an objective function at the point\n+     */\n+    public UnivariatePointValuePair(final double point,\n+                                    final double value) {\n+        this.point = point;\n+        this.value = value;\n+    }\n+\n+    /**\n+     * Get the point.\n+     *\n+     * @return the point.\n+     */\n+    public double getPoint() {\n+        return point;\n+    }\n+\n+    /**\n+     * Get the value of the objective function.\n+     *\n+     * @return the stored value of the objective function.\n+     */\n+    public double getValue() {\n+        return value;\n+    }\n+}\n--- /dev/null\n+++ b/src/main/java/org/apache/commons/math3/optim/univariate/package-info.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+/**\n+ * One-dimensional optimization algorithms.\n+ */\n--- a/src/test/java/org/apache/commons/math3/exception/util/LocalizedFormatsTest.java\n+++ b/src/test/java/org/apache/commons/math3/exception/util/LocalizedFormatsTest.java\n \n     @Test\n     public void testMessageNumber() {\n-        Assert.assertEquals(311, LocalizedFormats.values().length);\n+        Assert.assertEquals(312, LocalizedFormats.values().length);\n     }\n \n     @Test\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/fitting/CurveFitterTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import org.apache.commons.math3.optim.nonlinear.vector.jacobian.LevenbergMarquardtOptimizer;\n+import org.apache.commons.math3.analysis.ParametricUnivariateFunction;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class CurveFitterTest {\n+    @Test\n+    public void testMath303() {\n+        LevenbergMarquardtOptimizer optimizer = new LevenbergMarquardtOptimizer();\n+        CurveFitter<ParametricUnivariateFunction> fitter = new CurveFitter<ParametricUnivariateFunction>(optimizer);\n+        fitter.addObservedPoint(2.805d, 0.6934785852953367d);\n+        fitter.addObservedPoint(2.74333333333333d, 0.6306772025518496d);\n+        fitter.addObservedPoint(1.655d, 0.9474675497289684);\n+        fitter.addObservedPoint(1.725d, 0.9013594835804194d);\n+\n+        ParametricUnivariateFunction sif = new SimpleInverseFunction();\n+\n+        double[] initialguess1 = new double[1];\n+        initialguess1[0] = 1.0d;\n+        Assert.assertEquals(1, fitter.fit(sif, initialguess1).length);\n+\n+        double[] initialguess2 = new double[2];\n+        initialguess2[0] = 1.0d;\n+        initialguess2[1] = .5d;\n+        Assert.assertEquals(2, fitter.fit(sif, initialguess2).length);\n+    }\n+\n+    @Test\n+    public void testMath304() {\n+        LevenbergMarquardtOptimizer optimizer = new LevenbergMarquardtOptimizer();\n+        CurveFitter<ParametricUnivariateFunction> fitter = new CurveFitter<ParametricUnivariateFunction>(optimizer);\n+        fitter.addObservedPoint(2.805d, 0.6934785852953367d);\n+        fitter.addObservedPoint(2.74333333333333d, 0.6306772025518496d);\n+        fitter.addObservedPoint(1.655d, 0.9474675497289684);\n+        fitter.addObservedPoint(1.725d, 0.9013594835804194d);\n+\n+        ParametricUnivariateFunction sif = new SimpleInverseFunction();\n+\n+        double[] initialguess1 = new double[1];\n+        initialguess1[0] = 1.0d;\n+        Assert.assertEquals(1.6357215104109237, fitter.fit(sif, initialguess1)[0], 1.0e-14);\n+\n+        double[] initialguess2 = new double[1];\n+        initialguess2[0] = 10.0d;\n+        Assert.assertEquals(1.6357215104109237, fitter.fit(sif, initialguess1)[0], 1.0e-14);\n+    }\n+\n+    @Test\n+    public void testMath372() {\n+        LevenbergMarquardtOptimizer optimizer = new LevenbergMarquardtOptimizer();\n+        CurveFitter<ParametricUnivariateFunction> curveFitter = new CurveFitter<ParametricUnivariateFunction>(optimizer);\n+\n+        curveFitter.addObservedPoint( 15,  4443);\n+        curveFitter.addObservedPoint( 31,  8493);\n+        curveFitter.addObservedPoint( 62, 17586);\n+        curveFitter.addObservedPoint(125, 30582);\n+        curveFitter.addObservedPoint(250, 45087);\n+        curveFitter.addObservedPoint(500, 50683);\n+\n+        ParametricUnivariateFunction f = new ParametricUnivariateFunction() {\n+            public double value(double x, double ... parameters) {\n+                double a = parameters[0];\n+                double b = parameters[1];\n+                double c = parameters[2];\n+                double d = parameters[3];\n+\n+                return d + ((a - d) / (1 + FastMath.pow(x / c, b)));\n+            }\n+\n+            public double[] gradient(double x, double ... parameters) {\n+                double a = parameters[0];\n+                double b = parameters[1];\n+                double c = parameters[2];\n+                double d = parameters[3];\n+\n+                double[] gradients = new double[4];\n+                double den = 1 + FastMath.pow(x / c, b);\n+\n+                // derivative with respect to a\n+                gradients[0] = 1 / den;\n+\n+                // derivative with respect to b\n+                // in the reported (invalid) issue, there was a sign error here\n+                gradients[1] = -((a - d) * FastMath.pow(x / c, b) * FastMath.log(x / c)) / (den * den);\n+\n+                // derivative with respect to c\n+                gradients[2] = (b * FastMath.pow(x / c, b - 1) * (x / (c * c)) * (a - d)) / (den * den);\n+\n+                // derivative with respect to d\n+                gradients[3] = 1 - (1 / den);\n+\n+                return gradients;\n+\n+            }\n+        };\n+\n+        double[] initialGuess = new double[] { 1500, 0.95, 65, 35000 };\n+        double[] estimatedParameters = curveFitter.fit(f, initialGuess);\n+\n+        Assert.assertEquals( 2411.00, estimatedParameters[0], 500.00);\n+        Assert.assertEquals(    1.62, estimatedParameters[1],   0.04);\n+        Assert.assertEquals(  111.22, estimatedParameters[2],   0.30);\n+        Assert.assertEquals(55347.47, estimatedParameters[3], 300.00);\n+        Assert.assertTrue(optimizer.getRMS() < 600.0);\n+    }\n+\n+    private static class SimpleInverseFunction implements ParametricUnivariateFunction {\n+\n+        public double value(double x, double ... parameters) {\n+            return parameters[0] / x + (parameters.length < 2 ? 0 : parameters[1]);\n+        }\n+\n+        public double[] gradient(double x, double ... doubles) {\n+            double[] gradientVector = new double[doubles.length];\n+            gradientVector[0] = 1 / x;\n+            if (doubles.length >= 2) {\n+                gradientVector[1] = 1;\n+            }\n+            return gradientVector;\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/fitting/GaussianFitterTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import org.apache.commons.math3.optim.nonlinear.vector.jacobian.LevenbergMarquardtOptimizer;\n+import org.apache.commons.math3.exception.MathIllegalArgumentException;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Tests {@link GaussianFitter}.\n+ *\n+ * @since 2.2\n+ * @version $Id: GaussianFitterTest.java 1349707 2012-06-13 09:30:56Z erans $\n+ */\n+public class GaussianFitterTest {\n+    /** Good data. */\n+    protected static final double[][] DATASET1 = new double[][] {\n+        {4.0254623,  531026.0},\n+        {4.02804905, 664002.0},\n+        {4.02934242, 787079.0},\n+        {4.03128248, 984167.0},\n+        {4.03386923, 1294546.0},\n+        {4.03580929, 1560230.0},\n+        {4.03839603, 1887233.0},\n+        {4.0396894,  2113240.0},\n+        {4.04162946, 2375211.0},\n+        {4.04421621, 2687152.0},\n+        {4.04550958, 2862644.0},\n+        {4.04744964, 3078898.0},\n+        {4.05003639, 3327238.0},\n+        {4.05132976, 3461228.0},\n+        {4.05326982, 3580526.0},\n+        {4.05585657, 3576946.0},\n+        {4.05779662, 3439750.0},\n+        {4.06038337, 3220296.0},\n+        {4.06167674, 3070073.0},\n+        {4.0636168,  2877648.0},\n+        {4.06620355, 2595848.0},\n+        {4.06749692, 2390157.0},\n+        {4.06943698, 2175960.0},\n+        {4.07202373, 1895104.0},\n+        {4.0733171,  1687576.0},\n+        {4.07525716, 1447024.0},\n+        {4.0778439,  1130879.0},\n+        {4.07978396, 904900.0},\n+        {4.08237071, 717104.0},\n+        {4.08366408, 620014.0}\n+    };\n+    /** Poor data: right of peak not symmetric with left of peak. */\n+    protected static final double[][] DATASET2 = new double[][] {\n+        {-20.15,   1523.0},\n+        {-19.65,   1566.0},\n+        {-19.15,   1592.0},\n+        {-18.65,   1927.0},\n+        {-18.15,   3089.0},\n+        {-17.65,   6068.0},\n+        {-17.15,  14239.0},\n+        {-16.65,  34124.0},\n+        {-16.15,  64097.0},\n+        {-15.65, 110352.0},\n+        {-15.15, 164742.0},\n+        {-14.65, 209499.0},\n+        {-14.15, 267274.0},\n+        {-13.65, 283290.0},\n+        {-13.15, 275363.0},\n+        {-12.65, 258014.0},\n+        {-12.15, 225000.0},\n+        {-11.65, 200000.0},\n+        {-11.15, 190000.0},\n+        {-10.65, 185000.0},\n+        {-10.15, 180000.0},\n+        { -9.65, 179000.0},\n+        { -9.15, 178000.0},\n+        { -8.65, 177000.0},\n+        { -8.15, 176000.0},\n+        { -7.65, 175000.0},\n+        { -7.15, 174000.0},\n+        { -6.65, 173000.0},\n+        { -6.15, 172000.0},\n+        { -5.65, 171000.0},\n+        { -5.15, 170000.0}\n+    };\n+    /** Poor data: long tails. */\n+    protected static final double[][] DATASET3 = new double[][] {\n+        {-90.15,   1513.0},\n+        {-80.15,   1514.0},\n+        {-70.15,   1513.0},\n+        {-60.15,   1514.0},\n+        {-50.15,   1513.0},\n+        {-40.15,   1514.0},\n+        {-30.15,   1513.0},\n+        {-20.15,   1523.0},\n+        {-19.65,   1566.0},\n+        {-19.15,   1592.0},\n+        {-18.65,   1927.0},\n+        {-18.15,   3089.0},\n+        {-17.65,   6068.0},\n+        {-17.15,  14239.0},\n+        {-16.65,  34124.0},\n+        {-16.15,  64097.0},\n+        {-15.65, 110352.0},\n+        {-15.15, 164742.0},\n+        {-14.65, 209499.0},\n+        {-14.15, 267274.0},\n+        {-13.65, 283290.0},\n+        {-13.15, 275363.0},\n+        {-12.65, 258014.0},\n+        {-12.15, 214073.0},\n+        {-11.65, 182244.0},\n+        {-11.15, 136419.0},\n+        {-10.65,  97823.0},\n+        {-10.15,  58930.0},\n+        { -9.65,  35404.0},\n+        { -9.15,  16120.0},\n+        { -8.65,   9823.0},\n+        { -8.15,   5064.0},\n+        { -7.65,   2575.0},\n+        { -7.15,   1642.0},\n+        { -6.65,   1101.0},\n+        { -6.15,    812.0},\n+        { -5.65,    690.0},\n+        { -5.15,    565.0},\n+        {  5.15,    564.0},\n+        { 15.15,    565.0},\n+        { 25.15,    564.0},\n+        { 35.15,    565.0},\n+        { 45.15,    564.0},\n+        { 55.15,    565.0},\n+        { 65.15,    564.0},\n+        { 75.15,    565.0}\n+    };\n+    /** Poor data: right of peak is missing. */\n+    protected static final double[][] DATASET4 = new double[][] {\n+        {-20.15,   1523.0},\n+        {-19.65,   1566.0},\n+        {-19.15,   1592.0},\n+        {-18.65,   1927.0},\n+        {-18.15,   3089.0},\n+        {-17.65,   6068.0},\n+        {-17.15,  14239.0},\n+        {-16.65,  34124.0},\n+        {-16.15,  64097.0},\n+        {-15.65, 110352.0},\n+        {-15.15, 164742.0},\n+        {-14.65, 209499.0},\n+        {-14.15, 267274.0},\n+        {-13.65, 283290.0}\n+    };\n+    /** Good data, but few points. */\n+    protected static final double[][] DATASET5 = new double[][] {\n+        {4.0254623,  531026.0},\n+        {4.03128248, 984167.0},\n+        {4.03839603, 1887233.0},\n+        {4.04421621, 2687152.0},\n+        {4.05132976, 3461228.0},\n+        {4.05326982, 3580526.0},\n+        {4.05779662, 3439750.0},\n+        {4.0636168,  2877648.0},\n+        {4.06943698, 2175960.0},\n+        {4.07525716, 1447024.0},\n+        {4.08237071, 717104.0},\n+        {4.08366408, 620014.0}\n+    };\n+\n+    /**\n+     * Basic.\n+     */\n+    @Test\n+    public void testFit01() {\n+        GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+        addDatasetToGaussianFitter(DATASET1, fitter);\n+        double[] parameters = fitter.fit();\n+\n+        Assert.assertEquals(3496978.1837704973, parameters[0], 1e-4);\n+        Assert.assertEquals(4.054933085999146, parameters[1], 1e-4);\n+        Assert.assertEquals(0.015039355620304326, parameters[2], 1e-4);\n+    }\n+\n+    /**\n+     * Zero points is not enough observed points.\n+     */\n+    @Test(expected=MathIllegalArgumentException.class)\n+    public void testFit02() {\n+        GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+        fitter.fit();\n+    }\n+    \n+    /**\n+     * Two points is not enough observed points.\n+     */\n+    @Test(expected=MathIllegalArgumentException.class)\n+    public void testFit03() {\n+        GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+        addDatasetToGaussianFitter(new double[][] {\n+            {4.0254623,  531026.0},\n+            {4.02804905, 664002.0}},\n+            fitter);\n+        fitter.fit();\n+    }\n+    \n+    /**\n+     * Poor data: right of peak not symmetric with left of peak.\n+     */\n+    @Test\n+    public void testFit04() {\n+        GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+        addDatasetToGaussianFitter(DATASET2, fitter);\n+        double[] parameters = fitter.fit();\n+\n+        Assert.assertEquals(233003.2967252038, parameters[0], 1e-4);\n+        Assert.assertEquals(-10.654887521095983, parameters[1], 1e-4);\n+        Assert.assertEquals(4.335937353196641, parameters[2], 1e-4);\n+    }  \n+    \n+    /**\n+     * Poor data: long tails.\n+     */\n+    @Test\n+    public void testFit05() {\n+        GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+        addDatasetToGaussianFitter(DATASET3, fitter);\n+        double[] parameters = fitter.fit();\n+\n+        Assert.assertEquals(283863.81929180305, parameters[0], 1e-4);\n+        Assert.assertEquals(-13.29641995105174, parameters[1], 1e-4);\n+        Assert.assertEquals(1.7297330293549908, parameters[2], 1e-4);\n+    }\n+    \n+    /**\n+     * Poor data: right of peak is missing.\n+     */\n+    @Test\n+    public void testFit06() {\n+        GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+        addDatasetToGaussianFitter(DATASET4, fitter);\n+        double[] parameters = fitter.fit();\n+\n+        Assert.assertEquals(285250.66754309234, parameters[0], 1e-4);\n+        Assert.assertEquals(-13.528375695228455, parameters[1], 1e-4);\n+        Assert.assertEquals(1.5204344894331614, parameters[2], 1e-4);\n+    }    \n+\n+    /**\n+     * Basic with smaller dataset.\n+     */\n+    @Test\n+    public void testFit07() {\n+        GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+        addDatasetToGaussianFitter(DATASET5, fitter);\n+        double[] parameters = fitter.fit();\n+\n+        Assert.assertEquals(3514384.729342235, parameters[0], 1e-4);\n+        Assert.assertEquals(4.054970307455625, parameters[1], 1e-4);\n+        Assert.assertEquals(0.015029412832160017, parameters[2], 1e-4);\n+    }\n+\n+    @Test\n+    public void testMath519() {\n+        // The optimizer will try negative sigma values but \"GaussianFitter\"\n+        // will catch the raised exceptions and return NaN values instead.\n+\n+        final double[] data = { \n+            1.1143831578403364E-29,\n+            4.95281403484594E-28,\n+            1.1171347211930288E-26,\n+            1.7044813962636277E-25,\n+            1.9784716574832164E-24,\n+            1.8630236407866774E-23,\n+            1.4820532905097742E-22,\n+            1.0241963854632831E-21,\n+            6.275077366673128E-21,\n+            3.461808994532493E-20,\n+            1.7407124684715706E-19,\n+            8.056687953553974E-19,\n+            3.460193945992071E-18,\n+            1.3883326374011525E-17,\n+            5.233894983671116E-17,\n+            1.8630791465263745E-16,\n+            6.288759227922111E-16,\n+            2.0204433920597856E-15,\n+            6.198768938576155E-15,\n+            1.821419346860626E-14,\n+            5.139176445538471E-14,\n+            1.3956427429045787E-13,\n+            3.655705706448139E-13,\n+            9.253753324779779E-13,\n+            2.267636001476696E-12,\n+            5.3880460095836855E-12,\n+            1.2431632654852931E-11\n+        };\n+\n+        GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+        for (int i = 0; i < data.length; i++) {\n+            fitter.addObservedPoint(i, data[i]);\n+        }\n+        final double[] p = fitter.fit();\n+\n+        Assert.assertEquals(53.1572792, p[1], 1e-7);\n+        Assert.assertEquals(5.75214622, p[2], 1e-8);\n+    }\n+\n+    @Test\n+    public void testMath798() {\n+        final GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\n+\n+        // When the data points are not commented out below, the fit stalls.\n+        // This is expected however, since the whole dataset hardly looks like\n+        // a Gaussian.\n+        // When commented out, the fit proceeds fine.\n+\n+        fitter.addObservedPoint(0.23, 395.0);\n+        //fitter.addObservedPoint(0.68, 0.0);\n+        fitter.addObservedPoint(1.14, 376.0);\n+        //fitter.addObservedPoint(1.59, 0.0);\n+        fitter.addObservedPoint(2.05, 163.0);\n+        //fitter.addObservedPoint(2.50, 0.0);\n+        fitter.addObservedPoint(2.95, 49.0);\n+        //fitter.addObservedPoint(3.41, 0.0);\n+        fitter.addObservedPoint(3.86, 16.0);\n+        //fitter.addObservedPoint(4.32, 0.0);\n+        fitter.addObservedPoint(4.77, 1.0);\n+\n+        final double[] p = fitter.fit();\n+\n+        // Values are copied from a previous run of this test.\n+        Assert.assertEquals(420.8397296167364, p[0], 1e-12);\n+        Assert.assertEquals(0.603770729862231, p[1], 1e-15);\n+        Assert.assertEquals(1.0786447936766612, p[2], 1e-14);\n+    }\n+    \n+    /**\n+     * Adds the specified points to specified <code>GaussianFitter</code>\n+     * instance.\n+     *\n+     * @param points data points where first dimension is a point index and\n+     *        second dimension is an array of length two representing the point\n+     *        with the first value corresponding to X and the second value\n+     *        corresponding to Y\n+     * @param fitter fitter to which the points in <code>points</code> should be\n+     *        added as observed points\n+     */\n+    protected static void addDatasetToGaussianFitter(double[][] points,\n+                                                     GaussianFitter fitter) {\n+        for (int i = 0; i < points.length; i++) {\n+            fitter.addObservedPoint(points[i][0], points[i][1]);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/fitting/HarmonicFitterTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import java.util.Random;\n+import org.apache.commons.math3.optim.nonlinear.vector.jacobian.LevenbergMarquardtOptimizer;\n+import org.apache.commons.math3.analysis.function.HarmonicOscillator;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.util.MathUtils;\n+\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+public class HarmonicFitterTest {\n+    @Test(expected=NumberIsTooSmallException.class)\n+    public void testPreconditions1() {\n+        HarmonicFitter fitter =\n+            new HarmonicFitter(new LevenbergMarquardtOptimizer());\n+\n+        fitter.fit();\n+    }\n+\n+    @Test\n+    public void testNoError() {\n+        final double a = 0.2;\n+        final double w = 3.4;\n+        final double p = 4.1;\n+        HarmonicOscillator f = new HarmonicOscillator(a, w, p);\n+\n+        HarmonicFitter fitter =\n+            new HarmonicFitter(new LevenbergMarquardtOptimizer());\n+        for (double x = 0.0; x < 1.3; x += 0.01) {\n+            fitter.addObservedPoint(1, x, f.value(x));\n+        }\n+\n+        final double[] fitted = fitter.fit();\n+        Assert.assertEquals(a, fitted[0], 1.0e-13);\n+        Assert.assertEquals(w, fitted[1], 1.0e-13);\n+        Assert.assertEquals(p, MathUtils.normalizeAngle(fitted[2], p), 1e-13);\n+\n+        HarmonicOscillator ff = new HarmonicOscillator(fitted[0], fitted[1], fitted[2]);\n+\n+        for (double x = -1.0; x < 1.0; x += 0.01) {\n+            Assert.assertTrue(FastMath.abs(f.value(x) - ff.value(x)) < 1e-13);\n+        }\n+    }\n+\n+    @Test\n+    public void test1PercentError() {\n+        Random randomizer = new Random(64925784252l);\n+        final double a = 0.2;\n+        final double w = 3.4;\n+        final double p = 4.1;\n+        HarmonicOscillator f = new HarmonicOscillator(a, w, p);\n+\n+        HarmonicFitter fitter =\n+            new HarmonicFitter(new LevenbergMarquardtOptimizer());\n+        for (double x = 0.0; x < 10.0; x += 0.1) {\n+            fitter.addObservedPoint(1, x,\n+                                    f.value(x) + 0.01 * randomizer.nextGaussian());\n+        }\n+\n+        final double[] fitted = fitter.fit();\n+        Assert.assertEquals(a, fitted[0], 7.6e-4);\n+        Assert.assertEquals(w, fitted[1], 2.7e-3);\n+        Assert.assertEquals(p, MathUtils.normalizeAngle(fitted[2], p), 1.3e-2);\n+    }\n+\n+    @Test\n+    public void testTinyVariationsData() {\n+        Random randomizer = new Random(64925784252l);\n+\n+        HarmonicFitter fitter =\n+            new HarmonicFitter(new LevenbergMarquardtOptimizer());\n+        for (double x = 0.0; x < 10.0; x += 0.1) {\n+            fitter.addObservedPoint(1, x, 1e-7 * randomizer.nextGaussian());\n+        }\n+\n+        fitter.fit();\n+        // This test serves to cover the part of the code of \"guessAOmega\"\n+        // when the algorithm using integrals fails.\n+    }\n+\n+    @Test\n+    public void testInitialGuess() {\n+        Random randomizer = new Random(45314242l);\n+        final double a = 0.2;\n+        final double w = 3.4;\n+        final double p = 4.1;\n+        HarmonicOscillator f = new HarmonicOscillator(a, w, p);\n+\n+        HarmonicFitter fitter =\n+            new HarmonicFitter(new LevenbergMarquardtOptimizer());\n+        for (double x = 0.0; x < 10.0; x += 0.1) {\n+            fitter.addObservedPoint(1, x,\n+                                    f.value(x) + 0.01 * randomizer.nextGaussian());\n+        }\n+\n+        final double[] fitted = fitter.fit(new double[] { 0.15, 3.6, 4.5 });\n+        Assert.assertEquals(a, fitted[0], 1.2e-3);\n+        Assert.assertEquals(w, fitted[1], 3.3e-3);\n+        Assert.assertEquals(p, MathUtils.normalizeAngle(fitted[2], p), 1.7e-2);\n+    }\n+\n+    @Test\n+    public void testUnsorted() {\n+        Random randomizer = new Random(64925784252l);\n+        final double a = 0.2;\n+        final double w = 3.4;\n+        final double p = 4.1;\n+        HarmonicOscillator f = new HarmonicOscillator(a, w, p);\n+\n+        HarmonicFitter fitter =\n+            new HarmonicFitter(new LevenbergMarquardtOptimizer());\n+\n+        // build a regularly spaced array of measurements\n+        int size = 100;\n+        double[] xTab = new double[size];\n+        double[] yTab = new double[size];\n+        for (int i = 0; i < size; ++i) {\n+            xTab[i] = 0.1 * i;\n+            yTab[i] = f.value(xTab[i]) + 0.01 * randomizer.nextGaussian();\n+        }\n+\n+        // shake it\n+        for (int i = 0; i < size; ++i) {\n+            int i1 = randomizer.nextInt(size);\n+            int i2 = randomizer.nextInt(size);\n+            double xTmp = xTab[i1];\n+            double yTmp = yTab[i1];\n+            xTab[i1] = xTab[i2];\n+            yTab[i1] = yTab[i2];\n+            xTab[i2] = xTmp;\n+            yTab[i2] = yTmp;\n+        }\n+\n+        // pass it to the fitter\n+        for (int i = 0; i < size; ++i) {\n+            fitter.addObservedPoint(1, xTab[i], yTab[i]);\n+        }\n+\n+        final double[] fitted = fitter.fit();\n+        Assert.assertEquals(a, fitted[0], 7.6e-4);\n+        Assert.assertEquals(w, fitted[1], 3.5e-3);\n+        Assert.assertEquals(p, MathUtils.normalizeAngle(fitted[2], p), 1.5e-2);\n+    }\n+\n+    @Test(expected=MathIllegalStateException.class)\n+    public void testMath844() {\n+        final double[] y = { 0, 1, 2, 3, 2, 1,\n+                             0, -1, -2, -3, -2, -1,\n+                             0, 1, 2, 3, 2, 1,\n+                             0, -1, -2, -3, -2, -1,\n+                             0, 1, 2, 3, 2, 1, 0 };\n+        final int len = y.length;\n+        final WeightedObservedPoint[] points = new WeightedObservedPoint[len];\n+        for (int i = 0; i < len; i++) {\n+            points[i] = new WeightedObservedPoint(1, i, y[i]);\n+        }\n+\n+        // The guesser fails because the function is far from an harmonic\n+        // function: It is a triangular periodic function with amplitude 3\n+        // and period 12, and all sample points are taken at integer abscissae\n+        // so function values all belong to the integer subset {-3, -2, -1, 0,\n+        // 1, 2, 3}.\n+        final HarmonicFitter.ParameterGuesser guesser\n+            = new HarmonicFitter.ParameterGuesser(points);\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/fitting/PolynomialFitterTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.fitting;\n+\n+import java.util.Random;\n+import org.apache.commons.math3.analysis.polynomials.PolynomialFunction;\n+import org.apache.commons.math3.analysis.polynomials.PolynomialFunction.Parametric;\n+import org.apache.commons.math3.exception.ConvergenceException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.optim.nonlinear.vector.MultivariateVectorOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.vector.jacobian.LevenbergMarquardtOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.vector.jacobian.GaussNewtonOptimizer;\n+import org.apache.commons.math3.optim.SimpleVectorValueChecker;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.distribution.RealDistribution;\n+import org.apache.commons.math3.distribution.UniformRealDistribution;\n+import org.apache.commons.math3.TestUtils;\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+/**\n+ * Test for class {@link CurveFitter} where the function to fit is a\n+ * polynomial.\n+ */\n+public class PolynomialFitterTest {\n+    @Test\n+    public void testFit() {\n+        final RealDistribution rng = new UniformRealDistribution(-100, 100);\n+        rng.reseedRandomGenerator(64925784252L);\n+\n+        final LevenbergMarquardtOptimizer optim = new LevenbergMarquardtOptimizer();\n+        final PolynomialFitter fitter = new PolynomialFitter(optim);\n+        final double[] coeff = { 12.9, -3.4, 2.1 }; // 12.9 - 3.4 x + 2.1 x^2\n+        final PolynomialFunction f = new PolynomialFunction(coeff);\n+\n+        // Collect data from a known polynomial.\n+        for (int i = 0; i < 100; i++) {\n+            final double x = rng.sample();\n+            fitter.addObservedPoint(x, f.value(x));\n+        }\n+\n+        // Start fit from initial guesses that are far from the optimal values.\n+        final double[] best = fitter.fit(new double[] { -1e-20, 3e15, -5e25 });\n+\n+        TestUtils.assertEquals(\"best != coeff\", coeff, best, 1e-12);\n+    }\n+\n+    @Test\n+    public void testNoError() {\n+        Random randomizer = new Random(64925784252l);\n+        for (int degree = 1; degree < 10; ++degree) {\n+            PolynomialFunction p = buildRandomPolynomial(degree, randomizer);\n+\n+            PolynomialFitter fitter = new PolynomialFitter(new LevenbergMarquardtOptimizer());\n+            for (int i = 0; i <= degree; ++i) {\n+                fitter.addObservedPoint(1.0, i, p.value(i));\n+            }\n+\n+            final double[] init = new double[degree + 1];\n+            PolynomialFunction fitted = new PolynomialFunction(fitter.fit(init));\n+\n+            for (double x = -1.0; x < 1.0; x += 0.01) {\n+                double error = FastMath.abs(p.value(x) - fitted.value(x)) /\n+                               (1.0 + FastMath.abs(p.value(x)));\n+                Assert.assertEquals(0.0, error, 1.0e-6);\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testSmallError() {\n+        Random randomizer = new Random(53882150042l);\n+        double maxError = 0;\n+        for (int degree = 0; degree < 10; ++degree) {\n+            PolynomialFunction p = buildRandomPolynomial(degree, randomizer);\n+\n+            PolynomialFitter fitter = new PolynomialFitter(new LevenbergMarquardtOptimizer());\n+            for (double x = -1.0; x < 1.0; x += 0.01) {\n+                fitter.addObservedPoint(1.0, x,\n+                                        p.value(x) + 0.1 * randomizer.nextGaussian());\n+            }\n+\n+            final double[] init = new double[degree + 1];\n+            PolynomialFunction fitted = new PolynomialFunction(fitter.fit(init));\n+\n+            for (double x = -1.0; x < 1.0; x += 0.01) {\n+                double error = FastMath.abs(p.value(x) - fitted.value(x)) /\n+                              (1.0 + FastMath.abs(p.value(x)));\n+                maxError = FastMath.max(maxError, error);\n+                Assert.assertTrue(FastMath.abs(error) < 0.1);\n+            }\n+        }\n+        Assert.assertTrue(maxError > 0.01);\n+    }\n+\n+    @Test\n+    public void testMath798() {\n+        final double tol = 1e-14;\n+        final SimpleVectorValueChecker checker = new SimpleVectorValueChecker(tol, tol);\n+        final double[] init = new double[] { 0, 0 };\n+        final int maxEval = 3;\n+\n+        final double[] lm = doMath798(new LevenbergMarquardtOptimizer(checker), maxEval, init);\n+        final double[] gn = doMath798(new GaussNewtonOptimizer(checker), maxEval, init);\n+\n+        for (int i = 0; i <= 1; i++) {\n+            Assert.assertEquals(lm[i], gn[i], tol);\n+        }\n+    }\n+\n+    /**\n+     * This test shows that the user can set the maximum number of iterations\n+     * to avoid running for too long.\n+     * But in the test case, the real problem is that the tolerance is way too\n+     * stringent.\n+     */\n+    @Test(expected=TooManyEvaluationsException.class)\n+    public void testMath798WithToleranceTooLow() {\n+        final double tol = 1e-100;\n+        final SimpleVectorValueChecker checker = new SimpleVectorValueChecker(tol, tol);\n+        final double[] init = new double[] { 0, 0 };\n+        final int maxEval = 10000; // Trying hard to fit.\n+\n+        final double[] gn = doMath798(new GaussNewtonOptimizer(checker), maxEval, init);\n+    }\n+\n+    /**\n+     * This test shows that the user can set the maximum number of iterations\n+     * to avoid running for too long.\n+     * Even if the real problem is that the tolerance is way too stringent, it\n+     * is possible to get the best solution so far, i.e. a checker will return\n+     * the point when the maximum iteration count has been reached.\n+     */\n+    @Test\n+    public void testMath798WithToleranceTooLowButNoException() {\n+        final double tol = 1e-100;\n+        final double[] init = new double[] { 0, 0 };\n+        final int maxEval = 10000; // Trying hard to fit.\n+        final SimpleVectorValueChecker checker = new SimpleVectorValueChecker(tol, tol, maxEval);\n+\n+        final double[] lm = doMath798(new LevenbergMarquardtOptimizer(checker), maxEval, init);\n+        final double[] gn = doMath798(new GaussNewtonOptimizer(checker), maxEval, init);\n+\n+        for (int i = 0; i <= 1; i++) {\n+            Assert.assertEquals(lm[i], gn[i], 1e-15);\n+        }\n+    }\n+\n+    /**\n+     * @param optimizer Optimizer.\n+     * @param maxEval Maximum number of function evaluations.\n+     * @param init First guess.\n+     * @return the solution found by the given optimizer.\n+     */\n+    private double[] doMath798(MultivariateVectorOptimizer optimizer,\n+                               int maxEval,\n+                               double[] init) {\n+        final CurveFitter<Parametric> fitter = new CurveFitter<Parametric>(optimizer);\n+\n+        fitter.addObservedPoint(-0.2, -7.12442E-13);\n+        fitter.addObservedPoint(-0.199, -4.33397E-13);\n+        fitter.addObservedPoint(-0.198, -2.823E-13);\n+        fitter.addObservedPoint(-0.197, -1.40405E-13);\n+        fitter.addObservedPoint(-0.196, -7.80821E-15);\n+        fitter.addObservedPoint(-0.195, 6.20484E-14);\n+        fitter.addObservedPoint(-0.194, 7.24673E-14);\n+        fitter.addObservedPoint(-0.193, 1.47152E-13);\n+        fitter.addObservedPoint(-0.192, 1.9629E-13);\n+        fitter.addObservedPoint(-0.191, 2.12038E-13);\n+        fitter.addObservedPoint(-0.19, 2.46906E-13);\n+        fitter.addObservedPoint(-0.189, 2.77495E-13);\n+        fitter.addObservedPoint(-0.188, 2.51281E-13);\n+        fitter.addObservedPoint(-0.187, 2.64001E-13);\n+        fitter.addObservedPoint(-0.186, 2.8882E-13);\n+        fitter.addObservedPoint(-0.185, 3.13604E-13);\n+        fitter.addObservedPoint(-0.184, 3.14248E-13);\n+        fitter.addObservedPoint(-0.183, 3.1172E-13);\n+        fitter.addObservedPoint(-0.182, 3.12912E-13);\n+        fitter.addObservedPoint(-0.181, 3.06761E-13);\n+        fitter.addObservedPoint(-0.18, 2.8559E-13);\n+        fitter.addObservedPoint(-0.179, 2.86806E-13);\n+        fitter.addObservedPoint(-0.178, 2.985E-13);\n+        fitter.addObservedPoint(-0.177, 2.67148E-13);\n+        fitter.addObservedPoint(-0.176, 2.94173E-13);\n+        fitter.addObservedPoint(-0.175, 3.27528E-13);\n+        fitter.addObservedPoint(-0.174, 3.33858E-13);\n+        fitter.addObservedPoint(-0.173, 2.97511E-13);\n+        fitter.addObservedPoint(-0.172, 2.8615E-13);\n+        fitter.addObservedPoint(-0.171, 2.84624E-13);\n+\n+        final double[] coeff = fitter.fit(maxEval,\n+                                          new PolynomialFunction.Parametric(),\n+                                          init);\n+        return coeff;\n+    }\n+\n+    @Test\n+    public void testRedundantSolvable() {\n+        // Levenberg-Marquardt should handle redundant information gracefully\n+        checkUnsolvableProblem(new LevenbergMarquardtOptimizer(), true);\n+    }\n+\n+    @Test\n+    public void testRedundantUnsolvable() {\n+        // Gauss-Newton should not be able to solve redundant information\n+        checkUnsolvableProblem(new GaussNewtonOptimizer(true, new SimpleVectorValueChecker(1e-15, 1e-15)), false);\n+    }\n+\n+    private void checkUnsolvableProblem(MultivariateVectorOptimizer optimizer,\n+                                        boolean solvable) {\n+        Random randomizer = new Random(1248788532l);\n+        for (int degree = 0; degree < 10; ++degree) {\n+            PolynomialFunction p = buildRandomPolynomial(degree, randomizer);\n+\n+            PolynomialFitter fitter = new PolynomialFitter(optimizer);\n+\n+            // reusing the same point over and over again does not bring\n+            // information, the problem cannot be solved in this case for\n+            // degrees greater than 1 (but one point is sufficient for\n+            // degree 0)\n+            for (double x = -1.0; x < 1.0; x += 0.01) {\n+                fitter.addObservedPoint(1.0, 0.0, p.value(0.0));\n+            }\n+\n+            try {\n+                final double[] init = new double[degree + 1];\n+                fitter.fit(init);\n+                Assert.assertTrue(solvable || (degree == 0));\n+            } catch(ConvergenceException e) {\n+                Assert.assertTrue((! solvable) && (degree > 0));\n+            }\n+        }\n+    }\n+\n+    private PolynomialFunction buildRandomPolynomial(int degree, Random randomizer) {\n+        final double[] coefficients = new double[degree + 1];\n+        for (int i = 0; i <= degree; ++i) {\n+            coefficients[i] = randomizer.nextGaussian();\n+        }\n+        return new PolynomialFunction(coefficients);\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/PointValuePairTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.TestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class PointValuePairTest {\n+    @Test\n+    public void testSerial() {\n+        PointValuePair pv1 = new PointValuePair(new double[] { 1.0, 2.0, 3.0 }, 4.0);\n+        PointValuePair pv2 = (PointValuePair) TestUtils.serializeAndRecover(pv1);\n+        Assert.assertEquals(pv1.getKey().length, pv2.getKey().length);\n+        for (int i = 0; i < pv1.getKey().length; ++i) {\n+            Assert.assertEquals(pv1.getKey()[i], pv2.getKey()[i], 1.0e-15);\n+        }\n+        Assert.assertEquals(pv1.getValue(), pv2.getValue(), 1.0e-15);\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/PointVectorValuePairTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.TestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class PointVectorValuePairTest {\n+    @Test\n+    public void testSerial() {\n+        PointVectorValuePair pv1 = new PointVectorValuePair(new double[] { 1.0, 2.0, 3.0 },\n+                                                            new double[] { 4.0, 5.0 });\n+        PointVectorValuePair pv2 = (PointVectorValuePair) TestUtils.serializeAndRecover(pv1);\n+        Assert.assertEquals(pv1.getKey().length, pv2.getKey().length);\n+        for (int i = 0; i < pv1.getKey().length; ++i) {\n+            Assert.assertEquals(pv1.getKey()[i], pv2.getKey()[i], 1.0e-15);\n+        }\n+        Assert.assertEquals(pv1.getValue().length, pv2.getValue().length);\n+        for (int i = 0; i < pv1.getValue().length; ++i) {\n+            Assert.assertEquals(pv1.getValue()[i], pv2.getValue()[i], 1.0e-15);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/SimplePointCheckerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+public class SimplePointCheckerTest {\n+    @Test(expected=NotStrictlyPositiveException.class)\n+    public void testIterationCheckPrecondition() {\n+        new SimplePointChecker<PointValuePair>(1e-1, 1e-2, 0);\n+    }\n+\n+    @Test\n+    public void testIterationCheck() {\n+        final int max = 10;\n+        final SimplePointChecker<PointValuePair> checker\n+            = new SimplePointChecker<PointValuePair>(1e-1, 1e-2, max);\n+        Assert.assertTrue(checker.converged(max, null, null)); \n+        Assert.assertTrue(checker.converged(max + 1, null, null));\n+    }\n+\n+    @Test\n+    public void testIterationCheckDisabled() {\n+        final SimplePointChecker<PointValuePair> checker\n+            = new SimplePointChecker<PointValuePair>(1e-8, 1e-8);\n+\n+        final PointValuePair a = new PointValuePair(new double[] { 1d }, 1d);\n+        final PointValuePair b = new PointValuePair(new double[] { 10d }, 10d);\n+\n+        Assert.assertFalse(checker.converged(-1, a, b));\n+        Assert.assertFalse(checker.converged(0, a, b));\n+        Assert.assertFalse(checker.converged(1000000, a, b));\n+\n+        Assert.assertTrue(checker.converged(-1, a, a));\n+        Assert.assertTrue(checker.converged(-1, b, b));\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/SimpleValueCheckerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+public class SimpleValueCheckerTest {\n+    @Test(expected=NotStrictlyPositiveException.class)\n+    public void testIterationCheckPrecondition() {\n+        new SimpleValueChecker(1e-1, 1e-2, 0);\n+    }\n+\n+    @Test\n+    public void testIterationCheck() {\n+        final int max = 10;\n+        final SimpleValueChecker checker = new SimpleValueChecker(1e-1, 1e-2, max);\n+        Assert.assertTrue(checker.converged(max, null, null)); \n+        Assert.assertTrue(checker.converged(max + 1, null, null));\n+    }\n+\n+    @Test\n+    public void testIterationCheckDisabled() {\n+        final SimpleValueChecker checker = new SimpleValueChecker(1e-8, 1e-8);\n+\n+        final PointValuePair a = new PointValuePair(new double[] { 1d }, 1d);\n+        final PointValuePair b = new PointValuePair(new double[] { 10d }, 10d);\n+\n+        Assert.assertFalse(checker.converged(-1, a, b));\n+        Assert.assertFalse(checker.converged(0, a, b));\n+        Assert.assertFalse(checker.converged(1000000, a, b));\n+\n+        Assert.assertTrue(checker.converged(-1, a, a));\n+        Assert.assertTrue(checker.converged(-1, b, b));\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/SimpleVectorValueCheckerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim;\n+\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+public class SimpleVectorValueCheckerTest {\n+    @Test(expected=NotStrictlyPositiveException.class)\n+    public void testIterationCheckPrecondition() {\n+        new SimpleVectorValueChecker(1e-1, 1e-2, 0);\n+    }\n+\n+    @Test\n+    public void testIterationCheck() {\n+        final int max = 10;\n+        final SimpleVectorValueChecker checker = new SimpleVectorValueChecker(1e-1, 1e-2, max);\n+        Assert.assertTrue(checker.converged(max, null, null));\n+        Assert.assertTrue(checker.converged(max + 1, null, null));\n+    }\n+\n+    @Test\n+    public void testIterationCheckDisabled() {\n+        final SimpleVectorValueChecker checker = new SimpleVectorValueChecker(1e-8, 1e-8);\n+\n+        final PointVectorValuePair a = new PointVectorValuePair(new double[] { 1d },\n+                                                                new double[] { 1d });\n+        final PointVectorValuePair b = new PointVectorValuePair(new double[] { 10d },\n+                                                                new double[] { 10d });\n+\n+        Assert.assertFalse(checker.converged(-1, a, b));\n+        Assert.assertFalse(checker.converged(0, a, b));\n+        Assert.assertFalse(checker.converged(1000000, a, b));\n+\n+        Assert.assertTrue(checker.converged(-1, a, a));\n+        Assert.assertTrue(checker.converged(-1, b, b));\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/linear/SimplexSolverTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import org.apache.commons.math3.optim.MaxIter;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.util.Precision;\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+public class SimplexSolverTest {\n+    private static final MaxIter DEFAULT_MAX_ITER = new MaxIter(100);\n+\n+    @Test\n+    public void testMath828() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(\n+                new double[] { 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, 0.0);\n+        \n+        ArrayList <LinearConstraint>constraints = new ArrayList<LinearConstraint>();\n+\n+        constraints.add(new LinearConstraint(new double[] {0.0, 39.0, 23.0, 96.0, 15.0, 48.0, 9.0, 21.0, 48.0, 36.0, 76.0, 19.0, 88.0, 17.0, 16.0, 36.0,}, Relationship.GEQ, 15.0));\n+        constraints.add(new LinearConstraint(new double[] {0.0, 59.0, 93.0, 12.0, 29.0, 78.0, 73.0, 87.0, 32.0, 70.0, 68.0, 24.0, 11.0, 26.0, 65.0, 25.0,}, Relationship.GEQ, 29.0));\n+        constraints.add(new LinearConstraint(new double[] {0.0, 74.0, 5.0, 82.0, 6.0, 97.0, 55.0, 44.0, 52.0, 54.0, 5.0, 93.0, 91.0, 8.0, 20.0, 97.0,}, Relationship.GEQ, 6.0));\n+        constraints.add(new LinearConstraint(new double[] {8.0, -3.0, -28.0, -72.0, -8.0, -31.0, -31.0, -74.0, -47.0, -59.0, -24.0, -57.0, -56.0, -16.0, -92.0, -59.0,}, Relationship.GEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] {25.0, -7.0, -99.0, -78.0, -25.0, -14.0, -16.0, -89.0, -39.0, -56.0, -53.0, -9.0, -18.0, -26.0, -11.0, -61.0,}, Relationship.GEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] {33.0, -95.0, -15.0, -4.0, -33.0, -3.0, -20.0, -96.0, -27.0, -13.0, -80.0, -24.0, -3.0, -13.0, -57.0, -76.0,}, Relationship.GEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] {7.0, -95.0, -39.0, -93.0, -7.0, -94.0, -94.0, -62.0, -76.0, -26.0, -53.0, -57.0, -31.0, -76.0, -53.0, -52.0,}, Relationship.GEQ, 0.0));\n+        \n+        double epsilon = 1e-6;\n+        PointValuePair solution = new SimplexSolver().optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                               GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(1.0d, solution.getValue(), epsilon);\n+        Assert.assertTrue(validSolution(solution, constraints, epsilon));\n+    }\n+\n+    @Test\n+    public void testMath828Cycle() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(\n+                new double[] { 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, 0.0);\n+        \n+        ArrayList <LinearConstraint>constraints = new ArrayList<LinearConstraint>();\n+\n+        constraints.add(new LinearConstraint(new double[] {0.0, 16.0, 14.0, 69.0, 1.0, 85.0, 52.0, 43.0, 64.0, 97.0, 14.0, 74.0, 89.0, 28.0, 94.0, 58.0, 13.0, 22.0, 21.0, 17.0, 30.0, 25.0, 1.0, 59.0, 91.0, 78.0, 12.0, 74.0, 56.0, 3.0, 88.0,}, Relationship.GEQ, 91.0));\n+        constraints.add(new LinearConstraint(new double[] {0.0, 60.0, 40.0, 81.0, 71.0, 72.0, 46.0, 45.0, 38.0, 48.0, 40.0, 17.0, 33.0, 85.0, 64.0, 32.0, 84.0, 3.0, 54.0, 44.0, 71.0, 67.0, 90.0, 95.0, 54.0, 99.0, 99.0, 29.0, 52.0, 98.0, 9.0,}, Relationship.GEQ, 54.0));\n+        constraints.add(new LinearConstraint(new double[] {0.0, 41.0, 12.0, 86.0, 90.0, 61.0, 31.0, 41.0, 23.0, 89.0, 17.0, 74.0, 44.0, 27.0, 16.0, 47.0, 80.0, 32.0, 11.0, 56.0, 68.0, 82.0, 11.0, 62.0, 62.0, 53.0, 39.0, 16.0, 48.0, 1.0, 63.0,}, Relationship.GEQ, 62.0));\n+        constraints.add(new LinearConstraint(new double[] {83.0, -76.0, -94.0, -19.0, -15.0, -70.0, -72.0, -57.0, -63.0, -65.0, -22.0, -94.0, -22.0, -88.0, -86.0, -89.0, -72.0, -16.0, -80.0, -49.0, -70.0, -93.0, -95.0, -17.0, -83.0, -97.0, -31.0, -47.0, -31.0, -13.0, -23.0,}, Relationship.GEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] {41.0, -96.0, -41.0, -48.0, -70.0, -43.0, -43.0, -43.0, -97.0, -37.0, -85.0, -70.0, -45.0, -67.0, -87.0, -69.0, -94.0, -54.0, -54.0, -92.0, -79.0, -10.0, -35.0, -20.0, -41.0, -41.0, -65.0, -25.0, -12.0, -8.0, -46.0,}, Relationship.GEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] {27.0, -42.0, -65.0, -49.0, -53.0, -42.0, -17.0, -2.0, -61.0, -31.0, -76.0, -47.0, -8.0, -93.0, -86.0, -62.0, -65.0, -63.0, -22.0, -43.0, -27.0, -23.0, -32.0, -74.0, -27.0, -63.0, -47.0, -78.0, -29.0, -95.0, -73.0,}, Relationship.GEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] {15.0, -46.0, -41.0, -83.0, -98.0, -99.0, -21.0, -35.0, -7.0, -14.0, -80.0, -63.0, -18.0, -42.0, -5.0, -34.0, -56.0, -70.0, -16.0, -18.0, -74.0, -61.0, -47.0, -41.0, -15.0, -79.0, -18.0, -47.0, -88.0, -68.0, -55.0,}, Relationship.GEQ, 0.0));\n+        \n+        double epsilon = 1e-6;\n+        PointValuePair solution = new SimplexSolver().optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                               GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(1.0d, solution.getValue(), epsilon);\n+        Assert.assertTrue(validSolution(solution, constraints, epsilon));        \n+    }\n+\n+    @Test\n+    public void testMath781() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 2, 6, 7 }, 0);\n+\n+        ArrayList<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 2, 1 }, Relationship.LEQ, 2));\n+        constraints.add(new LinearConstraint(new double[] { -1, 1, 1 }, Relationship.LEQ, -1));\n+        constraints.add(new LinearConstraint(new double[] { 2, -3, 1 }, Relationship.LEQ, -1));\n+\n+        double epsilon = 1e-6;\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(false));\n+\n+        Assert.assertTrue(Precision.compareTo(solution.getPoint()[0], 0.0d, epsilon) > 0);\n+        Assert.assertTrue(Precision.compareTo(solution.getPoint()[1], 0.0d, epsilon) > 0);\n+        Assert.assertTrue(Precision.compareTo(solution.getPoint()[2], 0.0d, epsilon) < 0);\n+        Assert.assertEquals(2.0d, solution.getValue(), epsilon);\n+    }\n+\n+    @Test\n+    public void testMath713NegativeVariable() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] {1.0, 1.0}, 0.0d);\n+        ArrayList<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] {1, 0}, Relationship.EQ, 1));\n+\n+        double epsilon = 1e-6;\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+\n+        Assert.assertTrue(Precision.compareTo(solution.getPoint()[0], 0.0d, epsilon) >= 0);\n+        Assert.assertTrue(Precision.compareTo(solution.getPoint()[1], 0.0d, epsilon) >= 0);\n+    }\n+\n+    @Test\n+    public void testMath434NegativeVariable() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] {0.0, 0.0, 1.0}, 0.0d);\n+        ArrayList<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] {1, 1, 0}, Relationship.EQ, 5));\n+        constraints.add(new LinearConstraint(new double[] {0, 0, 1}, Relationship.GEQ, -10));\n+\n+        double epsilon = 1e-6;\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MINIMIZE, new NonNegativeConstraint(false));\n+\n+        Assert.assertEquals(5.0, solution.getPoint()[0] + solution.getPoint()[1], epsilon);\n+        Assert.assertEquals(-10.0, solution.getPoint()[2], epsilon);\n+        Assert.assertEquals(-10.0, solution.getValue(), epsilon);\n+\n+    }\n+\n+    @Test(expected = NoFeasibleSolutionException.class)\n+    public void testMath434UnfeasibleSolution() {\n+        double epsilon = 1e-6;\n+\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] {1.0, 0.0}, 0.0);\n+        ArrayList<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] {epsilon/2, 0.5}, Relationship.EQ, 0));\n+        constraints.add(new LinearConstraint(new double[] {1e-3, 0.1}, Relationship.EQ, 10));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        // allowing only non-negative values, no feasible solution shall be found\n+        solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                        GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+    }\n+\n+    @Test\n+    public void testMath434PivotRowSelection() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] {1.0}, 0.0);\n+\n+        double epsilon = 1e-6;\n+        ArrayList<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] {200}, Relationship.GEQ, 1));\n+        constraints.add(new LinearConstraint(new double[] {100}, Relationship.GEQ, 0.499900001));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MINIMIZE, new NonNegativeConstraint(false));\n+        \n+        Assert.assertTrue(Precision.compareTo(solution.getPoint()[0] * 200.d, 1.d, epsilon) >= 0);\n+        Assert.assertEquals(0.0050, solution.getValue(), epsilon);\n+    }\n+\n+    @Test\n+    public void testMath434PivotRowSelection2() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] {0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);\n+\n+        ArrayList<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d));\n+        constraints.add(new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d));\n+        constraints.add(new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d));\n+        constraints.add(new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d));\n+        constraints.add(new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d));\n+        constraints.add(new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d));\n+        constraints.add(new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d));\n+        constraints.add(new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d));\n+        constraints.add(new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d));\n+\n+        double epsilon = 1e-7;\n+        SimplexSolver simplex = new SimplexSolver();\n+        PointValuePair solution = simplex.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                   GoalType.MINIMIZE, new NonNegativeConstraint(false));\n+        \n+        Assert.assertTrue(Precision.compareTo(solution.getPoint()[0], -1e-18d, epsilon) >= 0);\n+        Assert.assertEquals(1.0d, solution.getPoint()[1], epsilon);        \n+        Assert.assertEquals(0.0d, solution.getPoint()[2], epsilon);\n+        Assert.assertEquals(1.0d, solution.getValue(), epsilon);\n+    }\n+    \n+    @Test\n+    public void testMath272() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 2, 2, 1 }, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 1, 0 }, Relationship.GEQ,  1));\n+        constraints.add(new LinearConstraint(new double[] { 1, 0, 1 }, Relationship.GEQ,  1));\n+        constraints.add(new LinearConstraint(new double[] { 0, 1, 0 }, Relationship.GEQ,  1));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+\n+        Assert.assertEquals(0.0, solution.getPoint()[0], .0000001);\n+        Assert.assertEquals(1.0, solution.getPoint()[1], .0000001);\n+        Assert.assertEquals(1.0, solution.getPoint()[2], .0000001);\n+        Assert.assertEquals(3.0, solution.getValue(), .0000001);\n+    }\n+\n+    @Test\n+    public void testMath286() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 0.8, 0.2, 0.7, 0.3, 0.6, 0.4 }, 0 );\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 0, 1, 0, 1, 0 }, Relationship.EQ, 23.0));\n+        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 1, 0, 1 }, Relationship.EQ, 23.0));\n+        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0, 0, 0 }, Relationship.GEQ, 10.0));\n+        constraints.add(new LinearConstraint(new double[] { 0, 0, 1, 0, 0, 0 }, Relationship.GEQ, 8.0));\n+        constraints.add(new LinearConstraint(new double[] { 0, 0, 0, 0, 1, 0 }, Relationship.GEQ, 5.0));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(true));\n+\n+        Assert.assertEquals(25.8, solution.getValue(), .0000001);\n+        Assert.assertEquals(23.0, solution.getPoint()[0] + solution.getPoint()[2] + solution.getPoint()[4], 0.0000001);\n+        Assert.assertEquals(23.0, solution.getPoint()[1] + solution.getPoint()[3] + solution.getPoint()[5], 0.0000001);\n+        Assert.assertTrue(solution.getPoint()[0] >= 10.0 - 0.0000001);\n+        Assert.assertTrue(solution.getPoint()[2] >= 8.0 - 0.0000001);\n+        Assert.assertTrue(solution.getPoint()[4] >= 5.0 - 0.0000001);\n+    }\n+\n+    @Test\n+    public void testDegeneracy() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 0.8, 0.7 }, 0 );\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 1 }, Relationship.LEQ, 18.0));\n+        constraints.add(new LinearConstraint(new double[] { 1, 0 }, Relationship.GEQ, 10.0));\n+        constraints.add(new LinearConstraint(new double[] { 0, 1 }, Relationship.GEQ, 8.0));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(13.6, solution.getValue(), .0000001);\n+    }\n+\n+    @Test\n+    public void testMath288() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));\n+        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));\n+        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(10.0, solution.getValue(), .0000001);\n+    }\n+\n+    @Test\n+    public void testMath290GEQ() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 1, 5 }, 0 );\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 2, 0 }, Relationship.GEQ, -1.0));\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(0, solution.getValue(), .0000001);\n+        Assert.assertEquals(0, solution.getPoint()[0], .0000001);\n+        Assert.assertEquals(0, solution.getPoint()[1], .0000001);\n+    }\n+\n+    @Test(expected=NoFeasibleSolutionException.class)\n+    public void testMath290LEQ() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 1, 5 }, 0 );\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 2, 0 }, Relationship.LEQ, -1.0));\n+        SimplexSolver solver = new SimplexSolver();\n+        solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                        GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+    }\n+\n+    @Test\n+    public void testMath293() {\n+      LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 0.8, 0.2, 0.7, 0.3, 0.4, 0.6}, 0 );\n+      Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+      constraints.add(new LinearConstraint(new double[] { 1, 0, 1, 0, 1, 0 }, Relationship.EQ, 30.0));\n+      constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 1, 0, 1 }, Relationship.EQ, 30.0));\n+      constraints.add(new LinearConstraint(new double[] { 0.8, 0.2, 0.0, 0.0, 0.0, 0.0 }, Relationship.GEQ, 10.0));\n+      constraints.add(new LinearConstraint(new double[] { 0.0, 0.0, 0.7, 0.3, 0.0, 0.0 }, Relationship.GEQ, 10.0));\n+      constraints.add(new LinearConstraint(new double[] { 0.0, 0.0, 0.0, 0.0, 0.4, 0.6 }, Relationship.GEQ, 10.0));\n+\n+      SimplexSolver solver = new SimplexSolver();\n+      PointValuePair solution1 = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                 GoalType.MAXIMIZE, new NonNegativeConstraint(true));\n+\n+      Assert.assertEquals(15.7143, solution1.getPoint()[0], .0001);\n+      Assert.assertEquals(0.0, solution1.getPoint()[1], .0001);\n+      Assert.assertEquals(14.2857, solution1.getPoint()[2], .0001);\n+      Assert.assertEquals(0.0, solution1.getPoint()[3], .0001);\n+      Assert.assertEquals(0.0, solution1.getPoint()[4], .0001);\n+      Assert.assertEquals(30.0, solution1.getPoint()[5], .0001);\n+      Assert.assertEquals(40.57143, solution1.getValue(), .0001);\n+\n+      double valA = 0.8 * solution1.getPoint()[0] + 0.2 * solution1.getPoint()[1];\n+      double valB = 0.7 * solution1.getPoint()[2] + 0.3 * solution1.getPoint()[3];\n+      double valC = 0.4 * solution1.getPoint()[4] + 0.6 * solution1.getPoint()[5];\n+\n+      f = new LinearObjectiveFunction(new double[] { 0.8, 0.2, 0.7, 0.3, 0.4, 0.6}, 0 );\n+      constraints = new ArrayList<LinearConstraint>();\n+      constraints.add(new LinearConstraint(new double[] { 1, 0, 1, 0, 1, 0 }, Relationship.EQ, 30.0));\n+      constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 1, 0, 1 }, Relationship.EQ, 30.0));\n+      constraints.add(new LinearConstraint(new double[] { 0.8, 0.2, 0.0, 0.0, 0.0, 0.0 }, Relationship.GEQ, valA));\n+      constraints.add(new LinearConstraint(new double[] { 0.0, 0.0, 0.7, 0.3, 0.0, 0.0 }, Relationship.GEQ, valB));\n+      constraints.add(new LinearConstraint(new double[] { 0.0, 0.0, 0.0, 0.0, 0.4, 0.6 }, Relationship.GEQ, valC));\n+\n+      PointValuePair solution2 = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                 GoalType.MAXIMIZE, new NonNegativeConstraint(true));\n+      Assert.assertEquals(40.57143, solution2.getValue(), .0001);\n+    }\n+\n+    @Test\n+    public void testSimplexSolver() {\n+        LinearObjectiveFunction f =\n+            new LinearObjectiveFunction(new double[] { 15, 10 }, 7);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 0 }, Relationship.LEQ, 2));\n+        constraints.add(new LinearConstraint(new double[] { 0, 1 }, Relationship.LEQ, 3));\n+        constraints.add(new LinearConstraint(new double[] { 1, 1 }, Relationship.EQ, 4));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(2.0, solution.getPoint()[0], 0.0);\n+        Assert.assertEquals(2.0, solution.getPoint()[1], 0.0);\n+        Assert.assertEquals(57.0, solution.getValue(), 0.0);\n+    }\n+\n+    @Test\n+    public void testSingleVariableAndConstraint() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 3 }, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1 }, Relationship.LEQ, 10));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(false));\n+        Assert.assertEquals(10.0, solution.getPoint()[0], 0.0);\n+        Assert.assertEquals(30.0, solution.getValue(), 0.0);\n+    }\n+\n+    /**\n+     * With no artificial variables needed (no equals and no greater than\n+     * constraints) we can go straight to Phase 2.\n+     */\n+    @Test\n+    public void testModelWithNoArtificialVars() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 15, 10 }, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 0 }, Relationship.LEQ, 2));\n+        constraints.add(new LinearConstraint(new double[] { 0, 1 }, Relationship.LEQ, 3));\n+        constraints.add(new LinearConstraint(new double[] { 1, 1 }, Relationship.LEQ, 4));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(false));\n+        Assert.assertEquals(2.0, solution.getPoint()[0], 0.0);\n+        Assert.assertEquals(2.0, solution.getPoint()[1], 0.0);\n+        Assert.assertEquals(50.0, solution.getValue(), 0.0);\n+    }\n+\n+    @Test\n+    public void testMinimization() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { -2, 1 }, -5);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 2 }, Relationship.LEQ, 6));\n+        constraints.add(new LinearConstraint(new double[] { 3, 2 }, Relationship.LEQ, 12));\n+        constraints.add(new LinearConstraint(new double[] { 0, 1 }, Relationship.GEQ, 0));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MINIMIZE, new NonNegativeConstraint(false));\n+        Assert.assertEquals(4.0, solution.getPoint()[0], 0.0);\n+        Assert.assertEquals(0.0, solution.getPoint()[1], 0.0);\n+        Assert.assertEquals(-13.0, solution.getValue(), 0.0);\n+    }\n+\n+    @Test\n+    public void testSolutionWithNegativeDecisionVariable() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { -2, 1 }, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 1 }, Relationship.GEQ, 6));\n+        constraints.add(new LinearConstraint(new double[] { 1, 2 }, Relationship.LEQ, 14));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(false));\n+        Assert.assertEquals(-2.0, solution.getPoint()[0], 0.0);\n+        Assert.assertEquals(8.0, solution.getPoint()[1], 0.0);\n+        Assert.assertEquals(12.0, solution.getValue(), 0.0);\n+    }\n+\n+    @Test(expected = NoFeasibleSolutionException.class)\n+    public void testInfeasibleSolution() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 15 }, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1 }, Relationship.LEQ, 1));\n+        constraints.add(new LinearConstraint(new double[] { 1 }, Relationship.GEQ, 3));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                        GoalType.MAXIMIZE, new NonNegativeConstraint(false));\n+    }\n+\n+    @Test(expected = UnboundedSolutionException.class)\n+    public void testUnboundedSolution() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 15, 10 }, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 0 }, Relationship.EQ, 2));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                        GoalType.MAXIMIZE, new NonNegativeConstraint(false));\n+    }\n+\n+    @Test\n+    public void testRestrictVariablesToNonNegative() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 409, 523, 70, 204, 339 }, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] {    43,   56, 345,  56,    5 }, Relationship.LEQ,  4567456));\n+        constraints.add(new LinearConstraint(new double[] {    12,   45,   7,  56,   23 }, Relationship.LEQ,    56454));\n+        constraints.add(new LinearConstraint(new double[] {     8,  768,   0,  34, 7456 }, Relationship.LEQ,  1923421));\n+        constraints.add(new LinearConstraint(new double[] { 12342, 2342,  34, 678, 2342 }, Relationship.GEQ,     4356));\n+        constraints.add(new LinearConstraint(new double[] {    45,  678,  76,  52,   23 }, Relationship.EQ,    456356));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(2902.92783505155, solution.getPoint()[0], .0000001);\n+        Assert.assertEquals(480.419243986254, solution.getPoint()[1], .0000001);\n+        Assert.assertEquals(0.0, solution.getPoint()[2], .0000001);\n+        Assert.assertEquals(0.0, solution.getPoint()[3], .0000001);\n+        Assert.assertEquals(0.0, solution.getPoint()[4], .0000001);\n+        Assert.assertEquals(1438556.7491409, solution.getValue(), .0000001);\n+    }\n+\n+    @Test\n+    public void testEpsilon() {\n+      LinearObjectiveFunction f =\n+          new LinearObjectiveFunction(new double[] { 10, 5, 1 }, 0);\n+      Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+      constraints.add(new LinearConstraint(new double[] {  9, 8, 0 }, Relationship.EQ,  17));\n+      constraints.add(new LinearConstraint(new double[] {  0, 7, 8 }, Relationship.LEQ,  7));\n+      constraints.add(new LinearConstraint(new double[] { 10, 0, 2 }, Relationship.LEQ, 10));\n+\n+      SimplexSolver solver = new SimplexSolver();\n+      PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                GoalType.MAXIMIZE, new NonNegativeConstraint(false));\n+      Assert.assertEquals(1.0, solution.getPoint()[0], 0.0);\n+      Assert.assertEquals(1.0, solution.getPoint()[1], 0.0);\n+      Assert.assertEquals(0.0, solution.getPoint()[2], 0.0);\n+      Assert.assertEquals(15.0, solution.getValue(), 0.0);\n+  }\n+\n+    @Test\n+    public void testTrivialModel() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 1, 1 }, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] { 1, 1 }, Relationship.EQ,  0));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MAXIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(0, solution.getValue(), .0000001);\n+    }\n+\n+    @Test\n+    public void testLargeModel() {\n+        double[] objective = new double[] {\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 12, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           12, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 12, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 12, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 12, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 12, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n+                                           1, 1, 1, 1, 1, 1};\n+\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(objective, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(equationFromString(objective.length, \"x0 + x1 + x2 + x3 - x12 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 - x13 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 >= 49\"));\n+        constraints.add(equationFromString(objective.length, \"x0 + x1 + x2 + x3 >= 42\"));\n+        constraints.add(equationFromString(objective.length, \"x14 + x15 + x16 + x17 - x26 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 - x27 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x14 + x15 + x16 + x17 - x12 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 - x13 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x28 + x29 + x30 + x31 - x40 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x32 + x33 + x34 + x35 + x36 + x37 + x38 + x39 - x41 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x32 + x33 + x34 + x35 + x36 + x37 + x38 + x39 >= 49\"));\n+        constraints.add(equationFromString(objective.length, \"x28 + x29 + x30 + x31 >= 42\"));\n+        constraints.add(equationFromString(objective.length, \"x42 + x43 + x44 + x45 - x54 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x46 + x47 + x48 + x49 + x50 + x51 + x52 + x53 - x55 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x42 + x43 + x44 + x45 - x40 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x46 + x47 + x48 + x49 + x50 + x51 + x52 + x53 - x41 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x56 + x57 + x58 + x59 - x68 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x60 + x61 + x62 + x63 + x64 + x65 + x66 + x67 - x69 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x60 + x61 + x62 + x63 + x64 + x65 + x66 + x67 >= 51\"));\n+        constraints.add(equationFromString(objective.length, \"x56 + x57 + x58 + x59 >= 44\"));\n+        constraints.add(equationFromString(objective.length, \"x70 + x71 + x72 + x73 - x82 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x74 + x75 + x76 + x77 + x78 + x79 + x80 + x81 - x83 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x70 + x71 + x72 + x73 - x68 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x74 + x75 + x76 + x77 + x78 + x79 + x80 + x81 - x69 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x84 + x85 + x86 + x87 - x96 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x88 + x89 + x90 + x91 + x92 + x93 + x94 + x95 - x97 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x88 + x89 + x90 + x91 + x92 + x93 + x94 + x95 >= 51\"));\n+        constraints.add(equationFromString(objective.length, \"x84 + x85 + x86 + x87 >= 44\"));\n+        constraints.add(equationFromString(objective.length, \"x98 + x99 + x100 + x101 - x110 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x102 + x103 + x104 + x105 + x106 + x107 + x108 + x109 - x111 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x98 + x99 + x100 + x101 - x96 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x102 + x103 + x104 + x105 + x106 + x107 + x108 + x109 - x97 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x112 + x113 + x114 + x115 - x124 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x116 + x117 + x118 + x119 + x120 + x121 + x122 + x123 - x125 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x116 + x117 + x118 + x119 + x120 + x121 + x122 + x123 >= 49\"));\n+        constraints.add(equationFromString(objective.length, \"x112 + x113 + x114 + x115 >= 42\"));\n+        constraints.add(equationFromString(objective.length, \"x126 + x127 + x128 + x129 - x138 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x130 + x131 + x132 + x133 + x134 + x135 + x136 + x137 - x139 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x126 + x127 + x128 + x129 - x124 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x130 + x131 + x132 + x133 + x134 + x135 + x136 + x137 - x125 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x140 + x141 + x142 + x143 - x152 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x144 + x145 + x146 + x147 + x148 + x149 + x150 + x151 - x153 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x144 + x145 + x146 + x147 + x148 + x149 + x150 + x151 >= 59\"));\n+        constraints.add(equationFromString(objective.length, \"x140 + x141 + x142 + x143 >= 42\"));\n+        constraints.add(equationFromString(objective.length, \"x154 + x155 + x156 + x157 - x166 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x158 + x159 + x160 + x161 + x162 + x163 + x164 + x165 - x167 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x154 + x155 + x156 + x157 - x152 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x158 + x159 + x160 + x161 + x162 + x163 + x164 + x165 - x153 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x83 + x82 - x168 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x111 + x110 - x169 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x170 - x182 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x171 - x183 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x172 - x184 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x173 - x185 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x174 - x186 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x175 + x176 - x187 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x177 - x188 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x178 - x189 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x179 - x190 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x180 - x191 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x181 - x192 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x170 - x26 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x171 - x27 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x172 - x54 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x173 - x55 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x174 - x168 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x177 - x169 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x178 - x138 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x179 - x139 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x180 - x166 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x181 - x167 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x193 - x205 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x194 - x206 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x195 - x207 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x196 - x208 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x197 - x209 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x198 + x199 - x210 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x200 - x211 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x201 - x212 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x202 - x213 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x203 - x214 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x204 - x215 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x193 - x182 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x194 - x183 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x195 - x184 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x196 - x185 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x197 - x186 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x198 + x199 - x187 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x200 - x188 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x201 - x189 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x202 - x190 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x203 - x191 = 0\"));\n+        constraints.add(equationFromString(objective.length, \"x204 - x192 = 0\"));\n+\n+        SimplexSolver solver = new SimplexSolver();\n+        PointValuePair solution = solver.optimize(DEFAULT_MAX_ITER, f, new LinearConstraintSet(constraints),\n+                                                  GoalType.MINIMIZE, new NonNegativeConstraint(true));\n+        Assert.assertEquals(7518.0, solution.getValue(), .0000001);\n+    }\n+\n+    /**\n+     * Converts a test string to a {@link LinearConstraint}.\n+     * Ex: x0 + x1 + x2 + x3 - x12 = 0\n+     */\n+    private LinearConstraint equationFromString(int numCoefficients, String s) {\n+        Relationship relationship;\n+        if (s.contains(\">=\")) {\n+            relationship = Relationship.GEQ;\n+        } else if (s.contains(\"<=\")) {\n+            relationship = Relationship.LEQ;\n+        } else if (s.contains(\"=\")) {\n+            relationship = Relationship.EQ;\n+        } else {\n+            throw new IllegalArgumentException();\n+        }\n+\n+        String[] equationParts = s.split(\"[>|<]?=\");\n+        double rhs = Double.parseDouble(equationParts[1].trim());\n+\n+        double[] lhs = new double[numCoefficients];\n+        String left = equationParts[0].replaceAll(\" ?x\", \"\");\n+        String[] coefficients = left.split(\" \");\n+        for (String coefficient : coefficients) {\n+            double value = coefficient.charAt(0) == '-' ? -1 : 1;\n+            int index = Integer.parseInt(coefficient.replaceFirst(\"[+|-]\", \"\").trim());\n+            lhs[index] = value;\n+        }\n+        return new LinearConstraint(lhs, relationship, rhs);\n+    }\n+\n+    private static boolean validSolution(PointValuePair solution, List<LinearConstraint> constraints, double epsilon) {\n+        double[] vals = solution.getPoint();\n+        for (LinearConstraint c : constraints) {\n+            double[] coeffs = c.getCoefficients().toArray();\n+            double result = 0.0d;\n+            for (int i = 0; i < vals.length; i++) {\n+                result += vals[i] * coeffs[i];\n+            }\n+            \n+            switch (c.getRelationship()) {\n+            case EQ:\n+                if (!Precision.equals(result, c.getValue(), epsilon)) {\n+                    return false;\n+                }\n+                break;\n+                \n+            case GEQ:\n+                if (Precision.compareTo(result, c.getValue(), epsilon) < 0) {\n+                    return false;\n+                }\n+                break;\n+                \n+            case LEQ:\n+                if (Precision.compareTo(result, c.getValue(), epsilon) > 0) {\n+                    return false;\n+                }\n+                break;\n+            }\n+        }\n+        \n+        return true;\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/linear/SimplexTableauTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.linear;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import org.apache.commons.math3.TestUtils;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class SimplexTableauTest {\n+\n+    @Test\n+    public void testInitialization() {\n+        LinearObjectiveFunction f = createFunction();\n+        Collection<LinearConstraint> constraints = createConstraints();\n+        SimplexTableau tableau =\n+            new SimplexTableau(f, constraints, GoalType.MAXIMIZE, false, 1.0e-6);\n+        double[][] expectedInitialTableau = {\n+                                             {-1, 0,  -1,  -1,  2, 0, 0, 0, -4},\n+                                             { 0, 1, -15, -10, 25, 0, 0, 0,  0},\n+                                             { 0, 0,   1,   0, -1, 1, 0, 0,  2},\n+                                             { 0, 0,   0,   1, -1, 0, 1, 0,  3},\n+                                             { 0, 0,   1,   1, -2, 0, 0, 1,  4}\n+        };\n+        assertMatrixEquals(expectedInitialTableau, tableau.getData());\n+    }\n+\n+    @Test\n+    public void testDropPhase1Objective() {\n+        LinearObjectiveFunction f = createFunction();\n+        Collection<LinearConstraint> constraints = createConstraints();\n+        SimplexTableau tableau =\n+            new SimplexTableau(f, constraints, GoalType.MAXIMIZE, false, 1.0e-6);\n+        double[][] expectedTableau = {\n+                                      { 1, -15, -10, 0, 0, 0, 0},\n+                                      { 0,   1,   0, 1, 0, 0, 2},\n+                                      { 0,   0,   1, 0, 1, 0, 3},\n+                                      { 0,   1,   1, 0, 0, 1, 4}\n+        };\n+        tableau.dropPhase1Objective();\n+        assertMatrixEquals(expectedTableau, tableau.getData());\n+    }\n+\n+    @Test\n+    public void testTableauWithNoArtificialVars() {\n+        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] {15, 10}, 0);\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] {1, 0}, Relationship.LEQ, 2));\n+        constraints.add(new LinearConstraint(new double[] {0, 1}, Relationship.LEQ, 3));\n+        constraints.add(new LinearConstraint(new double[] {1, 1}, Relationship.LEQ, 4));\n+        SimplexTableau tableau =\n+            new SimplexTableau(f, constraints, GoalType.MAXIMIZE, false, 1.0e-6);\n+        double[][] initialTableau = {\n+                                     {1, -15, -10, 25, 0, 0, 0, 0},\n+                                     {0,   1,   0, -1, 1, 0, 0, 2},\n+                                     {0,   0,   1, -1, 0, 1, 0, 3},\n+                                     {0,   1,   1, -2, 0, 0, 1, 4}\n+        };\n+        assertMatrixEquals(initialTableau, tableau.getData());\n+    }\n+\n+    @Test\n+    public void testSerial() {\n+        LinearObjectiveFunction f = createFunction();\n+        Collection<LinearConstraint> constraints = createConstraints();\n+        SimplexTableau tableau =\n+            new SimplexTableau(f, constraints, GoalType.MAXIMIZE, false, 1.0e-6);\n+        Assert.assertEquals(tableau, TestUtils.serializeAndRecover(tableau));\n+    }\n+\n+    private LinearObjectiveFunction createFunction() {\n+        return new LinearObjectiveFunction(new double[] {15, 10}, 0);\n+    }\n+\n+    private Collection<LinearConstraint> createConstraints() {\n+        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\n+        constraints.add(new LinearConstraint(new double[] {1, 0}, Relationship.LEQ, 2));\n+        constraints.add(new LinearConstraint(new double[] {0, 1}, Relationship.LEQ, 3));\n+        constraints.add(new LinearConstraint(new double[] {1, 1}, Relationship.EQ, 4));\n+        return constraints;\n+    }\n+\n+    private void assertMatrixEquals(double[][] expected, double[][] result) {\n+        Assert.assertEquals(\"Wrong number of rows.\", expected.length, result.length);\n+        for (int i = 0; i < expected.length; i++) {\n+            Assert.assertEquals(\"Wrong number of columns.\", expected[i].length, result[i].length);\n+            for (int j = 0; j < expected[i].length; j++) {\n+                Assert.assertEquals(\"Wrong value at position [\" + i + \",\" + j + \"]\", expected[i][j], result[i][j], 1.0e-15);\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/MultiStartMultivariateOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.SimpleValueChecker;\n+import org.apache.commons.math3.optim.nonlinear.scalar.gradient.CircleScalar;\n+import org.apache.commons.math3.optim.nonlinear.scalar.gradient.NonLinearConjugateGradientOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.NelderMeadSimplex;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer;\n+import org.apache.commons.math3.random.GaussianRandomGenerator;\n+import org.apache.commons.math3.random.JDKRandomGenerator;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+import org.apache.commons.math3.random.UncorrelatedRandomVectorGenerator;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class MultiStartMultivariateOptimizerTest {\n+    @Test\n+    public void testCircleFitting() {\n+        CircleScalar circle = new CircleScalar();\n+        circle.addPoint( 30.0,  68.0);\n+        circle.addPoint( 50.0,  -6.0);\n+        circle.addPoint(110.0, -20.0);\n+        circle.addPoint( 35.0,  15.0);\n+        circle.addPoint( 45.0,  97.0);\n+        // TODO: the wrapper around NonLinearConjugateGradientOptimizer is a temporary hack for\n+        // version 3.1 of the library. It should be removed when NonLinearConjugateGradientOptimizer\n+        // will officially be declared as implementing MultivariateDifferentiableOptimizer\n+        GradientMultivariateOptimizer underlying\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-10, 1e-10));\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(753289573253l);\n+        RandomVectorGenerator generator\n+            = new UncorrelatedRandomVectorGenerator(new double[] { 50, 50 },\n+                                                    new double[] { 10, 10 },\n+                                                    new GaussianRandomGenerator(g));\n+        MultiStartMultivariateOptimizer optimizer\n+            = new MultiStartMultivariateOptimizer(underlying, 10, generator);\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(200),\n+                                 circle.getObjectiveFunction(),\n+                                 circle.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 98.680, 47.345 }));\n+        Assert.assertEquals(200, optimizer.getMaxEvaluations());\n+        PointValuePair[] optima = optimizer.getOptima();\n+        for (PointValuePair o : optima) {\n+            Vector2D center = new Vector2D(o.getPointRef()[0], o.getPointRef()[1]);\n+            Assert.assertEquals(69.960161753, circle.getRadius(center), 1e-8);\n+            Assert.assertEquals(96.075902096, center.getX(), 1e-8);\n+            Assert.assertEquals(48.135167894, center.getY(), 1e-8);\n+        }\n+        Assert.assertTrue(optimizer.getEvaluations() > 70);\n+        Assert.assertTrue(optimizer.getEvaluations() < 90);\n+        Assert.assertEquals(3.1267527, optimum.getValue(), 1e-8);\n+    }\n+\n+    @Test\n+    public void testRosenbrock() {\n+        Rosenbrock rosenbrock = new Rosenbrock();\n+        SimplexOptimizer underlying\n+            = new SimplexOptimizer(new SimpleValueChecker(-1, 1e-3));\n+        NelderMeadSimplex simplex = new NelderMeadSimplex(new double[][] {\n+                { -1.2,  1.0 },\n+                { 0.9, 1.2 } ,\n+                {  3.5, -2.3 }\n+            });\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(16069223052l);\n+        RandomVectorGenerator generator\n+            = new UncorrelatedRandomVectorGenerator(2, new GaussianRandomGenerator(g));\n+        MultiStartMultivariateOptimizer optimizer\n+            = new MultiStartMultivariateOptimizer(underlying, 10, generator);\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(1100),\n+                                 new ObjectiveFunction(rosenbrock),\n+                                 GoalType.MINIMIZE,\n+                                 simplex,\n+                                 new InitialGuess(new double[] { -1.2, 1.0 }));\n+\n+        Assert.assertEquals(rosenbrock.getCount(), optimizer.getEvaluations());\n+        Assert.assertTrue(optimizer.getEvaluations() > 900);\n+        Assert.assertTrue(optimizer.getEvaluations() < 1200);\n+        Assert.assertTrue(optimum.getValue() < 8e-4);\n+    }\n+\n+    private static class Rosenbrock implements MultivariateFunction {\n+        private int count;\n+\n+        public Rosenbrock() {\n+            count = 0;\n+        }\n+\n+        public double value(double[] x) {\n+            ++count;\n+            double a = x[1] - x[0] * x[0];\n+            double b = 1 - x[0];\n+            return 100 * a * a + b * b;\n+        }\n+\n+        public int getCount() {\n+            return count;\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/MultivariateFunctionMappingAdapterTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.optim.SimplePointChecker;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.AbstractSimplex;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.NelderMeadSimplex;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class MultivariateFunctionMappingAdapterTest {\n+    @Test\n+    public void testStartSimplexInsideRange() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(2.0, 2.5, 1.0, 3.0, 2.0, 3.0);\n+        final MultivariateFunctionMappingAdapter wrapped\n+            = new MultivariateFunctionMappingAdapter(biQuadratic,\n+                                                     biQuadratic.getLower(),\n+                                                     biQuadratic.getUpper());\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[][] {\n+                wrapped.boundedToUnbounded(new double[] { 1.5, 2.75 }),\n+                wrapped.boundedToUnbounded(new double[] { 1.5, 2.95 }),\n+                wrapped.boundedToUnbounded(new double[] { 1.7, 2.90 })\n+            });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(300),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(wrapped.boundedToUnbounded(new double[] { 1.5, 2.25 })));\n+        final double[] bounded = wrapped.unboundedToBounded(optimum.getPoint());\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), bounded[0], 2e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), bounded[1], 2e-7);\n+    }\n+\n+    @Test\n+    public void testOptimumOutsideRange() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(4.0, 0.0, 1.0, 3.0, 2.0, 3.0);\n+        final MultivariateFunctionMappingAdapter wrapped\n+            = new MultivariateFunctionMappingAdapter(biQuadratic,\n+                                                     biQuadratic.getLower(),\n+                                                     biQuadratic.getUpper());\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[][] {\n+                wrapped.boundedToUnbounded(new double[] { 1.5, 2.75 }),\n+                wrapped.boundedToUnbounded(new double[] { 1.5, 2.95 }),\n+                wrapped.boundedToUnbounded(new double[] { 1.7, 2.90 })\n+            });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(wrapped.boundedToUnbounded(new double[] { 1.5, 2.25 })));\n+        final double[] bounded = wrapped.unboundedToBounded(optimum.getPoint());\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), bounded[0], 2e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), bounded[1], 2e-7);\n+    }\n+\n+    @Test\n+    public void testUnbounded() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(4.0, 0.0,\n+                                                        Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY,\n+                                                        Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY);\n+        final MultivariateFunctionMappingAdapter wrapped\n+            = new MultivariateFunctionMappingAdapter(biQuadratic,\n+                                                     biQuadratic.getLower(),\n+                                                     biQuadratic.getUpper());\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[][] {\n+                wrapped.boundedToUnbounded(new double[] { 1.5, 2.75 }),\n+                wrapped.boundedToUnbounded(new double[] { 1.5, 2.95 }),\n+                wrapped.boundedToUnbounded(new double[] { 1.7, 2.90 })\n+            });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(300),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(wrapped.boundedToUnbounded(new double[] { 1.5, 2.25 })));\n+        final double[] bounded = wrapped.unboundedToBounded(optimum.getPoint());\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), bounded[0], 2e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), bounded[1], 2e-7);\n+    }\n+\n+    @Test\n+    public void testHalfBounded() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(4.0, 4.0,\n+                                                        1.0, Double.POSITIVE_INFINITY,\n+                                                        Double.NEGATIVE_INFINITY, 3.0);\n+        final MultivariateFunctionMappingAdapter wrapped\n+            = new MultivariateFunctionMappingAdapter(biQuadratic,\n+                                                     biQuadratic.getLower(),\n+                                                     biQuadratic.getUpper());\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-13, 1e-30);\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[][] {\n+                wrapped.boundedToUnbounded(new double[] { 1.5, 2.75 }),\n+                wrapped.boundedToUnbounded(new double[] { 1.5, 2.95 }),\n+                wrapped.boundedToUnbounded(new double[] { 1.7, 2.90 })\n+            });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(200),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(wrapped.boundedToUnbounded(new double[] { 1.5, 2.25 })));\n+        final double[] bounded = wrapped.unboundedToBounded(optimum.getPoint());\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), bounded[0], 1e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), bounded[1], 1e-7);\n+    }\n+\n+    private static class BiQuadratic implements MultivariateFunction {\n+\n+        private final double xOptimum;\n+        private final double yOptimum;\n+\n+        private final double xMin;\n+        private final double xMax;\n+        private final double yMin;\n+        private final double yMax;\n+\n+        public BiQuadratic(final double xOptimum, final double yOptimum,\n+                           final double xMin, final double xMax,\n+                           final double yMin, final double yMax) {\n+            this.xOptimum = xOptimum;\n+            this.yOptimum = yOptimum;\n+            this.xMin     = xMin;\n+            this.xMax     = xMax;\n+            this.yMin     = yMin;\n+            this.yMax     = yMax;\n+        }\n+\n+        public double value(double[] point) {\n+            // the function should never be called with out of range points\n+            Assert.assertTrue(point[0] >= xMin);\n+            Assert.assertTrue(point[0] <= xMax);\n+            Assert.assertTrue(point[1] >= yMin);\n+            Assert.assertTrue(point[1] <= yMax);\n+\n+            final double dx = point[0] - xOptimum;\n+            final double dy = point[1] - yOptimum;\n+            return dx * dx + dy * dy;\n+\n+        }\n+\n+        public double[] getLower() {\n+            return new double[] { xMin, yMin };\n+        }\n+\n+        public double[] getUpper() {\n+            return new double[] { xMax, yMax };\n+        }\n+\n+        public double getBoundedXOptimum() {\n+            return (xOptimum < xMin) ? xMin : ((xOptimum > xMax) ? xMax : xOptimum);\n+        }\n+\n+        public double getBoundedYOptimum() {\n+            return (yOptimum < yMin) ? yMin : ((yOptimum > yMax) ? yMax : yOptimum);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/MultivariateFunctionPenaltyAdapterTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.optim.SimplePointChecker;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.AbstractSimplex;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.NelderMeadSimplex;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class MultivariateFunctionPenaltyAdapterTest {\n+    @Test\n+    public void testStartSimplexInsideRange() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(2.0, 2.5, 1.0, 3.0, 2.0, 3.0);\n+        final MultivariateFunctionPenaltyAdapter wrapped\n+              = new MultivariateFunctionPenaltyAdapter(biQuadratic,\n+                                                       biQuadratic.getLower(),\n+                                                       biQuadratic.getUpper(),\n+                                                       1000.0, new double[] { 100.0, 100.0 });\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[] { 1.0, 0.5 });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(300),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 1.5, 2.25 }));\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), optimum.getPoint()[0], 2e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), optimum.getPoint()[1], 2e-7);\n+    }\n+\n+    @Test\n+    public void testStartSimplexOutsideRange() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(2.0, 2.5, 1.0, 3.0, 2.0, 3.0);\n+        final MultivariateFunctionPenaltyAdapter wrapped\n+              = new MultivariateFunctionPenaltyAdapter(biQuadratic,\n+                                                       biQuadratic.getLower(),\n+                                                       biQuadratic.getUpper(),\n+                                                       1000.0, new double[] { 100.0, 100.0 });\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[] { 1.0, 0.5 });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(300),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { -1.5, 4.0 }));\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), optimum.getPoint()[0], 2e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), optimum.getPoint()[1], 2e-7);\n+    }\n+\n+    @Test\n+    public void testOptimumOutsideRange() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(4.0, 0.0, 1.0, 3.0, 2.0, 3.0);\n+        final MultivariateFunctionPenaltyAdapter wrapped\n+            =  new MultivariateFunctionPenaltyAdapter(biQuadratic,\n+                                                      biQuadratic.getLower(),\n+                                                      biQuadratic.getUpper(),\n+                                                      1000.0, new double[] { 100.0, 100.0 });\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(new SimplePointChecker<PointValuePair>(1.0e-11, 1.0e-20));\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[] { 1.0, 0.5 });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(600),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { -1.5, 4.0 }));\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), optimum.getPoint()[0], 2e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), optimum.getPoint()[1], 2e-7);\n+    }\n+\n+    @Test\n+    public void testUnbounded() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(4.0, 0.0,\n+                                                        Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY,\n+                                                        Double.NEGATIVE_INFINITY, Double.POSITIVE_INFINITY);\n+        final MultivariateFunctionPenaltyAdapter wrapped\n+            = new MultivariateFunctionPenaltyAdapter(biQuadratic,\n+                                                     biQuadratic.getLower(),\n+                                                     biQuadratic.getUpper(),\n+                                                     1000.0, new double[] { 100.0, 100.0 });\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[] { 1.0, 0.5 });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(300),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { -1.5, 4.0 }));\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), optimum.getPoint()[0], 2e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), optimum.getPoint()[1], 2e-7);\n+    }\n+\n+    @Test\n+    public void testHalfBounded() {\n+        final BiQuadratic biQuadratic = new BiQuadratic(4.0, 4.0,\n+                                                        1.0, Double.POSITIVE_INFINITY,\n+                                                        Double.NEGATIVE_INFINITY, 3.0);\n+        final MultivariateFunctionPenaltyAdapter wrapped\n+              = new MultivariateFunctionPenaltyAdapter(biQuadratic,\n+                                                       biQuadratic.getLower(),\n+                                                       biQuadratic.getUpper(),\n+                                                       1000.0, new double[] { 100.0, 100.0 });\n+\n+        SimplexOptimizer optimizer = new SimplexOptimizer(new SimplePointChecker<PointValuePair>(1.0e-10, 1.0e-20));\n+        final AbstractSimplex simplex = new NelderMeadSimplex(new double[] { 1.0, 0.5 });\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(400),\n+                                 new ObjectiveFunction(wrapped),\n+                                 simplex,\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { -1.5, 4.0 }));\n+\n+        Assert.assertEquals(biQuadratic.getBoundedXOptimum(), optimum.getPoint()[0], 2e-7);\n+        Assert.assertEquals(biQuadratic.getBoundedYOptimum(), optimum.getPoint()[1], 2e-7);\n+    }\n+\n+    private static class BiQuadratic implements MultivariateFunction {\n+\n+        private final double xOptimum;\n+        private final double yOptimum;\n+\n+        private final double xMin;\n+        private final double xMax;\n+        private final double yMin;\n+        private final double yMax;\n+\n+        public BiQuadratic(final double xOptimum, final double yOptimum,\n+                           final double xMin, final double xMax,\n+                           final double yMin, final double yMax) {\n+            this.xOptimum = xOptimum;\n+            this.yOptimum = yOptimum;\n+            this.xMin     = xMin;\n+            this.xMax     = xMax;\n+            this.yMin     = yMin;\n+            this.yMax     = yMax;\n+        }\n+\n+        public double value(double[] point) {\n+            // the function should never be called with out of range points\n+            Assert.assertTrue(point[0] >= xMin);\n+            Assert.assertTrue(point[0] <= xMax);\n+            Assert.assertTrue(point[1] >= yMin);\n+            Assert.assertTrue(point[1] <= yMax);\n+\n+            final double dx = point[0] - xOptimum;\n+            final double dy = point[1] - yOptimum;\n+            return dx * dx + dy * dy;\n+\n+        }\n+\n+        public double[] getLower() {\n+            return new double[] { xMin, yMin };\n+        }\n+\n+        public double[] getUpper() {\n+            return new double[] { xMax, yMax };\n+        }\n+\n+        public double getBoundedXOptimum() {\n+            return (xOptimum < xMin) ? xMin : ((xOptimum > xMax) ? xMax : xOptimum);\n+        }\n+\n+        public double getBoundedYOptimum() {\n+            return (yOptimum < yMin) ? yMin : ((yOptimum > yMax) ? yMax : yOptimum);\n+        }\n+\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/gradient/CircleScalar.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar.gradient;\n+\n+import java.util.ArrayList;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.optim.nonlinear.scalar.ObjectiveFunctionGradient;\n+\n+/**\n+ * Class used in the tests.\n+ */\n+public class CircleScalar {\n+    private ArrayList<Vector2D> points;\n+\n+    public CircleScalar() {\n+        points  = new ArrayList<Vector2D>();\n+    }\n+\n+    public void addPoint(double px, double py) {\n+        points.add(new Vector2D(px, py));\n+    }\n+\n+    public double getRadius(Vector2D center) {\n+        double r = 0;\n+        for (Vector2D point : points) {\n+            r += point.distance(center);\n+        }\n+        return r / points.size();\n+    }\n+\n+    public ObjectiveFunction getObjectiveFunction() {\n+        return new ObjectiveFunction(new MultivariateFunction() {\n+                public double value(double[] params)  {\n+                    Vector2D center = new Vector2D(params[0], params[1]);\n+                    double radius = getRadius(center);\n+                    double sum = 0;\n+                    for (Vector2D point : points) {\n+                        double di = point.distance(center) - radius;\n+                        sum += di * di;\n+                    }\n+                    return sum;\n+                }\n+            });\n+    }\n+\n+    public ObjectiveFunctionGradient getObjectiveFunctionGradient() {\n+        return new ObjectiveFunctionGradient(new MultivariateVectorFunction() {\n+                public double[] value(double[] params) {\n+                    Vector2D center = new Vector2D(params[0], params[1]);\n+                    double radius = getRadius(center);\n+                    // gradient of the sum of squared residuals\n+                    double dJdX = 0;\n+                    double dJdY = 0;\n+                    for (Vector2D pk : points) {\n+                        double dk = pk.distance(center);\n+                        dJdX += (center.getX() - pk.getX()) * (dk - radius) / dk;\n+                        dJdY += (center.getY() - pk.getY()) * (dk - radius) / dk;\n+                    }\n+                    dJdX *= 2;\n+                    dJdY *= 2;\n+\n+                    return new double[] { dJdX, dJdY };\n+                }\n+            });\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar.gradient;\n+\n+import java.io.Serializable;\n+\n+import org.apache.commons.math3.analysis.DifferentiableMultivariateFunction;\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;\n+import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableFunction;\n+import org.apache.commons.math3.analysis.solvers.BrentSolver;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.MathIllegalArgumentException;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n+import org.apache.commons.math3.linear.BlockRealMatrix;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.SimpleValueChecker;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.optim.nonlinear.scalar.ObjectiveFunctionGradient;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files.\n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+ *\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+ *\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class NonLinearConjugateGradientOptimizerTest {\n+    @Test\n+    public void testTrivial() {\n+        LinearProblem problem\n+            = new LinearProblem(new double[][] { { 2 } }, new double[] { 3 });\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 0 }));\n+        Assert.assertEquals(1.5, optimum.getPoint()[0], 1.0e-10);\n+        Assert.assertEquals(0.0, optimum.getValue(), 1.0e-10);\n+    }\n+\n+    @Test\n+    public void testColumnsPermutation() {\n+        LinearProblem problem\n+            = new LinearProblem(new double[][] { { 1.0, -1.0 }, { 0.0, 2.0 }, { 1.0, -2.0 } },\n+                                new double[] { 4.0, 6.0, 1.0 });\n+\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 0, 0 }));\n+        Assert.assertEquals(7.0, optimum.getPoint()[0], 1.0e-10);\n+        Assert.assertEquals(3.0, optimum.getPoint()[1], 1.0e-10);\n+        Assert.assertEquals(0.0, optimum.getValue(), 1.0e-10);\n+\n+    }\n+\n+    @Test\n+    public void testNoDependency() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 2, 0, 0, 0, 0, 0 },\n+                { 0, 2, 0, 0, 0, 0 },\n+                { 0, 0, 2, 0, 0, 0 },\n+                { 0, 0, 0, 2, 0, 0 },\n+                { 0, 0, 0, 0, 2, 0 },\n+                { 0, 0, 0, 0, 0, 2 }\n+        }, new double[] { 0.0, 1.1, 2.2, 3.3, 4.4, 5.5 });\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 0, 0, 0, 0, 0, 0 }));\n+        for (int i = 0; i < problem.target.length; ++i) {\n+            Assert.assertEquals(0.55 * i, optimum.getPoint()[i], 1.0e-10);\n+        }\n+    }\n+\n+    @Test\n+    public void testOneSet() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  1,  0, 0 },\n+                { -1,  1, 0 },\n+                {  0, -1, 1 }\n+        }, new double[] { 1, 1, 1});\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 0, 0, 0 }));\n+        Assert.assertEquals(1.0, optimum.getPoint()[0], 1.0e-10);\n+        Assert.assertEquals(2.0, optimum.getPoint()[1], 1.0e-10);\n+        Assert.assertEquals(3.0, optimum.getPoint()[2], 1.0e-10);\n+\n+    }\n+\n+    @Test\n+    public void testTwoSets() {\n+        final double epsilon = 1.0e-7;\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  2,  1,   0,  4,       0, 0 },\n+                { -4, -2,   3, -7,       0, 0 },\n+                {  4,  1,  -2,  8,       0, 0 },\n+                {  0, -3, -12, -1,       0, 0 },\n+                {  0,  0,   0,  0, epsilon, 1 },\n+                {  0,  0,   0,  0,       1, 1 }\n+        }, new double[] { 2, -9, 2, 2, 1 + epsilon * epsilon, 2});\n+\n+        final Preconditioner preconditioner\n+            = new Preconditioner() {\n+                    public double[] precondition(double[] point, double[] r) {\n+                        double[] d = r.clone();\n+                        d[0] /=  72.0;\n+                        d[1] /=  30.0;\n+                        d[2] /= 314.0;\n+                        d[3] /= 260.0;\n+                        d[4] /= 2 * (1 + epsilon * epsilon);\n+                        d[5] /= 4.0;\n+                        return d;\n+                    }\n+                };\n+\n+        NonLinearConjugateGradientOptimizer optimizer\n+           = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                     new SimpleValueChecker(1e-13, 1e-13),\n+                                                     new BrentSolver(),\n+                                                     preconditioner);\n+\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 0, 0, 0, 0, 0, 0 }));\n+        Assert.assertEquals( 3.0, optimum.getPoint()[0], 1.0e-10);\n+        Assert.assertEquals( 4.0, optimum.getPoint()[1], 1.0e-10);\n+        Assert.assertEquals(-1.0, optimum.getPoint()[2], 1.0e-10);\n+        Assert.assertEquals(-2.0, optimum.getPoint()[3], 1.0e-10);\n+        Assert.assertEquals( 1.0 + epsilon, optimum.getPoint()[4], 1.0e-10);\n+        Assert.assertEquals( 1.0 - epsilon, optimum.getPoint()[5], 1.0e-10);\n+\n+    }\n+\n+    @Test\n+    public void testNonInversible() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  1, 2, -3 },\n+                {  2, 1,  3 },\n+                { -3, 0, -9 }\n+        }, new double[] { 1, 1, 1 });\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 0, 0, 0 }));\n+        Assert.assertTrue(optimum.getValue() > 0.5);\n+    }\n+\n+    @Test\n+    public void testIllConditioned() {\n+        LinearProblem problem1 = new LinearProblem(new double[][] {\n+                { 10.0, 7.0,  8.0,  7.0 },\n+                {  7.0, 5.0,  6.0,  5.0 },\n+                {  8.0, 6.0, 10.0,  9.0 },\n+                {  7.0, 5.0,  9.0, 10.0 }\n+        }, new double[] { 32, 23, 33, 31 });\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-13, 1e-13),\n+                                                      new BrentSolver(1e-15, 1e-15));\n+        PointValuePair optimum1\n+            = optimizer.optimize(new MaxEval(200),\n+                                 problem1.getObjectiveFunction(),\n+                                 problem1.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 0, 1, 2, 3 }));\n+        Assert.assertEquals(1.0, optimum1.getPoint()[0], 1.0e-4);\n+        Assert.assertEquals(1.0, optimum1.getPoint()[1], 1.0e-4);\n+        Assert.assertEquals(1.0, optimum1.getPoint()[2], 1.0e-4);\n+        Assert.assertEquals(1.0, optimum1.getPoint()[3], 1.0e-4);\n+\n+        LinearProblem problem2 = new LinearProblem(new double[][] {\n+                { 10.00, 7.00, 8.10, 7.20 },\n+                {  7.08, 5.04, 6.00, 5.00 },\n+                {  8.00, 5.98, 9.89, 9.00 },\n+                {  6.99, 4.99, 9.00, 9.98 }\n+        }, new double[] { 32, 23, 33, 31 });\n+        PointValuePair optimum2\n+            = optimizer.optimize(new MaxEval(200),\n+                                 problem2.getObjectiveFunction(),\n+                                 problem2.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 0, 1, 2, 3 }));\n+        Assert.assertEquals(-81.0, optimum2.getPoint()[0], 1.0e-1);\n+        Assert.assertEquals(137.0, optimum2.getPoint()[1], 1.0e-1);\n+        Assert.assertEquals(-34.0, optimum2.getPoint()[2], 1.0e-1);\n+        Assert.assertEquals( 22.0, optimum2.getPoint()[3], 1.0e-1);\n+\n+    }\n+\n+    @Test\n+    public void testMoreEstimatedParametersSimple() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 3.0, 2.0,  0.0, 0.0 },\n+                { 0.0, 1.0, -1.0, 1.0 },\n+                { 2.0, 0.0,  1.0, 0.0 }\n+        }, new double[] { 7.0, 3.0, 5.0 });\n+\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 7, 6, 5, 4 }));\n+        Assert.assertEquals(0, optimum.getValue(), 1.0e-10);\n+\n+    }\n+\n+    @Test\n+    public void testMoreEstimatedParametersUnsorted() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                 { 1.0, 1.0,  0.0,  0.0, 0.0,  0.0 },\n+                 { 0.0, 0.0,  1.0,  1.0, 1.0,  0.0 },\n+                 { 0.0, 0.0,  0.0,  0.0, 1.0, -1.0 },\n+                 { 0.0, 0.0, -1.0,  1.0, 0.0,  1.0 },\n+                 { 0.0, 0.0,  0.0, -1.0, 1.0,  0.0 }\n+        }, new double[] { 3.0, 12.0, -1.0, 7.0, 1.0 });\n+        NonLinearConjugateGradientOptimizer optimizer\n+           = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                     new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 2, 2, 2, 2, 2, 2 }));\n+        Assert.assertEquals(0, optimum.getValue(), 1.0e-10);\n+    }\n+\n+    @Test\n+    public void testRedundantEquations() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 1.0,  1.0 },\n+                { 1.0, -1.0 },\n+                { 1.0,  3.0 }\n+        }, new double[] { 3.0, 1.0, 5.0 });\n+\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 1, 1 }));\n+        Assert.assertEquals(2.0, optimum.getPoint()[0], 1.0e-8);\n+        Assert.assertEquals(1.0, optimum.getPoint()[1], 1.0e-8);\n+\n+    }\n+\n+    @Test\n+    public void testInconsistentEquations() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 1.0,  1.0 },\n+                { 1.0, -1.0 },\n+                { 1.0,  3.0 }\n+        }, new double[] { 3.0, 1.0, 4.0 });\n+\n+        NonLinearConjugateGradientOptimizer optimizer\n+            = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                      new SimpleValueChecker(1e-6, 1e-6));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 1, 1 }));\n+        Assert.assertTrue(optimum.getValue() > 0.1);\n+\n+    }\n+\n+    @Test\n+    public void testCircleFitting() {\n+        CircleScalar problem = new CircleScalar();\n+        problem.addPoint( 30.0,  68.0);\n+        problem.addPoint( 50.0,  -6.0);\n+        problem.addPoint(110.0, -20.0);\n+        problem.addPoint( 35.0,  15.0);\n+        problem.addPoint( 45.0,  97.0);\n+        NonLinearConjugateGradientOptimizer optimizer\n+           = new NonLinearConjugateGradientOptimizer(NonLinearConjugateGradientOptimizer.Formula.POLAK_RIBIERE,\n+                                                     new SimpleValueChecker(1e-30, 1e-30),\n+                                                     new BrentSolver(1e-15, 1e-13));\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getObjectiveFunction(),\n+                                 problem.getObjectiveFunctionGradient(),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 98.680, 47.345 }));\n+        Vector2D center = new Vector2D(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n+        Assert.assertEquals(69.960161753, problem.getRadius(center), 1.0e-8);\n+        Assert.assertEquals(96.075902096, center.getX(), 1.0e-8);\n+        Assert.assertEquals(48.135167894, center.getY(), 1.0e-8);\n+    }\n+\n+    private static class LinearProblem {\n+        final RealMatrix factors;\n+        final double[] target;\n+\n+        public LinearProblem(double[][] factors,\n+                             double[] target) {\n+            this.factors = new BlockRealMatrix(factors);\n+            this.target  = target;\n+        }\n+\n+        public ObjectiveFunction getObjectiveFunction() {\n+            return new ObjectiveFunction(new MultivariateFunction() {\n+                    public double value(double[] point) {\n+                        double[] y = factors.operate(point);\n+                        double sum = 0;\n+                        for (int i = 0; i < y.length; ++i) {\n+                            double ri = y[i] - target[i];\n+                            sum += ri * ri;\n+                        }\n+                        return sum;\n+                    }\n+                });\n+        }\n+\n+        public ObjectiveFunctionGradient getObjectiveFunctionGradient() {\n+            return new ObjectiveFunctionGradient(new MultivariateVectorFunction() {\n+                    public double[] value(double[] point) {\n+                        double[] r = factors.operate(point);\n+                        for (int i = 0; i < r.length; ++i) {\n+                            r[i] -= target[i];\n+                        }\n+                        double[] p = factors.transpose().operate(r);\n+                        for (int i = 0; i < p.length; ++i) {\n+                            p[i] *= 2;\n+                        }\n+                        return p;\n+                    }\n+                });\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/BOBYQAOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import java.util.Arrays;\n+import java.util.Random;\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.exception.NumberIsTooLargeException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.SimpleBounds;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test for {@link BOBYQAOptimizer}.\n+ */\n+public class BOBYQAOptimizerTest {\n+\n+    static final int DIM = 13;\n+   \n+    @Test(expected=NumberIsTooLargeException.class)\n+    public void testInitOutOfBounds() {\n+        double[] startPoint = point(DIM, 3);\n+        double[][] boundaries = boundaries(DIM, -1, 2);\n+        doTest(new Rosen(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-13, 1e-6, 2000, null);\n+    }\n+    \n+    @Test(expected=DimensionMismatchException.class)\n+    public void testBoundariesDimensionMismatch() {\n+        double[] startPoint = point(DIM, 0.5);\n+        double[][] boundaries = boundaries(DIM + 1, -1, 2);\n+        doTest(new Rosen(), startPoint, boundaries,\n+               GoalType.MINIMIZE, \n+               1e-13, 1e-6, 2000, null);\n+    }\n+\n+    @Test(expected=NumberIsTooSmallException.class)\n+    public void testProblemDimensionTooSmall() {\n+        double[] startPoint = point(1, 0.5);\n+        doTest(new Rosen(), startPoint, null,\n+               GoalType.MINIMIZE,\n+               1e-13, 1e-6, 2000, null);\n+    }\n+\n+    @Test(expected=TooManyEvaluationsException.class)\n+    public void testMaxEvaluations() {\n+        final int lowMaxEval = 2;\n+        double[] startPoint = point(DIM, 0.1);\n+        double[][] boundaries = null;\n+        doTest(new Rosen(), startPoint, boundaries,\n+               GoalType.MINIMIZE, \n+               1e-13, 1e-6, lowMaxEval, null);\n+     }\n+\n+    @Test\n+    public void testRosen() {\n+        double[] startPoint = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected = new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-13, 1e-6, 2000, expected);\n+     }\n+\n+    @Test\n+    public void testMaximize() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected = new PointValuePair(point(DIM,0.0),1.0);\n+        doTest(new MinusElli(), startPoint, boundaries,\n+                GoalType.MAXIMIZE, \n+                2e-10, 5e-6, 1000, expected);\n+        boundaries = boundaries(DIM,-0.3,0.3); \n+        startPoint = point(DIM,0.1);\n+        doTest(new MinusElli(), startPoint, boundaries,\n+                GoalType.MAXIMIZE, \n+                2e-10, 5e-6, 1000, expected);\n+    }\n+\n+    @Test\n+    public void testEllipse() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Elli(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-13, 1e-6, 1000, expected);\n+     }\n+\n+    @Test\n+    public void testElliRotated() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new ElliRotated(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-12, 1e-6, 10000, expected);\n+    }\n+\n+    @Test\n+    public void testCigar() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Cigar(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-13, 1e-6, 100, expected);\n+    }\n+\n+    @Test\n+    public void testTwoAxes() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new TwoAxes(), startPoint, boundaries,\n+                GoalType.MINIMIZE, 2*\n+                1e-13, 1e-6, 100, expected);\n+     }\n+\n+    @Test\n+    public void testCigTab() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new CigTab(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-13, 5e-5, 100, expected);\n+     }\n+\n+    @Test\n+    public void testSphere() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Sphere(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-13, 1e-6, 100, expected);\n+    }\n+\n+    @Test\n+    public void testTablet() {\n+        double[] startPoint = point(DIM,1.0); \n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Tablet(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-13, 1e-6, 100, expected);\n+    }\n+\n+    @Test\n+    public void testDiffPow() {\n+        double[] startPoint = point(DIM/2,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM/2,0.0),0.0);\n+        doTest(new DiffPow(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-8, 1e-1, 12000, expected);\n+    }\n+\n+    @Test\n+    public void testSsDiffPow() {\n+        double[] startPoint = point(DIM/2,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM/2,0.0),0.0);\n+        doTest(new SsDiffPow(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-2, 1.3e-1, 50000, expected);\n+    }\n+\n+    @Test\n+    public void testAckley() {\n+        double[] startPoint = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Ackley(), startPoint, boundaries,\n+                GoalType.MINIMIZE,\n+                1e-8, 1e-5, 1000, expected);\n+    }\n+\n+    @Test\n+    public void testRastrigin() {\n+        double[] startPoint = point(DIM,1.0);\n+\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Rastrigin(), startPoint, boundaries,\n+                GoalType.MINIMIZE, \n+                1e-13, 1e-6, 1000, expected);\n+    }\n+\n+    @Test\n+    public void testConstrainedRosen() {\n+        double[] startPoint = point(DIM,0.1);\n+\n+        double[][] boundaries = boundaries(DIM,-1,2);\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, boundaries,\n+                GoalType.MINIMIZE,\n+                1e-13, 1e-6, 2000, expected);\n+    }\n+\n+    // See MATH-728\n+    @Test\n+    public void testConstrainedRosenWithMoreInterpolationPoints() {\n+        final double[] startPoint = point(DIM, 0.1);\n+        final double[][] boundaries = boundaries(DIM, -1, 2);\n+        final PointValuePair expected = new PointValuePair(point(DIM, 1.0), 0.0);\n+\n+        // This should have been 78 because in the code the hard limit is\n+        // said to be\n+        //   ((DIM + 1) * (DIM + 2)) / 2 - (2 * DIM + 1)\n+        // i.e. 78 in this case, but the test fails for 48, 59, 62, 63, 64,\n+        // 65, 66, ...\n+        final int maxAdditionalPoints = 47;\n+\n+        for (int num = 1; num <= maxAdditionalPoints; num++) {\n+            doTest(new Rosen(), startPoint, boundaries,\n+                   GoalType.MINIMIZE,\n+                   1e-12, 1e-6, 2000,\n+                   num,\n+                   expected,\n+                   \"num=\" + num);\n+        }\n+    }\n+\n+    /**\n+     * @param func Function to optimize.\n+     * @param startPoint Starting point.\n+     * @param boundaries Upper / lower point limit.\n+     * @param goal Minimization or maximization.\n+     * @param fTol Tolerance relative error on the objective function.\n+     * @param pointTol Tolerance for checking that the optimum is correct.\n+     * @param maxEvaluations Maximum number of evaluations.\n+     * @param expected Expected point / value.\n+     */\n+    private void doTest(MultivariateFunction func,\n+                        double[] startPoint,\n+                        double[][] boundaries,\n+                        GoalType goal,\n+                        double fTol,\n+                        double pointTol,\n+                        int maxEvaluations,\n+                        PointValuePair expected) {\n+        doTest(func,\n+               startPoint,\n+               boundaries,\n+               goal,\n+               fTol,\n+               pointTol,\n+               maxEvaluations,\n+               0,\n+               expected,\n+               \"\");\n+    }\n+\n+    /**\n+     * @param func Function to optimize.\n+     * @param startPoint Starting point.\n+     * @param boundaries Upper / lower point limit.\n+     * @param goal Minimization or maximization.\n+     * @param fTol Tolerance relative error on the objective function.\n+     * @param pointTol Tolerance for checking that the optimum is correct.\n+     * @param maxEvaluations Maximum number of evaluations.\n+     * @param additionalInterpolationPoints Number of interpolation to used\n+     * in addition to the default (2 * dim + 1).\n+     * @param expected Expected point / value.\n+     */\n+    private void doTest(MultivariateFunction func,\n+                        double[] startPoint,\n+                        double[][] boundaries,\n+                        GoalType goal,\n+                        double fTol,\n+                        double pointTol,\n+                        int maxEvaluations,\n+                        int additionalInterpolationPoints,\n+                        PointValuePair expected,\n+                        String assertMsg) {\n+\n+//         System.out.println(func.getClass().getName() + \" BEGIN\"); // XXX\n+\n+        int dim = startPoint.length;\n+        final int numIterpolationPoints = 2 * dim + 1 + additionalInterpolationPoints;\n+        BOBYQAOptimizer optim = new BOBYQAOptimizer(numIterpolationPoints);\n+        PointValuePair result = boundaries == null ?\n+            optim.optimize(new MaxEval(maxEvaluations),\n+                           new ObjectiveFunction(func),\n+                           goal,\n+                           SimpleBounds.unbounded(dim),\n+                           new InitialGuess(startPoint)) :\n+            optim.optimize(new MaxEval(maxEvaluations),\n+                           new ObjectiveFunction(func),\n+                           goal,\n+                           new InitialGuess(startPoint),\n+                           new SimpleBounds(boundaries[0],\n+                                            boundaries[1]));\n+//        System.out.println(func.getClass().getName() + \" = \" \n+//              + optim.getEvaluations() + \" f(\");\n+//        for (double x: result.getPoint())  System.out.print(x + \" \");\n+//        System.out.println(\") = \" +  result.getValue());\n+        Assert.assertEquals(assertMsg, expected.getValue(), result.getValue(), fTol);\n+        for (int i = 0; i < dim; i++) {\n+            Assert.assertEquals(expected.getPoint()[i],\n+                                result.getPoint()[i], pointTol);\n+        }\n+\n+//         System.out.println(func.getClass().getName() + \" END\"); // XXX\n+    }\n+\n+    private static double[] point(int n, double value) {\n+        double[] ds = new double[n];\n+        Arrays.fill(ds, value);\n+        return ds;\n+    }\n+\n+    private static double[][] boundaries(int dim,\n+            double lower, double upper) {\n+        double[][] boundaries = new double[2][dim];\n+        for (int i = 0; i < dim; i++)\n+            boundaries[0][i] = lower;\n+        for (int i = 0; i < dim; i++)\n+            boundaries[1][i] = upper;\n+        return boundaries;\n+    }\n+\n+    private static class Sphere implements MultivariateFunction {\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length; ++i)\n+                f += x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class Cigar implements MultivariateFunction {\n+        private double factor;\n+\n+        Cigar() {\n+            this(1e3);\n+        }\n+\n+        Cigar(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = x[0] * x[0];\n+            for (int i = 1; i < x.length; ++i)\n+                f += factor * x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class Tablet implements MultivariateFunction {\n+        private double factor;\n+\n+        Tablet() {\n+            this(1e3);\n+        }\n+\n+        Tablet(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = factor * x[0] * x[0];\n+            for (int i = 1; i < x.length; ++i)\n+                f += x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class CigTab implements MultivariateFunction {\n+        private double factor;\n+\n+        CigTab() {\n+            this(1e4);\n+        }\n+\n+        CigTab(double axisratio) {\n+            factor = axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            int end = x.length - 1;\n+            double f = x[0] * x[0] / factor + factor * x[end] * x[end];\n+            for (int i = 1; i < end; ++i)\n+                f += x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class TwoAxes implements MultivariateFunction {\n+\n+        private double factor;\n+\n+        TwoAxes() {\n+            this(1e6);\n+        }\n+\n+        TwoAxes(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length; ++i)\n+                f += (i < x.length / 2 ? factor : 1) * x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class ElliRotated implements MultivariateFunction {\n+        private Basis B = new Basis();\n+        private double factor;\n+\n+        ElliRotated() {\n+            this(1e3);\n+        }\n+\n+        ElliRotated(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            x = B.Rotate(x);\n+            for (int i = 0; i < x.length; ++i)\n+                f += Math.pow(factor, i / (x.length - 1.)) * x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class Elli implements MultivariateFunction {\n+\n+        private double factor;\n+\n+        Elli() {\n+            this(1e3);\n+        }\n+\n+        Elli(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length; ++i)\n+                f += Math.pow(factor, i / (x.length - 1.)) * x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class MinusElli implements MultivariateFunction {\n+        private final Elli elli = new Elli();\n+        public double value(double[] x) {\n+            return 1.0 - elli.value(x);\n+        }\n+    }\n+\n+    private static class DiffPow implements MultivariateFunction {\n+//        private int fcount = 0;\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length; ++i)\n+                f += Math.pow(Math.abs(x[i]), 2. + 10 * (double) i\n+                        / (x.length - 1.));\n+//            System.out.print(\"\" + (fcount++) + \") \");\n+//            for (int i = 0; i < x.length; i++)\n+//                System.out.print(x[i] +  \" \");\n+//            System.out.println(\" = \" + f);\n+            return f;\n+        }\n+    }\n+\n+    private static class SsDiffPow implements MultivariateFunction {\n+\n+        public double value(double[] x) {\n+            double f = Math.pow(new DiffPow().value(x), 0.25);\n+            return f;\n+        }\n+    }\n+\n+    private static class Rosen implements MultivariateFunction {\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length - 1; ++i)\n+                f += 1e2 * (x[i] * x[i] - x[i + 1]) * (x[i] * x[i] - x[i + 1])\n+                + (x[i] - 1.) * (x[i] - 1.);\n+            return f;\n+        }\n+    }\n+\n+    private static class Ackley implements MultivariateFunction {\n+        private double axisratio;\n+\n+        Ackley(double axra) {\n+            axisratio = axra;\n+        }\n+\n+        public Ackley() {\n+            this(1);\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            double res2 = 0;\n+            double fac = 0;\n+            for (int i = 0; i < x.length; ++i) {\n+                fac = Math.pow(axisratio, (i - 1.) / (x.length - 1.));\n+                f += fac * fac * x[i] * x[i];\n+                res2 += Math.cos(2. * Math.PI * fac * x[i]);\n+            }\n+            f = (20. - 20. * Math.exp(-0.2 * Math.sqrt(f / x.length))\n+                    + Math.exp(1.) - Math.exp(res2 / x.length));\n+            return f;\n+        }\n+    }\n+\n+    private static class Rastrigin implements MultivariateFunction {\n+\n+        private double axisratio;\n+        private double amplitude;\n+\n+        Rastrigin() {\n+            this(1, 10);\n+        }\n+\n+        Rastrigin(double axisratio, double amplitude) {\n+            this.axisratio = axisratio;\n+            this.amplitude = amplitude;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            double fac;\n+            for (int i = 0; i < x.length; ++i) {\n+                fac = Math.pow(axisratio, (i - 1.) / (x.length - 1.));\n+                if (i == 0 && x[i] < 0)\n+                    fac *= 1.;\n+                f += fac * fac * x[i] * x[i] + amplitude\n+                * (1. - Math.cos(2. * Math.PI * fac * x[i]));\n+            }\n+            return f;\n+        }\n+    }\n+\n+    private static class Basis {\n+        double[][] basis;\n+        Random rand = new Random(2); // use not always the same basis\n+\n+        double[] Rotate(double[] x) {\n+            GenBasis(x.length);\n+            double[] y = new double[x.length];\n+            for (int i = 0; i < x.length; ++i) {\n+                y[i] = 0;\n+                for (int j = 0; j < x.length; ++j)\n+                    y[i] += basis[i][j] * x[j];\n+            }\n+            return y;\n+        }\n+\n+        void GenBasis(int DIM) {\n+            if (basis != null ? basis.length == DIM : false)\n+                return;\n+\n+            double sp;\n+            int i, j, k;\n+\n+            /* generate orthogonal basis */\n+            basis = new double[DIM][DIM];\n+            for (i = 0; i < DIM; ++i) {\n+                /* sample components gaussian */\n+                for (j = 0; j < DIM; ++j)\n+                    basis[i][j] = rand.nextGaussian();\n+                /* substract projection of previous vectors */\n+                for (j = i - 1; j >= 0; --j) {\n+                    for (sp = 0., k = 0; k < DIM; ++k)\n+                        sp += basis[i][k] * basis[j][k]; /* scalar product */\n+                    for (k = 0; k < DIM; ++k)\n+                        basis[i][k] -= sp * basis[j][k]; /* substract */\n+                }\n+                /* normalize */\n+                for (sp = 0., k = 0; k < DIM; ++k)\n+                    sp += basis[i][k] * basis[i][k]; /* squared norm */\n+                for (k = 0; k < DIM; ++k)\n+                    basis[i][k] /= Math.sqrt(sp);\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import java.util.Arrays;\n+import java.util.Random;\n+import org.apache.commons.math3.Retry;\n+import org.apache.commons.math3.RetryRunner;\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.exception.NumberIsTooLargeException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.MathUnsupportedOperationException;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.NotPositiveException;\n+import org.apache.commons.math3.exception.OutOfRangeException;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.SimpleBounds;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.random.MersenneTwister;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Assert;\n+import org.junit.Test;\n+import org.junit.Ignore;\n+import org.junit.runner.RunWith;\n+\n+/**\n+ * Test for {@link CMAESOptimizer}.\n+ */\n+@RunWith(RetryRunner.class)\n+public class CMAESOptimizerTest {\n+\n+    static final int DIM = 13;\n+    static final int LAMBDA = 4 + (int)(3.*Math.log(DIM));\n+   \n+    @Test(expected = NumberIsTooLargeException.class)\n+    public void testInitOutofbounds1() {\n+        double[] startPoint = point(DIM,3);\n+        double[] insigma = point(DIM, 0.3);\n+        double[][] boundaries = boundaries(DIM,-1,2);\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+    @Test(expected = NumberIsTooSmallException.class)\n+    public void testInitOutofbounds2() {\n+        double[] startPoint = point(DIM, -2);\n+        double[] insigma = point(DIM, 0.3);\n+        double[][] boundaries = boundaries(DIM,-1,2);\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+    \n+    @Test(expected = DimensionMismatchException.class)\n+    public void testBoundariesDimensionMismatch() {\n+        double[] startPoint = point(DIM,0.5);\n+        double[] insigma = point(DIM, 0.3);\n+        double[][] boundaries = boundaries(DIM+1,-1,2);\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test(expected = NotPositiveException.class)\n+    public void testInputSigmaNegative() {\n+        double[] startPoint = point(DIM,0.5);\n+        double[] insigma = point(DIM,-0.5);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test(expected = OutOfRangeException.class)\n+    public void testInputSigmaOutOfRange() {\n+        double[] startPoint = point(DIM,0.5);\n+        double[] insigma = point(DIM, 1.1);\n+        double[][] boundaries = boundaries(DIM,-0.5,0.5);\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test(expected = DimensionMismatchException.class)\n+    public void testInputSigmaDimensionMismatch() {\n+        double[] startPoint = point(DIM,0.5);\n+        double[] insigma = point(DIM + 1, 0.5);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+    \n+    @Test\n+    @Retry(3)\n+    public void testRosen() {\n+        double[] startPoint = point(DIM,0.1);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    @Retry(3)\n+    public void testMaximize() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),1.0);\n+        doTest(new MinusElli(), startPoint, insigma, boundaries,\n+                GoalType.MAXIMIZE, LAMBDA, true, 0, 1.0-1e-13,\n+                2e-10, 5e-6, 100000, expected);\n+        doTest(new MinusElli(), startPoint, insigma, boundaries,\n+                GoalType.MAXIMIZE, LAMBDA, false, 0, 1.0-1e-13,\n+                2e-10, 5e-6, 100000, expected);\n+        boundaries = boundaries(DIM,-0.3,0.3); \n+        startPoint = point(DIM,0.1);\n+        doTest(new MinusElli(), startPoint, insigma, boundaries,\n+                GoalType.MAXIMIZE, LAMBDA, true, 0, 1.0-1e-13,\n+                2e-10, 5e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testEllipse() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Elli(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+        doTest(new Elli(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testElliRotated() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new ElliRotated(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+        doTest(new ElliRotated(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testCigar() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Cigar(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 200000, expected);\n+        doTest(new Cigar(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testCigarWithBoundaries() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = boundaries(DIM, -1e100, Double.POSITIVE_INFINITY);\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Cigar(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 200000, expected);\n+        doTest(new Cigar(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testTwoAxes() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new TwoAxes(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 2*LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 200000, expected);\n+        doTest(new TwoAxes(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 2*LAMBDA, false, 0, 1e-13,\n+                1e-8, 1e-3, 200000, expected);\n+    }\n+\n+    @Test\n+    public void testCigTab() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.3);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new CigTab(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 5e-5, 100000, expected);\n+        doTest(new CigTab(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n+                1e-13, 5e-5, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testSphere() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Sphere(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+        doTest(new Sphere(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testTablet() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Tablet(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+        doTest(new Tablet(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testDiffPow() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new DiffPow(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 10, true, 0, 1e-13,\n+                1e-8, 1e-1, 100000, expected);\n+        doTest(new DiffPow(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 10, false, 0, 1e-13,\n+                1e-8, 2e-1, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testSsDiffPow() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new SsDiffPow(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 10, true, 0, 1e-13,\n+                1e-4, 1e-1, 200000, expected);\n+        doTest(new SsDiffPow(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 10, false, 0, 1e-13,\n+                1e-4, 1e-1, 200000, expected);\n+    }\n+\n+    @Test\n+    public void testAckley() {\n+        double[] startPoint = point(DIM,1.0);\n+        double[] insigma = point(DIM,1.0);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Ackley(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 2*LAMBDA, true, 0, 1e-13,\n+                1e-9, 1e-5, 100000, expected);\n+        doTest(new Ackley(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 2*LAMBDA, false, 0, 1e-13,\n+                1e-9, 1e-5, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testRastrigin() {\n+        double[] startPoint = point(DIM,0.1);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,0.0),0.0);\n+        doTest(new Rastrigin(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, (int)(200*Math.sqrt(DIM)), true, 0, 1e-13,\n+                1e-13, 1e-6, 200000, expected);\n+        doTest(new Rastrigin(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, (int)(200*Math.sqrt(DIM)), false, 0, 1e-13,\n+                1e-13, 1e-6, 200000, expected);\n+    }\n+\n+    @Test\n+    public void testConstrainedRosen() {\n+        double[] startPoint = point(DIM, 0.1);\n+        double[] insigma = point(DIM, 0.1);\n+        double[][] boundaries = boundaries(DIM, -1, 2);\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 2*LAMBDA, true, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, 2*LAMBDA, false, 0, 1e-13,\n+                1e-13, 1e-6, 100000, expected);\n+    }\n+\n+    @Test\n+    public void testDiagonalRosen() {\n+        double[] startPoint = point(DIM,0.1);\n+        double[] insigma = point(DIM,0.1);\n+        double[][] boundaries = null;\n+        PointValuePair expected =\n+            new PointValuePair(point(DIM,1.0),0.0);\n+        doTest(new Rosen(), startPoint, insigma, boundaries,\n+                GoalType.MINIMIZE, LAMBDA, false, 1, 1e-13,\n+                1e-10, 1e-4, 1000000, expected);\n+     }\n+\n+    @Test\n+    public void testMath864() {\n+        final CMAESOptimizer optimizer\n+            = new CMAESOptimizer(30000, 0, true, 10,\n+                                 0, new MersenneTwister(), false, null);\n+        final MultivariateFunction fitnessFunction = new MultivariateFunction() {\n+                public double value(double[] parameters) {\n+                    final double target = 1;\n+                    final double error = target - parameters[0];\n+                    return error * error;\n+                }\n+            };\n+\n+        final double[] start = { 0 };\n+        final double[] lower = { -1e6 };\n+        final double[] upper = { 1.5 };\n+        final double[] sigma = { 1e-1 };\n+        final double[] result = optimizer.optimize(new MaxEval(10000),\n+                                                   new ObjectiveFunction(fitnessFunction),\n+                                                   GoalType.MINIMIZE,\n+                                                   new CMAESOptimizer.PopulationSize(5),\n+                                                   new CMAESOptimizer.Sigma(sigma),\n+                                                   new InitialGuess(start),\n+                                                   new SimpleBounds(lower, upper)).getPoint();\n+        Assert.assertTrue(\"Out of bounds (\" + result[0] + \" > \" + upper[0] + \")\",\n+                          result[0] <= upper[0]);\n+    }\n+\n+    /**\n+     * Cf. MATH-867\n+     */\n+    @Test\n+    public void testFitAccuracyDependsOnBoundary() {\n+        final CMAESOptimizer optimizer\n+            = new CMAESOptimizer(30000, 0, true, 10,\n+                                 0, new MersenneTwister(), false, null);\n+        final MultivariateFunction fitnessFunction = new MultivariateFunction() {\n+                public double value(double[] parameters) {\n+                    final double target = 11.1;\n+                    final double error = target - parameters[0];\n+                    return error * error;\n+                }\n+            };\n+\n+        final double[] start = { 1 };\n+ \n+        // No bounds.\n+        PointValuePair result = optimizer.optimize(new MaxEval(100000),\n+                                                   new ObjectiveFunction(fitnessFunction),\n+                                                   GoalType.MINIMIZE,\n+                                                   SimpleBounds.unbounded(1),\n+                                                   new CMAESOptimizer.PopulationSize(5),\n+                                                   new CMAESOptimizer.Sigma(new double[] { 1e-1 }),\n+                                                   new InitialGuess(start));\n+        final double resNoBound = result.getPoint()[0];\n+\n+        // Optimum is near the lower bound.\n+        final double[] lower = { -20 };\n+        final double[] upper = { 5e16 };\n+        final double[] sigma = { 10 };\n+        result = optimizer.optimize(new MaxEval(100000),\n+                                    new ObjectiveFunction(fitnessFunction),\n+                                    GoalType.MINIMIZE,\n+                                    new CMAESOptimizer.PopulationSize(5),\n+                                    new CMAESOptimizer.Sigma(sigma),\n+                                    new InitialGuess(start),\n+                                    new SimpleBounds(lower, upper));\n+        final double resNearLo = result.getPoint()[0];\n+\n+        // Optimum is near the upper bound.\n+        lower[0] = -5e16;\n+        upper[0] = 20;\n+        result = optimizer.optimize(new MaxEval(100000),\n+                                    new ObjectiveFunction(fitnessFunction),\n+                                    GoalType.MINIMIZE,\n+                                    new CMAESOptimizer.PopulationSize(5),\n+                                    new CMAESOptimizer.Sigma(sigma),\n+                                    new InitialGuess(start),\n+                                    new SimpleBounds(lower, upper));\n+        final double resNearHi = result.getPoint()[0];\n+\n+        // System.out.println(\"resNoBound=\" + resNoBound +\n+        //                    \" resNearLo=\" + resNearLo +\n+        //                    \" resNearHi=\" + resNearHi);\n+\n+        // The two values currently differ by a substantial amount, indicating that\n+        // the bounds definition can prevent reaching the optimum.\n+        Assert.assertEquals(resNoBound, resNearLo, 1e-3);\n+        Assert.assertEquals(resNoBound, resNearHi, 1e-3);\n+    }\n+ \n+    /**\n+     * @param func Function to optimize.\n+     * @param startPoint Starting point.\n+     * @param inSigma Individual input sigma.\n+     * @param boundaries Upper / lower point limit.\n+     * @param goal Minimization or maximization.\n+     * @param lambda Population size used for offspring.\n+     * @param isActive Covariance update mechanism.\n+     * @param diagonalOnly Simplified covariance update.\n+     * @param stopValue Termination criteria for optimization.\n+     * @param fTol Tolerance relative error on the objective function.\n+     * @param pointTol Tolerance for checking that the optimum is correct.\n+     * @param maxEvaluations Maximum number of evaluations.\n+     * @param expected Expected point / value.\n+     */\n+    private void doTest(MultivariateFunction func,\n+                        double[] startPoint,\n+                        double[] inSigma,\n+                        double[][] boundaries,\n+                        GoalType goal,\n+                        int lambda,\n+                        boolean isActive,\n+                        int diagonalOnly, \n+                        double stopValue,\n+                        double fTol,\n+                        double pointTol,\n+                        int maxEvaluations,\n+                        PointValuePair expected) {\n+        int dim = startPoint.length;\n+        // test diagonalOnly = 0 - slow but normally fewer feval#\n+        CMAESOptimizer optim = new CMAESOptimizer(30000, stopValue, isActive, diagonalOnly,\n+                                                  0, new MersenneTwister(), false, null);\n+        PointValuePair result = boundaries == null ?\n+            optim.optimize(new MaxEval(maxEvaluations),\n+                           new ObjectiveFunction(func),\n+                           goal,\n+                           new InitialGuess(startPoint),\n+                           SimpleBounds.unbounded(dim),\n+                           new CMAESOptimizer.Sigma(inSigma),\n+                           new CMAESOptimizer.PopulationSize(lambda)) :\n+            optim.optimize(new MaxEval(maxEvaluations),\n+                           new ObjectiveFunction(func),\n+                           goal,\n+                           new SimpleBounds(boundaries[0],\n+                                            boundaries[1]),\n+                           new InitialGuess(startPoint),\n+                           new CMAESOptimizer.Sigma(inSigma),\n+                           new CMAESOptimizer.PopulationSize(lambda));\n+\n+        // System.out.println(\"sol=\" + Arrays.toString(result.getPoint()));\n+        Assert.assertEquals(expected.getValue(), result.getValue(), fTol);\n+        for (int i = 0; i < dim; i++) {\n+            Assert.assertEquals(expected.getPoint()[i], result.getPoint()[i], pointTol);\n+        }\n+    }\n+\n+    private static double[] point(int n, double value) {\n+        double[] ds = new double[n];\n+        Arrays.fill(ds, value);\n+        return ds;\n+    }\n+\n+    private static double[][] boundaries(int dim,\n+            double lower, double upper) {\n+        double[][] boundaries = new double[2][dim];\n+        for (int i = 0; i < dim; i++)\n+            boundaries[0][i] = lower;\n+        for (int i = 0; i < dim; i++)\n+            boundaries[1][i] = upper;\n+        return boundaries;\n+    }\n+\n+    private static class Sphere implements MultivariateFunction {\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length; ++i)\n+                f += x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class Cigar implements MultivariateFunction {\n+        private double factor;\n+\n+        Cigar() {\n+            this(1e3);\n+        }\n+\n+        Cigar(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = x[0] * x[0];\n+            for (int i = 1; i < x.length; ++i)\n+                f += factor * x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class Tablet implements MultivariateFunction {\n+        private double factor;\n+\n+        Tablet() {\n+            this(1e3);\n+        }\n+\n+        Tablet(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = factor * x[0] * x[0];\n+            for (int i = 1; i < x.length; ++i)\n+                f += x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class CigTab implements MultivariateFunction {\n+        private double factor;\n+\n+        CigTab() {\n+            this(1e4);\n+        }\n+\n+        CigTab(double axisratio) {\n+            factor = axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            int end = x.length - 1;\n+            double f = x[0] * x[0] / factor + factor * x[end] * x[end];\n+            for (int i = 1; i < end; ++i)\n+                f += x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class TwoAxes implements MultivariateFunction {\n+\n+        private double factor;\n+\n+        TwoAxes() {\n+            this(1e6);\n+        }\n+\n+        TwoAxes(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length; ++i)\n+                f += (i < x.length / 2 ? factor : 1) * x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class ElliRotated implements MultivariateFunction {\n+        private Basis B = new Basis();\n+        private double factor;\n+\n+        ElliRotated() {\n+            this(1e3);\n+        }\n+\n+        ElliRotated(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            x = B.Rotate(x);\n+            for (int i = 0; i < x.length; ++i)\n+                f += Math.pow(factor, i / (x.length - 1.)) * x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class Elli implements MultivariateFunction {\n+\n+        private double factor;\n+\n+        Elli() {\n+            this(1e3);\n+        }\n+\n+        Elli(double axisratio) {\n+            factor = axisratio * axisratio;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length; ++i)\n+                f += Math.pow(factor, i / (x.length - 1.)) * x[i] * x[i];\n+            return f;\n+        }\n+    }\n+\n+    private static class MinusElli implements MultivariateFunction {\n+\n+        public double value(double[] x) {\n+            return 1.0-(new Elli().value(x));\n+        }\n+    }\n+\n+    private static class DiffPow implements MultivariateFunction {\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length; ++i)\n+                f += Math.pow(Math.abs(x[i]), 2. + 10 * (double) i\n+                        / (x.length - 1.));\n+            return f;\n+        }\n+    }\n+\n+    private static class SsDiffPow implements MultivariateFunction {\n+\n+        public double value(double[] x) {\n+            double f = Math.pow(new DiffPow().value(x), 0.25);\n+            return f;\n+        }\n+    }\n+\n+    private static class Rosen implements MultivariateFunction {\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            for (int i = 0; i < x.length - 1; ++i)\n+                f += 1e2 * (x[i] * x[i] - x[i + 1]) * (x[i] * x[i] - x[i + 1])\n+                + (x[i] - 1.) * (x[i] - 1.);\n+            return f;\n+        }\n+    }\n+\n+    private static class Ackley implements MultivariateFunction {\n+        private double axisratio;\n+\n+        Ackley(double axra) {\n+            axisratio = axra;\n+        }\n+\n+        public Ackley() {\n+            this(1);\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            double res2 = 0;\n+            double fac = 0;\n+            for (int i = 0; i < x.length; ++i) {\n+                fac = Math.pow(axisratio, (i - 1.) / (x.length - 1.));\n+                f += fac * fac * x[i] * x[i];\n+                res2 += Math.cos(2. * Math.PI * fac * x[i]);\n+            }\n+            f = (20. - 20. * Math.exp(-0.2 * Math.sqrt(f / x.length))\n+                    + Math.exp(1.) - Math.exp(res2 / x.length));\n+            return f;\n+        }\n+    }\n+\n+    private static class Rastrigin implements MultivariateFunction {\n+\n+        private double axisratio;\n+        private double amplitude;\n+\n+        Rastrigin() {\n+            this(1, 10);\n+        }\n+\n+        Rastrigin(double axisratio, double amplitude) {\n+            this.axisratio = axisratio;\n+            this.amplitude = amplitude;\n+        }\n+\n+        public double value(double[] x) {\n+            double f = 0;\n+            double fac;\n+            for (int i = 0; i < x.length; ++i) {\n+                fac = Math.pow(axisratio, (i - 1.) / (x.length - 1.));\n+                if (i == 0 && x[i] < 0)\n+                    fac *= 1.;\n+                f += fac * fac * x[i] * x[i] + amplitude\n+                * (1. - Math.cos(2. * Math.PI * fac * x[i]));\n+            }\n+            return f;\n+        }\n+    }\n+\n+    private static class Basis {\n+        double[][] basis;\n+        Random rand = new Random(2); // use not always the same basis\n+\n+        double[] Rotate(double[] x) {\n+            GenBasis(x.length);\n+            double[] y = new double[x.length];\n+            for (int i = 0; i < x.length; ++i) {\n+                y[i] = 0;\n+                for (int j = 0; j < x.length; ++j)\n+                    y[i] += basis[i][j] * x[j];\n+            }\n+            return y;\n+        }\n+\n+        void GenBasis(int DIM) {\n+            if (basis != null ? basis.length == DIM : false)\n+                return;\n+\n+            double sp;\n+            int i, j, k;\n+\n+            /* generate orthogonal basis */\n+            basis = new double[DIM][DIM];\n+            for (i = 0; i < DIM; ++i) {\n+                /* sample components gaussian */\n+                for (j = 0; j < DIM; ++j)\n+                    basis[i][j] = rand.nextGaussian();\n+                /* substract projection of previous vectors */\n+                for (j = i - 1; j >= 0; --j) {\n+                    for (sp = 0., k = 0; k < DIM; ++k)\n+                        sp += basis[i][k] * basis[j][k]; /* scalar product */\n+                    for (k = 0; k < DIM; ++k)\n+                        basis[i][k] -= sp * basis[j][k]; /* substract */\n+                }\n+                /* normalize */\n+                for (sp = 0., k = 0; k < DIM; ++k)\n+                    sp += basis[i][k] * basis[i][k]; /* squared norm */\n+                for (k = 0; k < DIM; ++k)\n+                    basis[i][k] /= Math.sqrt(sp);\n+            }\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.analysis.SumSincFunction;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test for {@link PowellOptimizer}.\n+ */\n+public class PowellOptimizerTest {\n+\n+    @Test\n+    public void testSumSinc() {\n+        final MultivariateFunction func = new SumSincFunction(-1);\n+\n+        int dim = 2;\n+        final double[] minPoint = new double[dim];\n+        for (int i = 0; i < dim; i++) {\n+            minPoint[i] = 0;\n+        }\n+\n+        double[] init = new double[dim];\n+\n+        // Initial is minimum.\n+        for (int i = 0; i < dim; i++) {\n+            init[i] = minPoint[i];\n+        }\n+        doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-9);\n+\n+        // Initial is far from minimum.\n+        for (int i = 0; i < dim; i++) {\n+            init[i] = minPoint[i] + 3;\n+        }\n+        doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-5);\n+        // More stringent line search tolerance enhances the precision\n+        // of the result.\n+        doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-9, 1e-7);\n+    }\n+\n+    @Test\n+    public void testQuadratic() {\n+        final MultivariateFunction func = new MultivariateFunction() {\n+                public double value(double[] x) {\n+                    final double a = x[0] - 1;\n+                    final double b = x[1] - 1;\n+                    return a * a + b * b + 1;\n+                }\n+            };\n+\n+        int dim = 2;\n+        final double[] minPoint = new double[dim];\n+        for (int i = 0; i < dim; i++) {\n+            minPoint[i] = 1;\n+        }\n+\n+        double[] init = new double[dim];\n+\n+        // Initial is minimum.\n+        for (int i = 0; i < dim; i++) {\n+            init[i] = minPoint[i];\n+        }\n+        doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-8);\n+\n+        // Initial is far from minimum.\n+        for (int i = 0; i < dim; i++) {\n+            init[i] = minPoint[i] - 20;\n+        }\n+        doTest(func, minPoint, init, GoalType.MINIMIZE, 1e-9, 1e-8);\n+    }\n+\n+    @Test\n+    public void testMaximizeQuadratic() {\n+        final MultivariateFunction func = new MultivariateFunction() {\n+                public double value(double[] x) {\n+                    final double a = x[0] - 1;\n+                    final double b = x[1] - 1;\n+                    return -a * a - b * b + 1;\n+                }\n+            };\n+\n+        int dim = 2;\n+        final double[] maxPoint = new double[dim];\n+        for (int i = 0; i < dim; i++) {\n+            maxPoint[i] = 1;\n+        }\n+\n+        double[] init = new double[dim];\n+\n+        // Initial is minimum.\n+        for (int i = 0; i < dim; i++) {\n+            init[i] = maxPoint[i];\n+        }\n+        doTest(func, maxPoint, init,  GoalType.MAXIMIZE, 1e-9, 1e-8);\n+\n+        // Initial is far from minimum.\n+        for (int i = 0; i < dim; i++) {\n+            init[i] = maxPoint[i] - 20;\n+        }\n+        doTest(func, maxPoint, init, GoalType.MAXIMIZE, 1e-9, 1e-8);\n+    }\n+\n+    /**\n+     * Ensure that we do not increase the number of function evaluations when\n+     * the function values are scaled up.\n+     * Note that the tolerances parameters passed to the constructor must\n+     * still hold sensible values because they are used to set the line search\n+     * tolerances.\n+     */\n+    @Test\n+    public void testRelativeToleranceOnScaledValues() {\n+        final MultivariateFunction func = new MultivariateFunction() {\n+                public double value(double[] x) {\n+                    final double a = x[0] - 1;\n+                    final double b = x[1] - 1;\n+                    return a * a * FastMath.sqrt(FastMath.abs(a)) + b * b + 1;\n+                }\n+            };\n+\n+        int dim = 2;\n+        final double[] minPoint = new double[dim];\n+        for (int i = 0; i < dim; i++) {\n+            minPoint[i] = 1;\n+        }\n+\n+        double[] init = new double[dim];\n+        // Initial is far from minimum.\n+        for (int i = 0; i < dim; i++) {\n+            init[i] = minPoint[i] - 20;\n+        }\n+\n+        final double relTol = 1e-10;\n+\n+        final int maxEval = 1000;\n+        // Very small absolute tolerance to rely solely on the relative\n+        // tolerance as a stopping criterion\n+        final PowellOptimizer optim = new PowellOptimizer(relTol, 1e-100);\n+\n+        final PointValuePair funcResult = optim.optimize(new MaxEval(maxEval),\n+                                                         new ObjectiveFunction(func),\n+                                                         GoalType.MINIMIZE,\n+                                                         new InitialGuess(init));\n+        final double funcValue = func.value(funcResult.getPoint());\n+        final int funcEvaluations = optim.getEvaluations();\n+\n+        final double scale = 1e10;\n+        final MultivariateFunction funcScaled = new MultivariateFunction() {\n+                public double value(double[] x) {\n+                    return scale * func.value(x);\n+                }\n+            };\n+\n+        final PointValuePair funcScaledResult = optim.optimize(new MaxEval(maxEval),\n+                                                               new ObjectiveFunction(funcScaled),\n+                                                               GoalType.MINIMIZE,\n+                                                               new InitialGuess(init));\n+        final double funcScaledValue = funcScaled.value(funcScaledResult.getPoint());\n+        final int funcScaledEvaluations = optim.getEvaluations();\n+\n+        // Check that both minima provide the same objective funciton values,\n+        // within the relative function tolerance.\n+        Assert.assertEquals(1, funcScaledValue / (scale * funcValue), relTol);\n+\n+        // Check that the numbers of evaluations are the same.\n+        Assert.assertEquals(funcEvaluations, funcScaledEvaluations);\n+    }\n+\n+    /**\n+     * @param func Function to optimize.\n+     * @param optimum Expected optimum.\n+     * @param init Starting point.\n+     * @param goal Minimization or maximization.\n+     * @param fTol Tolerance (relative error on the objective function) for\n+     * \"Powell\" algorithm.\n+     * @param pointTol Tolerance for checking that the optimum is correct.\n+     */\n+    private void doTest(MultivariateFunction func,\n+                        double[] optimum,\n+                        double[] init,\n+                        GoalType goal,\n+                        double fTol,\n+                        double pointTol) {\n+        final PowellOptimizer optim = new PowellOptimizer(fTol, Math.ulp(1d));\n+\n+        final PointValuePair result = optim.optimize(new MaxEval(1000),\n+                                                     new ObjectiveFunction(func),\n+                                                     goal,\n+                                                     new InitialGuess(init));\n+        final double[] point = result.getPoint();\n+\n+        for (int i = 0, dim = optimum.length; i < dim; i++) {\n+            Assert.assertEquals(\"found[\" + i + \"]=\" + point[i] + \" value=\" + result.getValue(),\n+                                optimum[i], point[i], pointTol);\n+        }\n+    }\n+\n+    /**\n+     * @param func Function to optimize.\n+     * @param optimum Expected optimum.\n+     * @param init Starting point.\n+     * @param goal Minimization or maximization.\n+     * @param fTol Tolerance (relative error on the objective function) for\n+     * \"Powell\" algorithm.\n+     * @param fLineTol Tolerance (relative error on the objective function)\n+     * for the internal line search algorithm.\n+     * @param pointTol Tolerance for checking that the optimum is correct.\n+     */\n+    private void doTest(MultivariateFunction func,\n+                        double[] optimum,\n+                        double[] init,\n+                        GoalType goal,\n+                        double fTol,\n+                        double fLineTol,\n+                        double pointTol) {\n+        final PowellOptimizer optim = new PowellOptimizer(fTol, Math.ulp(1d),\n+                                                          fLineTol, Math.ulp(1d));\n+\n+        final PointValuePair result = optim.optimize(new MaxEval(1000),\n+                                                     new ObjectiveFunction(func),\n+                                                     goal,\n+                                                     new InitialGuess(init));\n+        final double[] point = result.getPoint();\n+\n+        for (int i = 0, dim = optimum.length; i < dim; i++) {\n+            Assert.assertEquals(\"found[\" + i + \"]=\" + point[i] + \" value=\" + result.getValue(),\n+                                optimum[i], point[i], pointTol);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizerMultiDirectionalTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.SimpleValueChecker;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class SimplexOptimizerMultiDirectionalTest {\n+    @Test\n+    public void testMinimize1() {\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-11, 1e-30);\n+        final FourExtrema fourExtrema = new FourExtrema();\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(200),\n+                                 new ObjectiveFunction(fourExtrema),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { -3, 0 }),\n+                                 new MultiDirectionalSimplex(new double[] { 0.2, 0.2 }));\n+        Assert.assertEquals(fourExtrema.xM, optimum.getPoint()[0], 4e-6);\n+        Assert.assertEquals(fourExtrema.yP, optimum.getPoint()[1], 3e-6);\n+        Assert.assertEquals(fourExtrema.valueXmYp, optimum.getValue(), 8e-13);\n+        Assert.assertTrue(optimizer.getEvaluations() > 120);\n+        Assert.assertTrue(optimizer.getEvaluations() < 150);\n+    }\n+\n+    @Test\n+    public void testMinimize2() {\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-11, 1e-30);\n+        final FourExtrema fourExtrema = new FourExtrema();\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(200),\n+                                 new ObjectiveFunction(fourExtrema),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 1, 0 }),\n+                                 new MultiDirectionalSimplex(new double[] { 0.2, 0.2 }));\n+        Assert.assertEquals(fourExtrema.xP, optimum.getPoint()[0], 2e-8);\n+        Assert.assertEquals(fourExtrema.yM, optimum.getPoint()[1], 3e-6);\n+        Assert.assertEquals(fourExtrema.valueXpYm, optimum.getValue(), 2e-12);\n+        Assert.assertTrue(optimizer.getEvaluations() > 120);\n+        Assert.assertTrue(optimizer.getEvaluations() < 150);\n+    }\n+\n+    @Test\n+    public void testMaximize1() {\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-11, 1e-30);\n+        final FourExtrema fourExtrema = new FourExtrema();\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(200),\n+                                 new ObjectiveFunction(fourExtrema),\n+                                 GoalType.MAXIMIZE,\n+                                 new InitialGuess(new double[] { -3.0, 0.0 }),\n+                                 new MultiDirectionalSimplex(new double[] { 0.2, 0.2 }));\n+        Assert.assertEquals(fourExtrema.xM, optimum.getPoint()[0], 7e-7);\n+        Assert.assertEquals(fourExtrema.yM, optimum.getPoint()[1], 3e-7);\n+        Assert.assertEquals(fourExtrema.valueXmYm, optimum.getValue(), 2e-14);\n+        Assert.assertTrue(optimizer.getEvaluations() > 120);\n+        Assert.assertTrue(optimizer.getEvaluations() < 150);\n+    }\n+\n+    @Test\n+    public void testMaximize2() {\n+        SimplexOptimizer optimizer = new SimplexOptimizer(new SimpleValueChecker(1e-15, 1e-30));\n+        final FourExtrema fourExtrema = new FourExtrema();\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(200),\n+                                 new ObjectiveFunction(fourExtrema),\n+                                 GoalType.MAXIMIZE,\n+                                 new InitialGuess(new double[] { 1, 0 }),\n+                                 new MultiDirectionalSimplex(new double[] { 0.2, 0.2 }));\n+        Assert.assertEquals(fourExtrema.xP, optimum.getPoint()[0], 2e-8);\n+        Assert.assertEquals(fourExtrema.yP, optimum.getPoint()[1], 3e-6);\n+        Assert.assertEquals(fourExtrema.valueXpYp, optimum.getValue(), 2e-12);\n+        Assert.assertTrue(optimizer.getEvaluations() > 180);\n+        Assert.assertTrue(optimizer.getEvaluations() < 220);\n+    }\n+\n+    @Test\n+    public void testRosenbrock() {\n+        MultivariateFunction rosenbrock\n+            = new MultivariateFunction() {\n+                    public double value(double[] x) {\n+                        ++count;\n+                        double a = x[1] - x[0] * x[0];\n+                        double b = 1.0 - x[0];\n+                        return 100 * a * a + b * b;\n+                    }\n+                };\n+\n+        count = 0;\n+        SimplexOptimizer optimizer = new SimplexOptimizer(-1, 1e-3);\n+        PointValuePair optimum\n+           = optimizer.optimize(new MaxEval(100),\n+                                new ObjectiveFunction(rosenbrock),\n+                                GoalType.MINIMIZE,\n+                                new InitialGuess(new double[] { -1.2, 1 }),\n+                                new MultiDirectionalSimplex(new double[][] {\n+                                        { -1.2,  1.0 },\n+                                        { 0.9, 1.2 },\n+                                        {  3.5, -2.3 } }));\n+\n+        Assert.assertEquals(count, optimizer.getEvaluations());\n+        Assert.assertTrue(optimizer.getEvaluations() > 50);\n+        Assert.assertTrue(optimizer.getEvaluations() < 100);\n+        Assert.assertTrue(optimum.getValue() > 1e-2);\n+    }\n+\n+    @Test\n+    public void testPowell() {\n+        MultivariateFunction powell\n+            = new MultivariateFunction() {\n+                    public double value(double[] x) {\n+                        ++count;\n+                        double a = x[0] + 10 * x[1];\n+                        double b = x[2] - x[3];\n+                        double c = x[1] - 2 * x[2];\n+                        double d = x[0] - x[3];\n+                        return a * a + 5 * b * b + c * c * c * c + 10 * d * d * d * d;\n+                    }\n+                };\n+\n+        count = 0;\n+        SimplexOptimizer optimizer = new SimplexOptimizer(-1, 1e-3);\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(1000),\n+                                 new ObjectiveFunction(powell),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 3, -1, 0, 1 }),\n+                                 new MultiDirectionalSimplex(4));\n+        Assert.assertEquals(count, optimizer.getEvaluations());\n+        Assert.assertTrue(optimizer.getEvaluations() > 800);\n+        Assert.assertTrue(optimizer.getEvaluations() < 900);\n+        Assert.assertTrue(optimum.getValue() > 1e-2);\n+    }\n+\n+    @Test\n+    public void testMath283() {\n+        // fails because MultiDirectional.iterateSimplex is looping forever\n+        // the while(true) should be replaced with a convergence check\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-14, 1e-14);\n+        final Gaussian2D function = new Gaussian2D(0, 0, 1);\n+        PointValuePair estimate = optimizer.optimize(new MaxEval(1000),\n+                                                     new ObjectiveFunction(function),\n+                                                     GoalType.MAXIMIZE,\n+                                                     new InitialGuess(function.getMaximumPosition()),\n+                                                     new MultiDirectionalSimplex(2));\n+        final double EPSILON = 1e-5;\n+        final double expectedMaximum = function.getMaximum();\n+        final double actualMaximum = estimate.getValue();\n+        Assert.assertEquals(expectedMaximum, actualMaximum, EPSILON);\n+\n+        final double[] expectedPosition = function.getMaximumPosition();\n+        final double[] actualPosition = estimate.getPoint();\n+        Assert.assertEquals(expectedPosition[0], actualPosition[0], EPSILON );\n+        Assert.assertEquals(expectedPosition[1], actualPosition[1], EPSILON );\n+    }\n+\n+    private static class FourExtrema implements MultivariateFunction {\n+        // The following function has 4 local extrema.\n+        final double xM = -3.841947088256863675365;\n+        final double yM = -1.391745200270734924416;\n+        final double xP =  0.2286682237349059125691;\n+        final double yP = -yM;\n+        final double valueXmYm = 0.2373295333134216789769; // Local maximum.\n+        final double valueXmYp = -valueXmYm; // Local minimum.\n+        final double valueXpYm = -0.7290400707055187115322; // Global minimum.\n+        final double valueXpYp = -valueXpYm; // Global maximum.\n+\n+        public double value(double[] variables) {\n+            final double x = variables[0];\n+            final double y = variables[1];\n+            return (x == 0 || y == 0) ? 0 :\n+                FastMath.atan(x) * FastMath.atan(x + 2) * FastMath.atan(y) * FastMath.atan(y) / (x * y);\n+        }\n+    }\n+\n+    private static class Gaussian2D implements MultivariateFunction {\n+        private final double[] maximumPosition;\n+        private final double std;\n+\n+        public Gaussian2D(double xOpt, double yOpt, double std) {\n+            maximumPosition = new double[] { xOpt, yOpt };\n+            this.std = std;\n+        }\n+\n+        public double getMaximum() {\n+            return value(maximumPosition);\n+        }\n+\n+        public double[] getMaximumPosition() {\n+            return maximumPosition.clone();\n+        }\n+\n+        public double value(double[] point) {\n+            final double x = point[0], y = point[1];\n+            final double twoS2 = 2.0 * std * std;\n+            return 1.0 / (twoS2 * FastMath.PI) * FastMath.exp(-(x * x + y * y) / twoS2);\n+        }\n+    }\n+\n+    private int count;\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizerNelderMeadTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.scalar.noderiv;\n+\n+\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.analysis.MultivariateFunction;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.linear.Array2DRowRealMatrix;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.ObjectiveFunction;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.nonlinear.scalar.LeastSquaresConverter;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class SimplexOptimizerNelderMeadTest {\n+    @Test\n+    public void testMinimize1() {\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final FourExtrema fourExtrema = new FourExtrema();\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 new ObjectiveFunction(fourExtrema),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { -3, 0 }),\n+                                 new NelderMeadSimplex(new double[] { 0.2, 0.2 }));\n+        Assert.assertEquals(fourExtrema.xM, optimum.getPoint()[0], 2e-7);\n+        Assert.assertEquals(fourExtrema.yP, optimum.getPoint()[1], 2e-5);\n+        Assert.assertEquals(fourExtrema.valueXmYp, optimum.getValue(), 6e-12);\n+        Assert.assertTrue(optimizer.getEvaluations() > 60);\n+        Assert.assertTrue(optimizer.getEvaluations() < 90);\n+    }\n+\n+    @Test\n+    public void testMinimize2() {\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final FourExtrema fourExtrema = new FourExtrema();\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 new ObjectiveFunction(fourExtrema),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 1, 0 }),\n+                                 new NelderMeadSimplex(new double[] { 0.2, 0.2 }));\n+        Assert.assertEquals(fourExtrema.xP, optimum.getPoint()[0], 5e-6);\n+        Assert.assertEquals(fourExtrema.yM, optimum.getPoint()[1], 6e-6);\n+        Assert.assertEquals(fourExtrema.valueXpYm, optimum.getValue(), 1e-11);\n+        Assert.assertTrue(optimizer.getEvaluations() > 60);\n+        Assert.assertTrue(optimizer.getEvaluations() < 90);\n+    }\n+\n+    @Test\n+    public void testMaximize1() {\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final FourExtrema fourExtrema = new FourExtrema();\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 new ObjectiveFunction(fourExtrema),\n+                                 GoalType.MAXIMIZE,\n+                                 new InitialGuess(new double[] { -3, 0 }),\n+                                 new NelderMeadSimplex(new double[] { 0.2, 0.2 }));\n+        Assert.assertEquals(fourExtrema.xM, optimum.getPoint()[0], 1e-5);\n+        Assert.assertEquals(fourExtrema.yM, optimum.getPoint()[1], 3e-6);\n+        Assert.assertEquals(fourExtrema.valueXmYm, optimum.getValue(), 3e-12);\n+        Assert.assertTrue(optimizer.getEvaluations() > 60);\n+        Assert.assertTrue(optimizer.getEvaluations() < 90);\n+    }\n+\n+    @Test\n+    public void testMaximize2() {\n+        SimplexOptimizer optimizer = new SimplexOptimizer(1e-10, 1e-30);\n+        final FourExtrema fourExtrema = new FourExtrema();\n+\n+        final PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 new ObjectiveFunction(fourExtrema),\n+                                 GoalType.MAXIMIZE,\n+                                 new InitialGuess(new double[] { 1, 0 }),\n+                                 new NelderMeadSimplex(new double[] { 0.2, 0.2 }));\n+        Assert.assertEquals(fourExtrema.xP, optimum.getPoint()[0], 4e-6);\n+        Assert.assertEquals(fourExtrema.yP, optimum.getPoint()[1], 5e-6);\n+        Assert.assertEquals(fourExtrema.valueXpYp, optimum.getValue(), 7e-12);\n+        Assert.assertTrue(optimizer.getEvaluations() > 60);\n+        Assert.assertTrue(optimizer.getEvaluations() < 90);\n+    }\n+\n+    @Test\n+    public void testRosenbrock() {\n+\n+        Rosenbrock rosenbrock = new Rosenbrock();\n+        SimplexOptimizer optimizer = new SimplexOptimizer(-1, 1e-3);\n+        PointValuePair optimum\n+        = optimizer.optimize(new MaxEval(100),\n+                             new ObjectiveFunction(rosenbrock),\n+                             GoalType.MINIMIZE,\n+                             new InitialGuess(new double[] { -1.2, 1 }),\n+                                new NelderMeadSimplex(new double[][] {\n+                                        { -1.2,  1 },\n+                                        { 0.9, 1.2 },\n+                                        {  3.5, -2.3 } }));\n+\n+        Assert.assertEquals(rosenbrock.getCount(), optimizer.getEvaluations());\n+        Assert.assertTrue(optimizer.getEvaluations() > 40);\n+        Assert.assertTrue(optimizer.getEvaluations() < 50);\n+        Assert.assertTrue(optimum.getValue() < 8e-4);\n+    }\n+\n+    @Test\n+    public void testPowell() {\n+        Powell powell = new Powell();\n+        SimplexOptimizer optimizer = new SimplexOptimizer(-1, 1e-3);\n+        PointValuePair optimum =\n+            optimizer.optimize(new MaxEval(200),\n+                               new ObjectiveFunction(powell),\n+                               GoalType.MINIMIZE,\n+                               new InitialGuess(new double[] { 3, -1, 0, 1 }),\n+                               new NelderMeadSimplex(4));\n+        Assert.assertEquals(powell.getCount(), optimizer.getEvaluations());\n+        Assert.assertTrue(optimizer.getEvaluations() > 110);\n+        Assert.assertTrue(optimizer.getEvaluations() < 130);\n+        Assert.assertTrue(optimum.getValue() < 2e-3);\n+    }\n+\n+    @Test\n+    public void testLeastSquares1() {\n+        final RealMatrix factors\n+            = new Array2DRowRealMatrix(new double[][] {\n+                    { 1, 0 },\n+                    { 0, 1 }\n+                }, false);\n+        LeastSquaresConverter ls = new LeastSquaresConverter(new MultivariateVectorFunction() {\n+                public double[] value(double[] variables) {\n+                    return factors.operate(variables);\n+                }\n+            }, new double[] { 2.0, -3.0 });\n+        SimplexOptimizer optimizer = new SimplexOptimizer(-1, 1e-6);\n+        PointValuePair optimum =\n+            optimizer.optimize(new MaxEval(200),\n+                               new ObjectiveFunction(ls),\n+                               GoalType.MINIMIZE,\n+                               new InitialGuess(new double[] { 10, 10 }),\n+                               new NelderMeadSimplex(2));\n+        Assert.assertEquals( 2, optimum.getPointRef()[0], 3e-5);\n+        Assert.assertEquals(-3, optimum.getPointRef()[1], 4e-4);\n+        Assert.assertTrue(optimizer.getEvaluations() > 60);\n+        Assert.assertTrue(optimizer.getEvaluations() < 80);\n+        Assert.assertTrue(optimum.getValue() < 1.0e-6);\n+    }\n+\n+    @Test\n+    public void testLeastSquares2() {\n+        final RealMatrix factors\n+            = new Array2DRowRealMatrix(new double[][] {\n+                    { 1, 0 },\n+                    { 0, 1 }\n+                }, false);\n+        LeastSquaresConverter ls = new LeastSquaresConverter(new MultivariateVectorFunction() {\n+                public double[] value(double[] variables) {\n+                    return factors.operate(variables);\n+                }\n+            }, new double[] { 2, -3 }, new double[] { 10, 0.1 });\n+        SimplexOptimizer optimizer = new SimplexOptimizer(-1, 1e-6);\n+        PointValuePair optimum =\n+            optimizer.optimize(new MaxEval(200),\n+                               new ObjectiveFunction(ls),\n+                               GoalType.MINIMIZE,\n+                               new InitialGuess(new double[] { 10, 10 }),\n+                               new NelderMeadSimplex(2));\n+        Assert.assertEquals( 2, optimum.getPointRef()[0], 5e-5);\n+        Assert.assertEquals(-3, optimum.getPointRef()[1], 8e-4);\n+        Assert.assertTrue(optimizer.getEvaluations() > 60);\n+        Assert.assertTrue(optimizer.getEvaluations() < 80);\n+        Assert.assertTrue(optimum.getValue() < 1e-6);\n+    }\n+\n+    @Test\n+    public void testLeastSquares3() {\n+        final RealMatrix factors =\n+            new Array2DRowRealMatrix(new double[][] {\n+                    { 1, 0 },\n+                    { 0, 1 }\n+                }, false);\n+        LeastSquaresConverter ls = new LeastSquaresConverter(new MultivariateVectorFunction() {\n+                public double[] value(double[] variables) {\n+                    return factors.operate(variables);\n+                }\n+            }, new double[] { 2, -3 }, new Array2DRowRealMatrix(new double [][] {\n+                    { 1, 1.2 }, { 1.2, 2 }\n+                }));\n+        SimplexOptimizer optimizer = new SimplexOptimizer(-1, 1e-6);\n+        PointValuePair optimum\n+            = optimizer.optimize(new MaxEval(200),\n+                                 new ObjectiveFunction(ls),\n+                                 GoalType.MINIMIZE,\n+                                 new InitialGuess(new double[] { 10, 10 }),\n+                                 new NelderMeadSimplex(2));\n+        Assert.assertEquals( 2, optimum.getPointRef()[0], 2e-3);\n+        Assert.assertEquals(-3, optimum.getPointRef()[1], 8e-4);\n+        Assert.assertTrue(optimizer.getEvaluations() > 60);\n+        Assert.assertTrue(optimizer.getEvaluations() < 80);\n+        Assert.assertTrue(optimum.getValue() < 1e-6);\n+    }\n+\n+    @Test(expected=TooManyEvaluationsException.class)\n+    public void testMaxIterations() {\n+        Powell powell = new Powell();\n+        SimplexOptimizer optimizer = new SimplexOptimizer(-1, 1e-3);\n+        optimizer.optimize(new MaxEval(20),\n+                           new ObjectiveFunction(powell),\n+                           GoalType.MINIMIZE,\n+                           new InitialGuess(new double[] { 3, -1, 0, 1 }),\n+                           new NelderMeadSimplex(4));\n+    }\n+\n+    private static class FourExtrema implements MultivariateFunction {\n+        // The following function has 4 local extrema.\n+        final double xM = -3.841947088256863675365;\n+        final double yM = -1.391745200270734924416;\n+        final double xP =  0.2286682237349059125691;\n+        final double yP = -yM;\n+        final double valueXmYm = 0.2373295333134216789769; // Local maximum.\n+        final double valueXmYp = -valueXmYm; // Local minimum.\n+        final double valueXpYm = -0.7290400707055187115322; // Global minimum.\n+        final double valueXpYp = -valueXpYm; // Global maximum.\n+\n+        public double value(double[] variables) {\n+            final double x = variables[0];\n+            final double y = variables[1];\n+            return (x == 0 || y == 0) ? 0 :\n+                FastMath.atan(x) * FastMath.atan(x + 2) * FastMath.atan(y) * FastMath.atan(y) / (x * y);\n+        }\n+    }\n+\n+    private static class Rosenbrock implements MultivariateFunction {\n+        private int count;\n+\n+        public Rosenbrock() {\n+            count = 0;\n+        }\n+\n+        public double value(double[] x) {\n+            ++count;\n+            double a = x[1] - x[0] * x[0];\n+            double b = 1.0 - x[0];\n+            return 100 * a * a + b * b;\n+        }\n+\n+        public int getCount() {\n+            return count;\n+        }\n+    }\n+\n+    private static class Powell implements MultivariateFunction {\n+        private int count;\n+\n+        public Powell() {\n+            count = 0;\n+        }\n+\n+        public double value(double[] x) {\n+            ++count;\n+            double a = x[0] + 10 * x[1];\n+            double b = x[2] - x[3];\n+            double c = x[1] - 2 * x[2];\n+            double d = x[0] - x[3];\n+            return a * a + 5 * b * b + c * c * c * c + 10 * d * d * d * d;\n+        }\n+\n+        public int getCount() {\n+            return count;\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/MultiStartMultivariateVectorOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector;\n+\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.linear.BlockRealMatrix;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.SimpleVectorValueChecker;\n+import org.apache.commons.math3.optim.nonlinear.vector.jacobian.GaussNewtonOptimizer;\n+import org.apache.commons.math3.random.GaussianRandomGenerator;\n+import org.apache.commons.math3.random.JDKRandomGenerator;\n+import org.apache.commons.math3.random.RandomVectorGenerator;\n+import org.apache.commons.math3.random.UncorrelatedRandomVectorGenerator;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files.\n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+ *\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+ *\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class MultiStartMultivariateVectorOptimizerTest {\n+    @Test(expected=NullPointerException.class)\n+    public void testGetOptimaBeforeOptimize() {\n+        LinearProblem problem\n+            = new LinearProblem(new double[][] { { 2 } }, new double[] { 3 });\n+        JacobianMultivariateVectorOptimizer underlyingOptimizer\n+            = new GaussNewtonOptimizer(true, new SimpleVectorValueChecker(1e-6, 1e-6));\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(16069223052l);\n+        RandomVectorGenerator generator\n+            = new UncorrelatedRandomVectorGenerator(1, new GaussianRandomGenerator(g));\n+        MultiStartMultivariateVectorOptimizer optimizer\n+            = new MultiStartMultivariateVectorOptimizer(underlyingOptimizer, 10, generator);\n+\n+        optimizer.getOptima();\n+    }\n+\n+    @Test\n+    public void testTrivial() {\n+        LinearProblem problem\n+            = new LinearProblem(new double[][] { { 2 } }, new double[] { 3 });\n+        JacobianMultivariateVectorOptimizer underlyingOptimizer\n+            = new GaussNewtonOptimizer(true, new SimpleVectorValueChecker(1e-6, 1e-6));\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(16069223052l);\n+        RandomVectorGenerator generator\n+            = new UncorrelatedRandomVectorGenerator(1, new GaussianRandomGenerator(g));\n+        MultiStartMultivariateVectorOptimizer optimizer\n+            = new MultiStartMultivariateVectorOptimizer(underlyingOptimizer, 10, generator);\n+\n+        PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getModelFunction(),\n+                                 problem.getModelFunctionJacobian(),\n+                                 problem.getTarget(),\n+                                 new Weight(new double[] { 1 }),\n+                                 new InitialGuess(new double[] { 0 }));\n+        Assert.assertEquals(1.5, optimum.getPoint()[0], 1e-10);\n+        Assert.assertEquals(3.0, optimum.getValue()[0], 1e-10);\n+        PointVectorValuePair[] optima = optimizer.getOptima();\n+        Assert.assertEquals(10, optima.length);\n+        for (int i = 0; i < optima.length; i++) {\n+            Assert.assertEquals(1.5, optima[i].getPoint()[0], 1e-10);\n+            Assert.assertEquals(3.0, optima[i].getValue()[0], 1e-10);\n+        }\n+        Assert.assertTrue(optimizer.getEvaluations() > 20);\n+        Assert.assertTrue(optimizer.getEvaluations() < 50);\n+        Assert.assertEquals(100, optimizer.getMaxEvaluations());\n+    }\n+\n+    /**\n+     * Test demonstrating that the user exception is fnally thrown if none\n+     * of the runs succeed.\n+     */\n+    @Test(expected=TestException.class)\n+    public void testNoOptimum() {\n+        JacobianMultivariateVectorOptimizer underlyingOptimizer\n+            = new GaussNewtonOptimizer(true, new SimpleVectorValueChecker(1e-6, 1e-6));\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(12373523445l);\n+        RandomVectorGenerator generator\n+            = new UncorrelatedRandomVectorGenerator(1, new GaussianRandomGenerator(g));\n+        MultiStartMultivariateVectorOptimizer optimizer\n+            = new MultiStartMultivariateVectorOptimizer(underlyingOptimizer, 10, generator);\n+        optimizer.optimize(new MaxEval(100),\n+                           new Target(new double[] { 0 }),\n+                           new Weight(new double[] { 1 }),\n+                           new InitialGuess(new double[] { 0 }),\n+                           new ModelFunction(new MultivariateVectorFunction() {\n+                                   public double[] value(double[] point) {\n+                                       throw new TestException();\n+                                   }\n+                               }));\n+    }\n+\n+    private static class TestException extends RuntimeException {}\n+\n+    private static class LinearProblem {\n+        private final RealMatrix factors;\n+        private final double[] target;\n+\n+        public LinearProblem(double[][] factors,\n+                             double[] target) {\n+            this.factors = new BlockRealMatrix(factors);\n+            this.target  = target;\n+        }\n+\n+        public Target getTarget() {\n+            return new Target(target);\n+        }\n+\n+        public ModelFunction getModelFunction() {\n+            return new ModelFunction(new MultivariateVectorFunction() {\n+                    public double[] value(double[] variables) {\n+                        return factors.operate(variables);\n+                    }\n+                });\n+        }\n+\n+        public ModelFunctionJacobian getModelFunctionJacobian() {\n+            return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                    public double[][] value(double[] point) {\n+                        return factors.getData();\n+                    }\n+                });\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/AbstractLeastSquaresOptimizerAbstractTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.Arrays;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.exception.ConvergenceException;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n+import org.apache.commons.math3.linear.BlockRealMatrix;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.nonlinear.vector.Target;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files.\n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ * @version $Id: AbstractLeastSquaresOptimizerAbstractTest.java 1407467 2012-11-09 14:30:49Z erans $\n+ */\n+public abstract class AbstractLeastSquaresOptimizerAbstractTest {\n+\n+    public abstract AbstractLeastSquaresOptimizer createOptimizer();\n+\n+    @Test\n+    public void testTrivial() {\n+        LinearProblem problem\n+            = new LinearProblem(new double[][] { { 2 } }, new double[] { 3 });\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem.getModelFunction(),\n+                               problem.getModelFunctionJacobian(),\n+                               problem.getTarget(),\n+                               new Weight(new double[] { 1 }),\n+                               new InitialGuess(new double[] { 0 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(1.5, optimum.getPoint()[0], 1e-10);\n+        Assert.assertEquals(3.0, optimum.getValue()[0], 1e-10);\n+    }\n+\n+    @Test\n+    public void testQRColumnsPermutation() {\n+\n+        LinearProblem problem\n+            = new LinearProblem(new double[][] { { 1, -1 }, { 0, 2 }, { 1, -2 } },\n+                                new double[] { 4, 6, 1 });\n+\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem.getModelFunction(),\n+                               problem.getModelFunctionJacobian(),\n+                               problem.getTarget(),\n+                               new Weight(new double[] { 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 0, 0 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(7, optimum.getPoint()[0], 1e-10);\n+        Assert.assertEquals(3, optimum.getPoint()[1], 1e-10);\n+        Assert.assertEquals(4, optimum.getValue()[0], 1e-10);\n+        Assert.assertEquals(6, optimum.getValue()[1], 1e-10);\n+        Assert.assertEquals(1, optimum.getValue()[2], 1e-10);\n+    }\n+\n+    @Test\n+    public void testNoDependency() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 2, 0, 0, 0, 0, 0 },\n+                { 0, 2, 0, 0, 0, 0 },\n+                { 0, 0, 2, 0, 0, 0 },\n+                { 0, 0, 0, 2, 0, 0 },\n+                { 0, 0, 0, 0, 2, 0 },\n+                { 0, 0, 0, 0, 0, 2 }\n+        }, new double[] { 0, 1.1, 2.2, 3.3, 4.4, 5.5 });\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem.getModelFunction(),\n+                               problem.getModelFunctionJacobian(),\n+                               problem.getTarget(),\n+                               new Weight(new double[] { 1, 1, 1, 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 0, 0, 0, 0, 0, 0 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        for (int i = 0; i < problem.target.length; ++i) {\n+            Assert.assertEquals(0.55 * i, optimum.getPoint()[i], 1e-10);\n+        }\n+    }\n+\n+    @Test\n+    public void testOneSet() {\n+\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  1,  0, 0 },\n+                { -1,  1, 0 },\n+                {  0, -1, 1 }\n+        }, new double[] { 1, 1, 1});\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem.getModelFunction(),\n+                               problem.getModelFunctionJacobian(),\n+                               problem.getTarget(),\n+                               new Weight(new double[] { 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 0, 0, 0 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(1, optimum.getPoint()[0], 1e-10);\n+        Assert.assertEquals(2, optimum.getPoint()[1], 1e-10);\n+        Assert.assertEquals(3, optimum.getPoint()[2], 1e-10);\n+    }\n+\n+    @Test\n+    public void testTwoSets() {\n+        double epsilon = 1e-7;\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  2,  1,   0,  4,       0, 0 },\n+                { -4, -2,   3, -7,       0, 0 },\n+                {  4,  1,  -2,  8,       0, 0 },\n+                {  0, -3, -12, -1,       0, 0 },\n+                {  0,  0,   0,  0, epsilon, 1 },\n+                {  0,  0,   0,  0,       1, 1 }\n+        }, new double[] { 2, -9, 2, 2, 1 + epsilon * epsilon, 2});\n+\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem.getModelFunction(),\n+                               problem.getModelFunctionJacobian(),\n+                               problem.getTarget(),\n+                               new Weight(new double[] { 1, 1, 1, 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 0, 0, 0, 0, 0, 0 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(3, optimum.getPoint()[0], 1e-10);\n+        Assert.assertEquals(4, optimum.getPoint()[1], 1e-10);\n+        Assert.assertEquals(-1, optimum.getPoint()[2], 1e-10);\n+        Assert.assertEquals(-2, optimum.getPoint()[3], 1e-10);\n+        Assert.assertEquals(1 + epsilon, optimum.getPoint()[4], 1e-10);\n+        Assert.assertEquals(1 - epsilon, optimum.getPoint()[5], 1e-10);\n+    }\n+\n+    @Test(expected=ConvergenceException.class)\n+    public void testNonInvertible() throws Exception {\n+\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  1, 2, -3 },\n+                {  2, 1,  3 },\n+                { -3, 0, -9 }\n+        }, new double[] { 1, 1, 1 });\n+\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+\n+        optimizer.optimize(new MaxEval(100),\n+                           problem.getModelFunction(),\n+                           problem.getModelFunctionJacobian(),\n+                           problem.getTarget(),\n+                           new Weight(new double[] { 1, 1, 1 }),\n+                           new InitialGuess(new double[] { 0, 0, 0 }));\n+    }\n+\n+    @Test\n+    public void testIllConditioned() {\n+        LinearProblem problem1 = new LinearProblem(new double[][] {\n+                { 10, 7,  8,  7 },\n+                {  7, 5,  6,  5 },\n+                {  8, 6, 10,  9 },\n+                {  7, 5,  9, 10 }\n+        }, new double[] { 32, 23, 33, 31 });\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum1 =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem1.getModelFunction(),\n+                               problem1.getModelFunctionJacobian(),\n+                               problem1.getTarget(),\n+                               new Weight(new double[] { 1, 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 0, 1, 2, 3 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(1, optimum1.getPoint()[0], 1e-10);\n+        Assert.assertEquals(1, optimum1.getPoint()[1], 1e-10);\n+        Assert.assertEquals(1, optimum1.getPoint()[2], 1e-10);\n+        Assert.assertEquals(1, optimum1.getPoint()[3], 1e-10);\n+\n+        LinearProblem problem2 = new LinearProblem(new double[][] {\n+                { 10.00, 7.00, 8.10, 7.20 },\n+                {  7.08, 5.04, 6.00, 5.00 },\n+                {  8.00, 5.98, 9.89, 9.00 },\n+                {  6.99, 4.99, 9.00, 9.98 }\n+        }, new double[] { 32, 23, 33, 31 });\n+        PointVectorValuePair optimum2 =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem2.getModelFunction(),\n+                               problem2.getModelFunctionJacobian(),\n+                               problem2.getTarget(), \n+                               new Weight(new double[] { 1, 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 0, 1, 2, 3 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(-81, optimum2.getPoint()[0], 1e-8);\n+        Assert.assertEquals(137, optimum2.getPoint()[1], 1e-8);\n+        Assert.assertEquals(-34, optimum2.getPoint()[2], 1e-8);\n+        Assert.assertEquals( 22, optimum2.getPoint()[3], 1e-8);\n+    }\n+\n+    @Test\n+    public void testMoreEstimatedParametersSimple() {\n+\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 3, 2,  0, 0 },\n+                { 0, 1, -1, 1 },\n+                { 2, 0,  1, 0 }\n+        }, new double[] { 7, 3, 5 });\n+\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        optimizer.optimize(new MaxEval(100),\n+                           problem.getModelFunction(),\n+                           problem.getModelFunctionJacobian(),\n+                           problem.getTarget(),\n+                           new Weight(new double[] { 1, 1, 1 }),\n+                           new InitialGuess(new double[] { 7, 6, 5, 4 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+    }\n+\n+    @Test\n+    public void testMoreEstimatedParametersUnsorted() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 1, 1,  0,  0, 0,  0 },\n+                { 0, 0,  1,  1, 1,  0 },\n+                { 0, 0,  0,  0, 1, -1 },\n+                { 0, 0, -1,  1, 0,  1 },\n+                { 0, 0,  0, -1, 1,  0 }\n+       }, new double[] { 3, 12, -1, 7, 1 });\n+\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem.getModelFunction(),\n+                               problem.getModelFunctionJacobian(),\n+                               problem.getTarget(),\n+                               new Weight(new double[] { 1, 1, 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 2, 2, 2, 2, 2, 2 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(3, optimum.getPointRef()[2], 1e-10);\n+        Assert.assertEquals(4, optimum.getPointRef()[3], 1e-10);\n+        Assert.assertEquals(5, optimum.getPointRef()[4], 1e-10);\n+        Assert.assertEquals(6, optimum.getPointRef()[5], 1e-10);\n+    }\n+\n+    @Test\n+    public void testRedundantEquations() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 1,  1 },\n+                { 1, -1 },\n+                { 1,  3 }\n+        }, new double[] { 3, 1, 5 });\n+\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem.getModelFunction(),\n+                               problem.getModelFunctionJacobian(),\n+                               problem.getTarget(),\n+                               new Weight(new double[] { 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 1, 1 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(2, optimum.getPointRef()[0], 1e-10);\n+        Assert.assertEquals(1, optimum.getPointRef()[1], 1e-10);\n+    }\n+\n+    @Test\n+    public void testInconsistentEquations() {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 1,  1 },\n+                { 1, -1 },\n+                { 1,  3 }\n+        }, new double[] { 3, 1, 4 });\n+\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        optimizer.optimize(new MaxEval(100),\n+                           problem.getModelFunction(),\n+                           problem.getModelFunctionJacobian(),\n+                           problem.getTarget(),\n+                           new Weight(new double[] { 1, 1, 1 }),\n+                           new InitialGuess(new double[] { 1, 1 }));\n+        Assert.assertTrue(optimizer.getRMS() > 0.1);\n+    }\n+\n+    @Test(expected=DimensionMismatchException.class)\n+    public void testInconsistentSizes1() {\n+        LinearProblem problem\n+            = new LinearProblem(new double[][] { { 1, 0 }, { 0, 1 } },\n+                                new double[] { -1, 1 });\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               problem.getModelFunction(),\n+                               problem.getModelFunctionJacobian(),\n+                               problem.getTarget(),\n+                               new Weight(new double[] { 1, 1 }),\n+                               new InitialGuess(new double[] { 0, 0 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(-1, optimum.getPoint()[0], 1e-10);\n+        Assert.assertEquals(1, optimum.getPoint()[1], 1e-10);\n+\n+        optimizer.optimize(new MaxEval(100),\n+                           problem.getModelFunction(),\n+                           problem.getModelFunctionJacobian(),\n+                           problem.getTarget(),\n+                           new Weight(new double[] { 1 }),\n+                           new InitialGuess(new double[] { 0, 0 }));\n+    }\n+\n+    @Test(expected=DimensionMismatchException.class)\n+    public void testInconsistentSizes2() {\n+        LinearProblem problem\n+            = new LinearProblem(new double[][] { { 1, 0 }, { 0, 1 } },\n+                                new double[] { -1, 1 });\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getModelFunction(),\n+                                 problem.getModelFunctionJacobian(),\n+                                 problem.getTarget(),\n+                                 new Weight(new double[] { 1, 1 }),\n+                                 new InitialGuess(new double[] { 0, 0 }));\n+        Assert.assertEquals(0, optimizer.getRMS(), 1e-10);\n+        Assert.assertEquals(-1, optimum.getPoint()[0], 1e-10);\n+        Assert.assertEquals(1, optimum.getPoint()[1], 1e-10);\n+\n+        optimizer.optimize(new MaxEval(100),\n+                           problem.getModelFunction(),\n+                           problem.getModelFunctionJacobian(),\n+                           new Target(new double[] { 1 }),\n+                           new Weight(new double[] { 1 }),\n+                           new InitialGuess(new double[] { 0, 0 }));\n+    }\n+\n+    @Test\n+    public void testCircleFitting() {\n+        CircleVectorial circle = new CircleVectorial();\n+        circle.addPoint( 30,  68);\n+        circle.addPoint( 50,  -6);\n+        circle.addPoint(110, -20);\n+        circle.addPoint( 35,  15);\n+        circle.addPoint( 45,  97);\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 circle.getModelFunction(),\n+                                 circle.getModelFunctionJacobian(),\n+                                 new Target(new double[] { 0, 0, 0, 0, 0 }),\n+                                 new Weight(new double[] { 1, 1, 1, 1, 1 }),\n+                                 new InitialGuess(new double[] { 98.680, 47.345 }));\n+        Assert.assertTrue(optimizer.getEvaluations() < 10);\n+        double rms = optimizer.getRMS();\n+        Assert.assertEquals(1.768262623567235,  FastMath.sqrt(circle.getN()) * rms,  1e-10);\n+        Vector2D center = new Vector2D(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n+        Assert.assertEquals(69.96016176931406, circle.getRadius(center), 1e-6);\n+        Assert.assertEquals(96.07590211815305, center.getX(),            1e-6);\n+        Assert.assertEquals(48.13516790438953, center.getY(),            1e-6);\n+        double[][] cov = optimizer.computeCovariances(optimum.getPoint(), 1e-14);\n+        Assert.assertEquals(1.839, cov[0][0], 0.001);\n+        Assert.assertEquals(0.731, cov[0][1], 0.001);\n+        Assert.assertEquals(cov[0][1], cov[1][0], 1e-14);\n+        Assert.assertEquals(0.786, cov[1][1], 0.001);\n+\n+        // add perfect measurements and check errors are reduced\n+        double  r = circle.getRadius(center);\n+        for (double d= 0; d < 2 * FastMath.PI; d += 0.01) {\n+            circle.addPoint(center.getX() + r * FastMath.cos(d), center.getY() + r * FastMath.sin(d));\n+        }\n+        double[] target = new double[circle.getN()];\n+        Arrays.fill(target, 0);\n+        double[] weights = new double[circle.getN()];\n+        Arrays.fill(weights, 2);\n+        optimum = optimizer.optimize(new MaxEval(100),\n+                                     circle.getModelFunction(),\n+                                     circle.getModelFunctionJacobian(),\n+                                     new Target(target),\n+                                     new Weight(weights),\n+                                     new InitialGuess(new double[] { 98.680, 47.345 }));\n+        cov = optimizer.computeCovariances(optimum.getPoint(), 1e-14);\n+        Assert.assertEquals(0.0016, cov[0][0], 0.001);\n+        Assert.assertEquals(3.2e-7, cov[0][1], 1e-9);\n+        Assert.assertEquals(cov[0][1], cov[1][0], 1e-14);\n+        Assert.assertEquals(0.0016, cov[1][1], 0.001);\n+    }\n+\n+    @Test\n+    public void testCircleFittingBadInit() {\n+        CircleVectorial circle = new CircleVectorial();\n+        double[][] points = circlePoints;\n+        double[] target = new double[points.length];\n+        Arrays.fill(target, 0);\n+        double[] weights = new double[points.length];\n+        Arrays.fill(weights, 2);\n+        for (int i = 0; i < points.length; ++i) {\n+            circle.addPoint(points[i][0], points[i][1]);\n+        }\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 circle.getModelFunction(),\n+                                 circle.getModelFunctionJacobian(),\n+                                 new Target(target),\n+                                 new Weight(weights),\n+                                 new InitialGuess(new double[] { -12, -12 }));\n+        Vector2D center = new Vector2D(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n+        Assert.assertTrue(optimizer.getEvaluations() < 25);\n+        Assert.assertEquals( 0.043, optimizer.getRMS(), 1e-3);\n+        Assert.assertEquals( 0.292235,  circle.getRadius(center), 1e-6);\n+        Assert.assertEquals(-0.151738,  center.getX(),            1e-6);\n+        Assert.assertEquals( 0.2075001, center.getY(),            1e-6);\n+    }\n+\n+    @Test\n+    public void testCircleFittingGoodInit() {\n+        CircleVectorial circle = new CircleVectorial();\n+        double[][] points = circlePoints;\n+        double[] target = new double[points.length];\n+        Arrays.fill(target, 0);\n+        double[] weights = new double[points.length];\n+        Arrays.fill(weights, 2);\n+        for (int i = 0; i < points.length; ++i) {\n+            circle.addPoint(points[i][0], points[i][1]);\n+        }\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum =\n+            optimizer.optimize(new MaxEval(100),\n+                               circle.getModelFunction(),\n+                               circle.getModelFunctionJacobian(),\n+                               new Target(target),\n+                               new Weight(weights),\n+                               new InitialGuess(new double[] { 0, 0 }));\n+        Assert.assertEquals(-0.1517383071957963, optimum.getPointRef()[0], 1e-6);\n+        Assert.assertEquals(0.2074999736353867,  optimum.getPointRef()[1], 1e-6);\n+        Assert.assertEquals(0.04268731682389561, optimizer.getRMS(),       1e-8);\n+    }\n+\n+    private final double[][] circlePoints = new double[][] {\n+        {-0.312967,  0.072366}, {-0.339248,  0.132965}, {-0.379780,  0.202724},\n+        {-0.390426,  0.260487}, {-0.361212,  0.328325}, {-0.346039,  0.392619},\n+        {-0.280579,  0.444306}, {-0.216035,  0.470009}, {-0.149127,  0.493832},\n+        {-0.075133,  0.483271}, {-0.007759,  0.452680}, { 0.060071,  0.410235},\n+        { 0.103037,  0.341076}, { 0.118438,  0.273884}, { 0.131293,  0.192201},\n+        { 0.115869,  0.129797}, { 0.072223,  0.058396}, { 0.022884,  0.000718},\n+        {-0.053355, -0.020405}, {-0.123584, -0.032451}, {-0.216248, -0.032862},\n+        {-0.278592, -0.005008}, {-0.337655,  0.056658}, {-0.385899,  0.112526},\n+        {-0.405517,  0.186957}, {-0.415374,  0.262071}, {-0.387482,  0.343398},\n+        {-0.347322,  0.397943}, {-0.287623,  0.458425}, {-0.223502,  0.475513},\n+        {-0.135352,  0.478186}, {-0.061221,  0.483371}, { 0.003711,  0.422737},\n+        { 0.065054,  0.375830}, { 0.108108,  0.297099}, { 0.123882,  0.222850},\n+        { 0.117729,  0.134382}, { 0.085195,  0.056820}, { 0.029800, -0.019138},\n+        {-0.027520, -0.072374}, {-0.102268, -0.091555}, {-0.200299, -0.106578},\n+        {-0.292731, -0.091473}, {-0.356288, -0.051108}, {-0.420561,  0.014926},\n+        {-0.471036,  0.074716}, {-0.488638,  0.182508}, {-0.485990,  0.254068},\n+        {-0.463943,  0.338438}, {-0.406453,  0.404704}, {-0.334287,  0.466119},\n+        {-0.254244,  0.503188}, {-0.161548,  0.495769}, {-0.075733,  0.495560},\n+        { 0.001375,  0.434937}, { 0.082787,  0.385806}, { 0.115490,  0.323807},\n+        { 0.141089,  0.223450}, { 0.138693,  0.131703}, { 0.126415,  0.049174},\n+        { 0.066518, -0.010217}, {-0.005184, -0.070647}, {-0.080985, -0.103635},\n+        {-0.177377, -0.116887}, {-0.260628, -0.100258}, {-0.335756, -0.056251},\n+        {-0.405195, -0.000895}, {-0.444937,  0.085456}, {-0.484357,  0.175597},\n+        {-0.472453,  0.248681}, {-0.438580,  0.347463}, {-0.402304,  0.422428},\n+        {-0.326777,  0.479438}, {-0.247797,  0.505581}, {-0.152676,  0.519380},\n+        {-0.071754,  0.516264}, { 0.015942,  0.472802}, { 0.076608,  0.419077},\n+        { 0.127673,  0.330264}, { 0.159951,  0.262150}, { 0.153530,  0.172681},\n+        { 0.140653,  0.089229}, { 0.078666,  0.024981}, { 0.023807, -0.037022},\n+        {-0.048837, -0.077056}, {-0.127729, -0.075338}, {-0.221271, -0.067526}\n+    };\n+\n+    public void doTestStRD(final StatisticalReferenceDataset dataset,\n+                           final double errParams,\n+                           final double errParamsSd) {\n+        final AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        final double[] w = new double[dataset.getNumObservations()];\n+        Arrays.fill(w, 1);\n+\n+        final double[][] data = dataset.getData();\n+        final double[] initial = dataset.getStartingPoint(0);\n+        final StatisticalReferenceDataset.LeastSquaresProblem problem = dataset.getLeastSquaresProblem();\n+        final PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getModelFunction(),\n+                                 problem.getModelFunctionJacobian(),\n+                                 new Target(data[1]),\n+                                 new Weight(w),\n+                                 new InitialGuess(initial));\n+\n+        final double[] actual = optimum.getPoint();\n+        for (int i = 0; i < actual.length; i++) {\n+            double expected = dataset.getParameter(i);\n+            double delta = FastMath.abs(errParams * expected);\n+            Assert.assertEquals(dataset.getName() + \", param #\" + i,\n+                                expected, actual[i], delta);\n+        }\n+    }\n+\n+    @Test\n+    public void testKirby2() throws IOException {\n+        doTestStRD(StatisticalReferenceDatasetFactory.createKirby2(), 1E-7, 1E-7);\n+    }\n+\n+    @Test\n+    public void testHahn1() throws IOException {\n+        doTestStRD(StatisticalReferenceDatasetFactory.createHahn1(), 1E-7, 1E-4);\n+    }\n+\n+    static class LinearProblem {\n+        private final RealMatrix factors;\n+        private final double[] target;\n+\n+        public LinearProblem(double[][] factors, double[] target) {\n+            this.factors = new BlockRealMatrix(factors);\n+            this.target  = target;\n+        }\n+\n+        public Target getTarget() {\n+            return new Target(target);\n+        }\n+\n+        public ModelFunction getModelFunction() {\n+            return new ModelFunction(new MultivariateVectorFunction() {\n+                    public double[] value(double[] params) {\n+                        return factors.operate(params);\n+                    }\n+                });\n+        }\n+\n+        public ModelFunctionJacobian getModelFunctionJacobian() {\n+            return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                    public double[][] value(double[] params) {\n+                        return factors.getData();\n+                    }\n+                });\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/AbstractLeastSquaresOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law\n+ * or agreed to in writing, software distributed under the License is\n+ * distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied. See the License for the specific language\n+ * governing permissions and limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.nonlinear.vector.Target;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+public class AbstractLeastSquaresOptimizerTest {\n+\n+    public static AbstractLeastSquaresOptimizer createOptimizer() {\n+        return new AbstractLeastSquaresOptimizer(null) {\n+\n+            @Override\n+            protected PointVectorValuePair doOptimize() {\n+                final double[] params = getStartPoint();\n+                final double[] res = computeResiduals(computeObjectiveValue(params));\n+                setCost(computeCost(res));\n+                return new PointVectorValuePair(params, null);\n+            }\n+        };\n+    }\n+\n+    @Test\n+    public void testGetChiSquare() throws IOException {\n+        final StatisticalReferenceDataset dataset\n+            = StatisticalReferenceDatasetFactory.createKirby2();\n+        final AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        final double[] a = dataset.getParameters();\n+        final double[] y = dataset.getData()[1];\n+        final double[] w = new double[y.length];\n+        Arrays.fill(w, 1.0);\n+\n+        StatisticalReferenceDataset.LeastSquaresProblem problem\n+            = dataset.getLeastSquaresProblem();\n+\n+        optimizer.optimize(new MaxEval(1),\n+                           problem.getModelFunction(),\n+                           problem.getModelFunctionJacobian(),\n+                           new Target(y),\n+                           new Weight(w),\n+                           new InitialGuess(a));\n+        final double expected = dataset.getResidualSumOfSquares();\n+        final double actual = optimizer.getChiSquare();\n+        Assert.assertEquals(dataset.getName(), expected, actual,\n+                            1E-11 * expected);\n+    }\n+\n+    @Test\n+    public void testGetRMS() throws IOException {\n+        final StatisticalReferenceDataset dataset\n+            = StatisticalReferenceDatasetFactory.createKirby2();\n+        final AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        final double[] a = dataset.getParameters();\n+        final double[] y = dataset.getData()[1];\n+        final double[] w = new double[y.length];\n+        Arrays.fill(w, 1);\n+\n+        StatisticalReferenceDataset.LeastSquaresProblem problem\n+            = dataset.getLeastSquaresProblem();\n+\n+        optimizer.optimize(new MaxEval(1),\n+                           problem.getModelFunction(),\n+                           problem.getModelFunctionJacobian(),\n+                           new Target(y),\n+                           new Weight(w),\n+                           new InitialGuess(a));\n+\n+        final double expected = FastMath\n+            .sqrt(dataset.getResidualSumOfSquares() /\n+                  dataset.getNumObservations());\n+        final double actual = optimizer.getRMS();\n+        Assert.assertEquals(dataset.getName(), expected, actual,\n+                            1E-11 * expected);\n+    }\n+\n+    @Test\n+    public void testComputeSigma() throws IOException {\n+        final StatisticalReferenceDataset dataset\n+            = StatisticalReferenceDatasetFactory.createKirby2();\n+        final AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        final double[] a = dataset.getParameters();\n+        final double[] y = dataset.getData()[1];\n+        final double[] w = new double[y.length];\n+        Arrays.fill(w, 1);\n+\n+        StatisticalReferenceDataset.LeastSquaresProblem problem\n+            = dataset.getLeastSquaresProblem();\n+\n+        final PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(1),\n+                                 problem.getModelFunction(),\n+                                 problem.getModelFunctionJacobian(),\n+                                 new Target(y),\n+                                 new Weight(w),\n+                                 new InitialGuess(a));\n+\n+        final double[] sig = optimizer.computeSigma(optimum.getPoint(), 1e-14);\n+\n+        final int dof = y.length - a.length;\n+        final double[] expected = dataset.getParametersStandardDeviations();\n+        for (int i = 0; i < sig.length; i++) {\n+            final double actual = FastMath.sqrt(optimizer.getChiSquare() / dof) * sig[i];\n+            Assert.assertEquals(dataset.getName() + \", parameter #\" + i,\n+                                expected[i], actual, 1e-6 * expected[i]);\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/AbstractLeastSquaresOptimizerTestValidation.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law\n+ * or agreed to in writing, software distributed under the License is\n+ * distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied. See the License for the specific language\n+ * governing permissions and limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.ArrayList;\n+import java.awt.geom.Point2D;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.nonlinear.vector.Target;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+import org.apache.commons.math3.stat.descriptive.SummaryStatistics;\n+import org.apache.commons.math3.stat.descriptive.StatisticalSummary;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+/**\n+ * This class demonstrates the main functionality of the\n+ * {@link AbstractLeastSquaresOptimizer}, common to the\n+ * optimizer implementations in package\n+ * {@link org.apache.commons.math3.optimization.general}.\n+ * <br/>\n+ * Not enabled by default, as the class name does not end with \"Test\".\n+ * <br/>\n+ * Invoke by running\n+ * <pre><code>\n+ *  mvn test -Dtest=AbstractLeastSquaresOptimizerTestValidation\n+ * </code></pre>\n+ * or by running\n+ * <pre><code>\n+ *  mvn test -Dtest=AbstractLeastSquaresOptimizerTestValidation -DargLine=\"-DmcRuns=1234 -server\"\n+ * </code></pre>\n+ */\n+public class AbstractLeastSquaresOptimizerTestValidation {\n+    private static final int MONTE_CARLO_RUNS = Integer.parseInt(System.getProperty(\"mcRuns\",\n+                                                                                    \"100\"));\n+\n+    /**\n+     * Using a Monte-Carlo procedure, this test checks the error estimations\n+     * as provided by the square-root of the diagonal elements of the\n+     * covariance matrix.\n+     * <br/>\n+     * The test generates sets of observations, each sampled from\n+     * a Gaussian distribution.\n+     * <br/>\n+     * The optimization problem solved is defined in class\n+     * {@link StraightLineProblem}.\n+     * <br/>\n+     * The output (on stdout) will be a table summarizing the distribution\n+     * of parameters generated by the Monte-Carlo process and by the direct\n+     * estimation provided by the diagonal elements of the covariance matrix.\n+     */\n+    @Test\n+    public void testParametersErrorMonteCarloObservations() {\n+        // Error on the observations.\n+        final double yError = 15;\n+\n+        // True values of the parameters.\n+        final double slope = 123.456;\n+        final double offset = -98.765;\n+\n+        // Samples generator.\n+        final RandomStraightLinePointGenerator lineGenerator\n+            = new RandomStraightLinePointGenerator(slope, offset,\n+                                                   yError,\n+                                                   -1e3, 1e4,\n+                                                   138577L);\n+\n+        // Number of observations.\n+        final int numObs = 100; // XXX Should be a command-line option.\n+        // number of parameters.\n+        final int numParams = 2;\n+\n+        // Parameters found for each of Monte-Carlo run.\n+        final SummaryStatistics[] paramsFoundByDirectSolution = new SummaryStatistics[numParams];\n+        // Sigma estimations (square-root of the diagonal elements of the\n+        // covariance matrix), for each Monte-Carlo run.\n+        final SummaryStatistics[] sigmaEstimate = new SummaryStatistics[numParams];\n+\n+        // Initialize statistics accumulators.\n+        for (int i = 0; i < numParams; i++) {\n+            paramsFoundByDirectSolution[i] = new SummaryStatistics();\n+            sigmaEstimate[i] = new SummaryStatistics();\n+        }\n+\n+        // Dummy optimizer (to compute the covariance matrix).\n+        final AbstractLeastSquaresOptimizer optim = new DummyOptimizer();\n+        final double[] init = { slope, offset };\n+\n+        // Monte-Carlo (generates many sets of observations).\n+        final int mcRepeat = MONTE_CARLO_RUNS;\n+        int mcCount = 0;\n+        while (mcCount < mcRepeat) {\n+            // Observations.\n+            final Point2D.Double[] obs = lineGenerator.generate(numObs);\n+\n+            final StraightLineProblem problem = new StraightLineProblem(yError);\n+            for (int i = 0; i < numObs; i++) {\n+                final Point2D.Double p = obs[i];\n+                problem.addPoint(p.x, p.y);\n+            }\n+\n+            // Direct solution (using simple regression).\n+            final double[] regress = problem.solve();\n+\n+            // Estimation of the standard deviation (diagonal elements of the\n+            // covariance matrix).\n+            final PointVectorValuePair optimum\n+                = optim.optimize(new MaxEval(Integer.MAX_VALUE),\n+                                 problem.getModelFunction(),\n+                                 problem.getModelFunctionJacobian(),\n+                                 new Target(problem.target()),\n+                                 new Weight(problem.weight()),\n+                                 new InitialGuess(init));\n+            final double[] sigma = optim.computeSigma(optimum.getPoint(), 1e-14);\n+\n+            // Accumulate statistics.\n+            for (int i = 0; i < numParams; i++) {\n+                paramsFoundByDirectSolution[i].addValue(regress[i]);\n+                sigmaEstimate[i].addValue(sigma[i]);\n+            }\n+\n+            // Next Monte-Carlo.\n+            ++mcCount;\n+        }\n+\n+        // Print statistics.\n+        final String line = \"--------------------------------------------------------------\";\n+        System.out.println(\"                 True value       Mean        Std deviation\");\n+        for (int i = 0; i < numParams; i++) {\n+            System.out.println(line);\n+            System.out.println(\"Parameter #\" + i);\n+\n+            StatisticalSummary s = paramsFoundByDirectSolution[i].getSummary();\n+            System.out.printf(\"              %+.6e   %+.6e   %+.6e\\n\",\n+                              init[i],\n+                              s.getMean(),\n+                              s.getStandardDeviation());\n+\n+            s = sigmaEstimate[i].getSummary();\n+            System.out.printf(\"sigma: %+.6e (%+.6e)\\n\",\n+                              s.getMean(),\n+                              s.getStandardDeviation());\n+        }\n+        System.out.println(line);\n+\n+        // Check the error estimation.\n+        for (int i = 0; i < numParams; i++) {\n+            Assert.assertEquals(paramsFoundByDirectSolution[i].getSummary().getStandardDeviation(),\n+                                sigmaEstimate[i].getSummary().getMean(),\n+                                8e-2);\n+        }\n+    }\n+\n+    /**\n+     * In this test, the set of observations is fixed.\n+     * Using a Monte-Carlo procedure, it generates sets of parameters,\n+     * and determine the parameter change that will result in the\n+     * normalized chi-square becoming larger by one than the value from\n+     * the best fit solution.\n+     * <br/>\n+     * The optimization problem solved is defined in class\n+     * {@link StraightLineProblem}.\n+     * <br/>\n+     * The output (on stdout) will be a list of lines containing:\n+     * <ul>\n+     *  <li>slope of the straight line,</li>\n+     *  <li>intercept of the straight line,</li>\n+     *  <li>chi-square of the solution defined by the above two values.</li>\n+     * </ul>\n+     * The output is separated into two blocks (with a blank line between\n+     * them); the first block will contain all parameter sets for which\n+     * {@code chi2 < chi2_b + 1}\n+     * and the second block, all sets for which\n+     * {@code chi2 >= chi2_b + 1}\n+     * where {@code chi2_b} is the lowest chi-square (corresponding to the\n+     * best solution).\n+     */\n+    @Test\n+    public void testParametersErrorMonteCarloParameters() {\n+        // Error on the observations.\n+        final double yError = 15;\n+\n+        // True values of the parameters.\n+        final double slope = 123.456;\n+        final double offset = -98.765;\n+\n+        // Samples generator.\n+        final RandomStraightLinePointGenerator lineGenerator\n+            = new RandomStraightLinePointGenerator(slope, offset,\n+                                                   yError,\n+                                                   -1e3, 1e4,\n+                                                   13839013L);\n+\n+        // Number of observations.\n+        final int numObs = 10;\n+        // number of parameters.\n+        final int numParams = 2;\n+\n+        // Create a single set of observations.\n+        final Point2D.Double[] obs = lineGenerator.generate(numObs);\n+\n+        final StraightLineProblem problem = new StraightLineProblem(yError);\n+        for (int i = 0; i < numObs; i++) {\n+            final Point2D.Double p = obs[i];\n+            problem.addPoint(p.x, p.y);\n+        }\n+\n+        // Direct solution (using simple regression).\n+        final double[] regress = problem.solve();\n+\n+        // Dummy optimizer (to compute the chi-square).\n+        final AbstractLeastSquaresOptimizer optim = new DummyOptimizer();\n+        final double[] init = { slope, offset };\n+        // Get chi-square of the best parameters set for the given set of\n+        // observations.\n+        final double bestChi2N = getChi2N(optim, problem, regress);\n+        final double[] sigma = optim.computeSigma(regress, 1e-14);\n+\n+        // Monte-Carlo (generates a grid of parameters).\n+        final int mcRepeat = MONTE_CARLO_RUNS;\n+        final int gridSize = (int) FastMath.sqrt(mcRepeat);\n+\n+        // Parameters found for each of Monte-Carlo run.\n+        // Index 0 = slope\n+        // Index 1 = offset\n+        // Index 2 = normalized chi2\n+        final List<double[]> paramsAndChi2 = new ArrayList<double[]>(gridSize * gridSize);\n+\n+        final double slopeRange = 10 * sigma[0];\n+        final double offsetRange = 10 * sigma[1];\n+        final double minSlope = slope - 0.5 * slopeRange;\n+        final double minOffset = offset - 0.5 * offsetRange;\n+        final double deltaSlope =  slopeRange/ gridSize;\n+        final double deltaOffset = offsetRange / gridSize;\n+        for (int i = 0; i < gridSize; i++) {\n+            final double s = minSlope + i * deltaSlope;\n+            for (int j = 0; j < gridSize; j++) {\n+                final double o = minOffset + j * deltaOffset;\n+                final double chi2N = getChi2N(optim, problem, new double[] {s, o});\n+\n+                paramsAndChi2.add(new double[] {s, o, chi2N});\n+            }\n+        }\n+\n+        // Output (for use with \"gnuplot\").\n+\n+        // Some info.\n+\n+        // For plotting separately sets of parameters that have a large chi2.\n+        final double chi2NPlusOne = bestChi2N + 1;\n+        int numLarger = 0;\n+\n+        final String lineFmt = \"%+.10e %+.10e   %.8e\\n\";\n+\n+        // Point with smallest chi-square.\n+        System.out.printf(lineFmt, regress[0], regress[1], bestChi2N);\n+        System.out.println(); // Empty line.\n+\n+        // Points within the confidence interval.\n+        for (double[] d : paramsAndChi2) {\n+            if (d[2] <= chi2NPlusOne) {\n+                System.out.printf(lineFmt, d[0], d[1], d[2]);\n+            }\n+        }\n+        System.out.println(); // Empty line.\n+\n+        // Points outside the confidence interval.\n+        for (double[] d : paramsAndChi2) {\n+            if (d[2] > chi2NPlusOne) {\n+                ++numLarger;\n+                System.out.printf(lineFmt, d[0], d[1], d[2]);\n+            }\n+        }\n+        System.out.println(); // Empty line.\n+\n+        System.out.println(\"# sigma=\" + Arrays.toString(sigma));\n+        System.out.println(\"# \" + numLarger + \" sets filtered out\");\n+    }\n+\n+    /**\n+     * @return the normalized chi-square.\n+     */\n+    private double getChi2N(AbstractLeastSquaresOptimizer optim,\n+                            StraightLineProblem problem,\n+                            double[] params) {\n+        final double[] t = problem.target();\n+        final double[] w = problem.weight();\n+\n+        optim.optimize(new MaxEval(Integer.MAX_VALUE),\n+                       problem.getModelFunction(),\n+                       problem.getModelFunctionJacobian(),\n+                       new Target(t),\n+                       new Weight(w),\n+                       new InitialGuess(params));\n+\n+        return optim.getChiSquare() / (t.length - params.length);\n+    }\n+}\n+\n+/**\n+ * A dummy optimizer.\n+ * Used for computing the covariance matrix.\n+ */\n+class DummyOptimizer extends AbstractLeastSquaresOptimizer {\n+    public DummyOptimizer() {\n+        super(null);\n+    }\n+\n+    /**\n+     * This method does nothing and returns a dummy value.\n+     */\n+    @Override\n+    public PointVectorValuePair doOptimize() {\n+        final double[] params = getStartPoint();\n+        final double[] res = computeResiduals(computeObjectiveValue(params));\n+        setCost(computeCost(res));\n+        return new PointVectorValuePair(params, null);\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/CircleProblem.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.util.ArrayList;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.util.MathUtils;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+\n+/**\n+ * Class that models a circle.\n+ * The parameters of problem are:\n+ * <ul>\n+ *  <li>the x-coordinate of the circle center,</li>\n+ *  <li>the y-coordinate of the circle center,</li>\n+ *  <li>the radius of the circle.</li>\n+ * </ul>\n+ * The model functions are:\n+ * <ul>\n+ *  <li>for each triplet (cx, cy, r), the (x, y) coordinates of a point on the\n+ *   corresponding circle.</li>\n+ * </ul>\n+ */\n+class CircleProblem {\n+    /** Cloud of points assumed to be fitted by a circle. */\n+    private final ArrayList<double[]> points;\n+    /** Error on the x-coordinate of the points. */\n+    private final double xSigma;\n+    /** Error on the y-coordinate of the points. */\n+    private final double ySigma;\n+    /** Number of points on the circumference (when searching which\n+        model point is closest to a given \"observation\". */\n+    private final int resolution;\n+\n+    /**\n+     * @param xError Assumed error for the x-coordinate of the circle points.\n+     * @param yError Assumed error for the y-coordinate of the circle points.\n+     * @param searchResolution Number of points to try when searching the one\n+     * that is closest to a given \"observed\" point.\n+     */\n+    public CircleProblem(double xError,\n+                         double yError,\n+                         int searchResolution) {\n+        points = new ArrayList<double[]>();\n+        xSigma = xError;\n+        ySigma = yError;\n+        resolution = searchResolution;\n+    }\n+\n+    /**\n+     * @param xError Assumed error for the x-coordinate of the circle points.\n+     * @param yError Assumed error for the y-coordinate of the circle points.\n+     */\n+    public CircleProblem(double xError,\n+                         double yError) {\n+        this(xError, yError, 500);\n+    }\n+\n+    public void addPoint(double px, double py) {\n+        points.add(new double[] { px, py });\n+    }\n+\n+    public double[] target() {\n+        final double[] t = new double[points.size() * 2];\n+        for (int i = 0; i < points.size(); i++) {\n+            final double[] p = points.get(i);\n+            final int index = i * 2;\n+            t[index] = p[0];\n+            t[index + 1] = p[1];\n+        }\n+\n+        return t;\n+    }\n+\n+    public double[] weight() {\n+        final double wX = 1 / (xSigma * xSigma);\n+        final double wY = 1 / (ySigma * ySigma);\n+        final double[] w = new double[points.size() * 2];\n+        for (int i = 0; i < points.size(); i++) {\n+            final int index = i * 2;\n+            w[index] = wX;\n+            w[index + 1] = wY;\n+        }\n+\n+        return w;\n+    }\n+\n+    public ModelFunction getModelFunction() {\n+        return new ModelFunction(new MultivariateVectorFunction() {\n+                public double[] value(double[] params) {\n+                    final double cx = params[0];\n+                    final double cy = params[1];\n+                    final double r = params[2];\n+\n+                    final double[] model = new double[points.size() * 2];\n+\n+                    final double deltaTheta = MathUtils.TWO_PI / resolution;\n+                    for (int i = 0; i < points.size(); i++) {\n+                        final double[] p = points.get(i);\n+                        final double px = p[0];\n+                        final double py = p[1];\n+\n+                        double bestX = 0;\n+                        double bestY = 0;\n+                        double dMin = Double.POSITIVE_INFINITY;\n+\n+                        // Find the angle for which the circle passes closest to the\n+                        // current point (using a resolution of 100 points along the\n+                        // circumference).\n+                        for (double theta = 0; theta <= MathUtils.TWO_PI; theta += deltaTheta) {\n+                            final double currentX = cx + r * FastMath.cos(theta);\n+                            final double currentY = cy + r * FastMath.sin(theta);\n+                            final double dX = currentX - px;\n+                            final double dY = currentY - py;\n+                            final double d = dX * dX + dY * dY;\n+                            if (d < dMin) {\n+                                dMin = d;\n+                                bestX = currentX;\n+                                bestY = currentY;\n+                            }\n+                        }\n+\n+                        final int index = i * 2;\n+                        model[index] = bestX;\n+                        model[index + 1] = bestY;\n+                    }\n+\n+                    return model;\n+                }\n+            });\n+    }\n+\n+    public ModelFunctionJacobian getModelFunctionJacobian() {\n+        return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                public double[][] value(double[] point) {\n+                    return jacobian(point);\n+                }\n+        });\n+    }\n+\n+    private double[][] jacobian(double[] params) {\n+        final double[][] jacobian = new double[points.size() * 2][3];\n+\n+        for (int i = 0; i < points.size(); i++) {\n+            final int index = i * 2;\n+            // Partial derivative wrt x-coordinate of center. \n+            jacobian[index][0] = 1;\n+            jacobian[index + 1][0] = 0;\n+            // Partial derivative wrt y-coordinate of center.\n+            jacobian[index][1] = 0;\n+            jacobian[index + 1][1] = 1;\n+            // Partial derivative wrt radius.\n+            final double[] p = points.get(i);\n+            jacobian[index][2] = (p[0] - params[0]) / params[2];\n+            jacobian[index + 1][2] = (p[1] - params[1]) / params[2];\n+        }\n+\n+        return jacobian;\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/CircleVectorial.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.util.ArrayList;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+\n+/**\n+ * Class used in the tests.\n+ */\n+class CircleVectorial {\n+    private ArrayList<Vector2D> points;\n+\n+    public CircleVectorial() {\n+        points  = new ArrayList<Vector2D>();\n+    }\n+\n+    public void addPoint(double px, double py) {\n+        points.add(new Vector2D(px, py));\n+    }\n+\n+    public int getN() {\n+        return points.size();\n+    }\n+\n+    public double getRadius(Vector2D center) {\n+        double r = 0;\n+        for (Vector2D point : points) {\n+            r += point.distance(center);\n+        }\n+        return r / points.size();\n+    }\n+\n+    public ModelFunction getModelFunction() {\n+        return new ModelFunction(new MultivariateVectorFunction() {\n+                public double[] value(double[] params) {\n+                    Vector2D center = new Vector2D(params[0], params[1]);\n+                    double radius = getRadius(center);\n+                    double[] residuals = new double[points.size()];\n+                    for (int i = 0; i < residuals.length; i++) {\n+                        residuals[i] = points.get(i).distance(center) - radius;\n+                    }\n+\n+                    return residuals;\n+                }\n+        });\n+    }\n+\n+    public ModelFunctionJacobian getModelFunctionJacobian() {\n+        return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                public double[][] value(double[] params) {\n+                    final int n = points.size();\n+                    final Vector2D center = new Vector2D(params[0], params[1]);\n+\n+                    double dRdX = 0;\n+                    double dRdY = 0;\n+                    for (Vector2D pk : points) {\n+                        double dk = pk.distance(center);\n+                        dRdX += (center.getX() - pk.getX()) / dk;\n+                        dRdY += (center.getY() - pk.getY()) / dk;\n+                    }\n+                    dRdX /= n;\n+                    dRdY /= n;\n+\n+                    // Jacobian of the radius residuals.\n+                    double[][] jacobian = new double[n][2];\n+                    for (int i = 0; i < n; i++) {\n+                        final Vector2D pi = points.get(i);\n+                        final double di = pi.distance(center);\n+                        jacobian[i][0] = (center.getX() - pi.getX()) / di - dRdX;\n+                        jacobian[i][1] = (center.getY() - pi.getY()) / di - dRdY;\n+                    }\n+\n+                    return jacobian;\n+                }\n+        });\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.io.IOException;\n+import org.apache.commons.math3.exception.ConvergenceException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.optim.SimpleVectorValueChecker;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.nonlinear.vector.Target;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+import org.junit.Test;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files.\n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class GaussNewtonOptimizerTest\n+    extends AbstractLeastSquaresOptimizerAbstractTest {\n+\n+    @Override\n+    public AbstractLeastSquaresOptimizer createOptimizer() {\n+        return new GaussNewtonOptimizer(new SimpleVectorValueChecker(1.0e-6, 1.0e-6));\n+    }\n+\n+    @Override\n+    @Test(expected = ConvergenceException.class)\n+    public void testMoreEstimatedParametersSimple() {\n+        /*\n+         * Exception is expected with this optimizer\n+         */\n+        super.testMoreEstimatedParametersSimple();\n+    }\n+\n+    @Override\n+    @Test(expected=ConvergenceException.class)\n+    public void testMoreEstimatedParametersUnsorted() {\n+        /*\n+         * Exception is expected with this optimizer\n+         */\n+        super.testMoreEstimatedParametersUnsorted();\n+    }\n+\n+    @Test(expected=TooManyEvaluationsException.class)\n+    public void testMaxEvaluations() throws Exception {\n+        CircleVectorial circle = new CircleVectorial();\n+        circle.addPoint( 30.0,  68.0);\n+        circle.addPoint( 50.0,  -6.0);\n+        circle.addPoint(110.0, -20.0);\n+        circle.addPoint( 35.0,  15.0);\n+        circle.addPoint( 45.0,  97.0);\n+\n+        GaussNewtonOptimizer optimizer\n+            = new GaussNewtonOptimizer(new SimpleVectorValueChecker(1e-30, 1e-30));\n+\n+        optimizer.optimize(new MaxEval(100),\n+                           circle.getModelFunction(),\n+                           circle.getModelFunctionJacobian(),\n+                           new Target(new double[] { 0, 0, 0, 0, 0 }),\n+                           new Weight(new double[] { 1, 1, 1, 1, 1 }),\n+                           new InitialGuess(new double[] { 98.680, 47.345 }));\n+    }\n+\n+    @Override\n+    @Test(expected=ConvergenceException.class)\n+    public void testCircleFittingBadInit() {\n+        /*\n+         * This test does not converge with this optimizer.\n+         */\n+        super.testCircleFittingBadInit();\n+    }\n+\n+    @Override\n+    @Test(expected = ConvergenceException.class)\n+    public void testHahn1()\n+        throws IOException {\n+        /*\n+         * TODO This test leads to a singular problem with the Gauss-Newton\n+         * optimizer. This should be inquired.\n+         */\n+        super.testHahn1();\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.nonlinear.vector.Target;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.exception.ConvergenceException;\n+import org.apache.commons.math3.exception.DimensionMismatchException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n+import org.apache.commons.math3.linear.SingularMatrixException;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.util.Precision;\n+import org.junit.Assert;\n+import org.junit.Test;\n+import org.junit.Ignore;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files.\n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class LevenbergMarquardtOptimizerTest\n+    extends AbstractLeastSquaresOptimizerAbstractTest {\n+    @Override\n+    public AbstractLeastSquaresOptimizer createOptimizer() {\n+        return new LevenbergMarquardtOptimizer();\n+    }\n+\n+    @Override\n+    @Test(expected=SingularMatrixException.class)\n+    public void testNonInvertible() {\n+        /*\n+         * Overrides the method from parent class, since the default singularity\n+         * threshold (1e-14) does not trigger the expected exception.\n+         */\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  1, 2, -3 },\n+                {  2, 1,  3 },\n+                { -3, 0, -9 }\n+        }, new double[] { 1, 1, 1 });\n+\n+        AbstractLeastSquaresOptimizer optimizer = createOptimizer();\n+        PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getModelFunction(),\n+                                 problem.getModelFunctionJacobian(),\n+                                 problem.getTarget(),\n+                                 new Weight(new double[] { 1, 1, 1 }),\n+                                 new InitialGuess(new double[] { 0, 0, 0 }));\n+        Assert.assertTrue(FastMath.sqrt(optimizer.getTargetSize()) * optimizer.getRMS() > 0.6);\n+\n+        optimizer.computeCovariances(optimum.getPoint(), 1.5e-14);\n+    }\n+\n+    @Test\n+    public void testControlParameters() {\n+        CircleVectorial circle = new CircleVectorial();\n+        circle.addPoint( 30.0,  68.0);\n+        circle.addPoint( 50.0,  -6.0);\n+        circle.addPoint(110.0, -20.0);\n+        circle.addPoint( 35.0,  15.0);\n+        circle.addPoint( 45.0,  97.0);\n+        checkEstimate(circle.getModelFunction(),\n+                      circle.getModelFunctionJacobian(),\n+                      0.1, 10, 1.0e-14, 1.0e-16, 1.0e-10, false);\n+        checkEstimate(circle.getModelFunction(),\n+                      circle.getModelFunctionJacobian(),\n+                      0.1, 10, 1.0e-15, 1.0e-17, 1.0e-10, true);\n+        checkEstimate(circle.getModelFunction(),\n+                      circle.getModelFunctionJacobian(),\n+                      0.1,  5, 1.0e-15, 1.0e-16, 1.0e-10, true);\n+        circle.addPoint(300, -300);\n+        checkEstimate(circle.getModelFunction(),\n+                      circle.getModelFunctionJacobian(),\n+                      0.1, 20, 1.0e-18, 1.0e-16, 1.0e-10, true);\n+    }\n+\n+    private void checkEstimate(ModelFunction problem,\n+                               ModelFunctionJacobian problemJacobian,\n+                               double initialStepBoundFactor, int maxCostEval,\n+                               double costRelativeTolerance, double parRelativeTolerance,\n+                               double orthoTolerance, boolean shouldFail) {\n+        try {\n+            LevenbergMarquardtOptimizer optimizer\n+                = new LevenbergMarquardtOptimizer(initialStepBoundFactor,\n+                                                  costRelativeTolerance,\n+                                                  parRelativeTolerance,\n+                                                  orthoTolerance,\n+                                                  Precision.SAFE_MIN);\n+            optimizer.optimize(new MaxEval(maxCostEval),\n+                               problem,\n+                               problemJacobian,\n+                               new Target(new double[] { 0, 0, 0, 0, 0 }),\n+                               new Weight(new double[] { 1, 1, 1, 1, 1 }),\n+                               new InitialGuess(new double[] { 98.680, 47.345 }));\n+            Assert.assertTrue(!shouldFail);\n+        } catch (DimensionMismatchException ee) {\n+            Assert.assertTrue(shouldFail);\n+        } catch (TooManyEvaluationsException ee) {\n+            Assert.assertTrue(shouldFail);\n+        }\n+    }\n+\n+    /**\n+     * Non-linear test case: fitting of decay curve (from Chapter 8 of\n+     * Bevington's textbook, \"Data reduction and analysis for the physical sciences\").\n+     * XXX The expected (\"reference\") values may not be accurate and the tolerance too\n+     * relaxed for this test to be currently really useful (the issue is under\n+     * investigation).\n+     */\n+    @Test\n+    public void testBevington() {\n+        final double[][] dataPoints = {\n+            // column 1 = times\n+            { 15, 30, 45, 60, 75, 90, 105, 120, 135, 150,\n+              165, 180, 195, 210, 225, 240, 255, 270, 285, 300,\n+              315, 330, 345, 360, 375, 390, 405, 420, 435, 450,\n+              465, 480, 495, 510, 525, 540, 555, 570, 585, 600,\n+              615, 630, 645, 660, 675, 690, 705, 720, 735, 750,\n+              765, 780, 795, 810, 825, 840, 855, 870, 885, },\n+            // column 2 = measured counts\n+            { 775, 479, 380, 302, 185, 157, 137, 119, 110, 89,\n+              74, 61, 66, 68, 48, 54, 51, 46, 55, 29,\n+              28, 37, 49, 26, 35, 29, 31, 24, 25, 35,\n+              24, 30, 26, 28, 21, 18, 20, 27, 17, 17,\n+              14, 17, 24, 11, 22, 17, 12, 10, 13, 16,\n+              9, 9, 14, 21, 17, 13, 12, 18, 10, },\n+        };\n+\n+        final BevingtonProblem problem = new BevingtonProblem();\n+\n+        final int len = dataPoints[0].length;\n+        final double[] weights = new double[len];\n+        for (int i = 0; i < len; i++) {\n+            problem.addPoint(dataPoints[0][i],\n+                             dataPoints[1][i]);\n+\n+            weights[i] = 1 / dataPoints[1][i];\n+        }\n+\n+        final LevenbergMarquardtOptimizer optimizer\n+            = new LevenbergMarquardtOptimizer();\n+\n+        final PointVectorValuePair optimum\n+            = optimizer.optimize(new MaxEval(100),\n+                                 problem.getModelFunction(),\n+                                 problem.getModelFunctionJacobian(),\n+                                 new Target(dataPoints[1]),\n+                                 new Weight(weights),\n+                                 new InitialGuess(new double[] { 10, 900, 80, 27, 225 }));\n+\n+        final double[] solution = optimum.getPoint();\n+        final double[] expectedSolution = { 10.4, 958.3, 131.4, 33.9, 205.0 };\n+\n+        final double[][] covarMatrix = optimizer.computeCovariances(solution, 1e-14);\n+        final double[][] expectedCovarMatrix = {\n+            { 3.38, -3.69, 27.98, -2.34, -49.24 },\n+            { -3.69, 2492.26, 81.89, -69.21, -8.9 },\n+            { 27.98, 81.89, 468.99, -44.22, -615.44 },\n+            { -2.34, -69.21, -44.22, 6.39, 53.80 },\n+            { -49.24, -8.9, -615.44, 53.8, 929.45 }\n+        };\n+\n+        final int numParams = expectedSolution.length;\n+\n+        // Check that the computed solution is within the reference error range.\n+        for (int i = 0; i < numParams; i++) {\n+            final double error = FastMath.sqrt(expectedCovarMatrix[i][i]);\n+            Assert.assertEquals(\"Parameter \" + i, expectedSolution[i], solution[i], error);\n+        }\n+\n+        // Check that each entry of the computed covariance matrix is within 10%\n+        // of the reference matrix entry.\n+        for (int i = 0; i < numParams; i++) {\n+            for (int j = 0; j < numParams; j++) {\n+                Assert.assertEquals(\"Covariance matrix [\" + i + \"][\" + j + \"]\",\n+                                    expectedCovarMatrix[i][j],\n+                                    covarMatrix[i][j],\n+                                    FastMath.abs(0.1 * expectedCovarMatrix[i][j]));\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testCircleFitting2() {\n+        final double xCenter = 123.456;\n+        final double yCenter = 654.321;\n+        final double xSigma = 10;\n+        final double ySigma = 15;\n+        final double radius = 111.111;\n+        // The test is extremely sensitive to the seed.\n+        final long seed = 59421061L;\n+        final RandomCirclePointGenerator factory\n+            = new RandomCirclePointGenerator(xCenter, yCenter, radius,\n+                                             xSigma, ySigma,\n+                                             seed);\n+        final CircleProblem circle = new CircleProblem(xSigma, ySigma);\n+\n+        final int numPoints = 10;\n+        for (Vector2D p : factory.generate(numPoints)) {\n+            circle.addPoint(p.getX(), p.getY());\n+        }\n+\n+        // First guess for the center's coordinates and radius.\n+        final double[] init = { 90, 659, 115 };\n+\n+        final LevenbergMarquardtOptimizer optimizer\n+            = new LevenbergMarquardtOptimizer();\n+        final PointVectorValuePair optimum = optimizer.optimize(new MaxEval(100),\n+                                                                circle.getModelFunction(),\n+                                                                circle.getModelFunctionJacobian(),\n+                                                                new Target(circle.target()),\n+                                                                new Weight(circle.weight()),\n+                                                                new InitialGuess(init));\n+\n+        final double[] paramFound = optimum.getPoint();\n+\n+        // Retrieve errors estimation.\n+        final double[] asymptoticStandardErrorFound = optimizer.computeSigma(paramFound, 1e-14);\n+\n+        // Check that the parameters are found within the assumed error bars.\n+        Assert.assertEquals(xCenter, paramFound[0], asymptoticStandardErrorFound[0]);\n+        Assert.assertEquals(yCenter, paramFound[1], asymptoticStandardErrorFound[1]);\n+        Assert.assertEquals(radius, paramFound[2], asymptoticStandardErrorFound[2]);\n+    }\n+\n+    private static class QuadraticProblem {\n+        private List<Double> x;\n+        private List<Double> y;\n+\n+        public QuadraticProblem() {\n+            x = new ArrayList<Double>();\n+            y = new ArrayList<Double>();\n+        }\n+\n+        public void addPoint(double x, double y) {\n+            this.x.add(x);\n+            this.y.add(y);\n+        }\n+\n+        public ModelFunction getModelFunction() {\n+            return new ModelFunction(new MultivariateVectorFunction() {\n+                    public double[] value(double[] variables) {\n+                        double[] values = new double[x.size()];\n+                        for (int i = 0; i < values.length; ++i) {\n+                            values[i] = (variables[0] * x.get(i) + variables[1]) * x.get(i) + variables[2];\n+                        }\n+                        return values;\n+                    }\n+                });\n+        }\n+\n+        public ModelFunctionJacobian getModelFunctionJacobian() {\n+            return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                    public double[][] value(double[] params) {                    \n+                        double[][] jacobian = new double[x.size()][3];\n+                        for (int i = 0; i < jacobian.length; ++i) {\n+                            jacobian[i][0] = x.get(i) * x.get(i);\n+                            jacobian[i][1] = x.get(i);\n+                            jacobian[i][2] = 1.0;\n+                        }\n+                        return jacobian;\n+                    }\n+                });\n+        }\n+    }\n+\n+    private static class BevingtonProblem {\n+        private List<Double> time;\n+        private List<Double> count;\n+\n+        public BevingtonProblem() {\n+            time = new ArrayList<Double>();\n+            count = new ArrayList<Double>();\n+        }\n+\n+        public void addPoint(double t, double c) {\n+            time.add(t);\n+            count.add(c);\n+        }\n+\n+        public ModelFunction getModelFunction() {\n+            return new ModelFunction(new MultivariateVectorFunction() {\n+                    public double[] value(double[] params) {\n+                        double[] values = new double[time.size()];\n+                        for (int i = 0; i < values.length; ++i) {\n+                            final double t = time.get(i);\n+                            values[i] = params[0] +\n+                                params[1] * Math.exp(-t / params[3]) +\n+                                params[2] * Math.exp(-t / params[4]);\n+                        }\n+                        return values;\n+                    }\n+                });\n+        }\n+\n+        public ModelFunctionJacobian getModelFunctionJacobian() {\n+            return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                    public double[][] value(double[] params) {\n+                        double[][] jacobian = new double[time.size()][5];\n+\n+                        for (int i = 0; i < jacobian.length; ++i) {\n+                            final double t = time.get(i);\n+                            jacobian[i][0] = 1;\n+\n+                            final double p3 =  params[3];\n+                            final double p4 =  params[4];\n+                            final double tOp3 = t / p3;\n+                            final double tOp4 = t / p4;\n+                            jacobian[i][1] = Math.exp(-tOp3);\n+                            jacobian[i][2] = Math.exp(-tOp4);\n+                            jacobian[i][3] = params[1] * Math.exp(-tOp3) * tOp3 / p3;\n+                            jacobian[i][4] = params[2] * Math.exp(-tOp4) * tOp4 / p4;\n+                        }\n+                        return jacobian;\n+                    }\n+                });\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/MinpackTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.io.Serializable;\n+import java.util.Arrays;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.InitialGuess;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.optim.nonlinear.vector.Target;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files.\n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class MinpackTest {\n+\n+    @Test\n+    public void testMinpackLinearFullRank() {\n+        minpackTest(new LinearFullRankFunction(10, 5, 1.0,\n+                                               5.0, 2.23606797749979), false);\n+        minpackTest(new LinearFullRankFunction(50, 5, 1.0,\n+                                               8.06225774829855, 6.70820393249937), false);\n+    }\n+\n+    @Test\n+    public void testMinpackLinearRank1() {\n+        minpackTest(new LinearRank1Function(10, 5, 1.0,\n+                                            291.521868819476, 1.4638501094228), false);\n+        minpackTest(new LinearRank1Function(50, 5, 1.0,\n+                                            3101.60039334535, 3.48263016573496), false);\n+    }\n+\n+    @Test\n+    public void testMinpackLinearRank1ZeroColsAndRows() {\n+        minpackTest(new LinearRank1ZeroColsAndRowsFunction(10, 5, 1.0), false);\n+        minpackTest(new LinearRank1ZeroColsAndRowsFunction(50, 5, 1.0), false);\n+    }\n+\n+    @Test\n+    public void testMinpackRosenbrok() {\n+        minpackTest(new RosenbrockFunction(new double[] { -1.2, 1.0 },\n+                                           FastMath.sqrt(24.2)), false);\n+        minpackTest(new RosenbrockFunction(new double[] { -12.0, 10.0 },\n+                                           FastMath.sqrt(1795769.0)), false);\n+        minpackTest(new RosenbrockFunction(new double[] { -120.0, 100.0 },\n+                                           11.0 * FastMath.sqrt(169000121.0)), false);\n+    }\n+\n+    @Test\n+    public void testMinpackHelicalValley() {\n+        minpackTest(new HelicalValleyFunction(new double[] { -1.0, 0.0, 0.0 },\n+                                              50.0), false);\n+        minpackTest(new HelicalValleyFunction(new double[] { -10.0, 0.0, 0.0 },\n+                                              102.95630140987), false);\n+        minpackTest(new HelicalValleyFunction(new double[] { -100.0, 0.0, 0.0},\n+                                              991.261822123701), false);\n+    }\n+\n+    @Test\n+    public void testMinpackPowellSingular() {\n+        minpackTest(new PowellSingularFunction(new double[] { 3.0, -1.0, 0.0, 1.0 },\n+                                               14.6628782986152), false);\n+        minpackTest(new PowellSingularFunction(new double[] { 30.0, -10.0, 0.0, 10.0 },\n+                                               1270.9838708654), false);\n+        minpackTest(new PowellSingularFunction(new double[] { 300.0, -100.0, 0.0, 100.0 },\n+                                               126887.903284750), false);\n+    }\n+\n+    @Test\n+    public void testMinpackFreudensteinRoth() {\n+        minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n+                                                 20.0124960961895, 6.99887517584575,\n+                                                 new double[] {\n+                                                     11.4124844654993,\n+                                                     -0.896827913731509\n+                                                 }), false);\n+        minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n+                                                 12432.833948863, 6.9988751744895,\n+                                                 new double[] {\n+                                                     11.41300466147456,\n+                                                     -0.896796038685959\n+                                                 }), false);\n+        minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n+                                                 11426454.595762, 6.99887517242903,\n+                                                 new double[] {\n+                                                     11.412781785788564,\n+                                                     -0.8968051074920405\n+                                                 }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackBard() {\n+        minpackTest(new BardFunction(1.0, 6.45613629515967, 0.0906359603390466,\n+                                     new double[] {\n+                                         0.0824105765758334,\n+                                         1.1330366534715,\n+                                         2.34369463894115\n+                                     }), false);\n+        minpackTest(new BardFunction(10.0, 36.1418531596785, 4.17476870138539,\n+                                     new double[] {\n+                                         0.840666673818329,\n+                                         -158848033.259565,\n+                                         -164378671.653535\n+                                     }), false);\n+        minpackTest(new BardFunction(100.0, 384.114678637399, 4.17476870135969,\n+                                     new double[] {\n+                                         0.840666673867645,\n+                                         -158946167.205518,\n+                                         -164464906.857771\n+                                     }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackKowalikOsborne() {\n+        minpackTest(new KowalikOsborneFunction(new double[] { 0.25, 0.39, 0.415, 0.39 },\n+                                               0.0728915102882945,\n+                                               0.017535837721129,\n+                                               new double[] {\n+                                                   0.192807810476249,\n+                                                   0.191262653354071,\n+                                                   0.123052801046931,\n+                                                   0.136053221150517\n+                                               }), false);\n+        minpackTest(new KowalikOsborneFunction(new double[] { 2.5, 3.9, 4.15, 3.9 },\n+                                               2.97937007555202,\n+                                               0.032052192917937,\n+                                               new double[] {\n+                                                   728675.473768287,\n+                                                   -14.0758803129393,\n+                                                   -32977797.7841797,\n+                                                   -20571594.1977912\n+                                               }), false);\n+        minpackTest(new KowalikOsborneFunction(new double[] { 25.0, 39.0, 41.5, 39.0 },\n+                                               29.9590617016037,\n+                                               0.0175364017658228,\n+                                               new double[] {\n+                                                   0.192948328597594,\n+                                                   0.188053165007911,\n+                                                   0.122430604321144,\n+                                                   0.134575665392506\n+                                               }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackMeyer() {\n+        minpackTest(new MeyerFunction(new double[] { 0.02, 4000.0, 250.0 },\n+                                      41153.4665543031, 9.37794514651874,\n+                                      new double[] {\n+                                          0.00560963647102661,\n+                                          6181.34634628659,\n+                                          345.223634624144\n+                                      }), false);\n+        minpackTest(new MeyerFunction(new double[] { 0.2, 40000.0, 2500.0 },\n+                                      4168216.89130846, 792.917871779501,\n+                                      new double[] {\n+                                          1.42367074157994e-11,\n+                                          33695.7133432541,\n+                                          901.268527953801\n+                                      }), true);\n+    }\n+\n+    @Test\n+    public void testMinpackWatson() {\n+        minpackTest(new WatsonFunction(6, 0.0,\n+                                       5.47722557505166, 0.0478295939097601,\n+                                       new double[] {\n+                                           -0.0157249615083782, 1.01243488232965,\n+                                           -0.232991722387673,  1.26043101102818,\n+                                           -1.51373031394421,   0.99299727291842\n+                                       }), false);\n+        minpackTest(new WatsonFunction(6, 10.0,\n+                                       6433.12578950026, 0.0478295939096951,\n+                                       new double[] {\n+                                           -0.0157251901386677, 1.01243485860105,\n+                                           -0.232991545843829,  1.26042932089163,\n+                                           -1.51372776706575,   0.99299573426328\n+                                       }), false);\n+        minpackTest(new WatsonFunction(6, 100.0,\n+                                       674256.040605213, 0.047829593911544,\n+                                       new double[] {\n+                                           -0.0157247019712586, 1.01243490925658,\n+                                           -0.232991922761641,  1.26043292929555,\n+                                           -1.51373320452707,   0.99299901922322\n+                                       }), false);\n+        minpackTest(new WatsonFunction(9, 0.0,\n+                                       5.47722557505166, 0.00118311459212420,\n+                                       new double[] {\n+                                           -0.153070644166722e-4, 0.999789703934597,\n+                                           0.0147639634910978,   0.146342330145992,\n+                                           1.00082109454817,    -2.61773112070507,\n+                                           4.10440313943354,    -3.14361226236241,\n+                                           1.05262640378759\n+                                       }), false);\n+        minpackTest(new WatsonFunction(9, 10.0,\n+                                       12088.127069307, 0.00118311459212513,\n+                                       new double[] {\n+                                           -0.153071334849279e-4, 0.999789703941234,\n+                                           0.0147639629786217,   0.146342334818836,\n+                                           1.00082107321386,    -2.61773107084722,\n+                                           4.10440307655564,    -3.14361222178686,\n+                                           1.05262639322589\n+                                       }), false);\n+        minpackTest(new WatsonFunction(9, 100.0,\n+                                       1269109.29043834, 0.00118311459212384,\n+                                       new double[] {\n+                                           -0.153069523352176e-4, 0.999789703958371,\n+                                           0.0147639625185392,   0.146342341096326,\n+                                           1.00082104729164,    -2.61773101573645,\n+                                           4.10440301427286,    -3.14361218602503,\n+                                           1.05262638516774\n+                                       }), false);\n+        minpackTest(new WatsonFunction(12, 0.0,\n+                                       5.47722557505166, 0.217310402535861e-4,\n+                                       new double[] {\n+                                           -0.660266001396382e-8, 1.00000164411833,\n+                                           -0.000563932146980154, 0.347820540050756,\n+                                           -0.156731500244233,    1.05281515825593,\n+                                           -3.24727109519451,     7.2884347837505,\n+                                           -10.271848098614,       9.07411353715783,\n+                                           -4.54137541918194,     1.01201187975044\n+                                       }), false);\n+        minpackTest(new WatsonFunction(12, 10.0,\n+                                       19220.7589790951, 0.217310402518509e-4,\n+                                       new double[] {\n+                                           -0.663710223017410e-8, 1.00000164411787,\n+                                           -0.000563932208347327, 0.347820540486998,\n+                                           -0.156731503955652,    1.05281517654573,\n+                                           -3.2472711515214,      7.28843489430665,\n+                                           -10.2718482369638,      9.07411364383733,\n+                                           -4.54137546533666,     1.01201188830857\n+                                       }), false);\n+        minpackTest(new WatsonFunction(12, 100.0,\n+                                       2018918.04462367, 0.217310402539845e-4,\n+                                       new double[] {\n+                                           -0.663806046485249e-8, 1.00000164411786,\n+                                           -0.000563932210324959, 0.347820540503588,\n+                                           -0.156731504091375,    1.05281517718031,\n+                                           -3.24727115337025,     7.28843489775302,\n+                                           -10.2718482410813,      9.07411364688464,\n+                                           -4.54137546660822,     1.0120118885369\n+                                       }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackBox3Dimensional() {\n+        minpackTest(new Box3DimensionalFunction(10, new double[] { 0.0, 10.0, 20.0 },\n+                                                32.1115837449572), false);\n+    }\n+\n+    @Test\n+    public void testMinpackJennrichSampson() {\n+        minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n+                                                64.5856498144943, 11.1517793413499,\n+                                                new double[] {\n+//                                                     0.2578330049, 0.257829976764542\n+                                                    0.2578199266368004, 0.25782997676455244\n+                                                }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackBrownDennis() {\n+        minpackTest(new BrownDennisFunction(20,\n+                                            new double[] { 25.0, 5.0, -5.0, -1.0 },\n+                                            2815.43839161816, 292.954288244866,\n+                                            new double[] {\n+                                                -11.59125141003, 13.2024883984741,\n+                                                -0.403574643314272, 0.236736269844604\n+                                            }), false);\n+        minpackTest(new BrownDennisFunction(20,\n+                                            new double[] { 250.0, 50.0, -50.0, -10.0 },\n+                                            555073.354173069, 292.954270581415,\n+                                            new double[] {\n+                                                -11.5959274272203, 13.2041866926242,\n+                                                -0.403417362841545, 0.236771143410386\n+                                            }), false);\n+        minpackTest(new BrownDennisFunction(20,\n+                                            new double[] { 2500.0, 500.0, -500.0, -100.0 },\n+                                            61211252.2338581, 292.954306151134,\n+                                            new double[] {\n+                                                -11.5902596937374, 13.2020628854665,\n+                                                -0.403688070279258, 0.236665033746463\n+                                            }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackChebyquad() {\n+        minpackTest(new ChebyquadFunction(1, 8, 1.0,\n+                                          1.88623796907732, 1.88623796907732,\n+                                          new double[] { 0.5 }), false);\n+        minpackTest(new ChebyquadFunction(1, 8, 10.0,\n+                                          5383344372.34005, 1.88424820499951,\n+                                          new double[] { 0.9817314924684 }), false);\n+        minpackTest(new ChebyquadFunction(1, 8, 100.0,\n+                                          0.118088726698392e19, 1.88424820499347,\n+                                          new double[] { 0.9817314852934 }), false);\n+        minpackTest(new ChebyquadFunction(8, 8, 1.0,\n+                                          0.196513862833975, 0.0593032355046727,\n+                                          new double[] {\n+                                              0.0431536648587336, 0.193091637843267,\n+                                              0.266328593812698,  0.499999334628884,\n+                                              0.500000665371116,  0.733671406187302,\n+                                              0.806908362156733,  0.956846335141266\n+                                          }), false);\n+        minpackTest(new ChebyquadFunction(9, 9, 1.0,\n+                                          0.16994993465202, 0.0,\n+                                          new double[] {\n+                                              0.0442053461357828, 0.199490672309881,\n+                                              0.23561910847106,   0.416046907892598,\n+                                              0.5,                0.583953092107402,\n+                                              0.764380891528940,  0.800509327690119,\n+                                              0.955794653864217\n+                                          }), false);\n+        minpackTest(new ChebyquadFunction(10, 10, 1.0,\n+                                          0.183747831178711, 0.0806471004038253,\n+                                          new double[] {\n+                                              0.0596202671753563, 0.166708783805937,\n+                                              0.239171018813509,  0.398885290346268,\n+                                              0.398883667870681,  0.601116332129320,\n+                                              0.60111470965373,   0.760828981186491,\n+                                              0.833291216194063,  0.940379732824644\n+                                          }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackBrownAlmostLinear() {\n+        minpackTest(new BrownAlmostLinearFunction(10, 0.5,\n+                                                  16.5302162063499, 0.0,\n+                                                  new double[] {\n+                                                      0.979430303349862, 0.979430303349862,\n+                                                      0.979430303349862, 0.979430303349862,\n+                                                      0.979430303349862, 0.979430303349862,\n+                                                      0.979430303349862, 0.979430303349862,\n+                                                      0.979430303349862, 1.20569696650138\n+                                                  }), false);\n+        minpackTest(new BrownAlmostLinearFunction(10, 5.0,\n+                                                  9765624.00089211, 0.0,\n+                                                  new double[] {\n+                                                      0.979430303349865, 0.979430303349865,\n+                                                      0.979430303349865, 0.979430303349865,\n+                                                      0.979430303349865, 0.979430303349865,\n+                                                      0.979430303349865, 0.979430303349865,\n+                                                      0.979430303349865, 1.20569696650135\n+                                                  }), false);\n+        minpackTest(new BrownAlmostLinearFunction(10, 50.0,\n+                                                  0.9765625e17, 0.0,\n+                                                  new double[] {\n+                                                      1.0, 1.0, 1.0, 1.0, 1.0,\n+                                                      1.0, 1.0, 1.0, 1.0, 1.0\n+                                                  }), false);\n+        minpackTest(new BrownAlmostLinearFunction(30, 0.5,\n+                                                  83.476044467848, 0.0,\n+                                                  new double[] {\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 0.997754216442807,\n+                                                      0.997754216442807, 1.06737350671578\n+                                                  }), false);\n+        minpackTest(new BrownAlmostLinearFunction(40, 0.5,\n+                                                  128.026364472323, 0.0,\n+                                                  new double[] {\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      1.00000000000002, 1.00000000000002,\n+                                                      0.999999999999121\n+                                                  }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackOsborne1() {\n+        minpackTest(new Osborne1Function(new double[] { 0.5, 1.5, -1.0, 0.01, 0.02, },\n+                                         0.937564021037838, 0.00739249260904843,\n+                                         new double[] {\n+                                             0.375410049244025, 1.93584654543108,\n+                                             -1.46468676748716, 0.0128675339110439,\n+                                             0.0221227011813076\n+                                         }), false);\n+    }\n+\n+    @Test\n+    public void testMinpackOsborne2() {\n+        minpackTest(new Osborne2Function(new double[] {\n+                    1.3, 0.65, 0.65, 0.7, 0.6,\n+                    3.0, 5.0, 7.0, 2.0, 4.5, 5.5\n+                },\n+                1.44686540984712, 0.20034404483314,\n+                new double[] {\n+                    1.30997663810096,  0.43155248076,\n+                    0.633661261602859, 0.599428560991695,\n+                    0.754179768272449, 0.904300082378518,\n+                    1.36579949521007, 4.82373199748107,\n+                    2.39868475104871, 4.56887554791452,\n+                    5.67534206273052\n+                }), false);\n+    }\n+\n+    private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n+        LevenbergMarquardtOptimizer optimizer\n+            = new LevenbergMarquardtOptimizer(FastMath.sqrt(2.22044604926e-16),\n+                                              FastMath.sqrt(2.22044604926e-16),\n+                                              2.22044604926e-16);\n+        try {\n+            PointVectorValuePair optimum\n+                = optimizer.optimize(new MaxEval(400 * (function.getN() + 1)),\n+                                     function.getModelFunction(),\n+                                     function.getModelFunctionJacobian(),\n+                                     new Target(function.getTarget()),\n+                                     new Weight(function.getWeight()),\n+                                     new InitialGuess(function.getStartPoint()));\n+            Assert.assertFalse(exceptionExpected);\n+            function.checkTheoreticalMinCost(optimizer.getRMS());\n+            function.checkTheoreticalMinParams(optimum);\n+        } catch (TooManyEvaluationsException e) {\n+            Assert.assertTrue(exceptionExpected);\n+        }\n+    }\n+\n+    private static abstract class MinpackFunction {\n+        protected int      n;\n+        protected int      m;\n+        protected double[] startParams;\n+        protected double   theoreticalMinCost;\n+        protected double[] theoreticalMinParams;\n+        protected double   costAccuracy;\n+        protected double   paramsAccuracy;\n+\n+        protected MinpackFunction(int m, double[] startParams,\n+                                  double theoreticalMinCost,\n+                                  double[] theoreticalMinParams) {\n+            this.m = m;\n+            this.n = startParams.length;\n+            this.startParams          = startParams.clone();\n+            this.theoreticalMinCost   = theoreticalMinCost;\n+            this.theoreticalMinParams = theoreticalMinParams;\n+            this.costAccuracy         = 1.0e-8;\n+            this.paramsAccuracy       = 1.0e-5;\n+        }\n+\n+        protected static double[] buildArray(int n, double x) {\n+            double[] array = new double[n];\n+            Arrays.fill(array, x);\n+            return array;\n+        }\n+\n+        public double[] getTarget() {\n+            return buildArray(m, 0.0);\n+        }\n+\n+        public double[] getWeight() {\n+            return buildArray(m, 1.0);\n+        }\n+\n+        public double[] getStartPoint() {\n+            return startParams.clone();\n+        }\n+\n+        protected void setCostAccuracy(double costAccuracy) {\n+            this.costAccuracy = costAccuracy;\n+        }\n+\n+        protected void setParamsAccuracy(double paramsAccuracy) {\n+            this.paramsAccuracy = paramsAccuracy;\n+        }\n+\n+        public int getN() {\n+            return startParams.length;\n+        }\n+\n+        public void checkTheoreticalMinCost(double rms) {\n+            double threshold = costAccuracy * (1.0 + theoreticalMinCost);\n+            Assert.assertEquals(theoreticalMinCost, FastMath.sqrt(m) * rms, threshold);\n+        }\n+\n+        public void checkTheoreticalMinParams(PointVectorValuePair optimum) {\n+            double[] params = optimum.getPointRef();\n+            if (theoreticalMinParams != null) {\n+                for (int i = 0; i < theoreticalMinParams.length; ++i) {\n+                    double mi = theoreticalMinParams[i];\n+                    double vi = params[i];\n+                    Assert.assertEquals(mi, vi, paramsAccuracy * (1.0 + FastMath.abs(mi)));\n+                }\n+            }\n+        }\n+\n+        public ModelFunction getModelFunction() {\n+            return new ModelFunction(new MultivariateVectorFunction() {\n+                    public double[] value(double[] point) {\n+                        return computeValue(point);\n+                    }\n+                });\n+        }\n+\n+        public ModelFunctionJacobian getModelFunctionJacobian() {\n+            return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                    public double[][] value(double[] point) {\n+                        return computeJacobian(point);\n+                    }\n+                });\n+        }\n+\n+        public abstract double[][] computeJacobian(double[] variables);\n+        public abstract double[] computeValue(double[] variables);\n+    }\n+\n+    private static class LinearFullRankFunction extends MinpackFunction {\n+        private static final long serialVersionUID = -9030323226268039536L;\n+        \n+        public LinearFullRankFunction(int m, int n, double x0,\n+                                      double theoreticalStartCost,\n+                                      double theoreticalMinCost) {\n+            super(m, buildArray(n, x0), theoreticalMinCost,\n+                  buildArray(n, -1.0));\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double t = 2.0 / m;\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                jacobian[i] = new double[n];\n+                for (int j = 0; j < n; ++j) {\n+                    jacobian[i][j] = (i == j) ? (1 - t) : -t;\n+                }\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double sum = 0;\n+            for (int i = 0; i < n; ++i) {\n+                sum += variables[i];\n+            }\n+            double t  = 1 + 2 * sum / m;\n+            double[] f = new double[m];\n+            for (int i = 0; i < n; ++i) {\n+                f[i] = variables[i] - t;\n+            }\n+            Arrays.fill(f, n, m, -t);\n+            return f;\n+        }\n+    }\n+\n+    private static class LinearRank1Function extends MinpackFunction {\n+        private static final long serialVersionUID = 8494863245104608300L;\n+\n+        public LinearRank1Function(int m, int n, double x0,\n+                                   double theoreticalStartCost,\n+                                   double theoreticalMinCost) {\n+            super(m, buildArray(n, x0), theoreticalMinCost, null);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                jacobian[i] = new double[n];\n+                for (int j = 0; j < n; ++j) {\n+                    jacobian[i][j] = (i + 1) * (j + 1);\n+                }\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double[] f = new double[m];\n+            double sum = 0;\n+            for (int i = 0; i < n; ++i) {\n+                sum += (i + 1) * variables[i];\n+            }\n+            for (int i = 0; i < m; ++i) {\n+                f[i] = (i + 1) * sum - 1;\n+            }\n+            return f;\n+        }\n+    }\n+\n+    private static class LinearRank1ZeroColsAndRowsFunction extends MinpackFunction {\n+        private static final long serialVersionUID = -3316653043091995018L;\n+\n+        public LinearRank1ZeroColsAndRowsFunction(int m, int n, double x0) {\n+            super(m, buildArray(n, x0),\n+                  FastMath.sqrt((m * (m + 3) - 6) / (2.0 * (2 * m - 3))),\n+                  null);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                jacobian[i] = new double[n];\n+                jacobian[i][0] = 0;\n+                for (int j = 1; j < (n - 1); ++j) {\n+                    if (i == 0) {\n+                        jacobian[i][j] = 0;\n+                    } else if (i != (m - 1)) {\n+                        jacobian[i][j] = i * (j + 1);\n+                    } else {\n+                        jacobian[i][j] = 0;\n+                    }\n+                }\n+                jacobian[i][n - 1] = 0;\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double[] f = new double[m];\n+            double sum = 0;\n+            for (int i = 1; i < (n - 1); ++i) {\n+                sum += (i + 1) * variables[i];\n+            }\n+            for (int i = 0; i < (m - 1); ++i) {\n+                f[i] = i * sum - 1;\n+            }\n+            f[m - 1] = -1;\n+            return f;\n+        }\n+    }\n+\n+    private static class RosenbrockFunction extends MinpackFunction {\n+        private static final long serialVersionUID = 2893438180956569134L;\n+        public RosenbrockFunction(double[] startParams, double theoreticalStartCost) {\n+            super(2, startParams, 0.0, buildArray(2, 1.0));\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double x1 = variables[0];\n+            return new double[][] { { -20 * x1, 10 }, { -1, 0 } };\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            return new double[] { 10 * (x2 - x1 * x1), 1 - x1 };\n+        }\n+    }\n+\n+    private static class HelicalValleyFunction extends MinpackFunction {\n+        private static final long serialVersionUID = 220613787843200102L;\n+        public HelicalValleyFunction(double[] startParams,\n+                                     double theoreticalStartCost) {\n+            super(3, startParams, 0.0, new double[] { 1.0, 0.0, 0.0 });\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double tmpSquare = x1 * x1 + x2 * x2;\n+            double tmp1 = twoPi * tmpSquare;\n+            double tmp2 = FastMath.sqrt(tmpSquare);\n+            return new double[][] {\n+                {  100 * x2 / tmp1, -100 * x1 / tmp1, 10 },\n+                { 10 * x1 / tmp2, 10 * x2 / tmp2, 0 },\n+                { 0, 0, 1 }\n+            };\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double x3 = variables[2];\n+            double tmp1;\n+            if (x1 == 0) {\n+                tmp1 = (x2 >= 0) ? 0.25 : -0.25;\n+            } else {\n+                tmp1 = FastMath.atan(x2 / x1) / twoPi;\n+                if (x1 < 0) {\n+                    tmp1 += 0.5;\n+                }\n+            }\n+            double tmp2 = FastMath.sqrt(x1 * x1 + x2 * x2);\n+            return new double[] {\n+                10.0 * (x3 - 10 * tmp1),\n+                10.0 * (tmp2 - 1),\n+                x3\n+            };\n+        }\n+\n+        private static final double twoPi = 2.0 * FastMath.PI;\n+    }\n+\n+    private static class PowellSingularFunction extends MinpackFunction {\n+        private static final long serialVersionUID = 7298364171208142405L;\n+\n+        public PowellSingularFunction(double[] startParams,\n+                                      double theoreticalStartCost) {\n+            super(4, startParams, 0.0, buildArray(4, 0.0));\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double x3 = variables[2];\n+            double x4 = variables[3];\n+            return new double[][] {\n+                { 1, 10, 0, 0 },\n+                { 0, 0, sqrt5, -sqrt5 },\n+                { 0, 2 * (x2 - 2 * x3), -4 * (x2 - 2 * x3), 0 },\n+                { 2 * sqrt10 * (x1 - x4), 0, 0, -2 * sqrt10 * (x1 - x4) }\n+            };\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double x3 = variables[2];\n+            double x4 = variables[3];\n+            return new double[] {\n+                x1 + 10 * x2,\n+                sqrt5 * (x3 - x4),\n+                (x2 - 2 * x3) * (x2 - 2 * x3),\n+                sqrt10 * (x1 - x4) * (x1 - x4)\n+            };\n+        }\n+\n+        private static final double sqrt5  = FastMath.sqrt( 5.0);\n+        private static final double sqrt10 = FastMath.sqrt(10.0);\n+  }\n+\n+    private static class FreudensteinRothFunction extends MinpackFunction {\n+        private static final long serialVersionUID = 2892404999344244214L;\n+\n+        public FreudensteinRothFunction(double[] startParams,\n+                                        double theoreticalStartCost,\n+                                        double theoreticalMinCost,\n+                                        double[] theoreticalMinParams) {\n+            super(2, startParams, theoreticalMinCost,\n+                  theoreticalMinParams);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double x2 = variables[1];\n+            return new double[][] {\n+                { 1, x2 * (10 - 3 * x2) -  2 },\n+                { 1, x2 * ( 2 + 3 * x2) - 14, }\n+            };\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            return new double[] {\n+                -13.0 + x1 + ((5.0 - x2) * x2 -  2.0) * x2,\n+                -29.0 + x1 + ((1.0 + x2) * x2 - 14.0) * x2\n+            };\n+        }\n+    }\n+\n+    private static class BardFunction extends MinpackFunction {\n+        private static final long serialVersionUID = 5990442612572087668L;\n+\n+        public BardFunction(double x0,\n+                            double theoreticalStartCost,\n+                            double theoreticalMinCost,\n+                            double[] theoreticalMinParams) {\n+            super(15, buildArray(3, x0), theoreticalMinCost,\n+                  theoreticalMinParams);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double   x2 = variables[1];\n+            double   x3 = variables[2];\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                double tmp1 = i  + 1;\n+                double tmp2 = 15 - i;\n+                double tmp3 = (i <= 7) ? tmp1 : tmp2;\n+                double tmp4 = x2 * tmp2 + x3 * tmp3;\n+                tmp4 *= tmp4;\n+                jacobian[i] = new double[] { -1, tmp1 * tmp2 / tmp4, tmp1 * tmp3 / tmp4 };\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double   x1 = variables[0];\n+            double   x2 = variables[1];\n+            double   x3 = variables[2];\n+            double[] f = new double[m];\n+            for (int i = 0; i < m; ++i) {\n+                double tmp1 = i + 1;\n+                double tmp2 = 15 - i;\n+                double tmp3 = (i <= 7) ? tmp1 : tmp2;\n+                f[i] = y[i] - (x1 + tmp1 / (x2 * tmp2 + x3 * tmp3));\n+            }\n+            return f;\n+        }\n+\n+        private static final double[] y = {\n+            0.14, 0.18, 0.22, 0.25, 0.29,\n+            0.32, 0.35, 0.39, 0.37, 0.58,\n+            0.73, 0.96, 1.34, 2.10, 4.39\n+        };\n+    }\n+\n+    private static class KowalikOsborneFunction extends MinpackFunction {\n+        private static final long serialVersionUID = -4867445739880495801L;\n+\n+        public KowalikOsborneFunction(double[] startParams,\n+                                      double theoreticalStartCost,\n+                                      double theoreticalMinCost,\n+                                      double[] theoreticalMinParams) {\n+            super(11, startParams, theoreticalMinCost,\n+                  theoreticalMinParams);\n+            if (theoreticalStartCost > 20.0) {\n+                setCostAccuracy(2.0e-4);\n+                setParamsAccuracy(5.0e-3);\n+            }\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double   x1 = variables[0];\n+            double   x2 = variables[1];\n+            double   x3 = variables[2];\n+            double   x4 = variables[3];\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                double tmp = v[i] * (v[i] + x3) + x4;\n+                double j1  = -v[i] * (v[i] + x2) / tmp;\n+                double j2  = -v[i] * x1 / tmp;\n+                double j3  = j1 * j2;\n+                double j4  = j3 / v[i];\n+                jacobian[i] = new double[] { j1, j2, j3, j4 };\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double x3 = variables[2];\n+            double x4 = variables[3];\n+            double[] f = new double[m];\n+            for (int i = 0; i < m; ++i) {\n+                f[i] = y[i] - x1 * (v[i] * (v[i] + x2)) / (v[i] * (v[i] + x3) + x4);\n+            }\n+            return f;\n+        }\n+\n+        private static final double[] v = {\n+            4.0, 2.0, 1.0, 0.5, 0.25, 0.167, 0.125, 0.1, 0.0833, 0.0714, 0.0625\n+        };\n+\n+        private static final double[] y = {\n+            0.1957, 0.1947, 0.1735, 0.1600, 0.0844, 0.0627,\n+            0.0456, 0.0342, 0.0323, 0.0235, 0.0246\n+        };\n+    }\n+\n+    private static class MeyerFunction extends MinpackFunction {\n+        private static final long serialVersionUID = -838060619150131027L;\n+\n+        public MeyerFunction(double[] startParams,\n+                             double theoreticalStartCost,\n+                             double theoreticalMinCost,\n+                             double[] theoreticalMinParams) {\n+            super(16, startParams, theoreticalMinCost,\n+                  theoreticalMinParams);\n+            if (theoreticalStartCost > 1.0e6) {\n+                setCostAccuracy(7.0e-3);\n+                setParamsAccuracy(2.0e-2);\n+            }\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double   x1 = variables[0];\n+            double   x2 = variables[1];\n+            double   x3 = variables[2];\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                double temp = 5.0 * (i + 1) + 45.0 + x3;\n+                double tmp1 = x2 / temp;\n+                double tmp2 = FastMath.exp(tmp1);\n+                double tmp3 = x1 * tmp2 / temp;\n+                jacobian[i] = new double[] { tmp2, tmp3, -tmp1 * tmp3 };\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double x3 = variables[2];\n+            double[] f = new double[m];\n+            for (int i = 0; i < m; ++i) {\n+                f[i] = x1 * FastMath.exp(x2 / (5.0 * (i + 1) + 45.0 + x3)) - y[i];\n+            }\n+            return f;\n+        }\n+\n+        private static final double[] y = {\n+            34780.0, 28610.0, 23650.0, 19630.0,\n+            16370.0, 13720.0, 11540.0,  9744.0,\n+            8261.0,  7030.0,  6005.0,  5147.0,\n+            4427.0,  3820.0,  3307.0,  2872.0\n+        };\n+    }\n+\n+    private static class WatsonFunction extends MinpackFunction {\n+        private static final long serialVersionUID = -9034759294980218927L;\n+\n+        public WatsonFunction(int n, double x0,\n+                              double theoreticalStartCost,\n+                              double theoreticalMinCost,\n+                              double[] theoreticalMinParams) {\n+            super(31, buildArray(n, x0), theoreticalMinCost,\n+                  theoreticalMinParams);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double[][] jacobian = new double[m][];\n+\n+            for (int i = 0; i < (m - 2); ++i) {\n+                double div = (i + 1) / 29.0;\n+                double s2  = 0.0;\n+                double dx  = 1.0;\n+                for (int j = 0; j < n; ++j) {\n+                    s2 += dx * variables[j];\n+                    dx *= div;\n+                }\n+                double temp= 2 * div * s2;\n+                dx = 1.0 / div;\n+                jacobian[i] = new double[n];\n+                for (int j = 0; j < n; ++j) {\n+                    jacobian[i][j] = dx * (j - temp);\n+                    dx *= div;\n+                }\n+            }\n+\n+            jacobian[m - 2]    = new double[n];\n+            jacobian[m - 2][0] = 1;\n+\n+            jacobian[m - 1]   = new double[n];\n+            jacobian[m - 1][0]= -2 * variables[0];\n+            jacobian[m - 1][1]= 1;\n+\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double[] f = new double[m];\n+            for (int i = 0; i < (m - 2); ++i) {\n+                double div = (i + 1) / 29.0;\n+                double s1 = 0;\n+                double dx = 1;\n+                for (int j = 1; j < n; ++j) {\n+                    s1 += j * dx * variables[j];\n+                    dx *= div;\n+                }\n+                double s2 = 0;\n+                dx = 1;\n+                for (int j = 0; j < n; ++j) {\n+                    s2 += dx * variables[j];\n+                    dx *= div;\n+                }\n+                f[i] = s1 - s2 * s2 - 1;\n+            }\n+\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            f[m - 2] = x1;\n+            f[m - 1] = x2 - x1 * x1 - 1;\n+\n+            return f;\n+        }\n+    }\n+\n+    private static class Box3DimensionalFunction extends MinpackFunction {\n+        private static final long serialVersionUID = 5511403858142574493L;\n+\n+        public Box3DimensionalFunction(int m, double[] startParams,\n+                                       double theoreticalStartCost) {\n+            super(m, startParams, 0.0,\n+                  new double[] { 1.0, 10.0, 1.0 });\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double   x1 = variables[0];\n+            double   x2 = variables[1];\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                double tmp = (i + 1) / 10.0;\n+                jacobian[i] = new double[] {\n+                    -tmp * FastMath.exp(-tmp * x1),\n+                    tmp * FastMath.exp(-tmp * x2),\n+                    FastMath.exp(-i - 1) - FastMath.exp(-tmp)\n+                };\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double x3 = variables[2];\n+            double[] f = new double[m];\n+            for (int i = 0; i < m; ++i) {\n+                double tmp = (i + 1) / 10.0;\n+                f[i] = FastMath.exp(-tmp * x1) - FastMath.exp(-tmp * x2)\n+                    + (FastMath.exp(-i - 1) - FastMath.exp(-tmp)) * x3;\n+            }\n+            return f;\n+        }\n+    }\n+\n+    private static class JennrichSampsonFunction extends MinpackFunction {\n+        private static final long serialVersionUID = -2489165190443352947L;\n+\n+        public JennrichSampsonFunction(int m, double[] startParams,\n+                                       double theoreticalStartCost,\n+                                       double theoreticalMinCost,\n+                                       double[] theoreticalMinParams) {\n+            super(m, startParams, theoreticalMinCost,\n+                  theoreticalMinParams);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double   x1 = variables[0];\n+            double   x2 = variables[1];\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                double t = i + 1;\n+                jacobian[i] = new double[] { -t * FastMath.exp(t * x1), -t * FastMath.exp(t * x2) };\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double[] f = new double[m];\n+            for (int i = 0; i < m; ++i) {\n+                double temp = i + 1;\n+                f[i] = 2 + 2 * temp - FastMath.exp(temp * x1) - FastMath.exp(temp * x2);\n+            }\n+            return f;\n+        }\n+    }\n+\n+    private static class BrownDennisFunction extends MinpackFunction {\n+        private static final long serialVersionUID = 8340018645694243910L;\n+\n+        public BrownDennisFunction(int m, double[] startParams,\n+                                   double theoreticalStartCost,\n+                                   double theoreticalMinCost,\n+                                   double[] theoreticalMinParams) {\n+            super(m, startParams, theoreticalMinCost,\n+                theoreticalMinParams);\n+            setCostAccuracy(2.5e-8);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double   x1 = variables[0];\n+            double   x2 = variables[1];\n+            double   x3 = variables[2];\n+            double   x4 = variables[3];\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                double temp = (i + 1) / 5.0;\n+                double ti   = FastMath.sin(temp);\n+                double tmp1 = x1 + temp * x2 - FastMath.exp(temp);\n+                double tmp2 = x3 + ti   * x4 - FastMath.cos(temp);\n+                jacobian[i] = new double[] {\n+                    2 * tmp1, 2 * temp * tmp1, 2 * tmp2, 2 * ti * tmp2\n+                };\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double x3 = variables[2];\n+            double x4 = variables[3];\n+            double[] f = new double[m];\n+            for (int i = 0; i < m; ++i) {\n+                double temp = (i + 1) / 5.0;\n+                double tmp1 = x1 + temp * x2 - FastMath.exp(temp);\n+                double tmp2 = x3 + FastMath.sin(temp) * x4 - FastMath.cos(temp);\n+                f[i] = tmp1 * tmp1 + tmp2 * tmp2;\n+            }\n+            return f;\n+        }\n+    }\n+\n+    private static class ChebyquadFunction extends MinpackFunction {\n+        private static final long serialVersionUID = -2394877275028008594L;\n+\n+        private static double[] buildChebyquadArray(int n, double factor) {\n+            double[] array = new double[n];\n+            double inv = factor / (n + 1);\n+            for (int i = 0; i < n; ++i) {\n+                array[i] = (i + 1) * inv;\n+            }\n+            return array;\n+        }\n+\n+        public ChebyquadFunction(int n, int m, double factor,\n+                                 double theoreticalStartCost,\n+                                 double theoreticalMinCost,\n+                                 double[] theoreticalMinParams) {\n+            super(m, buildChebyquadArray(n, factor), theoreticalMinCost,\n+                  theoreticalMinParams);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                jacobian[i] = new double[n];\n+            }\n+\n+            double dx = 1.0 / n;\n+            for (int j = 0; j < n; ++j) {\n+                double tmp1 = 1;\n+                double tmp2 = 2 * variables[j] - 1;\n+                double temp = 2 * tmp2;\n+                double tmp3 = 0;\n+                double tmp4 = 2;\n+                for (int i = 0; i < m; ++i) {\n+                    jacobian[i][j] = dx * tmp4;\n+                    double ti = 4 * tmp2 + temp * tmp4 - tmp3;\n+                    tmp3 = tmp4;\n+                    tmp4 = ti;\n+                    ti   = temp * tmp2 - tmp1;\n+                    tmp1 = tmp2;\n+                    tmp2 = ti;\n+                }\n+            }\n+\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double[] f = new double[m];\n+\n+            for (int j = 0; j < n; ++j) {\n+                double tmp1 = 1;\n+                double tmp2 = 2 * variables[j] - 1;\n+                double temp = 2 * tmp2;\n+                for (int i = 0; i < m; ++i) {\n+                    f[i] += tmp2;\n+                    double ti = temp * tmp2 - tmp1;\n+                    tmp1 = tmp2;\n+                    tmp2 = ti;\n+                }\n+            }\n+\n+            double dx = 1.0 / n;\n+            boolean iev = false;\n+            for (int i = 0; i < m; ++i) {\n+                f[i] *= dx;\n+                if (iev) {\n+                    f[i] += 1.0 / (i * (i + 2));\n+                }\n+                iev = ! iev;\n+            }\n+\n+            return f;\n+        }\n+    }\n+\n+    private static class BrownAlmostLinearFunction extends MinpackFunction {\n+        private static final long serialVersionUID = 8239594490466964725L;\n+\n+        public BrownAlmostLinearFunction(int m, double factor,\n+                                         double theoreticalStartCost,\n+                                         double theoreticalMinCost,\n+                                         double[] theoreticalMinParams) {\n+            super(m, buildArray(m, factor), theoreticalMinCost,\n+                  theoreticalMinParams);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                jacobian[i] = new double[n];\n+            }\n+\n+            double prod = 1;\n+            for (int j = 0; j < n; ++j) {\n+                prod *= variables[j];\n+                for (int i = 0; i < n; ++i) {\n+                    jacobian[i][j] = 1;\n+                }\n+                jacobian[j][j] = 2;\n+            }\n+\n+            for (int j = 0; j < n; ++j) {\n+                double temp = variables[j];\n+                if (temp == 0) {\n+                    temp = 1;\n+                    prod = 1;\n+                    for (int k = 0; k < n; ++k) {\n+                        if (k != j) {\n+                            prod *= variables[k];\n+                        }\n+                    }\n+                }\n+                jacobian[n - 1][j] = prod / temp;\n+            }\n+\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double[] f = new double[m];\n+            double sum  = -(n + 1);\n+            double prod = 1;\n+            for (int j = 0; j < n; ++j) {\n+                sum  += variables[j];\n+                prod *= variables[j];\n+            }\n+            for (int i = 0; i < n; ++i) {\n+                f[i] = variables[i] + sum;\n+            }\n+            f[n - 1] = prod - 1;\n+            return f;\n+        }\n+    }\n+\n+    private static class Osborne1Function extends MinpackFunction {\n+        private static final long serialVersionUID = 4006743521149849494L;\n+\n+        public Osborne1Function(double[] startParams,\n+                                double theoreticalStartCost,\n+                                double theoreticalMinCost,\n+                                double[] theoreticalMinParams) {\n+            super(33, startParams, theoreticalMinCost,\n+                  theoreticalMinParams);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double   x2 = variables[1];\n+            double   x3 = variables[2];\n+            double   x4 = variables[3];\n+            double   x5 = variables[4];\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                double temp = 10.0 * i;\n+                double tmp1 = FastMath.exp(-temp * x4);\n+                double tmp2 = FastMath.exp(-temp * x5);\n+                jacobian[i] = new double[] {\n+                    -1, -tmp1, -tmp2, temp * x2 * tmp1, temp * x3 * tmp2\n+                };\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x1 = variables[0];\n+            double x2 = variables[1];\n+            double x3 = variables[2];\n+            double x4 = variables[3];\n+            double x5 = variables[4];\n+            double[] f = new double[m];\n+            for (int i = 0; i < m; ++i) {\n+                double temp = 10.0 * i;\n+                double tmp1 = FastMath.exp(-temp * x4);\n+                double tmp2 = FastMath.exp(-temp * x5);\n+                f[i] = y[i] - (x1 + x2 * tmp1 + x3 * tmp2);\n+            }\n+            return f;\n+        }\n+        \n+        private static final double[] y = {\n+            0.844, 0.908, 0.932, 0.936, 0.925, 0.908, 0.881, 0.850, 0.818, 0.784, 0.751,\n+            0.718, 0.685, 0.658, 0.628, 0.603, 0.580, 0.558, 0.538, 0.522, 0.506, 0.490,\n+            0.478, 0.467, 0.457, 0.448, 0.438, 0.431, 0.424, 0.420, 0.414, 0.411, 0.406\n+        };\n+    }\n+\n+    private static class Osborne2Function extends MinpackFunction {\n+        private static final long serialVersionUID = -8418268780389858746L;\n+\n+        public Osborne2Function(double[] startParams,\n+                                double theoreticalStartCost,\n+                                double theoreticalMinCost,\n+                                double[] theoreticalMinParams) {\n+            super(65, startParams, theoreticalMinCost,\n+                  theoreticalMinParams);\n+        }\n+\n+        @Override\n+        public double[][] computeJacobian(double[] variables) {\n+            double   x01 = variables[0];\n+            double   x02 = variables[1];\n+            double   x03 = variables[2];\n+            double   x04 = variables[3];\n+            double   x05 = variables[4];\n+            double   x06 = variables[5];\n+            double   x07 = variables[6];\n+            double   x08 = variables[7];\n+            double   x09 = variables[8];\n+            double   x10 = variables[9];\n+            double   x11 = variables[10];\n+            double[][] jacobian = new double[m][];\n+            for (int i = 0; i < m; ++i) {\n+                double temp = i / 10.0;\n+                double tmp1 = FastMath.exp(-x05 * temp);\n+                double tmp2 = FastMath.exp(-x06 * (temp - x09) * (temp - x09));\n+                double tmp3 = FastMath.exp(-x07 * (temp - x10) * (temp - x10));\n+                double tmp4 = FastMath.exp(-x08 * (temp - x11) * (temp - x11));\n+                jacobian[i] = new double[] {\n+                    -tmp1,\n+                    -tmp2,\n+                    -tmp3,\n+                    -tmp4,\n+                    temp * x01 * tmp1,\n+                    x02 * (temp - x09) * (temp - x09) * tmp2,\n+                    x03 * (temp - x10) * (temp - x10) * tmp3,\n+                    x04 * (temp - x11) * (temp - x11) * tmp4,\n+                    -2 * x02 * x06 * (temp - x09) * tmp2,\n+                    -2 * x03 * x07 * (temp - x10) * tmp3,\n+                    -2 * x04 * x08 * (temp - x11) * tmp4\n+                };\n+            }\n+            return jacobian;\n+        }\n+\n+        @Override\n+        public double[] computeValue(double[] variables) {\n+            double x01 = variables[0];\n+            double x02 = variables[1];\n+            double x03 = variables[2];\n+            double x04 = variables[3];\n+            double x05 = variables[4];\n+            double x06 = variables[5];\n+            double x07 = variables[6];\n+            double x08 = variables[7];\n+            double x09 = variables[8];\n+            double x10 = variables[9];\n+            double x11 = variables[10];\n+            double[] f = new double[m];\n+            for (int i = 0; i < m; ++i) {\n+                double temp = i / 10.0;\n+                double tmp1 = FastMath.exp(-x05 * temp);\n+                double tmp2 = FastMath.exp(-x06 * (temp - x09) * (temp - x09));\n+                double tmp3 = FastMath.exp(-x07 * (temp - x10) * (temp - x10));\n+                double tmp4 = FastMath.exp(-x08 * (temp - x11) * (temp - x11));\n+                f[i] = y[i] - (x01 * tmp1 + x02 * tmp2 + x03 * tmp3 + x04 * tmp4);\n+            }\n+            return f;\n+        }\n+\n+        private static final double[] y = {\n+            1.366, 1.191, 1.112, 1.013, 0.991,\n+            0.885, 0.831, 0.847, 0.786, 0.725,\n+            0.746, 0.679, 0.608, 0.655, 0.616,\n+            0.606, 0.602, 0.626, 0.651, 0.724,\n+            0.649, 0.649, 0.694, 0.644, 0.624,\n+            0.661, 0.612, 0.558, 0.533, 0.495,\n+            0.500, 0.423, 0.395, 0.375, 0.372,\n+            0.391, 0.396, 0.405, 0.428, 0.429,\n+            0.523, 0.562, 0.607, 0.653, 0.672,\n+            0.708, 0.633, 0.668, 0.645, 0.632,\n+            0.591, 0.559, 0.597, 0.625, 0.739,\n+            0.710, 0.729, 0.720, 0.636, 0.581,\n+            0.428, 0.292, 0.162, 0.098, 0.054\n+        };\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/RandomCirclePointGenerator.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import org.apache.commons.math3.random.RandomGenerator;\n+import org.apache.commons.math3.random.Well44497b;\n+import org.apache.commons.math3.util.MathUtils;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.distribution.RealDistribution;\n+import org.apache.commons.math3.distribution.UniformRealDistribution;\n+import org.apache.commons.math3.distribution.NormalDistribution;\n+import org.apache.commons.math3.geometry.euclidean.twod.Vector2D;\n+\n+/**\n+ * Factory for generating a cloud of points that approximate a circle.\n+ */\n+public class RandomCirclePointGenerator {\n+    /** RNG for the x-coordinate of the center. */\n+    private final RealDistribution cX;\n+    /** RNG for the y-coordinate of the center. */\n+    private final RealDistribution cY;\n+    /** RNG for the parametric position of the point. */\n+    private final RealDistribution tP;\n+    /** Radius of the circle. */\n+    private final double radius;\n+\n+    /**\n+     * @param x Abscissa of the circle center.\n+     * @param y Ordinate of the circle center.\n+     * @param radius Radius of the circle.\n+     * @param xSigma Error on the x-coordinate of the circumference points.\n+     * @param ySigma Error on the y-coordinate of the circumference points.\n+     * @param seed RNG seed.\n+     */\n+    public RandomCirclePointGenerator(double x,\n+                                      double y,\n+                                      double radius,\n+                                      double xSigma,\n+                                      double ySigma,\n+                                      long seed) {\n+        final RandomGenerator rng = new Well44497b(seed);\n+        this.radius = radius;\n+        cX = new NormalDistribution(rng, x, xSigma,\n+                                    NormalDistribution.DEFAULT_INVERSE_ABSOLUTE_ACCURACY);\n+        cY = new NormalDistribution(rng, y, ySigma,\n+                                    NormalDistribution.DEFAULT_INVERSE_ABSOLUTE_ACCURACY);\n+        tP = new UniformRealDistribution(rng, 0, MathUtils.TWO_PI,\n+                                         UniformRealDistribution.DEFAULT_INVERSE_ABSOLUTE_ACCURACY);\n+    }\n+\n+    /**\n+     * Point generator.\n+     *\n+     * @param n Number of points to create.\n+     * @return the cloud of {@code n} points.\n+     */\n+    public Vector2D[] generate(int n) {\n+        final Vector2D[] cloud = new Vector2D[n];\n+        for (int i = 0; i < n; i++) {\n+            cloud[i] = create();\n+        }\n+        return cloud;\n+    }\n+\n+    /**\n+     * Create one point.\n+     *\n+     * @return a point.\n+     */\n+    private Vector2D create() {\n+        final double t = tP.sample();\n+        final double pX = cX.sample() + radius * FastMath.cos(t);\n+        final double pY = cY.sample() + radius * FastMath.sin(t);\n+\n+        return new Vector2D(pX, pY);\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/RandomStraightLinePointGenerator.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.awt.geom.Point2D;\n+import org.apache.commons.math3.random.RandomGenerator;\n+import org.apache.commons.math3.random.Well44497b;\n+import org.apache.commons.math3.distribution.RealDistribution;\n+import org.apache.commons.math3.distribution.UniformRealDistribution;\n+import org.apache.commons.math3.distribution.NormalDistribution;\n+\n+/**\n+ * Factory for generating a cloud of points that approximate a straight line.\n+ */\n+public class RandomStraightLinePointGenerator {\n+    /** Slope. */\n+    private final double slope;\n+    /** Intercept. */\n+    private final double intercept;\n+    /** RNG for the x-coordinate. */\n+    private final RealDistribution x;\n+    /** RNG for the error on the y-coordinate. */\n+    private final RealDistribution error;\n+\n+    /**\n+     * The generator will create a cloud of points whose x-coordinates\n+     * will be randomly sampled between {@code xLo} and {@code xHi}, and\n+     * the corresponding y-coordinates will be computed as\n+     * <pre><code>\n+     *  y = a x + b + N(0, error)\n+     * </code></pre>\n+     * where {@code N(mean, sigma)} is a Gaussian distribution with the\n+     * given mean and standard deviation.\n+     *\n+     * @param a Slope.\n+     * @param b Intercept.\n+     * @param sigma Standard deviation on the y-coordinate of the point.\n+     * @param lo Lowest value of the x-coordinate.\n+     * @param hi Highest value of the x-coordinate.\n+     * @param seed RNG seed.\n+     */\n+    public RandomStraightLinePointGenerator(double a,\n+                                            double b,\n+                                            double sigma,\n+                                            double lo,\n+                                            double hi,\n+                                            long seed) {\n+        final RandomGenerator rng = new Well44497b(seed);\n+        slope = a;\n+        intercept = b;\n+        error = new NormalDistribution(rng, 0, sigma,\n+                                       NormalDistribution.DEFAULT_INVERSE_ABSOLUTE_ACCURACY);\n+        x = new UniformRealDistribution(rng, lo, hi,\n+                                        UniformRealDistribution.DEFAULT_INVERSE_ABSOLUTE_ACCURACY);\n+    }\n+\n+    /**\n+     * Point generator.\n+     *\n+     * @param n Number of points to create.\n+     * @return the cloud of {@code n} points.\n+     */\n+    public Point2D.Double[] generate(int n) {\n+        final Point2D.Double[] cloud = new Point2D.Double[n];\n+        for (int i = 0; i < n; i++) {\n+            cloud[i] = create();\n+        }\n+        return cloud;\n+    }\n+\n+    /**\n+     * Create one point.\n+     *\n+     * @return a point.\n+     */\n+    private Point2D.Double create() {\n+        final double abscissa = x.sample();\n+        final double yModel = slope * abscissa + intercept;\n+        final double ordinate = yModel + error.sample();\n+\n+        return new Point2D.Double(abscissa, ordinate);\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/StatisticalReferenceDataset.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+import org.apache.commons.math3.util.MathArrays;\n+\n+/**\n+ * This class gives access to the statistical reference datasets provided by the\n+ * NIST (available\n+ * <a href=\"http://www.itl.nist.gov/div898/strd/general/dataarchive.html\">here</a>).\n+ * Instances of this class can be created by invocation of the\n+ * {@link StatisticalReferenceDatasetFactory}.\n+ */\n+public abstract class StatisticalReferenceDataset {\n+\n+    /** The name of this dataset. */\n+    private final String name;\n+\n+    /** The total number of observations (data points). */\n+    private final int numObservations;\n+\n+    /** The total number of parameters. */\n+    private final int numParameters;\n+\n+    /** The total number of starting points for the optimizations. */\n+    private final int numStartingPoints;\n+\n+    /** The values of the predictor. */\n+    private final double[] x;\n+\n+    /** The values of the response. */\n+    private final double[] y;\n+\n+    /**\n+     * The starting values. {@code startingValues[j][i]} is the value of the\n+     * {@code i}-th parameter in the {@code j}-th set of starting values.\n+     */\n+    private final double[][] startingValues;\n+\n+    /** The certified values of the parameters. */\n+    private final double[] a;\n+\n+    /** The certified values of the standard deviation of the parameters. */\n+    private final double[] sigA;\n+\n+    /** The certified value of the residual sum of squares. */\n+    private double residualSumOfSquares;\n+\n+    /** The least-squares problem. */\n+    private final LeastSquaresProblem problem;\n+\n+    /**\n+     * Creates a new instance of this class from the specified data file. The\n+     * file must follow the StRD format.\n+     *\n+     * @param in the data file\n+     * @throws IOException if an I/O error occurs\n+     */\n+    public StatisticalReferenceDataset(final BufferedReader in)\n+        throws IOException {\n+\n+        final ArrayList<String> lines = new ArrayList<String>();\n+        for (String line = in.readLine(); line != null; line = in.readLine()) {\n+            lines.add(line);\n+        }\n+        int[] index = findLineNumbers(\"Data\", lines);\n+        if (index == null) {\n+            throw new AssertionError(\"could not find line indices for data\");\n+        }\n+        this.numObservations = index[1] - index[0] + 1;\n+        this.x = new double[this.numObservations];\n+        this.y = new double[this.numObservations];\n+        for (int i = 0; i < this.numObservations; i++) {\n+            final String line = lines.get(index[0] + i - 1);\n+            final String[] tokens = line.trim().split(\" ++\");\n+            // Data columns are in reverse order!!!\n+            this.y[i] = Double.parseDouble(tokens[0]);\n+            this.x[i] = Double.parseDouble(tokens[1]);\n+        }\n+\n+        index = findLineNumbers(\"Starting Values\", lines);\n+        if (index == null) {\n+            throw new AssertionError(\n+                                     \"could not find line indices for starting values\");\n+        }\n+        this.numParameters = index[1] - index[0] + 1;\n+\n+        double[][] start = null;\n+        this.a = new double[numParameters];\n+        this.sigA = new double[numParameters];\n+        for (int i = 0; i < numParameters; i++) {\n+            final String line = lines.get(index[0] + i - 1);\n+            final String[] tokens = line.trim().split(\" ++\");\n+            if (start == null) {\n+                start = new double[tokens.length - 4][numParameters];\n+            }\n+            for (int j = 2; j < tokens.length - 2; j++) {\n+                start[j - 2][i] = Double.parseDouble(tokens[j]);\n+            }\n+            this.a[i] = Double.parseDouble(tokens[tokens.length - 2]);\n+            this.sigA[i] = Double.parseDouble(tokens[tokens.length - 1]);\n+        }\n+        if (start == null) {\n+            throw new IOException(\"could not find starting values\");\n+        }\n+        this.numStartingPoints = start.length;\n+        this.startingValues = start;\n+\n+        double dummyDouble = Double.NaN;\n+        String dummyString = null;\n+        for (String line : lines) {\n+            if (line.contains(\"Dataset Name:\")) {\n+                dummyString = line\n+                    .substring(line.indexOf(\"Dataset Name:\") + 13,\n+                               line.indexOf(\"(\")).trim();\n+            }\n+            if (line.contains(\"Residual Sum of Squares\")) {\n+                final String[] tokens = line.split(\" ++\");\n+                dummyDouble = Double.parseDouble(tokens[4].trim());\n+            }\n+        }\n+        if (Double.isNaN(dummyDouble)) {\n+            throw new IOException(\n+                                  \"could not find certified value of residual sum of squares\");\n+        }\n+        this.residualSumOfSquares = dummyDouble;\n+\n+        if (dummyString == null) {\n+            throw new IOException(\"could not find dataset name\");\n+        }\n+        this.name = dummyString;\n+\n+        this.problem = new LeastSquaresProblem();\n+    }\n+\n+    class LeastSquaresProblem {\n+        public ModelFunction getModelFunction() {\n+            return new ModelFunction(new MultivariateVectorFunction() {\n+                    public double[] value(final double[] a) {\n+                        final int n = getNumObservations();\n+                        final double[] yhat = new double[n];\n+                        for (int i = 0; i < n; i++) {\n+                            yhat[i] = getModelValue(getX(i), a);\n+                        }\n+                        return yhat;\n+                    }\n+                });\n+        }\n+\n+        public ModelFunctionJacobian getModelFunctionJacobian() {\n+            return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                    public double[][] value(final double[] a)\n+                        throws IllegalArgumentException {\n+                        final int n = getNumObservations();\n+                        final double[][] j = new double[n][];\n+                        for (int i = 0; i < n; i++) {\n+                            j[i] = getModelDerivatives(getX(i), a);\n+                        }\n+                        return j;\n+                    }\n+                });\n+        }\n+    }\n+\n+    /**\n+     * Returns the name of this dataset.\n+     *\n+     * @return the name of the dataset\n+     */\n+    public String getName() {\n+        return name;\n+    }\n+\n+    /**\n+     * Returns the total number of observations (data points).\n+     *\n+     * @return the number of observations\n+     */\n+    public int getNumObservations() {\n+        return numObservations;\n+    }\n+\n+    /**\n+     * Returns a copy of the data arrays. The data is laid out as follows <li>\n+     * {@code data[0][i] = x[i]},</li> <li>{@code data[1][i] = y[i]},</li>\n+     *\n+     * @return the array of data points.\n+     */\n+    public double[][] getData() {\n+        return new double[][] {\n+            MathArrays.copyOf(x), MathArrays.copyOf(y)\n+        };\n+    }\n+\n+    /**\n+     * Returns the x-value of the {@code i}-th data point.\n+     *\n+     * @param i the index of the data point\n+     * @return the x-value\n+     */\n+    public double getX(final int i) {\n+        return x[i];\n+    }\n+\n+    /**\n+     * Returns the y-value of the {@code i}-th data point.\n+     *\n+     * @param i the index of the data point\n+     * @return the y-value\n+     */\n+    public double getY(final int i) {\n+        return y[i];\n+    }\n+\n+    /**\n+     * Returns the total number of parameters.\n+     *\n+     * @return the number of parameters\n+     */\n+    public int getNumParameters() {\n+        return numParameters;\n+    }\n+\n+    /**\n+     * Returns the certified values of the paramters.\n+     *\n+     * @return the values of the parameters\n+     */\n+    public double[] getParameters() {\n+        return MathArrays.copyOf(a);\n+    }\n+\n+    /**\n+     * Returns the certified value of the {@code i}-th parameter.\n+     *\n+     * @param i the index of the parameter\n+     * @return the value of the parameter\n+     */\n+    public double getParameter(final int i) {\n+        return a[i];\n+    }\n+\n+    /**\n+     * Reurns the certified values of the standard deviations of the parameters.\n+     *\n+     * @return the standard deviations of the parameters\n+     */\n+    public double[] getParametersStandardDeviations() {\n+        return MathArrays.copyOf(sigA);\n+    }\n+\n+    /**\n+     * Returns the certified value of the standard deviation of the {@code i}-th\n+     * parameter.\n+     *\n+     * @param i the index of the parameter\n+     * @return the standard deviation of the parameter\n+     */\n+    public double getParameterStandardDeviation(final int i) {\n+        return sigA[i];\n+    }\n+\n+    /**\n+     * Returns the certified value of the residual sum of squares.\n+     *\n+     * @return the residual sum of squares\n+     */\n+    public double getResidualSumOfSquares() {\n+        return residualSumOfSquares;\n+    }\n+\n+    /**\n+     * Returns the total number of starting points (initial guesses for the\n+     * optimization process).\n+     *\n+     * @return the number of starting points\n+     */\n+    public int getNumStartingPoints() {\n+        return numStartingPoints;\n+    }\n+\n+    /**\n+     * Returns the {@code i}-th set of initial values of the parameters.\n+     *\n+     * @param i the index of the starting point\n+     * @return the starting point\n+     */\n+    public double[] getStartingPoint(final int i) {\n+        return MathArrays.copyOf(startingValues[i]);\n+    }\n+\n+    /**\n+     * Returns the least-squares problem corresponding to fitting the model to\n+     * the specified data.\n+     *\n+     * @return the least-squares problem\n+     */\n+    public LeastSquaresProblem getLeastSquaresProblem() {\n+        return problem;\n+    }\n+\n+    /**\n+     * Returns the value of the model for the specified values of the predictor\n+     * variable and the parameters.\n+     *\n+     * @param x the predictor variable\n+     * @param a the parameters\n+     * @return the value of the model\n+     */\n+    public abstract double getModelValue(final double x, final double[] a);\n+\n+    /**\n+     * Returns the values of the partial derivatives of the model with respect\n+     * to the parameters.\n+     *\n+     * @param x the predictor variable\n+     * @param a the parameters\n+     * @return the partial derivatives\n+     */\n+    public abstract double[] getModelDerivatives(final double x,\n+                                                 final double[] a);\n+\n+    /**\n+     * <p>\n+     * Parses the specified text lines, and extracts the indices of the first\n+     * and last lines of the data defined by the specified {@code key}. This key\n+     * must be one of\n+     * </p>\n+     * <ul>\n+     * <li>{@code \"Starting Values\"},</li>\n+     * <li>{@code \"Certified Values\"},</li>\n+     * <li>{@code \"Data\"}.</li>\n+     * </ul>\n+     * <p>\n+     * In the NIST data files, the line indices are separated by the keywords\n+     * {@code \"lines\"} and {@code \"to\"}.\n+     * </p>\n+     *\n+     * @param lines the line of text to be parsed\n+     * @return an array of two {@code int}s. First value is the index of the\n+     *         first line, second value is the index of the last line.\n+     *         {@code null} if the line could not be parsed.\n+     */\n+    private static int[] findLineNumbers(final String key,\n+                                         final Iterable<String> lines) {\n+        for (String text : lines) {\n+            boolean flag = text.contains(key) && text.contains(\"lines\") &&\n+                           text.contains(\"to\") && text.contains(\")\");\n+            if (flag) {\n+                final int[] numbers = new int[2];\n+                final String from = text.substring(text.indexOf(\"lines\") + 5,\n+                                                   text.indexOf(\"to\"));\n+                numbers[0] = Integer.parseInt(from.trim());\n+                final String to = text.substring(text.indexOf(\"to\") + 2,\n+                                                 text.indexOf(\")\"));\n+                numbers[1] = Integer.parseInt(to.trim());\n+                return numbers;\n+            }\n+        }\n+        return null;\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/StatisticalReferenceDatasetFactory.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import org.apache.commons.math3.util.FastMath;\n+\n+/**\n+ * A factory to create instances of {@link StatisticalReferenceDataset} from\n+ * available resources.\n+ */\n+public class StatisticalReferenceDatasetFactory {\n+\n+    private StatisticalReferenceDatasetFactory() {\n+        // Do nothing\n+    }\n+\n+    /**\n+     * Creates a new buffered reader from the specified resource name.\n+     *\n+     * @param name the name of the resource\n+     * @return a buffered reader\n+     * @throws IOException if an I/O error occured\n+     */\n+    public static BufferedReader createBufferedReaderFromResource(final String name)\n+        throws IOException {\n+        final InputStream resourceAsStream;\n+        resourceAsStream = StatisticalReferenceDatasetFactory.class\n+            .getResourceAsStream(name);\n+        if (resourceAsStream == null) {\n+            throw new IOException(\"could not find resource \" + name);\n+        }\n+        return new BufferedReader(new InputStreamReader(resourceAsStream));\n+    }\n+\n+    public static StatisticalReferenceDataset createKirby2()\n+        throws IOException {\n+        final BufferedReader in = createBufferedReaderFromResource(\"Kirby2.dat\");\n+        StatisticalReferenceDataset dataset = null;\n+        try {\n+            dataset = new StatisticalReferenceDataset(in) {\n+\n+                @Override\n+                public double getModelValue(final double x, final double[] a) {\n+                    final double p = a[0] + x * (a[1] + x * a[2]);\n+                    final double q = 1.0 + x * (a[3] + x * a[4]);\n+                    return p / q;\n+                }\n+\n+                @Override\n+                public double[] getModelDerivatives(final double x,\n+                                                    final double[] a) {\n+                    final double[] dy = new double[5];\n+                    final double p = a[0] + x * (a[1] + x * a[2]);\n+                    final double q = 1.0 + x * (a[3] + x * a[4]);\n+                    dy[0] = 1.0 / q;\n+                    dy[1] = x / q;\n+                    dy[2] = x * dy[1];\n+                    dy[3] = -x * p / (q * q);\n+                    dy[4] = x * dy[3];\n+                    return dy;\n+                }\n+            };\n+        } finally {\n+            in.close();\n+        }\n+        return dataset;\n+    }\n+\n+    public static StatisticalReferenceDataset createHahn1()\n+        throws IOException {\n+        final BufferedReader in = createBufferedReaderFromResource(\"Hahn1.dat\");\n+        StatisticalReferenceDataset dataset = null;\n+        try {\n+            dataset = new StatisticalReferenceDataset(in) {\n+\n+                @Override\n+                public double getModelValue(final double x, final double[] a) {\n+                    final double p = a[0] + x * (a[1] + x * (a[2] + x * a[3]));\n+                    final double q = 1.0 + x * (a[4] + x * (a[5] + x * a[6]));\n+                    return p / q;\n+                }\n+\n+                @Override\n+                public double[] getModelDerivatives(final double x,\n+                                                    final double[] a) {\n+                    final double[] dy = new double[7];\n+                    final double p = a[0] + x * (a[1] + x * (a[2] + x * a[3]));\n+                    final double q = 1.0 + x * (a[4] + x * (a[5] + x * a[6]));\n+                    dy[0] = 1.0 / q;\n+                    dy[1] = x * dy[0];\n+                    dy[2] = x * dy[1];\n+                    dy[3] = x * dy[2];\n+                    dy[4] = -x * p / (q * q);\n+                    dy[5] = x * dy[4];\n+                    dy[6] = x * dy[5];\n+                    return dy;\n+                }\n+            };\n+        } finally {\n+            in.close();\n+        }\n+        return dataset;\n+    }\n+\n+    public static StatisticalReferenceDataset createMGH17()\n+        throws IOException {\n+        final BufferedReader in = createBufferedReaderFromResource(\"MGH17.dat\");\n+        StatisticalReferenceDataset dataset = null;\n+        try {\n+            dataset = new StatisticalReferenceDataset(in) {\n+\n+                @Override\n+                public double getModelValue(final double x, final double[] a) {\n+                    return a[0] + a[1] * FastMath.exp(-a[3] * x) + a[2] *\n+                           FastMath.exp(-a[4] * x);\n+                }\n+\n+                @Override\n+                public double[] getModelDerivatives(final double x,\n+                                                    final double[] a) {\n+                    final double[] dy = new double[5];\n+                    dy[0] = 1.0;\n+                    dy[1] = FastMath.exp(-x * a[3]);\n+                    dy[2] = FastMath.exp(-x * a[4]);\n+                    dy[3] = -x * a[1] * dy[1];\n+                    dy[4] = -x * a[2] * dy[2];\n+                    return dy;\n+                }\n+            };\n+        } finally {\n+            in.close();\n+        }\n+        return dataset;\n+    }\n+\n+    public static StatisticalReferenceDataset createLanczos1()\n+        throws IOException {\n+        final BufferedReader in =\n+            createBufferedReaderFromResource(\"Lanczos1.dat\");\n+        StatisticalReferenceDataset dataset = null;\n+        try {\n+            dataset = new StatisticalReferenceDataset(in) {\n+\n+                @Override\n+                public double getModelValue(final double x, final double[] a) {\n+                    System.out.println(a[0]+\", \"+a[1]+\", \"+a[2]+\", \"+a[3]+\", \"+a[4]+\", \"+a[5]);\n+                    return a[0] * FastMath.exp(-a[3] * x) +\n+                           a[1] * FastMath.exp(-a[4] * x) +\n+                           a[2] * FastMath.exp(-a[5] * x);\n+                }\n+\n+                @Override\n+                public double[] getModelDerivatives(final double x,\n+                    final double[] a) {\n+                    final double[] dy = new double[6];\n+                    dy[0] = FastMath.exp(-x * a[3]);\n+                    dy[1] = FastMath.exp(-x * a[4]);\n+                    dy[2] = FastMath.exp(-x * a[5]);\n+                    dy[3] = -x * a[0] * dy[0];\n+                    dy[4] = -x * a[1] * dy[1];\n+                    dy[5] = -x * a[2] * dy[2];\n+                    return dy;\n+                }\n+            };\n+        } finally {\n+            in.close();\n+        }\n+        return dataset;\n+    }\n+\n+    /**\n+     * Returns an array with all available reference datasets.\n+     *\n+     * @return the array of datasets\n+     * @throws IOException if an I/O error occurs\n+     */\n+    public StatisticalReferenceDataset[] createAll()\n+        throws IOException {\n+        return new StatisticalReferenceDataset[] {\n+            createKirby2(), createMGH17()\n+        };\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/StraightLineProblem.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optim.nonlinear.vector.jacobian;\n+\n+import java.util.ArrayList;\n+import org.apache.commons.math3.analysis.MultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.stat.regression.SimpleRegression;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;\n+\n+/**\n+ * Class that models a straight line defined as {@code y = a x + b}.\n+ * The parameters of problem are:\n+ * <ul>\n+ *  <li>{@code a}</li>\n+ *  <li>{@code b}</li>\n+ * </ul>\n+ * The model functions are:\n+ * <ul>\n+ *  <li>for each pair (a, b), the y-coordinate of the line.</li>\n+ * </ul>\n+ */\n+class StraightLineProblem {\n+    /** Cloud of points assumed to be fitted by a straight line. */\n+    private final ArrayList<double[]> points;\n+    /** Error (on the y-coordinate of the points). */\n+    private final double sigma;\n+\n+    /**\n+     * @param error Assumed error for the y-coordinate.\n+     */\n+    public StraightLineProblem(double error) {\n+        points = new ArrayList<double[]>();\n+        sigma = error;\n+    }\n+\n+    public void addPoint(double px, double py) {\n+        points.add(new double[] { px, py });\n+    }\n+\n+    /**\n+     * @return the list of x-coordinates.\n+     */\n+    public double[] x() {\n+        final double[] v = new double[points.size()];\n+        for (int i = 0; i < points.size(); i++) {\n+            final double[] p = points.get(i);\n+            v[i] = p[0]; // x-coordinate.\n+        }\n+\n+        return v;\n+    }\n+\n+    /**\n+     * @return the list of y-coordinates.\n+     */\n+    public double[] y() {\n+        final double[] v = new double[points.size()];\n+        for (int i = 0; i < points.size(); i++) {\n+            final double[] p = points.get(i);\n+            v[i] = p[1]; // y-coordinate.\n+        }\n+\n+        return v;\n+    }\n+\n+    public double[] target() {\n+        return y();\n+    }\n+\n+    public double[] weight() {\n+        final double weight = 1 / (sigma * sigma);\n+        final double[] w = new double[points.size()];\n+        for (int i = 0; i < points.size(); i++) {\n+            w[i] = weight;\n+        }\n+\n+        return w;\n+    }\n+\n+    public ModelFunction getModelFunction() {\n+        return new ModelFunction(new MultivariateVectorFunction() {\n+                public double[] value(double[] params) {\n+                    final Model line = new Model(params[0], params[1]);\n+\n+                    final double[] model = new double[points.size()];\n+                    for (int i = 0; i < points.size(); i++) {\n+                        final double[] p = points.get(i);\n+                        model[i] = line.value(p[0]);\n+                    }\n+\n+                    return model;\n+                }\n+            });\n+    }\n+\n+    public ModelFunctionJacobian getModelFunctionJacobian() {\n+        return new ModelFunctionJacobian(new MultivariateMatrixFunction() {\n+                public double[][] value(double[] point) {\n+                    return jacobian(point);\n+                }\n+            });\n+    }\n+\n+    /**\n+     * Directly solve the linear problem, using the {@link SimpleRegression}\n+     * class.\n+     */\n+    public double[] solve() {\n+        final SimpleRegression regress = new SimpleRegression(true);\n+        for (double[] d : points) {\n+            regress.addData(d[0], d[1]);\n+        }\n+\n+        final double[] result = { regress.getSlope(), regress.getIntercept() };\n+        return result;\n+    }\n+\n+    private double[][] jacobian(double[] params) {\n+        final double[][] jacobian = new double[points.size()][2];\n+\n+        for (int i = 0; i < points.size(); i++) {\n+            final double[] p = points.get(i);\n+            // Partial derivative wrt \"a\".\n+            jacobian[i][0] = p[0];\n+            // Partial derivative wrt \"b\".\n+            jacobian[i][1] = 1;\n+        }\n+\n+        return jacobian;\n+    }\n+\n+    /**\n+     * Linear function.\n+     */\n+    public static class Model implements UnivariateFunction {\n+        final double a;\n+        final double b;\n+\n+        public Model(double a,\n+                     double b) {\n+            this.a = a;\n+            this.b = b;\n+        }\n+\n+        public double value(double x) {\n+            return a * x + b;\n+        }\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/univariate/BracketFinderTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test for {@link BracketFinder}.\n+ */\n+public class BracketFinderTest {\n+\n+    @Test\n+    public void testCubicMin() {\n+        final BracketFinder bFind = new BracketFinder();\n+        final UnivariateFunction func = new UnivariateFunction() {\n+                public double value(double x) {\n+                    if (x < -2) {\n+                        return value(-2);\n+                    }\n+                    else  {\n+                        return (x - 1) * (x + 2) * (x + 3);\n+                    }\n+                }\n+            };\n+\n+        bFind.search(func, GoalType.MINIMIZE, -2 , -1);\n+        final double tol = 1e-15;\n+        // Comparing with results computed in Python.\n+        Assert.assertEquals(-2, bFind.getLo(), tol);\n+        Assert.assertEquals(-1, bFind.getMid(), tol);\n+        Assert.assertEquals(0.61803399999999997, bFind.getHi(), tol);\n+    }\n+\n+    @Test\n+    public void testCubicMax() {\n+        final BracketFinder bFind = new BracketFinder();\n+        final UnivariateFunction func = new UnivariateFunction() {\n+                public double value(double x) {\n+                    if (x < -2) {\n+                        return value(-2);\n+                    }\n+                    else  {\n+                        return -(x - 1) * (x + 2) * (x + 3);\n+                    }\n+                }\n+            };\n+\n+        bFind.search(func, GoalType.MAXIMIZE, -2 , -1);\n+        final double tol = 1e-15;\n+        Assert.assertEquals(-2, bFind.getLo(), tol);\n+        Assert.assertEquals(-1, bFind.getMid(), tol);\n+        Assert.assertEquals(0.61803399999999997, bFind.getHi(), tol);\n+    }\n+\n+    @Test\n+    public void testMinimumIsOnIntervalBoundary() {\n+        final UnivariateFunction func = new UnivariateFunction() {\n+                public double value(double x) {\n+                    return x * x;\n+                }\n+            };\n+\n+        final BracketFinder bFind = new BracketFinder();\n+\n+        bFind.search(func, GoalType.MINIMIZE, 0, 1);\n+        Assert.assertTrue(bFind.getLo() <= 0);\n+        Assert.assertTrue(0 <= bFind.getHi());\n+\n+        bFind.search(func, GoalType.MINIMIZE, -1, 0);\n+        Assert.assertTrue(bFind.getLo() <= 0);\n+        Assert.assertTrue(0 <= bFind.getHi());\n+    }\n+\n+    @Test\n+    public void testIntervalBoundsOrdering() {\n+        final UnivariateFunction func = new UnivariateFunction() {\n+                public double value(double x) {\n+                    return x * x;\n+                }\n+            };\n+\n+        final BracketFinder bFind = new BracketFinder();\n+\n+        bFind.search(func, GoalType.MINIMIZE, -1, 1);\n+        Assert.assertTrue(bFind.getLo() <= 0);\n+        Assert.assertTrue(0 <= bFind.getHi());\n+\n+        bFind.search(func, GoalType.MINIMIZE, 1, -1);\n+        Assert.assertTrue(bFind.getLo() <= 0);\n+        Assert.assertTrue(0 <= bFind.getHi());\n+\n+        bFind.search(func, GoalType.MINIMIZE, 1, 2);\n+        Assert.assertTrue(bFind.getLo() <= 0);\n+        Assert.assertTrue(0 <= bFind.getHi());\n+\n+        bFind.search(func, GoalType.MINIMIZE, 2, 1);\n+        Assert.assertTrue(bFind.getLo() <= 0);\n+        Assert.assertTrue(0 <= bFind.getHi());\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/univariate/BrentOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+\n+import org.apache.commons.math3.analysis.QuinticFunction;\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.analysis.function.Sin;\n+import org.apache.commons.math3.analysis.function.StepFunction;\n+import org.apache.commons.math3.analysis.FunctionUtils;\n+import org.apache.commons.math3.exception.NumberIsTooLargeException;\n+import org.apache.commons.math3.exception.NumberIsTooSmallException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.stat.descriptive.DescriptiveStatistics;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * @version $Id$\n+ */\n+public final class BrentOptimizerTest {\n+\n+    @Test\n+    public void testSinMin() {\n+        UnivariateFunction f = new Sin();\n+        UnivariateOptimizer optimizer = new BrentOptimizer(1e-10, 1e-14);\n+        Assert.assertEquals(3 * Math.PI / 2, optimizer.optimize(new MaxEval(200),\n+                                                                new UnivariateObjectiveFunction(f),\n+                                                                GoalType.MINIMIZE,\n+                                                                new SearchInterval(4, 5)).getPoint(), 1e-8);\n+        Assert.assertTrue(optimizer.getEvaluations() <= 50);\n+        Assert.assertEquals(200, optimizer.getMaxEvaluations());\n+        Assert.assertEquals(3 * Math.PI / 2, optimizer.optimize(new MaxEval(200),\n+                                                                new UnivariateObjectiveFunction(f),\n+                                                                GoalType.MINIMIZE,\n+                                                                new SearchInterval(1, 5)).getPoint(), 1e-8);\n+        Assert.assertTrue(optimizer.getEvaluations() <= 100);\n+        Assert.assertTrue(optimizer.getEvaluations() >= 15);\n+        try {\n+            optimizer.optimize(new MaxEval(10),\n+                               new UnivariateObjectiveFunction(f),\n+                               GoalType.MINIMIZE,\n+                               new SearchInterval(4, 5));\n+            Assert.fail(\"an exception should have been thrown\");\n+        } catch (TooManyEvaluationsException fee) {\n+            // expected\n+        }\n+    }\n+\n+    @Test\n+    public void testSinMinWithValueChecker() {\n+        final UnivariateFunction f = new Sin();\n+        final ConvergenceChecker<UnivariatePointValuePair> checker = new SimpleUnivariateValueChecker(1e-5, 1e-14);\n+        // The default stopping criterion of Brent's algorithm should not\n+        // pass, but the search will stop at the given relative tolerance\n+        // for the function value.\n+        final UnivariateOptimizer optimizer = new BrentOptimizer(1e-10, 1e-14, checker);\n+        final UnivariatePointValuePair result = optimizer.optimize(new MaxEval(200),\n+                                                                   new UnivariateObjectiveFunction(f),\n+                                                                   GoalType.MINIMIZE,\n+                                                                   new SearchInterval(4, 5));\n+        Assert.assertEquals(3 * Math.PI / 2, result.getPoint(), 1e-3);\n+    }\n+\n+    @Test\n+    public void testBoundaries() {\n+        final double lower = -1.0;\n+        final double upper = +1.0;\n+        UnivariateFunction f = new UnivariateFunction() {            \n+            public double value(double x) {\n+                if (x < lower) {\n+                    throw new NumberIsTooSmallException(x, lower, true);\n+                } else if (x > upper) {\n+                    throw new NumberIsTooLargeException(x, upper, true);\n+                } else {\n+                    return x;\n+                }\n+            }\n+        };\n+        UnivariateOptimizer optimizer = new BrentOptimizer(1e-10, 1e-14);\n+        Assert.assertEquals(lower,\n+                            optimizer.optimize(new MaxEval(100),\n+                                               new UnivariateObjectiveFunction(f),\n+                                               GoalType.MINIMIZE,\n+                                               new SearchInterval(lower, upper)).getPoint(),\n+                            1.0e-8);\n+        Assert.assertEquals(upper,\n+                            optimizer.optimize(new MaxEval(100),\n+                                               new UnivariateObjectiveFunction(f),\n+                                               GoalType.MAXIMIZE,\n+                                               new SearchInterval(lower, upper)).getPoint(),\n+                            1.0e-8);\n+    }\n+\n+    @Test\n+    public void testQuinticMin() {\n+        // The function has local minima at -0.27195613 and 0.82221643.\n+        UnivariateFunction f = new QuinticFunction();\n+        UnivariateOptimizer optimizer = new BrentOptimizer(1e-10, 1e-14);\n+        Assert.assertEquals(-0.27195613, optimizer.optimize(new MaxEval(200),\n+                                                            new UnivariateObjectiveFunction(f),\n+                                                            GoalType.MINIMIZE,\n+                                                            new SearchInterval(-0.3, -0.2)).getPoint(), 1.0e-8);\n+        Assert.assertEquals( 0.82221643, optimizer.optimize(new MaxEval(200),\n+                                                            new UnivariateObjectiveFunction(f),\n+                                                            GoalType.MINIMIZE,\n+                                                            new SearchInterval(0.3,  0.9)).getPoint(), 1.0e-8);\n+        Assert.assertTrue(optimizer.getEvaluations() <= 50);\n+\n+        // search in a large interval\n+        Assert.assertEquals(-0.27195613, optimizer.optimize(new MaxEval(200),\n+                                                            new UnivariateObjectiveFunction(f),\n+                                                            GoalType.MINIMIZE,\n+                                                            new SearchInterval(-1.0, 0.2)).getPoint(), 1.0e-8);\n+        Assert.assertTrue(optimizer.getEvaluations() <= 50);\n+    }\n+\n+    @Test\n+    public void testQuinticMinStatistics() {\n+        // The function has local minima at -0.27195613 and 0.82221643.\n+        UnivariateFunction f = new QuinticFunction();\n+        UnivariateOptimizer optimizer = new BrentOptimizer(1e-11, 1e-14);\n+\n+        final DescriptiveStatistics[] stat = new DescriptiveStatistics[2];\n+        for (int i = 0; i < stat.length; i++) {\n+            stat[i] = new DescriptiveStatistics();\n+        }\n+\n+        final double min = -0.75;\n+        final double max = 0.25;\n+        final int nSamples = 200;\n+        final double delta = (max - min) / nSamples;\n+        for (int i = 0; i < nSamples; i++) {\n+            final double start = min + i * delta;\n+            stat[0].addValue(optimizer.optimize(new MaxEval(40),\n+                                                new UnivariateObjectiveFunction(f),\n+                                                GoalType.MINIMIZE,\n+                                                new SearchInterval(min, max, start)).getPoint());\n+            stat[1].addValue(optimizer.getEvaluations());\n+        }\n+\n+        final double meanOptValue = stat[0].getMean();\n+        final double medianEval = stat[1].getPercentile(50);\n+        Assert.assertTrue(meanOptValue > -0.2719561281);\n+        Assert.assertTrue(meanOptValue < -0.2719561280);\n+        Assert.assertEquals(23, (int) medianEval);\n+    }\n+\n+    @Test\n+    public void testQuinticMax() {\n+        // The quintic function has zeros at 0, +-0.5 and +-1.\n+        // The function has a local maximum at 0.27195613.\n+        UnivariateFunction f = new QuinticFunction();\n+        UnivariateOptimizer optimizer = new BrentOptimizer(1e-12, 1e-14);\n+        Assert.assertEquals(0.27195613, optimizer.optimize(new MaxEval(100),\n+                                                           new UnivariateObjectiveFunction(f),\n+                                                           GoalType.MAXIMIZE,\n+                                                           new SearchInterval(0.2, 0.3)).getPoint(), 1e-8);\n+        try {\n+            optimizer.optimize(new MaxEval(5),\n+                               new UnivariateObjectiveFunction(f),\n+                               GoalType.MAXIMIZE,\n+                               new SearchInterval(0.2, 0.3));\n+            Assert.fail(\"an exception should have been thrown\");\n+        } catch (TooManyEvaluationsException miee) {\n+            // expected\n+        }\n+    }\n+\n+    @Test\n+    public void testMinEndpoints() {\n+        UnivariateFunction f = new Sin();\n+        UnivariateOptimizer optimizer = new BrentOptimizer(1e-8, 1e-14);\n+\n+        // endpoint is minimum\n+        double result = optimizer.optimize(new MaxEval(50),\n+                                           new UnivariateObjectiveFunction(f),\n+                                           GoalType.MINIMIZE,\n+                                           new SearchInterval(3 * Math.PI / 2, 5)).getPoint();\n+        Assert.assertEquals(3 * Math.PI / 2, result, 1e-6);\n+\n+        result = optimizer.optimize(new MaxEval(50),\n+                                    new UnivariateObjectiveFunction(f),\n+                                    GoalType.MINIMIZE,\n+                                    new SearchInterval(4, 3 * Math.PI / 2)).getPoint();\n+        Assert.assertEquals(3 * Math.PI / 2, result, 1e-6);\n+    }\n+\n+    @Test\n+    public void testMath832() {\n+        final UnivariateFunction f = new UnivariateFunction() {\n+                public double value(double x) {\n+                    final double sqrtX = FastMath.sqrt(x);\n+                    final double a = 1e2 * sqrtX;\n+                    final double b = 1e6 / x;\n+                    final double c = 1e4 / sqrtX;\n+\n+                    return a + b + c;\n+                }\n+            };\n+\n+        UnivariateOptimizer optimizer = new BrentOptimizer(1e-10, 1e-8);\n+        final double result = optimizer.optimize(new MaxEval(1483),\n+                                                 new UnivariateObjectiveFunction(f),\n+                                                 GoalType.MINIMIZE,\n+                                                 new SearchInterval(Double.MIN_VALUE,\n+                                                                    Double.MAX_VALUE)).getPoint();\n+\n+        Assert.assertEquals(804.9355825, result, 1e-6);\n+    }\n+\n+    /**\n+     * Contrived example showing that prior to the resolution of MATH-855\n+     * (second revision), the algorithm would not return the best point if\n+     * it happened to be the initial guess.\n+     */\n+    @Test\n+    public void testKeepInitIfBest() {\n+        final double minSin = 3 * Math.PI / 2;\n+        final double offset = 1e-8;\n+        final double delta = 1e-7;\n+        final UnivariateFunction f1 = new Sin();\n+        final UnivariateFunction f2 = new StepFunction(new double[] { minSin, minSin + offset, minSin + 2 * offset},\n+                                                       new double[] { 0, -1, 0 });\n+        final UnivariateFunction f = FunctionUtils.add(f1, f2);\n+        // A slightly less stringent tolerance would make the test pass\n+        // even with the previous implementation.\n+        final double relTol = 1e-8;\n+        final UnivariateOptimizer optimizer = new BrentOptimizer(relTol, 1e-100);\n+        final double init = minSin + 1.5 * offset;\n+        final UnivariatePointValuePair result\n+            = optimizer.optimize(new MaxEval(200),\n+                                 new UnivariateObjectiveFunction(f),\n+                                 GoalType.MINIMIZE,\n+                                 new SearchInterval(minSin - 6.789 * delta,\n+                                                    minSin + 9.876 * delta,\n+                                                    init));\n+        final int numEval = optimizer.getEvaluations();\n+\n+        final double sol = result.getPoint();\n+        final double expected = init;\n+\n+//         System.out.println(\"numEval=\" + numEval);\n+//         System.out.println(\"min=\" + init + \" f=\" + f.value(init));\n+//         System.out.println(\"sol=\" + sol + \" f=\" + f.value(sol));\n+//         System.out.println(\"exp=\" + expected + \" f=\" + f.value(expected));\n+\n+        Assert.assertTrue(\"Best point not reported\", f.value(sol) <= f.value(expected));\n+    }\n+\n+    /**\n+     * Contrived example showing that prior to the resolution of MATH-855,\n+     * the algorithm, by always returning the last evaluated point, would\n+     * sometimes not report the best point it had found.\n+     */\n+    @Test\n+    public void testMath855() {\n+        final double minSin = 3 * Math.PI / 2;\n+        final double offset = 1e-8;\n+        final double delta = 1e-7;\n+        final UnivariateFunction f1 = new Sin();\n+        final UnivariateFunction f2 = new StepFunction(new double[] { minSin, minSin + offset, minSin + 5 * offset },\n+                                                       new double[] { 0, -1, 0 });\n+        final UnivariateFunction f = FunctionUtils.add(f1, f2);\n+        final UnivariateOptimizer optimizer = new BrentOptimizer(1e-8, 1e-100);\n+        final UnivariatePointValuePair result\n+            = optimizer.optimize(new MaxEval(200),\n+                                 new UnivariateObjectiveFunction(f),\n+                                 GoalType.MINIMIZE,\n+                                 new SearchInterval(minSin - 6.789 * delta,\n+                                                    minSin + 9.876 * delta));\n+        final int numEval = optimizer.getEvaluations();\n+\n+        final double sol = result.getPoint();\n+        final double expected = 4.712389027602411;\n+\n+        // System.out.println(\"min=\" + (minSin + offset) + \" f=\" + f.value(minSin + offset));\n+        // System.out.println(\"sol=\" + sol + \" f=\" + f.value(sol));\n+        // System.out.println(\"exp=\" + expected + \" f=\" + f.value(expected));\n+\n+        Assert.assertTrue(\"Best point not reported\", f.value(sol) <= f.value(expected));\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/univariate/MultiStartUnivariateOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.analysis.QuinticFunction;\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.analysis.function.Sin;\n+import org.apache.commons.math3.optim.GoalType;\n+import org.apache.commons.math3.optim.MaxEval;\n+import org.apache.commons.math3.random.JDKRandomGenerator;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class MultiStartUnivariateOptimizerTest {\n+    @Test(expected=MathIllegalStateException.class)\n+    public void testMissingMaxEval() {\n+        UnivariateOptimizer underlying = new BrentOptimizer(1e-10, 1e-14);\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(44428400075l);\n+        MultiStartUnivariateOptimizer optimizer = new MultiStartUnivariateOptimizer(underlying, 10, g);\n+        optimizer.optimize(new UnivariateObjectiveFunction(new Sin()),\n+                           GoalType.MINIMIZE,\n+                           new SearchInterval(-1, 1));\n+    }\n+    @Test(expected=MathIllegalStateException.class)\n+    public void testMissingSearchInterval() {\n+        UnivariateOptimizer underlying = new BrentOptimizer(1e-10, 1e-14);\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(44428400075l);\n+        MultiStartUnivariateOptimizer optimizer = new MultiStartUnivariateOptimizer(underlying, 10, g);\n+        optimizer.optimize(new MaxEval(300),\n+                           new UnivariateObjectiveFunction(new Sin()),\n+                           GoalType.MINIMIZE);\n+    }\n+\n+    @Test\n+    public void testSinMin() {\n+        UnivariateFunction f = new Sin();\n+        UnivariateOptimizer underlying = new BrentOptimizer(1e-10, 1e-14);\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(44428400075l);\n+        MultiStartUnivariateOptimizer optimizer = new MultiStartUnivariateOptimizer(underlying, 10, g);\n+        optimizer.optimize(new MaxEval(300),\n+                           new UnivariateObjectiveFunction(f),\n+                           GoalType.MINIMIZE,\n+                           new SearchInterval(-100.0, 100.0));\n+        UnivariatePointValuePair[] optima = optimizer.getOptima();\n+        for (int i = 1; i < optima.length; ++i) {\n+            double d = (optima[i].getPoint() - optima[i-1].getPoint()) / (2 * FastMath.PI);\n+            Assert.assertTrue(FastMath.abs(d - FastMath.rint(d)) < 1.0e-8);\n+            Assert.assertEquals(-1.0, f.value(optima[i].getPoint()), 1.0e-10);\n+            Assert.assertEquals(f.value(optima[i].getPoint()), optima[i].getValue(), 1.0e-10);\n+        }\n+        Assert.assertTrue(optimizer.getEvaluations() > 200);\n+        Assert.assertTrue(optimizer.getEvaluations() < 300);\n+    }\n+\n+    @Test\n+    public void testQuinticMin() {\n+        // The quintic function has zeros at 0, +-0.5 and +-1.\n+        // The function has extrema (first derivative is zero) at 0.27195613 and 0.82221643,\n+        UnivariateFunction f = new QuinticFunction();\n+        UnivariateOptimizer underlying = new BrentOptimizer(1e-9, 1e-14);\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(4312000053L);\n+        MultiStartUnivariateOptimizer optimizer = new MultiStartUnivariateOptimizer(underlying, 5, g);\n+\n+        UnivariatePointValuePair optimum\n+            = optimizer.optimize(new MaxEval(300),\n+                                 new UnivariateObjectiveFunction(f),\n+                                 GoalType.MINIMIZE,\n+                                 new SearchInterval(-0.3, -0.2));\n+        Assert.assertEquals(-0.27195613, optimum.getPoint(), 1e-9);\n+        Assert.assertEquals(-0.0443342695, optimum.getValue(), 1e-9);\n+\n+        UnivariatePointValuePair[] optima = optimizer.getOptima();\n+        for (int i = 0; i < optima.length; ++i) {\n+            Assert.assertEquals(f.value(optima[i].getPoint()), optima[i].getValue(), 1e-9);\n+        }\n+        Assert.assertTrue(optimizer.getEvaluations() >= 50);\n+        Assert.assertTrue(optimizer.getEvaluations() <= 100);\n+    }\n+\n+    @Test\n+    public void testBadFunction() {\n+        UnivariateFunction f = new UnivariateFunction() {\n+                public double value(double x) {\n+                    if (x < 0) {\n+                        throw new LocalException();\n+                    }\n+                    return 0;\n+                }\n+            };\n+        UnivariateOptimizer underlying = new BrentOptimizer(1e-9, 1e-14);\n+        JDKRandomGenerator g = new JDKRandomGenerator();\n+        g.setSeed(4312000053L);\n+        MultiStartUnivariateOptimizer optimizer = new MultiStartUnivariateOptimizer(underlying, 5, g);\n+ \n+        try {\n+            optimizer.optimize(new MaxEval(300),\n+                               new UnivariateObjectiveFunction(f),\n+                               GoalType.MINIMIZE,\n+                               new SearchInterval(-0.3, -0.2));\n+            Assert.fail();\n+        } catch (LocalException e) {\n+            // Expected.\n+        }\n+\n+        // Ensure that the exception was thrown because no optimum was found.\n+        Assert.assertTrue(optimizer.getOptima()[0] == null);\n+    }\n+\n+    private static class LocalException extends RuntimeException {\n+        private static final long serialVersionUID = 1194682757034350629L;\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optim/univariate/SimpleUnivariateValueCheckerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math3.optim.univariate;\n+\n+import org.apache.commons.math3.exception.NotStrictlyPositiveException;\n+import org.junit.Test;\n+import org.junit.Assert;\n+\n+public class SimpleUnivariateValueCheckerTest {\n+    @Test(expected=NotStrictlyPositiveException.class)\n+    public void testIterationCheckPrecondition() {\n+        new SimpleUnivariateValueChecker(1e-1, 1e-2, 0);\n+    }\n+\n+    @Test\n+    public void testIterationCheck() {\n+        final int max = 10;\n+        final SimpleUnivariateValueChecker checker = new SimpleUnivariateValueChecker(1e-1, 1e-2, max);\n+        Assert.assertTrue(checker.converged(max, null, null)); \n+        Assert.assertTrue(checker.converged(max + 1, null, null));\n+    }\n+\n+    @Test\n+    public void testIterationCheckDisabled() {\n+        final SimpleUnivariateValueChecker checker = new SimpleUnivariateValueChecker(1e-8, 1e-8);\n+\n+        final UnivariatePointValuePair a = new UnivariatePointValuePair(1d, 1d);\n+        final UnivariatePointValuePair b = new UnivariatePointValuePair(10d, 10d);\n+\n+        Assert.assertFalse(checker.converged(-1, a, b));\n+        Assert.assertFalse(checker.converged(0, a, b));\n+        Assert.assertFalse(checker.converged(1000000, a, b));\n+\n+        Assert.assertTrue(checker.converged(-1, a, a));\n+        Assert.assertTrue(checker.converged(-1, b, b));\n+    }\n+\n+}", "timestamp": 1355321438, "metainfo": ""}