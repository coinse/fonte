{"sha": "e60890df685a9dc2f324cb31c709718e3f43198b", "log": "Additional \"validation\" test in relation to MATH-784. [Not enabled by default (as its name does not end with the string \"Test\").]   ", "commit": "\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerTestValidation.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law\n+ * or agreed to in writing, software distributed under the License is\n+ * distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied. See the License for the specific language\n+ * governing permissions and limitations under the License.\n+ */\n+package org.apache.commons.math3.optimization.general;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.ArrayList;\n+import java.awt.geom.Point2D;\n+import org.apache.commons.math3.optimization.PointVectorValuePair;\n+import org.apache.commons.math3.stat.descriptive.SummaryStatistics;\n+import org.apache.commons.math3.stat.descriptive.StatisticalSummary;\n+import org.apache.commons.math3.util.FastMath;\n+import org.junit.Test;\n+import org.junit.Assert;\n+import org.junit.Ignore;\n+\n+/**\n+ * This class demonstrates the main functionality of the\n+ * {@link AbstractLeastSquaresOptimizer}, common to the\n+ * optimizer implementations in package\n+ * {@link org.apache.commons.math3.optimization.general}.\n+ * <br/>\n+ * Not enabled by default, as the class name does not end with \"Test\".\n+ * <br/>\n+ * Invoke by running\n+ * <pre><code>\n+ *  mvn test -Dtest=AbstractLeastSquaresOptimizerTestValidation\n+ * </code></pre>\n+ * or by running\n+ * <pre><code>\n+ *  mvn test -Dtest=AbstractLeastSquaresOptimizerTestValidation -DargLine=\"-DmcRuns=1234 -server\"\n+ * </code></pre>\n+ */\n+public class AbstractLeastSquaresOptimizerTestValidation {\n+    private static final int MONTE_CARLO_RUNS = Integer.parseInt(System.getProperty(\"mcRuns\",\n+                                                                                    \"100\"));\n+\n+    /**\n+     * Using a Monte-Carlo procedure, this test checks the error estimations\n+     * as provided by the square-root of the diagonal elements of the\n+     * covariance matrix.\n+     * <br/>\n+     * The test generates sets of observations, each sampled from\n+     * a Gaussian distribution.\n+     * <br/>\n+     * The optimization problem solved is defined in class\n+     * {@link StraightLineProblem}.\n+     * <br/>\n+     * The output (on stdout) will be a table summarizing the distribution\n+     * of parameters generated by the Monte-Carlo process and by the direct\n+     * estimation provided by the diagonal elements of the covariance matrix.\n+     */\n+    @Test\n+    public void testParametersErrorMonteCarloObservations() {\n+        // Error on the observations.\n+        final double yError = 15;\n+\n+        // True values of the parameters.\n+        final double slope = 123.456;\n+        final double offset = -98.765;\n+\n+        // Samples generator.\n+        final RandomStraightLinePointGenerator lineGenerator\n+            = new RandomStraightLinePointGenerator(slope, offset,\n+                                                   yError,\n+                                                   -1e3, 1e4,\n+                                                   138577L);\n+\n+        // Number of observations.\n+        final int numObs = 100; // XXX Should be a command-line option.\n+        // number of parameters.\n+        final int numParams = 2;\n+\n+        // Parameters found for each of Monte-Carlo run.\n+        final SummaryStatistics[] paramsFoundByDirectSolution = new SummaryStatistics[numParams];\n+        // Sigma estimations (square-root of the diagonal elements of the\n+        // covariance matrix), for each Monte-Carlo run.\n+        final SummaryStatistics[] sigmaEstimate = new SummaryStatistics[numParams];\n+\n+        // Initialize statistics accumulators.\n+        for (int i = 0; i < numParams; i++) {\n+            paramsFoundByDirectSolution[i] = new SummaryStatistics();\n+            sigmaEstimate[i] = new SummaryStatistics();\n+        }\n+\n+        // Dummy optimizer (to compute the covariance matrix).\n+        final AbstractLeastSquaresOptimizer optim = new DummyOptimizer();\n+        final double[] init = { slope, offset };\n+\n+        // Monte-Carlo (generates many sets of observations).\n+        final int mcRepeat = MONTE_CARLO_RUNS;\n+        int mcCount = 0;\n+        while (mcCount < mcRepeat) {\n+            // Observations.\n+            final Point2D.Double[] obs = lineGenerator.generate(numObs);\n+\n+            final StraightLineProblem problem = new StraightLineProblem(yError);\n+            for (int i = 0; i < numObs; i++) {\n+                final Point2D.Double p = obs[i];\n+                problem.addPoint(p.x, p.y);\n+            }\n+\n+            // Direct solution (using simple regression).\n+            final double[] regress = problem.solve();\n+\n+            // Estimation of the standard deviation (diagonal elements of the\n+            // covariance matrix).\n+            optim.optimize(Integer.MAX_VALUE,\n+                           problem, problem.target(), problem.weight(), init);\n+            final double[] sigma = optim.getSigma();\n+\n+            // Accumulate statistics.\n+            for (int i = 0; i < numParams; i++) {\n+                paramsFoundByDirectSolution[i].addValue(regress[i]);\n+                sigmaEstimate[i].addValue(sigma[i]);\n+            }\n+\n+            // Next Monte-Carlo.\n+            ++mcCount;\n+        }\n+\n+        // Print statistics.\n+        final String line = \"--------------------------------------------------------------\";\n+        System.out.println(\"                 True value       Mean        Std deviation\");\n+        for (int i = 0; i < numParams; i++) {\n+            System.out.println(line);\n+            System.out.println(\"Parameter #\" + i);\n+\n+            StatisticalSummary s = paramsFoundByDirectSolution[i].getSummary();\n+            System.out.printf(\"              %+.6e   %+.6e   %+.6e\\n\",\n+                              init[i],\n+                              s.getMean(),\n+                              s.getStandardDeviation());\n+\n+            s = sigmaEstimate[i].getSummary();\n+            System.out.printf(\"sigma: %+.6e (%+.6e)\\n\",\n+                              s.getMean(),\n+                              s.getStandardDeviation());\n+        }\n+        System.out.println(line);\n+\n+        // Check the error estimation.\n+        for (int i = 0; i < numParams; i++) {\n+            Assert.assertEquals(paramsFoundByDirectSolution[i].getSummary().getStandardDeviation(),\n+                                sigmaEstimate[i].getSummary().getMean(),\n+                                8e-2);\n+        }\n+    }\n+\n+    /**\n+     * In this test, the set of observations is fixed.\n+     * Using a Monte-Carlo procedure, it generates sets of parameters,\n+     * and determine the parameter change that will result in the\n+     * normalized chi-square becoming larger by one than the value from\n+     * the best fit solution.\n+     * <br/>\n+     * The optimization problem solved is defined in class\n+     * {@link StraightLineProblem}.\n+     * <br/>\n+     * The output (on stdout) will be a list of lines containing:\n+     * <ul>\n+     *  <li>slope of the straight line,</li>\n+     *  <li>intercept of the straight line,</li>\n+     *  <li>chi-square of the solution defined by the above two values.</li>\n+     * </ul>\n+     * The output is separated into two blocks (with a blank line between\n+     * them); the first block will contain all parameter sets for which\n+     * {@code chi2 < chi2_b + 1}\n+     * and the second block, all sets for which\n+     * {@code chi2 >= chi2_b + 1}\n+     * where {@code chi2_b} is the lowest chi-square (corresponding to the\n+     * best solution).\n+     */\n+    @Test\n+    public void testParametersErrorMonteCarloParameters() {\n+        // Error on the observations.\n+        final double yError = 15;\n+\n+        // True values of the parameters.\n+        final double slope = 123.456;\n+        final double offset = -98.765;\n+\n+        // Samples generator.\n+        final RandomStraightLinePointGenerator lineGenerator\n+            = new RandomStraightLinePointGenerator(slope, offset,\n+                                                   yError,\n+                                                   -1e3, 1e4,\n+                                                   13839013L);\n+\n+        // Number of observations.\n+        final int numObs = 10;\n+        // number of parameters.\n+        final int numParams = 2;\n+\n+        // Create a single set of observations.\n+        final Point2D.Double[] obs = lineGenerator.generate(numObs);\n+\n+        final StraightLineProblem problem = new StraightLineProblem(yError);\n+        for (int i = 0; i < numObs; i++) {\n+            final Point2D.Double p = obs[i];\n+            problem.addPoint(p.x, p.y);\n+        }\n+\n+        // Direct solution (using simple regression).\n+        final double[] regress = problem.solve();\n+\n+        // Dummy optimizer (to compute the chi-square).\n+        final AbstractLeastSquaresOptimizer optim = new DummyOptimizer();\n+        final double[] init = { slope, offset };\n+        // Get chi-square of the best parameters set for the given set of\n+        // observations.\n+        final double bestChi2N = getChi2N(optim, problem, regress);\n+        final double[] sigma = optim.getSigma();\n+\n+        // Monte-Carlo (generates a grid of parameters).\n+        final int mcRepeat = MONTE_CARLO_RUNS;\n+        final int gridSize = (int) FastMath.sqrt(mcRepeat);\n+\n+        // Parameters found for each of Monte-Carlo run.\n+        // Index 0 = slope\n+        // Index 1 = offset\n+        // Index 2 = normalized chi2\n+        final List<double[]> paramsAndChi2 = new ArrayList<double[]>(gridSize * gridSize);\n+\n+        final double slopeRange = 10 * sigma[0];\n+        final double offsetRange = 10 * sigma[1];\n+        final double minSlope = slope - 0.5 * slopeRange;\n+        final double minOffset = offset - 0.5 * offsetRange;\n+        final double deltaSlope =  slopeRange/ gridSize;\n+        final double deltaOffset = offsetRange / gridSize;\n+        for (int i = 0; i < gridSize; i++) {\n+            final double s = minSlope + i * deltaSlope;\n+            for (int j = 0; j < gridSize; j++) {\n+                final double o = minOffset + j * deltaOffset;\n+                final double chi2N = getChi2N(optim, problem, new double[] {s, o});\n+\n+                paramsAndChi2.add(new double[] {s, o, chi2N});\n+            }\n+        }\n+\n+        // Output (for use with \"gnuplot\").\n+\n+        // Some info.\n+\n+        // For plotting separately sets of parameters that have a large chi2.\n+        final double chi2NPlusOne = bestChi2N + 1;\n+        int numLarger = 0;\n+\n+        final String lineFmt = \"%+.10e %+.10e   %.8e\\n\";\n+\n+        // Point with smallest chi-square.\n+        System.out.printf(lineFmt, regress[0], regress[1], bestChi2N);\n+        System.out.println(); // Empty line.\n+\n+        // Points within the confidence interval.\n+        for (double[] d : paramsAndChi2) {\n+            if (d[2] <= chi2NPlusOne) {\n+                System.out.printf(lineFmt, d[0], d[1], d[2]);\n+            }\n+        }\n+        System.out.println(); // Empty line.\n+\n+        // Points outside the confidence interval.\n+        for (double[] d : paramsAndChi2) {\n+            if (d[2] > chi2NPlusOne) {\n+                ++numLarger;\n+                System.out.printf(lineFmt, d[0], d[1], d[2]);\n+            }\n+        }\n+        System.out.println(); // Empty line.\n+\n+        System.out.println(\"# sigma=\" + Arrays.toString(sigma));\n+        System.out.println(\"# \" + numLarger + \" sets filtered out\");\n+    }\n+\n+    /**\n+     * @return the normalized chi-square.\n+     */\n+    private double getChi2N(AbstractLeastSquaresOptimizer optim,\n+                            StraightLineProblem problem,\n+                            double[] params) {\n+        final double[] t = problem.target();\n+        final double[] w = problem.weight();\n+\n+        optim.optimize(Integer.MAX_VALUE, problem, t, w, params);\n+\n+        return optim.getChiSquare() / (t.length - params.length);\n+    }\n+}\n+\n+/**\n+ * A dummy optimizer.\n+ * Used for computing the covariance matrix.\n+ */\n+class DummyOptimizer extends AbstractLeastSquaresOptimizer {\n+    /**\n+     * This method does nothing and returns a dummy value.\n+     */\n+    @Override\n+    public PointVectorValuePair doOptimize() {\n+        // In order to be able to access the chi-square.\n+        updateResidualsAndCost();\n+\n+        // Dummy value.\n+        return null;\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/RandomStraightLinePointGenerator.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization.general;\n+\n+import java.awt.geom.Point2D;\n+import org.apache.commons.math3.random.RandomData;\n+import org.apache.commons.math3.random.RandomDataImpl;\n+import org.apache.commons.math3.random.Well44497b;\n+import org.apache.commons.math3.util.MathUtils;\n+import org.apache.commons.math3.util.FastMath;\n+\n+/**\n+ * Factory for generating a cloud of points that approximate a straight line.\n+ */\n+public class RandomStraightLinePointGenerator {\n+    /** RNG. */\n+    private final RandomData random;\n+    /** Slope. */\n+    private final double slope;\n+    /** Intercept. */\n+    private final double intercept;\n+    /** Error on the y-coordinate. */\n+    private final double sigma;\n+    /** Lowest value of the x-coordinate. */\n+    private final double lo;\n+    /** Highest value of the x-coordinate. */\n+    private final double hi;\n+\n+    /**\n+     * The generator will create a cloud of points whose x-coordinates\n+     * will be randomly sampled between {@code xLo} and {@code xHi}, and\n+     * the correspoding y-coordinates will be computed as\n+     * <pre><code>\n+     *  y = a x + b + N(0, error)\n+     * </code></pre>\n+     * where {@code N(mean, sigma)} is a Gaussian distribution with the\n+     * given mean and standard deviation.\n+     *\n+     * @param a Slope.\n+     * @param b Intercept.\n+     * @param error Error on the y-coordinate of the point.\n+     * @param xLo Lowest value of the x-coordinate.\n+     * @param xHi Highest value of the x-coordinate.\n+     * @param seed RNG seed.\n+     */\n+    public RandomStraightLinePointGenerator(double a,\n+                                            double b,\n+                                            double error,\n+                                            double xLo,\n+                                            double xHi,\n+                                            long seed) {\n+        random = new RandomDataImpl(new Well44497b((seed)));\n+        slope = a;\n+        intercept = b;\n+        sigma = error;\n+        lo = xLo;\n+        hi = xHi;\n+    }\n+\n+    /**\n+     * Point generator.\n+     *\n+     * @param n Number of points to create.\n+     * @return the cloud of {@code n} points.\n+     */\n+    public Point2D.Double[] generate(int n) {\n+        final Point2D.Double[] cloud = new Point2D.Double[n];\n+        for (int i = 0; i < n; i++) {\n+            cloud[i] = create();\n+        }\n+        return cloud;\n+    }\n+\n+    /**\n+     * Create one point.\n+     *\n+     * @return a point.\n+     */\n+    private Point2D.Double create() {\n+        final double x = random.nextUniform(lo, hi);\n+        final double yModel = slope * x + intercept;\n+        final double y = yModel + random.nextGaussian(0, sigma);\n+\n+        return new Point2D.Double(x, y);\n+    }\n+}\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/StraightLineProblem.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math3.optimization.general;\n+\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;\n+import org.apache.commons.math3.analysis.MultivariateMatrixFunction;\n+import org.apache.commons.math3.analysis.UnivariateFunction;\n+import org.apache.commons.math3.util.MathUtils;\n+import org.apache.commons.math3.util.FastMath;\n+import org.apache.commons.math3.stat.regression.SimpleRegression;\n+\n+/**\n+ * Class that models a straight line defined as {@code y = a x + b}.\n+ * The parameters of problem are:\n+ * <ul>\n+ *  <li>{@code a}</li>\n+ *  <li>{@code b}</li>\n+ * </ul>\n+ * The model functions are:\n+ * <ul>\n+ *  <li>for each pair (a, b), the y-coordinate of the line.</li>\n+ * </ul>\n+ */\n+class StraightLineProblem implements DifferentiableMultivariateVectorFunction {\n+    /** Cloud of points assumed to be fitted by a straight line. */\n+    private final ArrayList<double[]> points;\n+    /** Error (on the y-coordinate of the points). */\n+    private final double sigma;\n+\n+    /**\n+     * @param error Assumed error for the y-coordinate.\n+     */\n+    public StraightLineProblem(double error) {\n+        points = new ArrayList<double[]>();\n+        sigma = error;\n+    }\n+\n+    public void addPoint(double px, double py) {\n+        points.add(new double[] { px, py });\n+    }\n+\n+    /**\n+     * @return the list of x-coordinates.\n+     */\n+    public double[] x() {\n+        final double[] v = new double[points.size()];\n+        for (int i = 0; i < points.size(); i++) {\n+            final double[] p = points.get(i);\n+            v[i] = p[0]; // x-coordinate.\n+        }\n+\n+        return v;\n+    }\n+\n+    /**\n+     * @return the list of y-coordinates.\n+     */\n+    public double[] y() {\n+        final double[] v = new double[points.size()];\n+        for (int i = 0; i < points.size(); i++) {\n+            final double[] p = points.get(i);\n+            v[i] = p[1]; // y-coordinate.\n+        }\n+\n+        return v;\n+    }\n+\n+    public double[] target() {\n+        return y();\n+    }\n+\n+    public double[] weight() {\n+        final double weight = 1 / (sigma * sigma);\n+        final double[] w = new double[points.size()];\n+        for (int i = 0; i < points.size(); i++) {\n+            w[i] = weight;\n+        }\n+\n+        return w;\n+    }\n+\n+    public double[] value(double[] params) {\n+        final Model line = new Model(params[0], params[1]);\n+\n+        final double[] model = new double[points.size()];\n+        for (int i = 0; i < points.size(); i++) {\n+            final double[] p = points.get(i);\n+            model[i] = line.value(p[0]);\n+        }\n+\n+        return model;\n+    }\n+\n+    public MultivariateMatrixFunction jacobian() {\n+        return new MultivariateMatrixFunction() {\n+            public double[][] value(double[] point) {\n+                return jacobian(point);\n+            }\n+        };\n+    }\n+\n+    /**\n+     * Directly solve the linear problem, using the {@link SimpleRegression}\n+     * class.\n+     */\n+    public double[] solve() {\n+        final SimpleRegression regress = new SimpleRegression(true);\n+        for (double[] d : points) {\n+            regress.addData(d[0], d[1]);\n+        }\n+\n+        final double[] result = { regress.getSlope(), regress.getIntercept() };\n+        return result;\n+    }\n+\n+    private double[][] jacobian(double[] params) {\n+        final double[][] jacobian = new double[points.size()][2];\n+\n+        for (int i = 0; i < points.size(); i++) {\n+            final double[] p = points.get(i);\n+            // Partial derivative wrt \"a\". \n+            jacobian[i][0] = p[0];\n+            // Partial derivative wrt \"b\".\n+            jacobian[i][1] = 1;\n+        }\n+\n+        return jacobian;\n+    }\n+\n+    /**\n+     * Linear function.\n+     */\n+    public static class Model implements UnivariateFunction {\n+        final double a;\n+        final double b;\n+\n+        public Model(double a,\n+                     double b) {\n+            this.a = a;\n+            this.b = b;\n+        }\n+\n+        @Override\n+        public double value(double x) {\n+            return a * x + b;\n+        }\n+    }\n+}", "timestamp": 1336992651, "metainfo": ""}