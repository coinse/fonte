{"sha": "ee089421f7b820c0bf70744dba9e4347b0600438", "log": "Added hat matrix computation.  ", "commit": "\n--- a/src/java/org/apache/commons/math/stat/regression/OLSMultipleLinearRegression.java\n+++ b/src/java/org/apache/commons/math/stat/regression/OLSMultipleLinearRegression.java\n package org.apache.commons.math.stat.regression;\n \n import org.apache.commons.math.linear.LUDecompositionImpl;\n-import org.apache.commons.math.linear.LUSolver;\n import org.apache.commons.math.linear.QRDecomposition;\n import org.apache.commons.math.linear.QRDecompositionImpl;\n import org.apache.commons.math.linear.RealMatrix;\n     }\n     \n     /**\n+     * <p>Compute the \"hat\" matrix.\n+     * </p>\n+     * <p>The hat matrix is defined in terms of the design matrix X\n+     *  by X(X^TX)^-1X^T\n+     * <p>\n+     * <p>The implementation here uses the QR decomposition to compute the\n+     * hat matrix as QIpQ^T where Ip is the p-dimensional identity matrix\n+     * augmented by 0's.  This computational formula is from \"The Hat Matrix\n+     * in Regression and ANOVA\", David C. Hoaglin and Roy E. Welsch, \n+     * The American Statistician, Vol. 32, No. 1 (Feb., 1978), pp. 17-22.\n+     * \n+     * @return the hat matrix\n+     */\n+    public RealMatrix calculateHat() {\n+        // Create augmented identity matrix\n+        RealMatrix Q = qr.getQ();\n+        final int p = qr.getR().getColumnDimension();\n+        final int n = Q.getColumnDimension();\n+        RealMatrixImpl augI = new RealMatrixImpl(n, n);\n+        double[][] augIData = augI.getDataRef();\n+        for (int i = 0; i < n; i++) {\n+            for (int j =0; j < n; j++) {\n+                if (i == j && i < p) {\n+                    augIData[i][j] = 1d;\n+                } else {\n+                    augIData[i][j] = 0d;\n+                }\n+            }\n+        }\n+        \n+        // Compute and return Hat matrix\n+        return Q.multiply(augI).multiply(Q.transpose());\n+    }\n+   \n+    /**\n      * Loads new x sample data, overriding any previous sample\n      * \n      * @param x the [n,k] array representing the x sample\n--- a/src/test/org/apache/commons/math/stat/regression/OLSMultipleLinearRegressionTest.java\n+++ b/src/test/org/apache/commons/math/stat/regression/OLSMultipleLinearRegressionTest.java\n package org.apache.commons.math.stat.regression;\n \n import org.apache.commons.math.TestUtils;\n+import org.apache.commons.math.linear.MatrixUtils;\n+import org.apache.commons.math.linear.RealMatrix;\n+import org.apache.commons.math.linear.RealMatrixImpl;\n import org.junit.Before;\n import org.junit.Test;\n+import static org.junit.Assert.assertEquals;\n \n public class OLSMultipleLinearRegressionTest extends MultipleLinearRegressionAbstractTest {\n \n                 -0.4515205619767598,-10.2916870903837587,-15.7812984571900063},\n                 1E-12);  \n     }\n+    \n+    /**\n+     * Test hat matrix computation\n+     * \n+     * @throws Exception\n+     */\n+    @Test\n+    public void testHat() throws Exception {\n+        \n+        /*\n+         * This example is from \"The Hat Matrix in Regression and ANOVA\", \n+         * David C. Hoaglin and Roy E. Welsch, \n+         * The American Statistician, Vol. 32, No. 1 (Feb., 1978), pp. 17-22.\n+         * \n+         */\n+        double[] design = new double[] {\n+                11.14, .499, 11.1,\n+                12.74, .558, 8.9,\n+                13.13, .604, 8.8,\n+                11.51, .441, 8.9,\n+                12.38, .550, 8.8,\n+                12.60, .528, 9.9,\n+                11.13, .418, 10.7,\n+                11.7, .480, 10.5,\n+                11.02, .406, 10.5,\n+                11.41, .467, 10.7\n+        };\n+        \n+        int nobs = 10;\n+        int nvars = 2;\n+        \n+        // Estimate the model\n+        OLSMultipleLinearRegression model = new OLSMultipleLinearRegression();\n+        model.newSampleData(design, nobs, nvars);\n+        \n+        RealMatrix hat = model.calculateHat();\n+        \n+        // Reference data is upper half of symmetric hat matrix\n+        double[] referenceData = new double[] {\n+                .418, -.002,  .079, -.274, -.046,  .181,  .128,  .222,  .050,  .242,\n+                       .242,  .292,  .136,  .243,  .128, -.041,  .033, -.035,  .004,\n+                              .417, -.019,  .273,  .187, -.126,  .044, -.153,  .004,\n+                                     .604,  .197, -.038,  .168, -.022,  .275, -.028,\n+                                            .252,  .111, -.030,  .019, -.010, -.010,\n+                                                   .148,  .042,  .117,  .012,  .111,\n+                                                          .262,  .145,  .277,  .174,\n+                                                                 .154,  .120,  .168,\n+                                                                        .315,  .148,\n+                                                                               .187\n+        };\n+        \n+        // Check against reference data and verify symmetry\n+        int k = 0;\n+        for (int i = 0; i < 10; i++) {\n+            for (int j = i; j < 10; j++) {\n+                assertEquals(referenceData[k], hat.getEntry(i, j), 10e-3);\n+                assertEquals(hat.getEntry(i, j), hat.getEntry(j, i), 10e-12);\n+                k++;  \n+            }\n+        }\n+        \n+        /* \n+         * Verify that residuals computed using the hat matrix are close to \n+         * what we get from direct computation, i.e. r = (I - H) y\n+         */\n+        double[] residuals = model.estimateResiduals();\n+        RealMatrix I = MatrixUtils.createRealIdentityMatrix(10);\n+        double[] hatResiduals = I.subtract(hat).multiply(model.Y).getColumn(0);\n+        TestUtils.assertEquals(residuals, hatResiduals, 10e-12);    \n+    }\n }", "timestamp": 1231042285, "metainfo": ""}