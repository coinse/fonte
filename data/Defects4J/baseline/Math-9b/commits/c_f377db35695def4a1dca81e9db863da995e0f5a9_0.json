{"sha": "f377db35695def4a1dca81e9db863da995e0f5a9", "log": "MATH-887 Deprecated \"protected\" fields. Created new methods (that take arguments and return a value) to replace those that operate on protected fields. Removed call to deprecated methods in unit tests. Added public method \"setCost\" to replace the direct assignment to a protected field.   ", "commit": "\n--- a/src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java\n+++ b/src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java\n import org.apache.commons.math3.exception.util.LocalizedFormats;\n import org.apache.commons.math3.linear.ArrayRealVector;\n import org.apache.commons.math3.linear.RealMatrix;\n-import org.apache.commons.math3.linear.Array2DRowRealMatrix;\n import org.apache.commons.math3.linear.DecompositionSolver;\n import org.apache.commons.math3.linear.MatrixUtils;\n import org.apache.commons.math3.linear.QRDecomposition;\n public abstract class AbstractLeastSquaresOptimizer\n     extends BaseAbstractMultivariateVectorOptimizer<DifferentiableMultivariateVectorFunction>\n     implements DifferentiableMultivariateVectorOptimizer {\n-    /** Singularity threshold (cf. {@link #getCovariances(double)}). */\n+    /**\n+     * Singularity threshold (cf. {@link #getCovariances(double)}).\n+     * @deprecated As of 3.1.\n+     */\n+    @Deprecated\n     private static final double DEFAULT_SINGULARITY_THRESHOLD = 1e-14;\n     /**\n      * Jacobian matrix of the weighted residuals.\n      * {@link #updateJacobian()}, but may be modified by the solver\n      * in the derived class (the {@link LevenbergMarquardtOptimizer\n      * Levenberg-Marquardt optimizer} does this).\n-     */\n+     * @deprecated As of 3.1. To be removed in 4.0. Please use\n+     * {@link #computeJacobian(double[])} instead.\n+     */\n+    @Deprecated\n     protected double[][] weightedResidualJacobian;\n-    /** Number of columns of the jacobian matrix. */\n+    /** Number of columns of the jacobian matrix.\n+     * @deprecated As of 3.1.\n+     */\n+    @Deprecated\n     protected int cols;\n-    /** Number of rows of the jacobian matrix. */\n+    /** Number of rows of the jacobian matrix.\n+     * @deprecated As of 3.1.\n+     */\n+    @Deprecated\n     protected int rows;\n-    /** Current point. */\n+    /** Current point.\n+     * @deprecated As of 3.1.\n+     */\n+    @Deprecated\n     protected double[] point;\n-    /** Current objective function value. */\n+    /** Current objective function value.\n+     * @deprecated As of 3.1.\n+     */\n+    @Deprecated\n     protected double[] objective;\n-    /** Weighted residuals */\n+    /** Weighted residuals\n+     * @deprecated As of 3.1.\n+     */\n+    @Deprecated\n     protected double[] weightedResiduals;\n-    /** Cost value (square root of the sum of the residuals). */\n+    /** Cost value (square root of the sum of the residuals).\n+     * @deprecated As of 3.1. Field to become \"private\" in 4.0.\n+     * Please use {@link #setCost(double)}.\n+     */\n+    @Deprecated\n     protected double cost;\n     /** Objective function derivatives. */\n     private MultivariateDifferentiableVectorFunction jF;\n      *\n      * @throws DimensionMismatchException if the Jacobian dimension does not\n      * match problem dimension.\n-     */\n+     * @deprecated As of 3.1. Please use {@link #computeJacobian(double[])}\n+     * instead.\n+     */\n+    @Deprecated\n     protected void updateJacobian() {\n+        computeJacobian(point);\n+    }\n+\n+    /**\n+     * Computes the Jacobian matrix.\n+     *\n+     * @param params Model parameters at which to compute the Jacobian.\n+     * @return the weighted Jacobian: -(W<sup>1/2</sup> J).\n+     * @throws DimensionMismatchException if the Jacobian dimension does not\n+     * match problem dimension.\n+     * @since 3.1\n+     */\n+    protected RealMatrix computeJacobian(double[] params) {\n         ++jacobianEvaluations;\n \n-        DerivativeStructure[] dsPoint = new DerivativeStructure[point.length];\n-        for (int i = 0; i < point.length; ++i) {\n-            dsPoint[i] = new DerivativeStructure(point.length, 1, i, point[i]);\n-        }\n-        DerivativeStructure[] dsValue = jF.value(dsPoint);\n-        if (dsValue.length != rows) {\n-            throw new DimensionMismatchException(dsValue.length, rows);\n-        }\n+        final DerivativeStructure[] dsPoint = new DerivativeStructure[params.length];\n+        final int nC = params.length;\n+        for (int i = 0; i < nC; ++i) {\n+            dsPoint[i] = new DerivativeStructure(nC, 1, i, params[i]);\n+        }\n+        final DerivativeStructure[] dsValue = jF.value(dsPoint);\n         final int nR = getTarget().length;\n-        final int nC = point.length;\n+        if (dsValue.length != nR) {\n+            throw new DimensionMismatchException(dsValue.length, nR);\n+        }\n         final double[][] jacobianData = new double[nR][nC];\n         for (int i = 0; i < nR; ++i) {\n-            int[] orders = new int[point.length];\n+            int[] orders = new int[nC];\n             for (int j = 0; j < nC; ++j) {\n                 orders[j] = 1;\n                 jacobianData[i][j] = dsValue[i].getPartialDerivative(orders);\n             }\n         }\n \n-        weightedResidualJacobian\n-            = weightMatrixSqrt.multiply(MatrixUtils.createRealMatrix(jacobianData)).scalarMultiply(-1).getData();\n+        // XXX What is the purpose of the multiplication by -1?\n+        final RealMatrix weightedJacobian\n+            = weightMatrixSqrt.multiply(MatrixUtils.createRealMatrix(jacobianData)).scalarMultiply(-1);\n+\n+        // XXX For backwards-compatibility (field \"weightedResidualJacobian\"\n+        // must be removed in 4.0).\n+        weightedResidualJacobian = weightedJacobian.getData();\n+\n+        return weightedJacobian;\n     }\n \n     /**\n      * problem dimension.\n      * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n      * if the maximal number of evaluations is exceeded.\n-     */\n+     * @deprecated As of 3.1. Please use {@link #computeResiduals(double[])},\n+     * {@link #computeObjectiveValue(double[])} and {@link #computeCost(double[])}\n+     * instead.\n+     */\n+    @Deprecated\n     protected void updateResidualsAndCost() {\n-        final double[] res = computeResidual(point);\n+        objective = computeObjectiveValue(point);\n+        final double[] res = computeResiduals(objective);\n+\n+        // Compute cost.\n+        cost = computeCost(res);\n+\n+        // Compute weighted residuals. XXX To be moved to \"LevenbergMarquardtOptimizer\".\n         final ArrayRealVector residuals = new ArrayRealVector(res);\n-        final RealMatrix weight = getWeight();\n-\n-        // Compute cost.\n-        cost = FastMath.sqrt(residuals.dotProduct(weight.operate(residuals)));\n-        // Compute weighted residuals.\n         weightedResiduals = weightMatrixSqrt.operate(residuals).toArray();\n+    }\n+\n+    /**\n+     * Computes the cost.\n+     *\n+     * @param residuals Residuals.\n+     * @return the cost.\n+     * @see #computeResiduals(double[])\n+     * @since 3.1\n+     */\n+    protected double computeCost(double[] residuals) {\n+        final ArrayRealVector r = new ArrayRealVector(residuals);\n+        return FastMath.sqrt(r.dotProduct(getWeight().operate(r)));\n     }\n \n     /**\n     }\n \n     /**\n+     * Sets the cost.\n+     *\n+     * @param cost Cost value.\n+     * @since 3.1\n+     */\n+    public void setCost(double cost) {\n+        this.cost = cost;\n+    }\n+\n+    /**\n      * Get the covariance matrix of the optimized parameters.\n      *\n      * @return the covariance matrix.\n      * @throws org.apache.commons.math3.linear.SingularMatrixException\n      * if the covariance matrix cannot be computed (singular problem).\n-     *\n      * @see #getCovariances(double)\n-     */\n+     * @deprecated As of 3.1. Please use {@link #computeCovariances(double[],double)}\n+     * instead.\n+     */\n+    @Deprecated\n     public double[][] getCovariances() {\n         return getCovariances(DEFAULT_SINGULARITY_THRESHOLD);\n     }\n      * @return the covariance matrix.\n      * @throws org.apache.commons.math3.linear.SingularMatrixException\n      * if the covariance matrix cannot be computed (singular problem).\n-     */\n+     * @deprecated As of 3.1. Please use {@link #computeCovariances(double[],double)}\n+     * instead.\n+     */\n+    @Deprecated\n     public double[][] getCovariances(double threshold) {\n-        // Set up the jacobian.\n-        updateJacobian();\n+        return computeCovariances(point, threshold);\n+    }\n+\n+    /**\n+     * Get the covariance matrix of the optimized parameters.\n+     * <br/>\n+     * Note that this operation involves the inversion of the\n+     * <code>J<sup>T</sup>J</code> matrix, where {@code J} is the\n+     * Jacobian matrix.\n+     * The {@code threshold} parameter is a way for the caller to specify\n+     * that the result of this computation should be considered meaningless,\n+     * and thus trigger an exception.\n+     *\n+     * @param params Model parameters.\n+     * @param threshold Singularity threshold.\n+     * @return the covariance matrix.\n+     * @throws org.apache.commons.math3.linear.SingularMatrixException\n+     * if the covariance matrix cannot be computed (singular problem).\n+     */\n+    public double[][] computeCovariances(double[] params,\n+                                         double threshold) {\n+        // Set up the Jacobian.\n+        final RealMatrix j = computeJacobian(params);\n \n         // Compute transpose(J)J.\n-        final RealMatrix wrj = new Array2DRowRealMatrix(weightedResidualJacobian);\n-        final RealMatrix jTj = wrj.transpose().multiply(wrj);\n+        final RealMatrix jTj = j.transpose().multiply(j);\n \n         // Compute the covariances matrix.\n         final DecompositionSolver solver\n      * @throws NumberIsTooSmallException if the number of degrees of freedom is not\n      * positive, i.e. the number of measurements is less or equal to the number of\n      * parameters.\n-     * @deprecated as of version 3.1, {@link #getSigma()} should be used\n-     * instead. It should be emphasized that {@link #guessParametersErrors()} and\n-     * {@link #getSigma()} are <em>not</em> strictly equivalent.\n+     * @deprecated as of version 3.1, {@link #computeSigma(double[],double)} should be used\n+     * instead. It should be emphasized that {@code guessParametersErrors} and\n+     * {@code computeSigma} are <em>not</em> strictly equivalent.\n      */\n     @Deprecated\n     public double[] guessParametersErrors() {\n         }\n         double[] errors = new double[cols];\n         final double c = FastMath.sqrt(getChiSquare() / (rows - cols));\n-        double[][] covar = getCovariances();\n+        double[][] covar = computeCovariances(point, 1e-14);\n         for (int i = 0; i < errors.length; ++i) {\n             errors[i] = FastMath.sqrt(covar[i][i]) * c;\n         }\n     }\n \n     /**\n-     * <p>\n-     * Returns an estimate of the standard deviation of the parameters. The\n+     * Computes an estimate of the standard deviation of the parameters. The\n      * returned values are the square root of the diagonal coefficients of the\n      * covariance matrix, {@code sd(a[i]) ~= sqrt(C[i][i])}, where {@code a[i]}\n      * is the optimized value of the {@code i}-th parameter, and {@code C} is\n      * the covariance matrix.\n-     * </p>\n-     *\n+     *\n+     * @param params Model parameters.\n+     * @param covarianceSingularityThreshold Singularity threshold (see\n+     * {@link #computeCovariances(double[],double) computeCovariances}).\n      * @return an estimate of the standard deviation of the optimized parameters\n      * @throws org.apache.commons.math3.linear.SingularMatrixException\n      * if the covariance matrix cannot be computed.\n      */\n-    public double[] getSigma() {\n-        final double[] sig = new double[cols];\n-        final double[][] cov = getCovariances();\n-        for (int i = 0; i < sig.length; ++i) {\n+    public double[] computeSigma(double[] params,\n+                                 double covarianceSingularityThreshold) {\n+        final int nC = params.length;\n+        final double[] sig = new double[nC];\n+        final double[][] cov = computeCovariances(params, covarianceSingularityThreshold);\n+        for (int i = 0; i < nC; ++i) {\n             sig[i] = FastMath.sqrt(cov[i][i]);\n         }\n         return sig;\n     }\n \n     /**\n+     * Computes the residuals.\n+     * The residual is the difference between the observed (target)\n+     * values and the model (objective function) value.\n+     * There is one residual for each element of the vector-valued\n+     * function.\n+     *\n+     * @param objectiveValue Value of the the objective function. This is\n+     * the value returned from a call to\n+     * {@link #computeObjectiveValue(double[]) computeObjectiveValue}\n+     * (whose array argument contains the model parameters).\n+     * @return the residuals.\n+     * @throws DimensionMismatchException if {@code params} has a wrong\n+     * length.\n+     */\n+    protected double[] computeResiduals(double[] objectiveValue) {\n+        final double[] target = getTarget();\n+        if (objectiveValue.length != target.length) {\n+            throw new DimensionMismatchException(target.length,\n+                                                 objectiveValue.length);\n+        }\n+\n+        final double[] residuals = new double[target.length];\n+        for (int i = 0; i < target.length; i++) {\n+            residuals[i] = target[i] - objectiveValue[i];\n+        }\n+\n+        return residuals;\n+    }\n+\n+    /**\n      * Computes the square-root of the weight matrix.\n      *\n      * @param m Symmetric, positive-definite (weight) matrix.\n         final EigenDecomposition dec = new EigenDecomposition(m);\n         return dec.getSquareRoot();\n     }\n-\n-    /**\n-     * Computes the residuals.\n-     * The residual is the difference between the observed (target)\n-     * values and the model (objective function) value, for the given\n-     * parameters.\n-     * There is one residual for each element of the vector-valued\n-     * function.\n-     *\n-     * @param params Parameters of the model.\n-     * @return the residuals.\n-     * @throws DimensionMismatchException if {@code params} has a wrong\n-     * length.\n-     */\n-    private double[] computeResidual(double[] params) {\n-        if (params.length != getStartPoint().length) {\n-            throw new DimensionMismatchException(params.length,\n-                                                 getStartPoint().length);\n-        }\n-\n-        objective = computeObjectiveValue(params);\n-        final double[] target = getTarget();\n-\n-        final double[] residuals = new double[target.length];\n-        for (int i = 0; i < target.length; i++) {\n-            residuals[i] = target[i] - objective[i];\n-        }\n-\n-        return residuals;\n-    }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerAbstractTest.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerAbstractTest.java\n         Assert.assertEquals(69.96016176931406, circle.getRadius(center), 1.0e-6);\n         Assert.assertEquals(96.07590211815305, center.getX(),            1.0e-6);\n         Assert.assertEquals(48.13516790438953, center.getY(),            1.0e-6);\n-        double[][] cov = optimizer.getCovariances();\n+        double[][] cov = optimizer.computeCovariances(optimum.getPoint(), 1e-14);\n         Assert.assertEquals(1.839, cov[0][0], 0.001);\n         Assert.assertEquals(0.731, cov[0][1], 0.001);\n         Assert.assertEquals(cov[0][1], cov[1][0], 1.0e-14);\n         Assert.assertEquals(0.786, cov[1][1], 0.001);\n-        double[] errors = optimizer.guessParametersErrors();\n-        Assert.assertEquals(1.384, errors[0], 0.001);\n-        Assert.assertEquals(0.905, errors[1], 0.001);\n \n         // add perfect measurements and check errors are reduced\n         double  r = circle.getRadius(center);\n         Arrays.fill(target, 0.0);\n         double[] weights = new double[circle.getN()];\n         Arrays.fill(weights, 2.0);\n-        optimizer.optimize(100, circle, target, weights, new double[] { 98.680, 47.345 });\n-        cov = optimizer.getCovariances();\n+        optimum = optimizer.optimize(100, circle, target, weights, new double[] { 98.680, 47.345 });\n+        cov = optimizer.computeCovariances(optimum.getPoint(), 1e-14);\n         Assert.assertEquals(0.0016, cov[0][0], 0.001);\n         Assert.assertEquals(3.2e-7, cov[0][1], 1.0e-9);\n         Assert.assertEquals(cov[0][1], cov[1][0], 1.0e-14);\n         Assert.assertEquals(0.0016, cov[1][1], 0.001);\n-        errors = optimizer.guessParametersErrors();\n-        Assert.assertEquals(0.004, errors[0], 0.001);\n-        Assert.assertEquals(0.004, errors[1], 0.001);\n     }\n \n     @Test\n         optimum = optimizer.optimize(100, problem, data[1], w, initial);\n \n         final double[] actual = optimum.getPoint();\n-        final double[] actualSig = optimizer.guessParametersErrors();\n         for (int i = 0; i < actual.length; i++) {\n             double expected = dataset.getParameter(i);\n             double delta = FastMath.abs(errParams * expected);\n             Assert.assertEquals(dataset.getName() + \", param #\" + i,\n                                 expected, actual[i], delta);\n-            expected = dataset.getParameterStandardDeviation(i);\n-            delta = FastMath.abs(errParamsSd * expected);\n-            Assert.assertEquals(dataset.getName() + \", sd of param #\" + i,\n-                                expected, actualSig[i], delta);\n         }\n     }\n \n--- a/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerTest.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerTest.java\n \n             @Override\n             protected PointVectorValuePair doOptimize() {\n-                updateResidualsAndCost();\n-                updateJacobian();\n-                return null;\n+                final double[] params = getStartPoint();\n+                final double[] res = computeResiduals(computeObjectiveValue(params));\n+                setCost(computeCost(res));\n+                return new PointVectorValuePair(params, null);\n             }\n         };\n     }\n     }\n \n     @Test\n-    public void testGetSigma() throws IOException {\n+    public void testComputeSigma() throws IOException {\n         final StatisticalReferenceDataset dataset;\n         dataset = StatisticalReferenceDatasetFactory.createKirby2();\n         final AbstractLeastSquaresOptimizer optimizer;\n         final double[] w = new double[y.length];\n         Arrays.fill(w, 1.0);\n \n-        final int dof = y.length-a.length;\n-        optimizer.optimize(1, dataset.getLeastSquaresProblem(), y, w, a);\n-        final double[] sig = optimizer.getSigma();\n+        final int dof = y.length - a.length;\n+        final PointVectorValuePair optimum = optimizer.optimize(1, dataset.getLeastSquaresProblem(), y, w, a);\n+        final double[] sig = optimizer.computeSigma(optimum.getPoint(), 1e-14);\n         final double[] expected = dataset.getParametersStandardDeviations();\n         for (int i = 0; i < sig.length; i++) {\n-            final double actual = FastMath.sqrt(optimizer.getChiSquare()/dof)*sig[i];\n+            final double actual = FastMath.sqrt(optimizer.getChiSquare() / dof) * sig[i];\n             Assert.assertEquals(dataset.getName() + \", parameter #\" + i,\n-                                expected[i], actual, 1.3e-8 * expected[i]);\n+                                expected[i], actual, 1e-7 * expected[i]);\n         }\n     }\n }\n--- a/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerTestValidation.java\n+++ b/src/test/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizerTestValidation.java\n \n             // Estimation of the standard deviation (diagonal elements of the\n             // covariance matrix).\n-            optim.optimize(Integer.MAX_VALUE,\n+            final PointVectorValuePair optimum = optim.optimize(Integer.MAX_VALUE,\n                            problem, problem.target(), problem.weight(), init);\n-            final double[] sigma = optim.getSigma();\n+            final double[] sigma = optim.computeSigma(optimum.getPoint(), 1e-14);\n \n             // Accumulate statistics.\n             for (int i = 0; i < numParams; i++) {\n         // Get chi-square of the best parameters set for the given set of\n         // observations.\n         final double bestChi2N = getChi2N(optim, problem, regress);\n-        final double[] sigma = optim.getSigma();\n+        final double[] sigma = optim.computeSigma(regress, 1e-14);\n \n         // Monte-Carlo (generates a grid of parameters).\n         final int mcRepeat = MONTE_CARLO_RUNS;\n      */\n     @Override\n     public PointVectorValuePair doOptimize() {\n-        // In order to be able to access the chi-square.\n-        updateResidualsAndCost();\n-\n-        // Dummy value.\n-        return null;\n+        final double[] params = getStartPoint();\n+        final double[] res = computeResiduals(computeObjectiveValue(params));\n+        setCost(computeCost(res));\n+        return new PointVectorValuePair(params, null);\n     }\n }", "timestamp": 1352371834, "metainfo": ""}