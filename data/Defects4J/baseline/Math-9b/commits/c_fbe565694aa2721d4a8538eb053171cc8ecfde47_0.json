{"sha": "fbe565694aa2721d4a8538eb053171cc8ecfde47", "log": "started refactoring of optimization framework:  - created subpackages optimization.direct, optimization.general,    optimization.linear (currently empty) and optimization.univariate  - removed packages analysis.minimization and estimation  - renamed all Cost-related interfaces/classes into Objective    (this allows both minimization and maximization)  - added a few new general interfaces  This work is not complete yet. The direct and general packages classes are very close to the former design, they have almost not been changed structurally.  ", "commit": "\n--- a/src/java/org/apache/commons/math/optimization/ConvergenceChecker.java\n+++ b/src/java/org/apache/commons/math/optimization/ConvergenceChecker.java\n \n package org.apache.commons.math.optimization;\n \n+import org.apache.commons.math.optimization.direct.DirectSearchOptimizer;\n+\n+\n /** This interface specifies how to check if a {@link\n  * DirectSearchOptimizer direct search method} has converged.\n  *\n public interface ConvergenceChecker {\n \n   /** Check if the optimization algorithm has converged on the simplex.\n-   * @param simplex ordered simplex (all points in the simplex have\n-   * been eavluated and are sorted from lowest to largest cost)\n+   * <p>\n+   * When this method is called, all points in the simplex have been evaluated\n+   * and are sorted from lowest to largest value. The values are either the\n+   * original objective function values if the optimizer was configured for\n+   * minimization, or the opposites of the original objective function values\n+   * if the optimizer was configured for maximization.\n+   * </p>\n+   * @param simplex ordered simplex\n    * @return true if the algorithm is considered to have converged\n    */\n-  public boolean converged (PointCostPair[] simplex);\n+  boolean converged(PointValuePair[] simplex);\n \n }\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/GoalType.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization;\n+\n+import java.io.Serializable;\n+\n+/** \n+ * Goal type for an optimization problem.\n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ */\n+public enum GoalType implements Serializable {\n+\n+    /** Maximization goal. */\n+    MAXIMIZE,\n+\n+    /** Minimization goal. */\n+    MINIMIZE\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/LeastSquaresConverter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization;\n+\n+import org.apache.commons.math.linear.RealMatrix;\n+\n+/** This class converts {@link MultiObjectiveFunction vectorial\n+ * objective functions} to {@link ObjectiveFunction scalar objective functions}\n+ * when the goal is to minimize them.\n+ * <p>\n+ * This class is mostly used when the vectorial objective function represents\n+ * residuals, i.e. differences between a theoretical result computed from a\n+ * variables set applied to a model and a reference. Residuals are intended to be\n+ * minimized in order to get the variables set that best fit the model to the\n+ * reference. The reference may be obtained for example from physical measurements\n+ * whether the model is built from theoretical considerations.\n+ * </p>\n+ * <p>\n+ * This class computes a possibly weighted squared sum of the residuals, which is\n+ * a scalar value. It implements the {@link ObjectiveFunction} interface and can\n+ * therefore be minimized by any optimizer supporting scalar objectives functions.\n+ * This correspond to a least square estimation.\n+ * </p>\n+ * <p>\n+ * This class support combination of residuals with or without weights and correlations.\n+ * </p>\n+  *\n+ * @see ObjectiveFunction\n+ * @see MultiObjectiveFunction\n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ */\n+\n+public class LeastSquaresConverter implements ObjectiveFunction {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -5174886571116126798L;\n+\n+    /** Underlying vectorial function. */\n+    private final MultiObjectiveFunction function;\n+\n+    /** Optional weights for the residuals. */\n+    private final double[] weights;\n+\n+    /** Optional scaling matrix (weight and correlations) for the residuals. */\n+    private final RealMatrix scale;\n+\n+    /** Build a simple converter for uncorrelated residuals with the same weight.\n+     * @param function vectorial residuals function to wrap\n+     */\n+    public LeastSquaresConverter (final MultiObjectiveFunction function) {\n+        this.function = function;\n+        this.weights  = null;\n+        this.scale    = null;\n+    }\n+\n+    /** Build a simple converter for uncorrelated residuals with the specific weights.\n+     * <p>\n+     * The scalar objective function value is computed as:\n+     * <pre>\n+     * objective = &sum;(weight<sub>i</sub>residual<sub>i</sub>)<sup>2</sup>\n+     * </pre>\n+     * </p>\n+     * <p>\n+     * Weights can be used for example to combine residuals with different standard\n+     * deviations. As an example, consider a 2000 elements residuals array in which\n+     * even elements are angular measurements in degrees with a 0.01&deg; standard\n+     * deviation and off elements are distance measurements in meters with a 15m\n+     * standard deviation. In this case, the weights array should be initialized with\n+     * value 1.0/0.01 in the even elements and 1.0/15.0 in the odd elements. \n+     * </p>\n+     * <p>\n+     * The residuals array computed by the function and the weights array must\n+     * have consistent sizes or a {@link ObjectiveException} will be triggered while\n+     * computing the scalar objective.\n+     * </p>\n+     * @param function vectorial residuals function to wrap\n+     * @param weights weights to apply to the residuals\n+     */\n+    public LeastSquaresConverter (final MultiObjectiveFunction function,\n+                                  final double[] weights) {\n+        this.function = function;\n+        this.weights  = weights.clone();\n+        this.scale    = null;\n+    }\n+\n+    /** Build a simple convertor for correlated residuals with the specific weights.\n+     * <p>\n+     * The scalar objective function value is computed as:\n+     * <pre>\n+     * objective = &sum;(y<sub>i</sub>)<sup>2</sup> with y = scale&times;residual\n+     * </pre>\n+     * </p>\n+     * <p>\n+     * The residuals array computed by the function and the scaling matrix must\n+     * have consistent sizes or a {@link ObjectiveException} will be triggered while\n+     * computing the scalar objective.\n+     * </p>\n+     * @param function vectorial residuals function to wrap\n+     * @param scale scaling matrix (\n+     */\n+    public LeastSquaresConverter (final MultiObjectiveFunction function,\n+                                  final RealMatrix scale) {\n+        this.function = function;\n+        this.weights  = null;\n+        this.scale    = scale.copy();\n+    }\n+\n+    /** {@inheritDoc} */\n+    public double objective(final double[] variables) throws ObjectiveException {\n+\n+        final double[] residuals = function.objective(variables);\n+        double sumSquares = 0;\n+\n+        if (weights != null) {\n+            if (weights.length != residuals.length) {\n+                throw new ObjectiveException(\"dimension mismatch {0} != {1}\",\n+                                        weights.length, residuals.length);\n+            }\n+            for (int i = 0; i < weights.length; ++i) {\n+                final double ai = residuals[i] * weights[i];\n+                sumSquares += ai * ai;\n+            }\n+        } else if (scale != null) {\n+            if (scale.getColumnDimension() != residuals.length) {\n+                throw new ObjectiveException(\"dimension mismatch {0} != {1}\",\n+                                        scale.getColumnDimension(), residuals.length);\n+            }\n+            for (final double yi : scale.operate(residuals)) {\n+                sumSquares += yi * yi;\n+            }\n+        } else {\n+            for (final double ri : residuals) {\n+                sumSquares += ri * ri;\n+            }\n+        }\n+\n+        return sumSquares;\n+\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/MultiObjectiveFunction.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization;\n+\n+import java.io.Serializable;\n+\n+/** \n+ * This interface represents a vectorial objective function to be either minimized or maximized.\n+ * @see LeastSquaresConverter\n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ */\n+public interface MultiObjectiveFunction extends Serializable {\n+\n+    /** \n+     * Compute the function value for the given variables set.\n+     * @param variables variables set\n+     * @return function value for the given variables set\n+     * @exception ObjectiveException if no cost can be computed for the parameters\n+     */\n+    double[] objective(double[] variables) throws ObjectiveException;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/ObjectiveException.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization;\n+\n+import org.apache.commons.math.MathException;\n+\n+/** \n+ * This class represents exceptions thrown by obective functions.\n+ *\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ */\n+\n+public class ObjectiveException\n+  extends MathException {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = 8738657724051397417L;\n+\n+    /**\n+     * Constructs a new <code>ObjectiveException</code> with specified\n+     * formatted detail message.\n+     * Message formatting is delegated to {@link java.text.MessageFormat}.\n+     * @param pattern format specifier\n+     * @param arguments format arguments\n+     */\n+    public ObjectiveException(String pattern, Object ... arguments) {\n+      super(pattern, arguments);\n+    }\n+\n+    /**\n+     * Constructs a new <code>ObjectiveException</code> with specified\n+     * nested <code>Throwable</code> root cause.\n+     *\n+     * @param rootCause  the exception or error that caused this exception\n+     *                   to be thrown.\n+     */\n+    public ObjectiveException(Throwable rootCause) {\n+        super(rootCause);\n+    }\n+    \n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/ObjectiveFunction.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization;\n+\n+import java.io.Serializable;\n+\n+/** \n+ * This interface represents a scalar objective function to be either minimized or maximized.\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ */\n+public interface ObjectiveFunction extends Serializable {\n+\n+    /** \n+     * Compute the function value for the given variables set.\n+     * @param variables variables set\n+     * @return function value for the given variables set\n+     * @exception ObjectiveException if no value can be computed for the parameters\n+     */\n+    double objective(double[] variables) throws ObjectiveException;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/OptimizationException.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization;\n+\n+import org.apache.commons.math.ConvergenceException;\n+\n+/** \n+ * This class represents exceptions thrown by the estimation solvers.\n+ *\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+\n+public class OptimizationException extends ConvergenceException {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -781139167958631145L;\n+\n+    /** \n+     * Simple constructor.\n+     * Build an exception by translating and formating a message\n+     * @param specifier format specifier (to be translated)\n+     * @param parts to insert in the format (no translation)\n+     */\n+    public OptimizationException(String specifier, Object ... parts) {\n+        super(specifier, parts);\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/Optimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization;\n+\n+import java.io.Serializable;\n+\n+/** \n+ * This interface represents an optimization algorithm.\n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ */\n+public interface Optimizer extends Serializable {\n+\n+    /** Set the maximal number of objective function calls.\n+     * @param maxEvaluations maximal number of function calls for each\n+     * start (note that the number may be checked <em>after</em>\n+     * a few related calls have been made, this means that in some\n+     * cases this number will be exceeded by a few units, depending on\n+     * the dimension of the problem and kind of optimizer).\n+     */\n+    void setMaxEvaluations(int maxEvaluations);\n+\n+    /** Set the convergence checker.\n+     * @param checker object to use to check for convergence\n+     */\n+    void setConvergenceChecker(ConvergenceChecker checker);\n+\n+    /** Optimizes an objective function.\n+     * @param f objective function\n+     * @param goalType type of optimization goal: either {@link GoalType#MAXIMIZE}\n+     * or {@link GoalType#MINIMIZE}\n+     * @return the point/value pair giving the optimal value for objective function\n+     * @exception ObjectiveException if the objective function throws one during\n+     * the search\n+     * @exception OptimizationException if the algorithm failed to converge\n+     */\n+    PointValuePair optimize(final ObjectiveFunction f, final GoalType goalType)\n+        throws ObjectiveException, OptimizationException;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/PointValuePair.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization;\n+\n+import java.io.Serializable;\n+\n+\n+/** \n+ * This class holds a point and the value of an objective function at this point.\n+ * <p>This is a simple immutable container.</p>\n+ * @version $Revision$ $Date$\n+ * @see ObjectiveFunction\n+ * @since 2.0\n+ */\n+public class PointValuePair implements Serializable {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = 2254035971797977063L;\n+\n+    /** Point coordinates. */\n+    private final double[] point;\n+\n+    /** Value of the objective function at the point. */\n+    private final double value;\n+\n+    /** Build a point/objective function value pair.\n+     * @param point point coordinates (the built instance will store\n+     * a copy of the array, not the array passed as argument)\n+     * @param value value of an objective function at the point\n+     */\n+    public PointValuePair(final double[] point, final double value) {\n+        this.point = point.clone();\n+        this.value  = value;\n+    }\n+\n+    /** Get the point.\n+     * @return a copy of the stored point\n+     */\n+    public double[] getPoint() {\n+        return point.clone();\n+    }\n+\n+    /** Get the value of the objective function.\n+     * @return the stored value of the objective function\n+     */\n+    public double getValue() {\n+        return value;\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/direct/DirectSearchOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.direct;\n+\n+import java.io.Serializable;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+\n+import org.apache.commons.math.ConvergenceException;\n+import org.apache.commons.math.DimensionMismatchException;\n+import org.apache.commons.math.MathRuntimeException;\n+import org.apache.commons.math.linear.RealMatrix;\n+import org.apache.commons.math.linear.decomposition.NotPositiveDefiniteMatrixException;\n+import org.apache.commons.math.optimization.ConvergenceChecker;\n+import org.apache.commons.math.optimization.ObjectiveException;\n+import org.apache.commons.math.optimization.ObjectiveFunction;\n+import org.apache.commons.math.optimization.PointValuePair;\n+import org.apache.commons.math.random.CorrelatedRandomVectorGenerator;\n+import org.apache.commons.math.random.JDKRandomGenerator;\n+import org.apache.commons.math.random.RandomGenerator;\n+import org.apache.commons.math.random.RandomVectorGenerator;\n+import org.apache.commons.math.random.UncorrelatedRandomVectorGenerator;\n+import org.apache.commons.math.random.UniformRandomGenerator;\n+import org.apache.commons.math.stat.descriptive.moment.VectorialCovariance;\n+import org.apache.commons.math.stat.descriptive.moment.VectorialMean;\n+\n+/** \n+ * This class implements simplex-based direct search optimization\n+ * algorithms.\n+ *\n+ * <p>Direct search methods only use objective function values, they don't\n+ * need derivatives and don't either try to compute approximation of\n+ * the derivatives. According to a 1996 paper by Margaret H. Wright\n+ * (<a href=\"http://cm.bell-labs.com/cm/cs/doc/96/4-02.ps.gz\">Direct\n+ * Search Methods: Once Scorned, Now Respectable</a>), they are used\n+ * when either the computation of the derivative is impossible (noisy\n+ * functions, unpredictable dicontinuities) or difficult (complexity,\n+ * computation cost). In the first cases, rather than an optimum, a\n+ * <em>not too bad</em> point is desired. In the latter cases, an\n+ * optimum is desired but cannot be reasonably found. In all cases\n+ * direct search methods can be useful.</p>\n+ *\n+ * <p>Simplex-based direct search methods are based on comparison of\n+ * the objective function values at the vertices of a simplex (which is a\n+ * set of n+1 points in dimension n) that is updated by the algorithms\n+ * steps.</p>\n+ *\n+ * <p>Optimization can be attempted either in single-start or in\n+ * multi-start mode. Multi-start is a traditional way to try to avoid\n+ * being trapped in a local optimum and miss the global optimum of a\n+ * function. It can also be used to verify the convergence of an\n+ * algorithm. The various multi-start-enabled <code>optimize</code>\n+ * methods return the best optimum found after all starts, and the\n+ * {@link #getOptimum getOptimum} method can be used to retrieve all\n+ * optima from all starts (including the one already provided by the\n+ * {@link #optimize(ObjectiveFunction, int, ConvergenceChecker, double[],\n+ * double[]) optimize} method).</p>\n+ *\n+ * <p>This class is the base class performing the boilerplate simplex\n+ * initialization and handling. The simplex update by itself is\n+ * performed by the derived classes according to the implemented\n+ * algorithms.</p>\n+ *\n+ * @see ObjectiveFunction\n+ * @see NelderMead\n+ * @see MultiDirectional\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ */\n+public abstract class DirectSearchOptimizer implements Serializable {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -3913013760494455466L;\n+\n+    /** Comparator for {@link PointValuePair} objects. */\n+    private static final Comparator<PointValuePair> PAIR_COMPARATOR =\n+        new Comparator<PointValuePair>() {\n+            public int compare(PointValuePair o1, PointValuePair o2) {\n+                if (o1 == null) {\n+                    return (o2 == null) ? 0 : +1;\n+                } else if (o2 == null) {\n+                    return -1;\n+                }\n+                return (o1.getValue() < o2.getValue()) ? -1 : ((o1 == o2) ? 0 : +1);\n+            }\n+        };\n+\n+    /** Simplex. */\n+    protected PointValuePair[] simplex;\n+\n+    /** Objective function. */\n+    private ObjectiveFunction f;\n+\n+    /** Indicator for minimization. */\n+    private boolean minimizing;\n+\n+    /** Number of evaluations already performed for the current start. */\n+    private int evaluations;\n+\n+    /** Number of evaluations already performed for all starts. */\n+    private int totalEvaluations;\n+\n+    /** Number of starts to go. */\n+    private int starts;\n+\n+    /** Random generator for multi-start. */\n+    private RandomVectorGenerator generator;\n+\n+    /** Found optima. */\n+    private PointValuePair[] optima;\n+\n+    /** Simple constructor.\n+     */\n+    protected DirectSearchOptimizer() {\n+    }\n+\n+    /** Optimizes an objective function.\n+     * <p>The initial simplex is built from two vertices that are\n+     * considered to represent two opposite vertices of a box parallel\n+     * to the canonical axes of the space. The simplex is the subset of\n+     * vertices encountered while going from vertexA to vertexB\n+     * traveling along the box edges only. This can be seen as a scaled\n+     * regular simplex using the projected separation between the given\n+     * points as the scaling factor along each coordinate axis.</p>\n+     * <p>The optimization is performed in single-start mode.</p>\n+     * @param f objective function\n+     * @param maxEvaluations maximal number of function calls for each\n+     * start (note that the number will be checked <em>after</em>\n+     * complete simplices have been evaluated, this means that in some\n+     * cases this number will be exceeded by a few units, depending on\n+     * the dimension of the problem)\n+     * @param checker object to use to check for convergence\n+     * @param minimizing if true, function must be minimize otherwise it must be maximized\n+     * @param vertexA first vertex\n+     * @param vertexB last vertex\n+     * @return the point/value pairs giving the optimal value for objective function\n+     * @exception ObjectiveException if the objective function throws one during\n+     * the search\n+     * @exception ConvergenceException if none of the starts did\n+     * converge (it is not thrown if at least one start did converge)\n+     */\n+    public PointValuePair optimize(final ObjectiveFunction f, final int maxEvaluations,\n+                                   final ConvergenceChecker checker, final boolean minimizing,\n+                                   final double[] vertexA, final double[] vertexB)\n+        throws ObjectiveException, ConvergenceException {\n+\n+        // set up optimizer\n+        buildSimplex(vertexA, vertexB);\n+        setSingleStart();\n+\n+        // compute optimum\n+        return optimize(f, maxEvaluations, checker, minimizing);\n+\n+    }\n+\n+    /** Optimizes an objective function.\n+     * <p>The initial simplex is built from two vertices that are\n+     * considered to represent two opposite vertices of a box parallel\n+     * to the canonical axes of the space. The simplex is the subset of\n+     * vertices encountered while going from vertexA to vertexB\n+     * traveling along the box edges only. This can be seen as a scaled\n+     * regular simplex using the projected separation between the given\n+     * points as the scaling factor along each coordinate axis.</p>\n+     * <p>The optimization is performed in multi-start mode.</p>\n+     * @param f objective function\n+     * @param maxEvaluations maximal number of function calls for each\n+     * start (note that the number will be checked <em>after</em>\n+     * complete simplices have been evaluated, this means that in some\n+     * cases this number will be exceeded by a few units, depending on\n+     * the dimension of the problem)\n+     * @param checker object to use to check for convergence\n+     * @param minimizing if true, function must be minimize otherwise it must be maximized\n+     * @param vertexA first vertex\n+     * @param vertexB last vertex\n+     * @param starts number of starts to perform (including the\n+     * first one), multi-start is disabled if value is less than or\n+     * equal to 1\n+     * @param seed seed for the random vector generator\n+     * @return the point/value pairs giving the optimal value for objective function\n+     * @exception ObjectiveException if the obective function throws one during\n+     * the search\n+     * @exception ConvergenceException if none of the starts did\n+     * converge (it is not thrown if at least one start did converge)\n+     */\n+    public PointValuePair optimize(final ObjectiveFunction f, final int maxEvaluations,\n+                                   final ConvergenceChecker checker, final boolean minimizing,\n+                                   final double[] vertexA, final double[] vertexB,\n+                                   final int starts, final long seed)\n+        throws ObjectiveException, ConvergenceException {\n+\n+        // set up the simplex traveling around the box\n+        buildSimplex(vertexA, vertexB);\n+\n+        // we consider the simplex could have been produced by a generator\n+        // having its mean value at the center of the box, the standard\n+        // deviation along each axe being the corresponding half size\n+        final double[] mean              = new double[vertexA.length];\n+        final double[] standardDeviation = new double[vertexA.length];\n+        for (int i = 0; i < vertexA.length; ++i) {\n+            mean[i]              = 0.5 * (vertexA[i] + vertexB[i]);\n+            standardDeviation[i] = 0.5 * Math.abs(vertexA[i] - vertexB[i]);\n+        }\n+\n+        final RandomGenerator rg = new JDKRandomGenerator();\n+        rg.setSeed(seed);\n+        final UniformRandomGenerator urg = new UniformRandomGenerator(rg);\n+        final RandomVectorGenerator rvg =\n+            new UncorrelatedRandomVectorGenerator(mean, standardDeviation, urg);\n+        setMultiStart(starts, rvg);\n+\n+        // compute optimum\n+        return optimize(f, maxEvaluations, checker, minimizing);\n+\n+    }\n+\n+    /** Optimizes an objective function.\n+     * <p>The simplex is built from all its vertices.</p>\n+     * <p>The optimization is performed in single-start mode.</p>\n+     * @param f objective function\n+     * @param maxEvaluations maximal number of function calls for each\n+     * start (note that the number will be checked <em>after</em>\n+     * complete simplices have been evaluated, this means that in some\n+     * cases this number will be exceeded by a few units, depending on\n+     * the dimension of the problem)\n+     * @param checker object to use to check for convergence\n+     * @param minimizing if true, function must be minimize otherwise it must be maximized\n+     * @param vertices array containing all vertices of the simplex\n+     * @return the point/value pairs giving the optimal value for objective function\n+     * @exception ObjectiveException if the objective function throws one during\n+     * the search\n+     * @exception ConvergenceException if none of the starts did\n+     * converge (it is not thrown if at least one start did converge)\n+     */\n+    public PointValuePair optimize(final ObjectiveFunction f, final int maxEvaluations,\n+                                   final ConvergenceChecker checker, final boolean minimizing,\n+                                   final double[][] vertices)\n+        throws ObjectiveException, ConvergenceException {\n+\n+        // set up optimizer\n+        buildSimplex(vertices);\n+        setSingleStart();\n+\n+        // compute optimum\n+        return optimize(f, maxEvaluations, checker, minimizing);\n+\n+    }\n+\n+    /** Optimizes an objective function.\n+     * <p>The simplex is built from all its vertices.</p>\n+     * <p>The optimization is performed in multi-start mode.</p>\n+     * @param f objective function\n+     * @param maxEvaluations maximal number of function calls for each\n+     * start (note that the number will be checked <em>after</em>\n+     * complete simplices have been evaluated, this means that in some\n+     * cases this number will be exceeded by a few units, depending on\n+     * the dimension of the problem)\n+     * @param checker object to use to check for convergence\n+     * @param minimizing if true, function must be minimize otherwise it must be maximized\n+     * @param vertices array containing all vertices of the simplex\n+     * @param starts number of starts to perform (including the\n+     * first one), multi-start is disabled if value is less than or\n+     * equal to 1\n+     * @param seed seed for the random vector generator\n+     * @return the point/value pairs giving the optimal value for objective function\n+     * @exception NotPositiveDefiniteMatrixException if the vertices\n+     * array is degenerated\n+     * @exception ObjectiveException if the objective function throws one during\n+     * the search\n+     * @exception ConvergenceException if none of the starts did\n+     * converge (it is not thrown if at least one start did converge)\n+     */\n+    public PointValuePair optimize(final ObjectiveFunction f, final int maxEvaluations,\n+                                   final ConvergenceChecker checker, final boolean minimizing,\n+                                   final double[][] vertices,\n+                                   final int starts, final long seed)\n+        throws NotPositiveDefiniteMatrixException, ObjectiveException, ConvergenceException {\n+\n+        try {\n+            // store the points into the simplex\n+            buildSimplex(vertices);\n+\n+            // compute the statistical properties of the simplex points\n+            final VectorialMean meanStat = new VectorialMean(vertices[0].length);\n+            final VectorialCovariance covStat = new VectorialCovariance(vertices[0].length, true);\n+            for (int i = 0; i < vertices.length; ++i) {\n+                meanStat.increment(vertices[i]);\n+                covStat.increment(vertices[i]);\n+            }\n+            final double[] mean = meanStat.getResult();\n+            final RealMatrix covariance = covStat.getResult();\n+            \n+\n+            final RandomGenerator rg = new JDKRandomGenerator();\n+            rg.setSeed(seed);\n+            final RandomVectorGenerator rvg =\n+                new CorrelatedRandomVectorGenerator(mean,\n+                                                    covariance, 1.0e-12 * covariance.getNorm(),\n+                                                    new UniformRandomGenerator(rg));\n+            setMultiStart(starts, rvg);\n+\n+            // compute optimum\n+            return optimize(f, maxEvaluations, checker, minimizing);\n+\n+        } catch (DimensionMismatchException dme) {\n+            // this should not happen\n+            throw new MathRuntimeException(dme, \"unexpected exception caught\");\n+        }\n+\n+    }\n+\n+    /** Optimizes an objective function.\n+     * <p>The simplex is built randomly.</p>\n+     * <p>The optimization is performed in single-start mode.</p>\n+     * @param f objective function\n+     * @param maxEvaluations maximal number of function calls for each\n+     * start (note that the number will be checked <em>after</em>\n+     * complete simplices have been evaluated, this means that in some\n+     * cases this number will be exceeded by a few units, depending on\n+     * the dimension of the problem)\n+     * @param checker object to use to check for convergence\n+     * @param minimizing if true, function must be minimize otherwise it must be maximized\n+     * @param generator random vector generator\n+     * @return the point/value pairs giving the optimal value for objective function\n+     * @exception ObjectiveException if the objective function throws one during\n+     * the search\n+     * @exception ConvergenceException if none of the starts did\n+     * converge (it is not thrown if at least one start did converge)\n+     */\n+    public PointValuePair optimize(final ObjectiveFunction f, final int maxEvaluations,\n+                                   final ConvergenceChecker checker, final boolean minimizing,\n+                                   final RandomVectorGenerator generator)\n+        throws ObjectiveException, ConvergenceException {\n+\n+        // set up optimizer\n+        buildSimplex(generator);\n+        setSingleStart();\n+\n+        // compute optimum\n+        return optimize(f, maxEvaluations, checker, minimizing);\n+\n+    }\n+\n+    /** Optimizes an objective function.\n+     * <p>The simplex is built randomly.</p>\n+     * <p>The optimization is performed in multi-start mode.</p>\n+     * @param f objective function\n+     * @param maxEvaluations maximal number of function calls for each\n+     * start (note that the number will be checked <em>after</em>\n+     * complete simplices have been evaluated, this means that in some\n+     * cases this number will be exceeded by a few units, depending on\n+     * the dimension of the problem)\n+     * @param checker object to use to check for convergence\n+     * @param minimizing if true, function must be minimize otherwise it must be maximized\n+     * @param generator random vector generator\n+     * @param starts number of starts to perform (including the\n+     * first one), multi-start is disabled if value is less than or\n+     * equal to 1\n+     * @return the point/value pairs giving the optimal value for objective function\n+     * @exception ObjectiveException if the objective function throws one during\n+     * the search\n+     * @exception ConvergenceException if none of the starts did\n+     * converge (it is not thrown if at least one start did converge)\n+     */\n+    public PointValuePair optimize(final ObjectiveFunction f, final int maxEvaluations,\n+                                   final ConvergenceChecker checker, final boolean minimizing,\n+                                   final RandomVectorGenerator generator,\n+                                   final int starts)\n+        throws ObjectiveException, ConvergenceException {\n+\n+        // set up optimizer\n+        buildSimplex(generator);\n+        setMultiStart(starts, generator);\n+\n+        // compute optimum\n+        return optimize(f, maxEvaluations, checker, minimizing);\n+\n+    }\n+\n+    /** Build a simplex from two extreme vertices.\n+     * <p>The two vertices are considered to represent two opposite\n+     * vertices of a box parallel to the canonical axes of the\n+     * space. The simplex is the subset of vertices encountered while\n+     * going from vertexA to vertexB traveling along the box edges\n+     * only. This can be seen as a scaled regular simplex using the\n+     * projected separation between the given points as the scaling\n+     * factor along each coordinate axis.</p>\n+     * @param vertexA first vertex\n+     * @param vertexB last vertex\n+     */\n+    private void buildSimplex(final double[] vertexA, final double[] vertexB) {\n+\n+        final int n = vertexA.length;\n+        simplex = new PointValuePair[n + 1];\n+\n+        // set up the simplex traveling around the box\n+        for (int i = 0; i <= n; ++i) {\n+            final double[] vertex = new double[n];\n+            if (i > 0) {\n+                System.arraycopy(vertexB, 0, vertex, 0, i);\n+            }\n+            if (i < n) {\n+                System.arraycopy(vertexA, i, vertex, i, n - i);\n+            }\n+            simplex[i] = new PointValuePair(vertex, Double.NaN);\n+        }\n+\n+    }\n+\n+    /** Build a simplex from all its points.\n+     * @param vertices array containing all vertices of the simplex\n+     */\n+    private void buildSimplex(final double[][] vertices) {\n+        final int n = vertices.length - 1;\n+        simplex = new PointValuePair[n + 1];\n+        for (int i = 0; i <= n; ++i) {\n+            simplex[i] = new PointValuePair(vertices[i], Double.NaN);\n+        }\n+    }\n+\n+    /** Build a simplex randomly.\n+     * @param generator random vector generator\n+     */\n+    private void buildSimplex(final RandomVectorGenerator generator) {\n+\n+        // use first vector size to compute the number of points\n+        final double[] vertex = generator.nextVector();\n+        final int n = vertex.length;\n+        simplex = new PointValuePair[n + 1];\n+        simplex[0] = new PointValuePair(vertex, Double.NaN);\n+\n+        // fill up the vertex\n+        for (int i = 1; i <= n; ++i) {\n+            simplex[i] = new PointValuePair(generator.nextVector(), Double.NaN);\n+        }\n+\n+    }\n+\n+    /** Set up single-start mode.\n+     */\n+    private void setSingleStart() {\n+        starts    = 1;\n+        generator = null;\n+        optima    = null;\n+    }\n+\n+    /** Set up multi-start mode.\n+     * @param starts number of starts to perform (including the\n+     * first one), multi-start is disabled if value is less than or\n+     * equal to 1\n+     * @param generator random vector generator to use for restarts\n+     */\n+    private void setMultiStart(final int starts, final RandomVectorGenerator generator) {\n+        if (starts < 2) {\n+            this.starts    = 1;\n+            this.generator = null;\n+            optima         = null;\n+        } else {\n+            this.starts    = starts;\n+            this.generator = generator;\n+            optima         = null;\n+        }\n+    }\n+\n+    /** Get all the optima found during the last call to {@link\n+     * #optimize(ObjectiveFunction, int, ConvergenceChecker, double[], double[])\n+     * minimize}.\n+     * <p>The optimizer stores all the optima found during a set of\n+     * restarts when multi-start mode is enabled. The {@link\n+     * #optimize(ObjectiveFunction, int, ConvergenceChecker, double[], double[])\n+     * optimize} method returns the best point only. This method\n+     * returns all the points found at the end of each starts, including\n+     * the best one already returned by the {@link #optimize(ObjectiveFunction,\n+     * int, ConvergenceChecker, double[], double[]) optimize} method.\n+     * The array as one element for each start as specified in the constructor\n+     * (it has one element only if optimizer has been set up for single-start).</p>\n+     * <p>The array containing the optimum is ordered with the results\n+     * from the runs that did converge first, sorted from lowest to\n+     * highest objective value if minimizing (from highest to lowest if maximizing),\n+     * and null elements corresponding to the runs that did not converge. This means\n+     * all elements will be null if the {@link #optimize(ObjectiveFunction, int,\n+     * ConvergenceChecker, double[], double[]) optimize} method did throw a {@link\n+     * ConvergenceException ConvergenceException}). This also means that if the first\n+     * element is non null, it is the best point found accross all starts.</p>\n+     * @return array containing the optima, or null if {@link\n+     * #optimize(ObjectiveFunction, int, ConvergenceChecker, double[], double[])\n+     * optimize} has not been called\n+     */\n+    public PointValuePair[] getOptima() {\n+        return (PointValuePair[]) optima.clone();\n+    }\n+\n+    /** Optimizes an objective function.\n+     * @param f objective function\n+     * @param maxEvaluations maximal number of function calls for each\n+     * start (note that the number will be checked <em>after</em>\n+     * complete simplices have been evaluated, this means that in some\n+     * cases this number will be exceeded by a few units, depending on\n+     * the dimension of the problem)\n+     * @param checker object to use to check for convergence\n+     * @param minimizing if true, function must be minimize otherwise it must be maximized\n+     * @return the point/value pairs giving the optimal value for objective function\n+     * @exception ObjectiveException if the objective function throws one during\n+     * the search\n+     * @exception ConvergenceException if none of the starts did\n+     * converge (it is not thrown if at least one start did converge)\n+     */\n+    private PointValuePair optimize(final ObjectiveFunction f, final int maxEvaluations,\n+                                   final ConvergenceChecker checker, final boolean minimizing)\n+        throws ObjectiveException, ConvergenceException {\n+\n+        this.f          = f;\n+        this.minimizing = minimizing;\n+        optima = new PointValuePair[starts];\n+        totalEvaluations = 0;\n+\n+        // multi-start loop\n+        for (int i = 0; i < starts; ++i) {\n+\n+            evaluations = 0;\n+            evaluateSimplex();\n+\n+            for (boolean loop = true; loop;) {\n+                if (checker.converged(simplex)) {\n+                    // we have found an optimum\n+                    optima[i] = simplex[0];\n+                    loop = false;\n+                } else if (evaluations >= maxEvaluations) {\n+                    // this start did not converge, try a new one\n+                    optima[i] = null;\n+                    loop = false;\n+                } else {\n+                    iterateSimplex();\n+                }\n+            }\n+\n+            totalEvaluations += evaluations;\n+\n+            if (i < (starts - 1)) {\n+                // restart\n+                buildSimplex(generator);\n+            }\n+\n+        }\n+\n+        // sort the optima from best to poorest, followed by\n+        // null elements\n+        Arrays.sort(optima, PAIR_COMPARATOR);\n+\n+        if (!minimizing) {\n+            // revert objective function sign to match user original definition\n+            for (int i = 0; i < optima.length; ++i) {\n+                final PointValuePair current = optima[i];\n+                if (current != null) {\n+                    optima[i] = new PointValuePair(current.getPoint(), -current.getValue());\n+                }\n+            }\n+        }\n+\n+        // return the found point given the best objective function value\n+        if (optima[0] == null) {\n+            throw new ConvergenceException(\n+                    \"none of the {0} start points lead to convergence\",\n+                    starts);\n+        }\n+        return optima[0];\n+\n+    }\n+\n+    /** Get the total number of evaluations of the objective function.\n+     * <p>\n+     * The total number of evaluations includes all evaluations for all\n+     * starts if in optimization was done in multi-start mode.\n+     * </p>\n+     * @return total number of evaluations of the objective function\n+     */\n+    public int getTotalEvaluations() {\n+        return totalEvaluations;\n+    }\n+\n+    /** Compute the next simplex of the algorithm.\n+     * @exception ObjectiveException if the function cannot be evaluated at\n+     * some point\n+     */\n+    protected abstract void iterateSimplex() throws ObjectiveException;\n+\n+    /** Evaluate the objective function on one point.\n+     * <p>A side effect of this method is to count the number of\n+     * function evaluations</p>\n+     * @param x point on which the objective function should be evaluated\n+     * @return objective function value at the given point\n+     * @exception ObjectiveException if no value can be computed for the parameters\n+     */\n+    protected double evaluate(final double[] x) throws ObjectiveException {\n+        evaluations++;\n+        return minimizing ? f.objective(x) : -f.objective(x);\n+    }\n+\n+    /** Evaluate all the non-evaluated points of the simplex.\n+     * @exception ObjectiveException if no value can be computed for the parameters\n+     */\n+    protected void evaluateSimplex() throws ObjectiveException {\n+\n+        // evaluate the objective function at all non-evaluated simplex points\n+        for (int i = 0; i < simplex.length; ++i) {\n+            PointValuePair pair = simplex[i];\n+            if (Double.isNaN(pair.getValue())) {\n+                simplex[i] = new PointValuePair(pair.getPoint(), evaluate(pair.getPoint()));\n+            }\n+        }\n+\n+        // sort the simplex from best to poorest\n+        Arrays.sort(simplex, PAIR_COMPARATOR);\n+\n+    }\n+\n+    /** Replace the worst point of the simplex by a new point.\n+     * @param pointValuePair point to insert\n+     */\n+    protected void replaceWorstPoint(PointValuePair pointValuePair) {\n+        int n = simplex.length - 1;\n+        for (int i = 0; i < n; ++i) {\n+            if (simplex[i].getValue() > pointValuePair.getValue()) {\n+                PointValuePair tmp = simplex[i];\n+                simplex[i]        = pointValuePair;\n+                pointValuePair     = tmp;\n+            }\n+        }\n+        simplex[n] = pointValuePair;\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/direct/MultiDirectional.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.direct;\n+\n+import org.apache.commons.math.optimization.ObjectiveException;\n+import org.apache.commons.math.optimization.PointValuePair;\n+\n+/** \n+ * This class implements the multi-directional direct search method.\n+ *\n+ * @version $Revision$ $Date$\n+ * @see NelderMead\n+ * @since 1.2\n+ */\n+public class MultiDirectional extends DirectSearchOptimizer {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -5347711305645019145L;\n+\n+    /** Expansion coefficient. */\n+    private final double khi;\n+\n+    /** Contraction coefficient. */\n+    private final double gamma;\n+\n+    /** Build a multi-directional optimizer with default coefficients.\n+     * <p>The default values are 2.0 for khi and 0.5 for gamma.</p>\n+     */\n+    public MultiDirectional() {\n+        this.khi   = 2.0;\n+        this.gamma = 0.5;\n+    }\n+\n+    /** Build a multi-directional optimizer with specified coefficients.\n+     * @param khi expansion coefficient\n+     * @param gamma contraction coefficient\n+     */\n+    public MultiDirectional(final double khi, final double gamma) {\n+        this.khi   = khi;\n+        this.gamma = gamma;\n+    }\n+\n+    /** Compute the next simplex of the algorithm.\n+     * @exception ObjectiveException if the function cannot be evaluated at\n+     * some point\n+     */\n+    protected void iterateSimplex() throws ObjectiveException {\n+\n+        while (true) {\n+\n+            // save the original vertex\n+            final PointValuePair[] original = simplex;\n+            final double originalValue = original[0].getValue();\n+\n+            // perform a reflection step\n+            final double reflectedValue = evaluateNewSimplex(original, 1.0);\n+            if (reflectedValue < originalValue) {\n+\n+                // compute the expanded simplex\n+                final PointValuePair[] reflected = simplex;\n+                final double expandedValue = evaluateNewSimplex(original, khi);\n+                if (reflectedValue <= expandedValue) {\n+                    // accept the reflected simplex\n+                    simplex = reflected;\n+                }\n+\n+                return;\n+\n+            }\n+\n+            // compute the contracted simplex\n+            final double contractedValue = evaluateNewSimplex(original, gamma);\n+            if (contractedValue < originalValue) {\n+                // accept the contracted simplex\n+                return;\n+            }\n+\n+        }\n+\n+    }\n+\n+    /** Compute and evaluate a new simplex.\n+     * @param original original simplex (to be preserved)\n+     * @param coeff linear coefficient\n+     * @return smallest value in the transformed simplex\n+     * @exception ObjectiveException if the function cannot be evaluated at\n+     * some point\n+     */\n+    private double evaluateNewSimplex(final PointValuePair[] original,\n+                                      final double coeff)\n+        throws ObjectiveException {\n+\n+        final double[] xSmallest = original[0].getPoint();\n+        final int n = xSmallest.length;\n+\n+        // create the linearly transformed simplex\n+        simplex = new PointValuePair[n + 1];\n+        simplex[0] = original[0];\n+        for (int i = 1; i <= n; ++i) {\n+            final double[] xOriginal    = original[i].getPoint();\n+            final double[] xTransformed = new double[n];\n+            for (int j = 0; j < n; ++j) {\n+                xTransformed[j] = xSmallest[j] + coeff * (xSmallest[j] - xOriginal[j]);\n+            }\n+            simplex[i] = new PointValuePair(xTransformed, Double.NaN);\n+        }\n+\n+        // evaluate it\n+        evaluateSimplex();\n+        return simplex[0].getValue();\n+\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/direct/NelderMead.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.direct;\n+\n+import org.apache.commons.math.optimization.ObjectiveException;\n+import org.apache.commons.math.optimization.PointValuePair;\n+\n+/** \n+ * This class implements the Nelder-Mead direct search method.\n+ *\n+ * @version $Revision$ $Date$\n+ * @see MultiDirectional\n+ * @since 1.2\n+ */\n+public class NelderMead extends DirectSearchOptimizer {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -5810365844886183056L;\n+\n+    /** Reflection coefficient. */\n+    private final double rho;\n+\n+    /** Expansion coefficient. */\n+    private final double khi;\n+\n+    /** Contraction coefficient. */\n+    private final double gamma;\n+\n+    /** Shrinkage coefficient. */\n+    private final double sigma;\n+\n+    /** Build a Nelder-Mead optimizer with default coefficients.\n+     * <p>The default coefficients are 1.0 for rho, 2.0 for khi and 0.5\n+     * for both gamma and sigma.</p>\n+     */\n+    public NelderMead() {\n+        this.rho   = 1.0;\n+        this.khi   = 2.0;\n+        this.gamma = 0.5;\n+        this.sigma = 0.5;\n+    }\n+\n+    /** Build a Nelder-Mead optimizer with specified coefficients.\n+     * @param rho reflection coefficient\n+     * @param khi expansion coefficient\n+     * @param gamma contraction coefficient\n+     * @param sigma shrinkage coefficient\n+     */\n+    public NelderMead(final double rho, final double khi,\n+                      final double gamma, final double sigma) {\n+        this.rho   = rho;\n+        this.khi   = khi;\n+        this.gamma = gamma;\n+        this.sigma = sigma;\n+    }\n+\n+    /** {@inheritDoc} */\n+    protected void iterateSimplex() throws ObjectiveException {\n+\n+        // the simplex has n+1 point if dimension is n\n+        final int n = simplex.length - 1;\n+\n+        // interesting values\n+        final double   smallest      = simplex[0].getValue();\n+        final double   secondLargest = simplex[n-1].getValue();\n+        final double   largest       = simplex[n].getValue();\n+        final double[] xLargest      = simplex[n].getPoint();\n+\n+        // compute the centroid of the best vertices\n+        // (dismissing the worst point at index n)\n+        final double[] centroid = new double[n];\n+        for (int i = 0; i < n; ++i) {\n+            final double[] x = simplex[i].getPoint();\n+            for (int j = 0; j < n; ++j) {\n+                centroid[j] += x[j];\n+            }\n+        }\n+        final double scaling = 1.0 / n;\n+        for (int j = 0; j < n; ++j) {\n+            centroid[j] *= scaling;\n+        }\n+\n+        // compute the reflection point\n+        final double[] xR = new double[n];\n+        for (int j = 0; j < n; ++j) {\n+            xR[j] = centroid[j] + rho * (centroid[j] - xLargest[j]);\n+        }\n+        final double valueR = evaluate(xR);\n+\n+        if ((smallest <= valueR) && (valueR < secondLargest)) {\n+\n+            // accept the reflected point\n+            replaceWorstPoint(new PointValuePair(xR, valueR));\n+\n+        } else if (valueR < smallest) {\n+\n+            // compute the expansion point\n+            final double[] xE = new double[n];\n+            for (int j = 0; j < n; ++j) {\n+                xE[j] = centroid[j] + khi * (xR[j] - centroid[j]);\n+            }\n+            final double valueE = evaluate(xE);\n+\n+            if (valueE < valueR) {\n+                // accept the expansion point\n+                replaceWorstPoint(new PointValuePair(xE, valueE));\n+            } else {\n+                // accept the reflected point\n+                replaceWorstPoint(new PointValuePair(xR, valueR));\n+            }\n+\n+        } else {\n+\n+            if (valueR < largest) {\n+\n+                // perform an outside contraction\n+                final double[] xC = new double[n];\n+                for (int j = 0; j < n; ++j) {\n+                    xC[j] = centroid[j] + gamma * (xR[j] - centroid[j]);\n+                }\n+                final double valueC = evaluate(xC);\n+\n+                if (valueC <= valueR) {\n+                    // accept the contraction point\n+                    replaceWorstPoint(new PointValuePair(xC, valueC));\n+                    return;\n+                }\n+\n+            } else {\n+\n+                // perform an inside contraction\n+                final double[] xC = new double[n];\n+                for (int j = 0; j < n; ++j) {\n+                    xC[j] = centroid[j] - gamma * (centroid[j] - xLargest[j]);\n+                }\n+                final double valueC = evaluate(xC);\n+\n+                if (valueC < largest) {\n+                    // accept the contraction point\n+                    replaceWorstPoint(new PointValuePair(xC, valueC));\n+                    return;\n+                }\n+\n+            }\n+\n+            // perform a shrink\n+            final double[] xSmallest = simplex[0].getPoint();\n+            for (int i = 1; i < simplex.length; ++i) {\n+                final double[] x = simplex[i].getPoint();\n+                for (int j = 0; j < n; ++j) {\n+                    x[j] = xSmallest[j] + sigma * (x[j] - xSmallest[j]);\n+                }\n+                simplex[i] = new PointValuePair(x, Double.NaN);\n+            }\n+            evaluateSimplex();\n+\n+        }\n+\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/AbstractEstimator.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.util.Arrays;\n+\n+import org.apache.commons.math.linear.InvalidMatrixException;\n+import org.apache.commons.math.linear.MatrixUtils;\n+import org.apache.commons.math.linear.RealMatrix;\n+import org.apache.commons.math.linear.decomposition.LUDecompositionImpl;\n+import org.apache.commons.math.optimization.OptimizationException;\n+\n+/**\n+ * Base class for implementing estimators.\n+ * <p>This base class handles the boilerplates methods associated to thresholds\n+ * settings, jacobian and error estimation.</p>\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+public abstract class AbstractEstimator implements Estimator {\n+\n+    /** Default maximal number of cost evaluations allowed. */\n+    public static final int DEFAULT_MAX_COST_EVALUATIONS = 100;\n+\n+    /**\n+     * Build an abstract estimator for least squares problems.\n+     * <p>The maximal number of cost evaluations allowed is set\n+     * to its default value {@link #DEFAULT_MAX_COST_EVALUATIONS}.</p>\n+     */\n+    protected AbstractEstimator() {\n+        setMaxCostEval(DEFAULT_MAX_COST_EVALUATIONS);\n+    }\n+\n+    /**\n+     * Set the maximal number of cost evaluations allowed.\n+     * \n+     * @param maxCostEval maximal number of cost evaluations allowed\n+     * @see #estimate\n+     */\n+    public final void setMaxCostEval(int maxCostEval) {\n+        this.maxCostEval = maxCostEval;\n+    }\n+\n+    /**\n+     * Get the number of cost evaluations.\n+     * \n+     * @return number of cost evaluations\n+     * */\n+    public final int getCostEvaluations() {\n+        return costEvaluations;\n+    }\n+\n+    /** \n+     * Get the number of jacobian evaluations.\n+     * \n+     * @return number of jacobian evaluations\n+     * */\n+    public final int getJacobianEvaluations() {\n+        return jacobianEvaluations;\n+    }\n+\n+    /** \n+     * Update the jacobian matrix.\n+     */\n+    protected void updateJacobian() {\n+        incrementJacobianEvaluationsCounter();\n+        Arrays.fill(jacobian, 0);\n+        for (int i = 0, index = 0; i < rows; i++) {\n+            WeightedMeasurement wm = measurements[i];\n+            double factor = -Math.sqrt(wm.getWeight());\n+            for (int j = 0; j < cols; ++j) {\n+                jacobian[index++] = factor * wm.getPartial(parameters[j]);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Increment the jacobian evaluations counter.\n+     */\n+    protected final void incrementJacobianEvaluationsCounter() {\n+      ++jacobianEvaluations;\n+    }\n+\n+    /** \n+     * Update the residuals array and cost function value.\n+     * @exception OptimizationException if the number of cost evaluations\n+     * exceeds the maximum allowed\n+     */\n+    protected void updateResidualsAndCost()\n+    throws OptimizationException {\n+\n+        if (++costEvaluations > maxCostEval) {\n+            throw new OptimizationException(\"maximal number of evaluations exceeded ({0})\",\n+                                          maxCostEval);\n+        }\n+\n+        cost = 0;\n+        for (int i = 0, index = 0; i < rows; i++, index += cols) {\n+            WeightedMeasurement wm = measurements[i];\n+            double residual = wm.getResidual();\n+            residuals[i] = Math.sqrt(wm.getWeight()) * residual;\n+            cost += wm.getWeight() * residual * residual;\n+        }\n+        cost = Math.sqrt(cost);\n+\n+    }\n+\n+    /** \n+     * Get the Root Mean Square value.\n+     * Get the Root Mean Square value, i.e. the root of the arithmetic\n+     * mean of the square of all weighted residuals. This is related to the\n+     * criterion that is minimized by the estimator as follows: if\n+     * <em>c</em> if the criterion, and <em>n</em> is the number of\n+     * measurements, then the RMS is <em>sqrt (c/n)</em>.\n+     * \n+     * @param problem estimation problem\n+     * @return RMS value\n+     */\n+    public double getRMS(EstimationProblem problem) {\n+        WeightedMeasurement[] wm = problem.getMeasurements();\n+        double criterion = 0;\n+        for (int i = 0; i < wm.length; ++i) {\n+            double residual = wm[i].getResidual();\n+            criterion += wm[i].getWeight() * residual * residual;\n+        }\n+        return Math.sqrt(criterion / wm.length);\n+    }\n+\n+    /**\n+     * Get the Chi-Square value.\n+     * @param problem estimation problem\n+     * @return chi-square value\n+     */\n+    public double getChiSquare(EstimationProblem problem) {\n+        WeightedMeasurement[] wm = problem.getMeasurements();\n+        double chiSquare = 0;\n+        for (int i = 0; i < wm.length; ++i) {\n+            double residual = wm[i].getResidual();\n+            chiSquare += residual * residual / wm[i].getWeight();\n+        }\n+        return chiSquare;\n+    }\n+\n+    /**\n+     * Get the covariance matrix of unbound estimated parameters.\n+     * @param problem estimation problem\n+     * @return covariance matrix\n+     * @exception OptimizationException if the covariance matrix\n+     * cannot be computed (singular problem)\n+     */\n+    public double[][] getCovariances(EstimationProblem problem)\n+      throws OptimizationException {\n+ \n+        // set up the jacobian\n+        updateJacobian();\n+\n+        // compute transpose(J).J, avoiding building big intermediate matrices\n+        final int rows = problem.getMeasurements().length;\n+        final int cols = problem.getUnboundParameters().length;\n+        final int max  = cols * rows;\n+        double[][] jTj = new double[cols][cols];\n+        for (int i = 0; i < cols; ++i) {\n+            for (int j = i; j < cols; ++j) {\n+                double sum = 0;\n+                for (int k = 0; k < max; k += cols) {\n+                    sum += jacobian[k + i] * jacobian[k + j];\n+                }\n+                jTj[i][j] = sum;\n+                jTj[j][i] = sum;\n+            }\n+        }\n+\n+        try {\n+            // compute the covariances matrix\n+            RealMatrix inverse =\n+                new LUDecompositionImpl(MatrixUtils.createRealMatrix(jTj)).getSolver().getInverse();\n+            return inverse.getData();\n+        } catch (InvalidMatrixException ime) {\n+            throw new OptimizationException(\"unable to compute covariances: singular problem\");\n+        }\n+\n+    }\n+\n+    /**\n+     * Guess the errors in unbound estimated parameters.\n+     * <p>Guessing is covariance-based, it only gives rough order of magnitude.</p>\n+     * @param problem estimation problem\n+     * @return errors in estimated parameters\n+     * @exception OptimizationException if the covariances matrix cannot be computed\n+     * or the number of degrees of freedom is not positive (number of measurements\n+     * lesser or equal to number of parameters)\n+     */\n+    public double[] guessParametersErrors(EstimationProblem problem)\n+      throws OptimizationException {\n+        int m = problem.getMeasurements().length;\n+        int p = problem.getUnboundParameters().length;\n+        if (m <= p) {\n+            throw new OptimizationException(\n+                    \"no degrees of freedom ({0} measurements, {1} parameters)\",\n+                    m, p);\n+        }\n+        double[] errors = new double[problem.getUnboundParameters().length];\n+        final double c = Math.sqrt(getChiSquare(problem) / (m - p));\n+        double[][] covar = getCovariances(problem);\n+        for (int i = 0; i < errors.length; ++i) {\n+            errors[i] = Math.sqrt(covar[i][i]) * c;\n+        }\n+        return errors;\n+    }\n+\n+    /**\n+     * Initialization of the common parts of the estimation.\n+     * <p>This method <em>must</em> be called at the start\n+     * of the {@link #estimate(EstimationProblem) estimate}\n+     * method.</p>\n+     * @param problem estimation problem to solve\n+     */\n+    protected void initializeEstimate(EstimationProblem problem) {\n+\n+        // reset counters\n+        costEvaluations     = 0;\n+        jacobianEvaluations = 0;\n+\n+        // retrieve the equations and the parameters\n+        measurements = problem.getMeasurements();\n+        parameters   = problem.getUnboundParameters();\n+\n+        // arrays shared with the other private methods\n+        rows      = measurements.length;\n+        cols      = parameters.length;\n+        jacobian  = new double[rows * cols];\n+        residuals = new double[rows];\n+\n+        cost = Double.POSITIVE_INFINITY;\n+\n+    }\n+\n+    /** \n+     * Solve an estimation problem.\n+     *\n+     * <p>The method should set the parameters of the problem to several\n+     * trial values until it reaches convergence. If this method returns\n+     * normally (i.e. without throwing an exception), then the best\n+     * estimate of the parameters can be retrieved from the problem\n+     * itself, through the {@link EstimationProblem#getAllParameters\n+     * EstimationProblem.getAllParameters} method.</p>\n+     *\n+     * @param problem estimation problem to solve\n+     * @exception OptimizationException if the problem cannot be solved\n+     *\n+     */\n+    public abstract void estimate(EstimationProblem problem)\n+    throws OptimizationException;\n+\n+    /** Array of measurements. */\n+    protected WeightedMeasurement[] measurements;\n+\n+    /** Array of parameters. */\n+    protected EstimatedParameter[] parameters;\n+\n+    /** \n+     * Jacobian matrix.\n+     * <p>This matrix is in canonical form just after the calls to\n+     * {@link #updateJacobian()}, but may be modified by the solver\n+     * in the derived class (the {@link LevenbergMarquardtEstimator\n+     * Levenberg-Marquardt estimator} does this).</p>\n+     */\n+    protected double[] jacobian;\n+\n+    /** Number of columns of the jacobian matrix. */\n+    protected int cols;\n+\n+    /** Number of rows of the jacobian matrix. */\n+    protected int rows;\n+\n+    /** Residuals array.\n+     * <p>This array is in canonical form just after the calls to\n+     * {@link #updateJacobian()}, but may be modified by the solver\n+     * in the derived class (the {@link LevenbergMarquardtEstimator\n+     * Levenberg-Marquardt estimator} does this).</p>\n+     */\n+    protected double[] residuals;\n+\n+    /** Cost value (square root of the sum of the residuals). */\n+    protected double cost;\n+\n+    /** Maximal allowed number of cost evaluations. */\n+    private int maxCostEval;\n+\n+    /** Number of cost evaluations. */\n+    private int costEvaluations;\n+\n+    /** Number of jacobian evaluations. */\n+    private int jacobianEvaluations;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/EstimatedParameter.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.io.Serializable;\n+\n+/** This class represents the estimated parameters of an estimation problem.\n+ *\n+ * <p>The parameters of an estimation problem have a name, a value and\n+ * a bound flag. The value of bound parameters is considered trusted\n+ * and the solvers should not adjust them. On the other hand, the\n+ * solvers should adjust the value of unbounds parameters until they\n+ * satisfy convergence criterions specific to each solver.</p>\n+ *\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+\n+public class EstimatedParameter\n+  implements Serializable {\n+\n+  /** Simple constructor.\n+   * Build an instance from a first estimate of the parameter,\n+   * initially considered unbound.\n+   * @param name name of the parameter\n+   * @param firstEstimate first estimate of the parameter\n+   */\n+  public EstimatedParameter(String name, double firstEstimate) {\n+    this.name = name;\n+    estimate  = firstEstimate;\n+    bound     = false;\n+  }\n+\n+  /** Simple constructor.\n+   * Build an instance from a first estimate of the parameter and a\n+   * bound flag\n+   * @param name name of the parameter\n+   * @param firstEstimate first estimate of the parameter\n+   * @param bound flag, should be true if the parameter is bound\n+   */\n+  public EstimatedParameter(String name,\n+                            double firstEstimate,\n+                            boolean bound) {\n+    this.name  = name;\n+    estimate   = firstEstimate;\n+    this.bound = bound;\n+  }\n+\n+  /** Copy constructor.\n+   * Build a copy of a parameter\n+   * @param parameter instance to copy\n+   */\n+  public EstimatedParameter(EstimatedParameter parameter) {\n+    name     = parameter.name;\n+    estimate = parameter.estimate;\n+    bound    = parameter.bound;\n+  }\n+\n+  /** Set a new estimated value for the parameter.\n+   * @param estimate new estimate for the parameter\n+   */\n+  public void setEstimate(double estimate) {\n+    this.estimate = estimate;\n+  }\n+\n+  /** Get the current estimate of the parameter\n+   * @return current estimate\n+   */\n+  public double getEstimate() {\n+    return estimate;\n+  }\n+\n+  /** get the name of the parameter\n+   * @return parameter name\n+   */\n+  public String getName() {\n+    return name;\n+  }\n+\n+  /** Set the bound flag of the parameter\n+   * @param bound this flag should be set to true if the parameter is\n+   * bound (i.e. if it should not be adjusted by the solver).\n+   */\n+  public void setBound(boolean bound) {\n+    this.bound = bound;\n+  }\n+\n+  /** Check if the parameter is bound\n+   * @return true if the parameter is bound */\n+  public boolean isBound() {\n+    return bound;\n+  }\n+\n+  /** Name of the parameter */\n+  private   String  name;\n+\n+  /** Current value of the parameter */\n+  protected double  estimate;\n+\n+  /** Indicator for bound parameters\n+   * (ie parameters that should not be estimated)\n+   */\n+  private   boolean bound;\n+\n+  /** Serializable version identifier */\n+  private static final long serialVersionUID = -555440800213416949L;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/EstimationProblem.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+/** \n+ * This interface represents an estimation problem.\n+ *\n+ * <p>This interface should be implemented by all real estimation\n+ * problems before they can be handled by the estimators through the\n+ * {@link Estimator#estimate Estimator.estimate} method.</p>\n+ *\n+ * <p>An estimation problem, as seen by a solver is a set of\n+ * parameters and a set of measurements. The parameters are adjusted\n+ * during the estimation through the {@link #getUnboundParameters\n+ * getUnboundParameters} and {@link EstimatedParameter#setEstimate\n+ * EstimatedParameter.setEstimate} methods. The measurements both have\n+ * a measured value which is generally fixed at construction and a\n+ * theoretical value which depends on the model and hence varies as\n+ * the parameters are adjusted. The purpose of the solver is to reduce\n+ * the residual between these values, it can retrieve the measurements\n+ * through the {@link #getMeasurements getMeasurements} method.</p>\n+ *\n+ * @see Estimator\n+ * @see WeightedMeasurement\n+ *\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+\n+public interface EstimationProblem {\n+  /** \n+   * Get the measurements of an estimation problem.\n+   * @return measurements\n+   */\n+  WeightedMeasurement[] getMeasurements();\n+\n+  /** \n+   * Get the unbound parameters of the problem.\n+   * @return unbound parameters\n+   */\n+  EstimatedParameter[] getUnboundParameters();\n+\n+  /** \n+   * Get all the parameters of the problem.\n+   * @return parameters\n+   */\n+  EstimatedParameter[] getAllParameters();\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/Estimator.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import org.apache.commons.math.optimization.OptimizationException;\n+\n+/**\n+ * This interface represents solvers for estimation problems.\n+ *\n+ * <p>The classes which are devoted to solve estimation problems\n+ * should implement this interface. The problems which can be handled\n+ * should implement the {@link EstimationProblem} interface which\n+ * gather all the information needed by the solver.</p>\n+ *\n+ * <p>The interface is composed only of the {@link #estimate estimate}\n+ * method.</p>\n+ *\n+ * @see EstimationProblem\n+ *\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+\n+public interface Estimator {\n+\n+  /** \n+   * Solve an estimation problem.\n+   *\n+   * <p>The method should set the parameters of the problem to several\n+   * trial values until it reaches convergence. If this method returns\n+   * normally (i.e. without throwing an exception), then the best\n+   * estimate of the parameters can be retrieved from the problem\n+   * itself, through the {@link EstimationProblem#getAllParameters\n+   * EstimationProblem.getAllParameters} method.</p>\n+   *\n+   * @param problem estimation problem to solve\n+   * @exception OptimizationException if the problem cannot be solved\n+   *\n+   */\n+  void estimate(EstimationProblem problem)\n+    throws OptimizationException;\n+\n+  /** \n+   * Get the Root Mean Square value.\n+   * Get the Root Mean Square value, i.e. the root of the arithmetic\n+   * mean of the square of all weighted residuals. This is related to the\n+   * criterion that is minimized by the estimator as follows: if\n+   * <em>c</em> is the criterion, and <em>n</em> is the number of\n+   * measurements, then the RMS is <em>sqrt (c/n)</em>.\n+   * @see #guessParametersErrors(EstimationProblem)\n+   * \n+   * @param problem estimation problem\n+   * @return RMS value\n+   */\n+  double getRMS(EstimationProblem problem);\n+\n+  /**\n+   * Get the covariance matrix of estimated parameters.\n+   * @param problem estimation problem\n+   * @return covariance matrix\n+   * @exception OptimizationException if the covariance matrix\n+   * cannot be computed (singular problem)\n+   */\n+  double[][] getCovariances(EstimationProblem problem)\n+    throws OptimizationException;\n+\n+  /**\n+   * Guess the errors in estimated parameters.\n+   * @see #getRMS(EstimationProblem)\n+   * @param problem estimation problem\n+   * @return errors in estimated parameters\n+     * @exception OptimizationException if the error cannot be guessed\n+   */\n+  double[] guessParametersErrors(EstimationProblem problem)\n+    throws OptimizationException;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/GaussNewtonEstimator.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.io.Serializable;\n+\n+import org.apache.commons.math.linear.InvalidMatrixException;\n+import org.apache.commons.math.linear.MatrixUtils;\n+import org.apache.commons.math.linear.RealMatrix;\n+import org.apache.commons.math.linear.RealVector;\n+import org.apache.commons.math.linear.RealVectorImpl;\n+import org.apache.commons.math.linear.decomposition.LUDecompositionImpl;\n+import org.apache.commons.math.optimization.OptimizationException;\n+\n+/** \n+ * This class implements a solver for estimation problems.\n+ *\n+ * <p>This class solves estimation problems using a weighted least\n+ * squares criterion on the measurement residuals. It uses a\n+ * Gauss-Newton algorithm.</p>\n+ *\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+\n+public class GaussNewtonEstimator extends AbstractEstimator implements Serializable {\n+\n+    /** Serializable version identifier */\n+    private static final long serialVersionUID = 5485001826076289109L;\n+\n+    /** Default threshold for cost steady state detection. */\n+    private static final double DEFAULT_STEADY_STATE_THRESHOLD = 1.0e-6;\n+\n+    /** Default threshold for cost convergence. */\n+    private static final double DEFAULT_CONVERGENCE = 1.0e-6;\n+\n+    /** Threshold for cost steady state detection. */\n+    private double steadyStateThreshold;\n+\n+    /** Threshold for cost convergence. */\n+    private double convergence;\n+\n+    /** Simple constructor with default settings.\n+     * <p>\n+     * The estimator is built with default values for all settings.\n+     * </p>\n+     * @see #DEFAULT_STEADY_STATE_THRESHOLD\n+     * @see #DEFAULT_CONVERGENCE\n+     * @see AbstractEstimator#DEFAULT_MAX_COST_EVALUATIONS\n+     */\n+    public GaussNewtonEstimator() {\n+        this.steadyStateThreshold = DEFAULT_STEADY_STATE_THRESHOLD;\n+        this.convergence          = DEFAULT_CONVERGENCE;        \n+    }\n+\n+    /** \n+     * Simple constructor.\n+     *\n+     * <p>This constructor builds an estimator and stores its convergence\n+     * characteristics.</p>\n+     *\n+     * <p>An estimator is considered to have converged whenever either\n+     * the criterion goes below a physical threshold under which\n+     * improvements are considered useless or when the algorithm is\n+     * unable to improve it (even if it is still high). The first\n+     * condition that is met stops the iterations.</p>\n+     *\n+     * <p>The fact an estimator has converged does not mean that the\n+     * model accurately fits the measurements. It only means no better\n+     * solution can be found, it does not mean this one is good. Such an\n+     * analysis is left to the caller.</p>\n+     *\n+     * <p>If neither conditions are fulfilled before a given number of\n+     * iterations, the algorithm is considered to have failed and an\n+     * {@link OptimizationException} is thrown.</p>\n+     *\n+     * @param maxCostEval maximal number of cost evaluations allowed\n+     * @param convergence criterion threshold below which we do not need\n+     * to improve the criterion anymore\n+     * @param steadyStateThreshold steady state detection threshold, the\n+     * problem has converged has reached a steady state if\n+     * <code>Math.abs(J<sub>n</sub> - J<sub>n-1</sub>) &lt;\n+     * J<sub>n</sub> &times convergence</code>, where <code>J<sub>n</sub></code>\n+     * and <code>J<sub>n-1</sub></code> are the current and preceding criterion\n+     * values (square sum of the weighted residuals of considered measurements).\n+     */\n+    public GaussNewtonEstimator(final int maxCostEval, final double convergence,\n+                                final double steadyStateThreshold) {\n+        setMaxCostEval(maxCostEval);\n+        this.steadyStateThreshold = steadyStateThreshold;\n+        this.convergence          = convergence;\n+    }\n+\n+    /**\n+     * Set the convergence criterion threshold.\n+     * @param convergence criterion threshold below which we do not need\n+     * to improve the criterion anymore\n+     */\n+    public void setConvergence(final double convergence) {\n+        this.convergence = convergence;\n+    }\n+\n+    /**\n+     * Set the steady state detection threshold.\n+     * <p>\n+     * The problem has converged has reached a steady state if\n+     * <code>Math.abs(J<sub>n</sub> - J<sub>n-1</sub>) &lt;\n+     * J<sub>n</sub> &times convergence</code>, where <code>J<sub>n</sub></code>\n+     * and <code>J<sub>n-1</sub></code> are the current and preceding criterion\n+     * values (square sum of the weighted residuals of considered measurements).\n+     * </p>\n+     * @param steadyStateThreshold steady state detection threshold\n+     */\n+    public void setSteadyStateThreshold(final double steadyStateThreshold) {\n+        this.steadyStateThreshold = steadyStateThreshold;\n+    }\n+\n+    /** \n+     * Solve an estimation problem using a least squares criterion.\n+     *\n+     * <p>This method set the unbound parameters of the given problem\n+     * starting from their current values through several iterations. At\n+     * each step, the unbound parameters are changed in order to\n+     * minimize a weighted least square criterion based on the\n+     * measurements of the problem.</p>\n+     *\n+     * <p>The iterations are stopped either when the criterion goes\n+     * below a physical threshold under which improvement are considered\n+     * useless or when the algorithm is unable to improve it (even if it\n+     * is still high). The first condition that is met stops the\n+     * iterations. If the convergence it not reached before the maximum\n+     * number of iterations, an {@link OptimizationException} is\n+     * thrown.</p>\n+     *\n+     * @param problem estimation problem to solve\n+     * @exception OptimizationException if the problem cannot be solved\n+     *\n+     * @see EstimationProblem\n+     *\n+     */\n+    public void estimate(EstimationProblem problem)\n+    throws OptimizationException {\n+\n+        initializeEstimate(problem);\n+\n+        // work matrices\n+        double[] grad             = new double[parameters.length];\n+        RealVectorImpl bDecrement = new RealVectorImpl(parameters.length);\n+        double[] bDecrementData   = bDecrement.getDataRef();\n+        RealMatrix wGradGradT     = MatrixUtils.createRealMatrix(parameters.length, parameters.length);\n+\n+        // iterate until convergence is reached\n+        double previous = Double.POSITIVE_INFINITY;\n+        do {\n+\n+            // build the linear problem\n+            incrementJacobianEvaluationsCounter();\n+            RealVector b = new RealVectorImpl(parameters.length);\n+            RealMatrix a = MatrixUtils.createRealMatrix(parameters.length, parameters.length);\n+            for (int i = 0; i < measurements.length; ++i) {\n+                if (! measurements [i].isIgnored()) {\n+\n+                    double weight   = measurements[i].getWeight();\n+                    double residual = measurements[i].getResidual();\n+\n+                    // compute the normal equation\n+                    for (int j = 0; j < parameters.length; ++j) {\n+                        grad[j] = measurements[i].getPartial(parameters[j]);\n+                        bDecrementData[j] = weight * residual * grad[j];\n+                    }\n+\n+                    // build the contribution matrix for measurement i\n+                    for (int k = 0; k < parameters.length; ++k) {\n+                        double gk = grad[k];\n+                        for (int l = 0; l < parameters.length; ++l) {\n+                            wGradGradT.setEntry(k, l, weight * gk * grad[l]);\n+                        }\n+                    }\n+\n+                    // update the matrices\n+                    a = a.add(wGradGradT);\n+                    b = b.add(bDecrement);\n+\n+                }\n+            }\n+\n+            try {\n+\n+                // solve the linearized least squares problem\n+                RealVector dX = new LUDecompositionImpl(a).getSolver().solve(b);\n+\n+                // update the estimated parameters\n+                for (int i = 0; i < parameters.length; ++i) {\n+                    parameters[i].setEstimate(parameters[i].getEstimate() + dX.getEntry(i));\n+                }\n+\n+            } catch(InvalidMatrixException e) {\n+                throw new OptimizationException(\"unable to solve: singular problem\");\n+            }\n+\n+\n+            previous = cost;\n+            updateResidualsAndCost();\n+\n+        } while ((getCostEvaluations() < 2) ||\n+                 (Math.abs(previous - cost) > (cost * steadyStateThreshold) &&\n+                  (Math.abs(cost) > convergence)));\n+\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/LevenbergMarquardtEstimator.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math.optimization.general;\n+\n+import java.io.Serializable;\n+import java.util.Arrays;\n+\n+import org.apache.commons.math.optimization.OptimizationException;\n+\n+\n+/** \n+ * This class solves a least squares problem.\n+ *\n+ * <p>This implementation <em>should</em> work even for over-determined systems\n+ * (i.e. systems having more variables than equations). Over-determined systems\n+ * are solved by ignoring the variables which have the smallest impact according\n+ * to their jacobian column norm. Only the rank of the matrix and some loop bounds\n+ * are changed to implement this.</p>\n+ *\n+ * <p>The resolution engine is a simple translation of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/lmder.f\">lmder</a> routine with minor\n+ * changes. The changes include the over-determined resolution and the Q.R.\n+ * decomposition which has been rewritten following the algorithm described in the\n+ * P. Lascaux and R. Theodor book <i>Analyse num&eacute;rique matricielle\n+ * appliqu&eacute;e &agrave; l'art de l'ing&eacute;nieur</i>, Masson 1986. The\n+ * redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for convenience, it\n+ * is reproduced below.</p>\n+ *\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran)\n+ * @author Burton S. Garbow (original fortran)\n+ * @author Kenneth E. Hillstrom (original fortran)\n+ * @author Jorge J. More (original fortran)\n+\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+public class LevenbergMarquardtEstimator extends AbstractEstimator implements Serializable {\n+\n+  /** \n+   * Build an estimator for least squares problems.\n+   * <p>The default values for the algorithm settings are:\n+   *   <ul>\n+   *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n+   *    <li>{@link #setMaxCostEval maximal cost evaluations}: 1000</li>\n+   *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n+   *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n+   *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n+   *   </ul>\n+   * </p>\n+   */\n+  public LevenbergMarquardtEstimator() {\n+\n+    // set up the superclass with a default  max cost evaluations setting\n+    setMaxCostEval(1000);\n+\n+    // default values for the tuning parameters\n+    setInitialStepBoundFactor(100.0);\n+    setCostRelativeTolerance(1.0e-10);\n+    setParRelativeTolerance(1.0e-10);\n+    setOrthoTolerance(1.0e-10);\n+\n+  }\n+\n+  /** \n+   * Set the positive input variable used in determining the initial step bound.\n+   * This bound is set to the product of initialStepBoundFactor and the euclidean norm of diag*x if nonzero,\n+   * or else to initialStepBoundFactor itself. In most cases factor should lie\n+   * in the interval (0.1, 100.0). 100.0 is a generally recommended value\n+   * \n+   * @param initialStepBoundFactor initial step bound factor\n+   * @see #estimate\n+   */\n+  public void setInitialStepBoundFactor(double initialStepBoundFactor) {\n+    this.initialStepBoundFactor = initialStepBoundFactor;\n+  }\n+\n+  /** \n+   * Set the desired relative error in the sum of squares.\n+   * \n+   * @param costRelativeTolerance desired relative error in the sum of squares\n+   * @see #estimate\n+   */\n+  public void setCostRelativeTolerance(double costRelativeTolerance) {\n+    this.costRelativeTolerance = costRelativeTolerance;\n+  }\n+\n+  /** \n+   * Set the desired relative error in the approximate solution parameters.\n+   * \n+   * @param parRelativeTolerance desired relative error\n+   * in the approximate solution parameters\n+   * @see #estimate\n+   */\n+  public void setParRelativeTolerance(double parRelativeTolerance) {\n+    this.parRelativeTolerance = parRelativeTolerance;\n+  }\n+\n+  /** \n+   * Set the desired max cosine on the orthogonality.\n+   * \n+   * @param orthoTolerance desired max cosine on the orthogonality\n+   * between the function vector and the columns of the jacobian\n+   * @see #estimate\n+   */\n+  public void setOrthoTolerance(double orthoTolerance) {\n+    this.orthoTolerance = orthoTolerance;\n+  }\n+\n+  /** \n+   * Solve an estimation problem using the Levenberg-Marquardt algorithm.\n+   * <p>The algorithm used is a modified Levenberg-Marquardt one, based\n+   * on the MINPACK <a href=\"http://www.netlib.org/minpack/lmder.f\">lmder</a>\n+   * routine. The algorithm settings must have been set up before this method\n+   * is called with the {@link #setInitialStepBoundFactor},\n+   * {@link #setMaxCostEval}, {@link #setCostRelativeTolerance},\n+   * {@link #setParRelativeTolerance} and {@link #setOrthoTolerance} methods.\n+   * If these methods have not been called, the default values set up by the\n+   * {@link #LevenbergMarquardtEstimator() constructor} will be used.</p>\n+   * <p>The authors of the original fortran function are:</p>\n+   * <ul>\n+   *   <li>Argonne National Laboratory. MINPACK project. March 1980</li>\n+   *   <li>Burton  S. Garbow</li>\n+   *   <li>Kenneth E. Hillstrom</li>\n+   *   <li>Jorge   J. More</li>\n+   *   </ul>\n+   * <p>Luc Maisonobe did the Java translation.</p>\n+   * \n+   * @param problem estimation problem to solve\n+   * @exception OptimizationException if convergence cannot be\n+   * reached with the specified algorithm settings or if there are more variables\n+   * than equations\n+   * @see #setInitialStepBoundFactor\n+   * @see #setCostRelativeTolerance\n+   * @see #setParRelativeTolerance\n+   * @see #setOrthoTolerance\n+   */\n+  public void estimate(EstimationProblem problem)\n+    throws OptimizationException {\n+\n+    initializeEstimate(problem);\n+\n+    // arrays shared with the other private methods\n+    solvedCols  = Math.min(rows, cols);\n+    diagR       = new double[cols];\n+    jacNorm     = new double[cols];\n+    beta        = new double[cols];\n+    permutation = new int[cols];\n+    lmDir       = new double[cols];\n+\n+    // local variables\n+    double   delta   = 0, xNorm = 0;\n+    double[] diag    = new double[cols];\n+    double[] oldX    = new double[cols];\n+    double[] oldRes  = new double[rows];\n+    double[] work1   = new double[cols];\n+    double[] work2   = new double[cols];\n+    double[] work3   = new double[cols];\n+\n+    // evaluate the function at the starting point and calculate its norm\n+    updateResidualsAndCost();\n+    \n+    // outer loop\n+    lmPar = 0;\n+    boolean firstIteration = true;\n+    while (true) {\n+\n+      // compute the Q.R. decomposition of the jacobian matrix\n+      updateJacobian();\n+      qrDecomposition();\n+\n+      // compute Qt.res\n+      qTy(residuals);\n+\n+      // now we don't need Q anymore,\n+      // so let jacobian contain the R matrix with its diagonal elements\n+      for (int k = 0; k < solvedCols; ++k) {\n+        int pk = permutation[k];\n+        jacobian[k * cols + pk] = diagR[pk];\n+      }\n+\n+      if (firstIteration) {\n+\n+        // scale the variables according to the norms of the columns\n+        // of the initial jacobian\n+        xNorm = 0;\n+        for (int k = 0; k < cols; ++k) {\n+          double dk = jacNorm[k];\n+          if (dk == 0) {\n+            dk = 1.0;\n+          }\n+          double xk = dk * parameters[k].getEstimate();\n+          xNorm  += xk * xk;\n+          diag[k] = dk;\n+        }\n+        xNorm = Math.sqrt(xNorm);\n+        \n+        // initialize the step bound delta\n+        delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n+ \n+      }\n+\n+      // check orthogonality between function vector and jacobian columns\n+      double maxCosine = 0;\n+      if (cost != 0) {\n+        for (int j = 0; j < solvedCols; ++j) {\n+          int    pj = permutation[j];\n+          double s  = jacNorm[pj];\n+          if (s != 0) {\n+            double sum = 0;\n+            for (int i = 0, index = pj; i <= j; ++i, index += cols) {\n+              sum += jacobian[index] * residuals[i];\n+            }\n+            maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n+          }\n+        }\n+      }\n+      if (maxCosine <= orthoTolerance) {\n+        return;\n+      }\n+\n+      // rescale if necessary\n+      for (int j = 0; j < cols; ++j) {\n+        diag[j] = Math.max(diag[j], jacNorm[j]);\n+      }\n+\n+      // inner loop\n+      for (double ratio = 0; ratio < 1.0e-4;) {\n+\n+        // save the state\n+        for (int j = 0; j < solvedCols; ++j) {\n+          int pj = permutation[j];\n+          oldX[pj] = parameters[pj].getEstimate();\n+        }\n+        double previousCost = cost;\n+        double[] tmpVec = residuals;\n+        residuals = oldRes;\n+        oldRes    = tmpVec;\n+        \n+        // determine the Levenberg-Marquardt parameter\n+        determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n+\n+        // compute the new point and the norm of the evolution direction\n+        double lmNorm = 0;\n+        for (int j = 0; j < solvedCols; ++j) {\n+          int pj = permutation[j];\n+          lmDir[pj] = -lmDir[pj];\n+          parameters[pj].setEstimate(oldX[pj] + lmDir[pj]);\n+          double s = diag[pj] * lmDir[pj];\n+          lmNorm  += s * s;\n+        }\n+        lmNorm = Math.sqrt(lmNorm);\n+\n+        // on the first iteration, adjust the initial step bound.\n+        if (firstIteration) {\n+          delta = Math.min(delta, lmNorm);\n+        }\n+\n+        // evaluate the function at x + p and calculate its norm\n+        updateResidualsAndCost();\n+\n+        // compute the scaled actual reduction\n+        double actRed = -1.0;\n+        if (0.1 * cost < previousCost) {\n+          double r = cost / previousCost;\n+          actRed = 1.0 - r * r;\n+        }\n+\n+        // compute the scaled predicted reduction\n+        // and the scaled directional derivative\n+        for (int j = 0; j < solvedCols; ++j) {\n+          int pj = permutation[j];\n+          double dirJ = lmDir[pj];\n+          work1[j] = 0;\n+          for (int i = 0, index = pj; i <= j; ++i, index += cols) {\n+            work1[i] += jacobian[index] * dirJ;\n+          }\n+        }\n+        double coeff1 = 0;\n+        for (int j = 0; j < solvedCols; ++j) {\n+         coeff1 += work1[j] * work1[j];\n+        }\n+        double pc2 = previousCost * previousCost;\n+        coeff1 = coeff1 / pc2;\n+        double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n+        double preRed = coeff1 + 2 * coeff2;\n+        double dirDer = -(coeff1 + coeff2);\n+\n+        // ratio of the actual to the predicted reduction\n+        ratio = (preRed == 0) ? 0 : (actRed / preRed);\n+\n+        // update the step bound\n+        if (ratio <= 0.25) {\n+          double tmp =\n+            (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n+          if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n+            tmp = 0.1;\n+          }\n+          delta = tmp * Math.min(delta, 10.0 * lmNorm);\n+          lmPar /= tmp;\n+        } else if ((lmPar == 0) || (ratio >= 0.75)) {\n+          delta = 2 * lmNorm;\n+          lmPar *= 0.5;\n+        }\n+\n+        // test for successful iteration.\n+        if (ratio >= 1.0e-4) {\n+          // successful iteration, update the norm\n+          firstIteration = false;\n+          xNorm = 0;\n+          for (int k = 0; k < cols; ++k) {\n+            double xK = diag[k] * parameters[k].getEstimate();\n+            xNorm    += xK * xK;\n+          }\n+          xNorm = Math.sqrt(xNorm);\n+        } else {\n+          // failed iteration, reset the previous values\n+          cost = previousCost;\n+          for (int j = 0; j < solvedCols; ++j) {\n+            int pj = permutation[j];\n+            parameters[pj].setEstimate(oldX[pj]);\n+          }\n+          tmpVec    = residuals;\n+          residuals = oldRes;\n+          oldRes    = tmpVec;\n+        }\n+   \n+        // tests for convergence.\n+        if (((Math.abs(actRed) <= costRelativeTolerance) &&\n+             (preRed <= costRelativeTolerance) &&\n+             (ratio <= 2.0)) ||\n+             (delta <= parRelativeTolerance * xNorm)) {\n+          return;\n+        }\n+\n+        // tests for termination and stringent tolerances\n+        // (2.2204e-16 is the machine epsilon for IEEE754)\n+        if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n+          throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n+                                        \" no further reduction in the\" +\n+                                        \" sum of squares is possible\",\n+                                        costRelativeTolerance);\n+        } else if (delta <= 2.2204e-16 * xNorm) {\n+          throw new OptimizationException(\"parameters relative tolerance is too small\" +\n+                                        \" ({0}), no further improvement in\" +\n+                                        \" the approximate solution is possible\",\n+                                        parRelativeTolerance);\n+        } else if (maxCosine <= 2.2204e-16)  {\n+          throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n+                                        \" solution is orthogonal to the jacobian\",\n+                                        orthoTolerance);\n+        }\n+\n+      }\n+\n+    }\n+\n+  }\n+\n+  /** \n+   * Determine the Levenberg-Marquardt parameter.\n+   * <p>This implementation is a translation in Java of the MINPACK\n+   * <a href=\"http://www.netlib.org/minpack/lmpar.f\">lmpar</a>\n+   * routine.</p>\n+   * <p>This method sets the lmPar and lmDir attributes.</p>\n+   * <p>The authors of the original fortran function are:</p>\n+   * <ul>\n+   *   <li>Argonne National Laboratory. MINPACK project. March 1980</li>\n+   *   <li>Burton  S. Garbow</li>\n+   *   <li>Kenneth E. Hillstrom</li>\n+   *   <li>Jorge   J. More</li>\n+   * </ul>\n+   * <p>Luc Maisonobe did the Java translation.</p>\n+   * \n+   * @param qy array containing qTy\n+   * @param delta upper bound on the euclidean norm of diagR * lmDir\n+   * @param diag diagonal matrix\n+   * @param work1 work array\n+   * @param work2 work array\n+   * @param work3 work array\n+   */\n+  private void determineLMParameter(double[] qy, double delta, double[] diag,\n+                                    double[] work1, double[] work2, double[] work3) {\n+\n+    // compute and store in x the gauss-newton direction, if the\n+    // jacobian is rank-deficient, obtain a least squares solution\n+    for (int j = 0; j < rank; ++j) {\n+      lmDir[permutation[j]] = qy[j];\n+    }\n+    for (int j = rank; j < cols; ++j) {\n+      lmDir[permutation[j]] = 0;\n+    }\n+    for (int k = rank - 1; k >= 0; --k) {\n+      int pk = permutation[k];\n+      double ypk = lmDir[pk] / diagR[pk];\n+      for (int i = 0, index = pk; i < k; ++i, index += cols) {\n+        lmDir[permutation[i]] -= ypk * jacobian[index];\n+      }\n+      lmDir[pk] = ypk;\n+    }\n+\n+    // evaluate the function at the origin, and test\n+    // for acceptance of the Gauss-Newton direction\n+    double dxNorm = 0;\n+    for (int j = 0; j < solvedCols; ++j) {\n+      int pj = permutation[j];\n+      double s = diag[pj] * lmDir[pj];\n+      work1[pj] = s;\n+      dxNorm += s * s;\n+    }\n+    dxNorm = Math.sqrt(dxNorm);\n+    double fp = dxNorm - delta;\n+    if (fp <= 0.1 * delta) {\n+      lmPar = 0;\n+      return;\n+    }\n+\n+    // if the jacobian is not rank deficient, the Newton step provides\n+    // a lower bound, parl, for the zero of the function,\n+    // otherwise set this bound to zero\n+    double sum2, parl = 0;\n+    if (rank == solvedCols) {\n+      for (int j = 0; j < solvedCols; ++j) {\n+        int pj = permutation[j];\n+        work1[pj] *= diag[pj] / dxNorm; \n+      }\n+      sum2 = 0;\n+      for (int j = 0; j < solvedCols; ++j) {\n+        int pj = permutation[j];\n+        double sum = 0;\n+        for (int i = 0, index = pj; i < j; ++i, index += cols) {\n+          sum += jacobian[index] * work1[permutation[i]];\n+        }\n+        double s = (work1[pj] - sum) / diagR[pj];\n+        work1[pj] = s;\n+        sum2 += s * s;\n+      }\n+      parl = fp / (delta * sum2);\n+    }\n+\n+    // calculate an upper bound, paru, for the zero of the function\n+    sum2 = 0;\n+    for (int j = 0; j < solvedCols; ++j) {\n+      int pj = permutation[j];\n+      double sum = 0;\n+      for (int i = 0, index = pj; i <= j; ++i, index += cols) {\n+        sum += jacobian[index] * qy[i];\n+      }\n+      sum /= diag[pj];\n+      sum2 += sum * sum;\n+    }\n+    double gNorm = Math.sqrt(sum2);\n+    double paru = gNorm / delta;\n+    if (paru == 0) {\n+      // 2.2251e-308 is the smallest positive real for IEE754\n+      paru = 2.2251e-308 / Math.min(delta, 0.1);\n+    }\n+\n+    // if the input par lies outside of the interval (parl,paru),\n+    // set par to the closer endpoint\n+    lmPar = Math.min(paru, Math.max(lmPar, parl));\n+    if (lmPar == 0) {\n+      lmPar = gNorm / dxNorm;\n+    }\n+\n+    for (int countdown = 10; countdown >= 0; --countdown) {\n+\n+      // evaluate the function at the current value of lmPar\n+      if (lmPar == 0) {\n+        lmPar = Math.max(2.2251e-308, 0.001 * paru);\n+      }\n+      double sPar = Math.sqrt(lmPar);\n+      for (int j = 0; j < solvedCols; ++j) {\n+        int pj = permutation[j];\n+        work1[pj] = sPar * diag[pj];\n+      }\n+      determineLMDirection(qy, work1, work2, work3);\n+\n+      dxNorm = 0;\n+      for (int j = 0; j < solvedCols; ++j) {\n+        int pj = permutation[j];\n+        double s = diag[pj] * lmDir[pj];\n+        work3[pj] = s;\n+        dxNorm += s * s;\n+      }\n+      dxNorm = Math.sqrt(dxNorm);\n+      double previousFP = fp;\n+      fp = dxNorm - delta;\n+\n+      // if the function is small enough, accept the current value\n+      // of lmPar, also test for the exceptional cases where parl is zero\n+      if ((Math.abs(fp) <= 0.1 * delta) ||\n+          ((parl == 0) && (fp <= previousFP) && (previousFP < 0))) {\n+        return;\n+      }\n+ \n+      // compute the Newton correction\n+      for (int j = 0; j < solvedCols; ++j) {\n+       int pj = permutation[j];\n+        work1[pj] = work3[pj] * diag[pj] / dxNorm; \n+      }\n+      for (int j = 0; j < solvedCols; ++j) {\n+        int pj = permutation[j];\n+        work1[pj] /= work2[j];\n+        double tmp = work1[pj];\n+        for (int i = j + 1; i < solvedCols; ++i) {\n+          work1[permutation[i]] -= jacobian[i * cols + pj] * tmp;\n+        }\n+      }\n+      sum2 = 0;\n+      for (int j = 0; j < solvedCols; ++j) {\n+        double s = work1[permutation[j]];\n+        sum2 += s * s;\n+      }\n+      double correction = fp / (delta * sum2);\n+\n+      // depending on the sign of the function, update parl or paru.\n+      if (fp > 0) {\n+        parl = Math.max(parl, lmPar);\n+      } else if (fp < 0) {\n+        paru = Math.min(paru, lmPar);\n+      }\n+\n+      // compute an improved estimate for lmPar\n+      lmPar = Math.max(parl, lmPar + correction);\n+\n+    }\n+  }\n+\n+  /** \n+   * Solve a*x = b and d*x = 0 in the least squares sense.\n+   * <p>This implementation is a translation in Java of the MINPACK\n+   * <a href=\"http://www.netlib.org/minpack/qrsolv.f\">qrsolv</a>\n+   * routine.</p>\n+   * <p>This method sets the lmDir and lmDiag attributes.</p>\n+   * <p>The authors of the original fortran function are:</p>\n+   * <ul>\n+   *   <li>Argonne National Laboratory. MINPACK project. March 1980</li>\n+   *   <li>Burton  S. Garbow</li>\n+   *   <li>Kenneth E. Hillstrom</li>\n+   *   <li>Jorge   J. More</li>\n+   * </ul>\n+   * <p>Luc Maisonobe did the Java translation.</p>\n+   * \n+   * @param qy array containing qTy\n+   * @param diag diagonal matrix\n+   * @param lmDiag diagonal elements associated with lmDir\n+   * @param work work array\n+   */\n+  private void determineLMDirection(double[] qy, double[] diag,\n+                                    double[] lmDiag, double[] work) {\n+\n+    // copy R and Qty to preserve input and initialize s\n+    //  in particular, save the diagonal elements of R in lmDir\n+    for (int j = 0; j < solvedCols; ++j) {\n+      int pj = permutation[j];\n+      for (int i = j + 1; i < solvedCols; ++i) {\n+        jacobian[i * cols + pj] = jacobian[j * cols + permutation[i]];\n+      }\n+      lmDir[j] = diagR[pj];\n+      work[j]  = qy[j];\n+    }\n+\n+    // eliminate the diagonal matrix d using a Givens rotation\n+    for (int j = 0; j < solvedCols; ++j) {\n+\n+      // prepare the row of d to be eliminated, locating the\n+      // diagonal element using p from the Q.R. factorization\n+      int pj = permutation[j];\n+      double dpj = diag[pj];\n+      if (dpj != 0) {\n+        Arrays.fill(lmDiag, j + 1, lmDiag.length, 0);\n+      }\n+      lmDiag[j] = dpj;\n+\n+      //  the transformations to eliminate the row of d\n+      // modify only a single element of Qty\n+      // beyond the first n, which is initially zero.\n+      double qtbpj = 0;\n+      for (int k = j; k < solvedCols; ++k) {\n+        int pk = permutation[k];\n+\n+        // determine a Givens rotation which eliminates the\n+        // appropriate element in the current row of d\n+        if (lmDiag[k] != 0) {\n+\n+          double sin, cos;\n+          double rkk = jacobian[k * cols + pk];\n+          if (Math.abs(rkk) < Math.abs(lmDiag[k])) {\n+            double cotan = rkk / lmDiag[k];\n+            sin   = 1.0 / Math.sqrt(1.0 + cotan * cotan);\n+            cos   = sin * cotan;\n+          } else {\n+            double tan = lmDiag[k] / rkk;\n+            cos = 1.0 / Math.sqrt(1.0 + tan * tan);\n+            sin = cos * tan;\n+          }\n+\n+          // compute the modified diagonal element of R and\n+          // the modified element of (Qty,0)\n+          jacobian[k * cols + pk] = cos * rkk + sin * lmDiag[k];\n+          double temp = cos * work[k] + sin * qtbpj;\n+          qtbpj = -sin * work[k] + cos * qtbpj;\n+          work[k] = temp;\n+\n+          // accumulate the tranformation in the row of s\n+          for (int i = k + 1; i < solvedCols; ++i) {\n+            double rik = jacobian[i * cols + pk];\n+            temp = cos * rik + sin * lmDiag[i];\n+            lmDiag[i] = -sin * rik + cos * lmDiag[i];\n+            jacobian[i * cols + pk] = temp;\n+          }\n+\n+        }\n+      }\n+\n+      // store the diagonal element of s and restore\n+      // the corresponding diagonal element of R\n+      int index = j * cols + permutation[j];\n+      lmDiag[j]       = jacobian[index];\n+      jacobian[index] = lmDir[j];\n+\n+    }\n+\n+    // solve the triangular system for z, if the system is\n+    // singular, then obtain a least squares solution\n+    int nSing = solvedCols;\n+    for (int j = 0; j < solvedCols; ++j) {\n+      if ((lmDiag[j] == 0) && (nSing == solvedCols)) {\n+        nSing = j;\n+      }\n+      if (nSing < solvedCols) {\n+        work[j] = 0;\n+      }\n+    }\n+    if (nSing > 0) {\n+      for (int j = nSing - 1; j >= 0; --j) {\n+        int pj = permutation[j];\n+        double sum = 0;\n+        for (int i = j + 1; i < nSing; ++i) {\n+          sum += jacobian[i * cols + pj] * work[i];\n+        }\n+        work[j] = (work[j] - sum) / lmDiag[j];\n+      }\n+    }\n+\n+    // permute the components of z back to components of lmDir\n+    for (int j = 0; j < lmDir.length; ++j) {\n+      lmDir[permutation[j]] = work[j];\n+    }\n+\n+  }\n+\n+  /** \n+   * Decompose a matrix A as A.P = Q.R using Householder transforms.\n+   * <p>As suggested in the P. Lascaux and R. Theodor book\n+   * <i>Analyse num&eacute;rique matricielle appliqu&eacute;e &agrave;\n+   * l'art de l'ing&eacute;nieur</i> (Masson, 1986), instead of representing\n+   * the Householder transforms with u<sub>k</sub> unit vectors such that:\n+   * <pre>\n+   * H<sub>k</sub> = I - 2u<sub>k</sub>.u<sub>k</sub><sup>t</sup>\n+   * </pre>\n+   * we use <sub>k</sub> non-unit vectors such that:\n+   * <pre>\n+   * H<sub>k</sub> = I - beta<sub>k</sub>v<sub>k</sub>.v<sub>k</sub><sup>t</sup>\n+   * </pre>\n+   * where v<sub>k</sub> = a<sub>k</sub> - alpha<sub>k</sub> e<sub>k</sub>.\n+   * The beta<sub>k</sub> coefficients are provided upon exit as recomputing\n+   * them from the v<sub>k</sub> vectors would be costly.</p>\n+   * <p>This decomposition handles rank deficient cases since the tranformations\n+   * are performed in non-increasing columns norms order thanks to columns\n+   * pivoting. The diagonal elements of the R matrix are therefore also in\n+   * non-increasing absolute values order.</p>\n+   * @exception OptimizationException if the decomposition cannot be performed\n+   */\n+  private void qrDecomposition() throws OptimizationException {\n+\n+    // initializations\n+    for (int k = 0; k < cols; ++k) {\n+      permutation[k] = k;\n+      double norm2 = 0;\n+      for (int index = k; index < jacobian.length; index += cols) {\n+        double akk = jacobian[index];\n+        norm2 += akk * akk;\n+      }\n+      jacNorm[k] = Math.sqrt(norm2);\n+    }\n+\n+    // transform the matrix column after column\n+    for (int k = 0; k < cols; ++k) {\n+\n+      // select the column with the greatest norm on active components\n+      int nextColumn = -1;\n+      double ak2 = Double.NEGATIVE_INFINITY;\n+      for (int i = k; i < cols; ++i) {\n+        double norm2 = 0;\n+        int iDiag = k * cols + permutation[i];\n+        for (int index = iDiag; index < jacobian.length; index += cols) {\n+          double aki = jacobian[index];\n+          norm2 += aki * aki;\n+        }\n+        if (Double.isInfinite(norm2) || Double.isNaN(norm2)) {\n+            throw new OptimizationException(\n+                    \"unable to perform Q.R decomposition on the {0}x{1} jacobian matrix\",\n+                    rows, cols);\n+        }\n+        if (norm2 > ak2) {\n+          nextColumn = i;\n+          ak2        = norm2;\n+        }\n+      }\n+      if (ak2 == 0) {\n+        rank = k;\n+        return;\n+      }\n+      int pk                  = permutation[nextColumn];\n+      permutation[nextColumn] = permutation[k];\n+      permutation[k]          = pk;\n+\n+      // choose alpha such that Hk.u = alpha ek\n+      int    kDiag = k * cols + pk;\n+      double akk   = jacobian[kDiag];\n+      double alpha = (akk > 0) ? -Math.sqrt(ak2) : Math.sqrt(ak2);\n+      double betak = 1.0 / (ak2 - akk * alpha);\n+      beta[pk]     = betak;\n+\n+      // transform the current column\n+      diagR[pk]        = alpha;\n+      jacobian[kDiag] -= alpha;\n+\n+      // transform the remaining columns\n+      for (int dk = cols - 1 - k; dk > 0; --dk) {\n+        int dkp = permutation[k + dk] - pk;\n+        double gamma = 0;\n+        for (int index = kDiag; index < jacobian.length; index += cols) {\n+          gamma += jacobian[index] * jacobian[index + dkp];\n+        }\n+        gamma *= betak;\n+        for (int index = kDiag; index < jacobian.length; index += cols) {\n+          jacobian[index + dkp] -= gamma * jacobian[index];\n+        }\n+      }\n+\n+    }\n+\n+    rank = solvedCols;\n+\n+  }\n+\n+  /** \n+   * Compute the product Qt.y for some Q.R. decomposition.\n+   * \n+   * @param y vector to multiply (will be overwritten with the result)\n+   */\n+  private void qTy(double[] y) {\n+    for (int k = 0; k < cols; ++k) {\n+      int pk = permutation[k];\n+      int kDiag = k * cols + pk;\n+      double gamma = 0;\n+      for (int i = k, index = kDiag; i < rows; ++i, index += cols) {\n+        gamma += jacobian[index] * y[i];\n+      }\n+      gamma *= beta[pk];\n+      for (int i = k, index = kDiag; i < rows; ++i, index += cols) {\n+        y[i] -= gamma * jacobian[index];\n+      }\n+    }\n+  }\n+\n+  /** Number of solved variables. */\n+  private int solvedCols;\n+\n+  /** Diagonal elements of the R matrix in the Q.R. decomposition. */\n+  private double[] diagR;\n+\n+  /** Norms of the columns of the jacobian matrix. */\n+  private double[] jacNorm;\n+\n+  /** Coefficients of the Householder transforms vectors. */\n+  private double[] beta;\n+\n+  /** Columns permutation array. */\n+  private int[] permutation;\n+\n+  /** Rank of the jacobian matrix. */\n+  private int rank;\n+\n+  /** Levenberg-Marquardt parameter. */\n+  private double lmPar;\n+\n+  /** Parameters evolution direction associated with lmPar. */\n+  private double[] lmDir;\n+\n+  /** Positive input variable used in determining the initial step bound. */\n+  private double initialStepBoundFactor;\n+\n+  /** Desired relative error in the sum of squares. */\n+  private double costRelativeTolerance;\n+\n+  /**  Desired relative error in the approximate solution parameters. */\n+  private double parRelativeTolerance;\n+\n+  /** Desired max cosine on the orthogonality between the function vector\n+   * and the columns of the jacobian. */\n+  private double orthoTolerance;\n+\n+  /** Serializable version identifier */\n+  private static final long serialVersionUID = -5705952631533171019L;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/SimpleEstimationProblem.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Simple implementation of the {@link EstimationProblem\n+ * EstimationProblem} interface for boilerplate data handling.\n+ * <p>This class <em>only</em> handles parameters and measurements\n+ * storage and unbound parameters filtering. It does not compute\n+ * anything by itself. It should either be used with measurements\n+ * implementation that are smart enough to know about the\n+ * various parameters in order to compute the partial derivatives\n+ * appropriately. Since the problem-specific logic is mainly related to\n+ * the various measurements models, the simplest way to use this class\n+ * is by extending it and using one internal class extending\n+ * {@link WeightedMeasurement WeightedMeasurement} for each measurement\n+ * type. The instances of the internal classes would have access to the\n+ * various parameters and their current estimate.</p>\n+\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+\n+ */\n+public class SimpleEstimationProblem implements EstimationProblem {\n+\n+    /**\n+     * Build an empty instance without parameters nor measurements.\n+     */\n+    public SimpleEstimationProblem() {\n+        parameters   = new ArrayList<EstimatedParameter>();\n+        measurements = new ArrayList<WeightedMeasurement>();\n+    }\n+\n+    /** \n+     * Get all the parameters of the problem.\n+     * @return parameters\n+     */\n+    public EstimatedParameter[] getAllParameters() {\n+        return (EstimatedParameter[]) parameters.toArray(new EstimatedParameter[parameters.size()]);\n+    }\n+\n+    /** \n+     * Get the unbound parameters of the problem.\n+     * @return unbound parameters\n+     */\n+    public EstimatedParameter[] getUnboundParameters() {\n+\n+        // filter the unbound parameters\n+        List<EstimatedParameter> unbound = new ArrayList<EstimatedParameter>(parameters.size());\n+        for (EstimatedParameter p : parameters) {\n+            if (! p.isBound()) {\n+                unbound.add(p);\n+            }\n+        }\n+\n+        // convert to an array\n+        return (EstimatedParameter[]) unbound.toArray(new EstimatedParameter[unbound.size()]);\n+        \n+    }\n+\n+    /** \n+     * Get the measurements of an estimation problem.\n+     * @return measurements\n+     */\n+    public WeightedMeasurement[] getMeasurements() {\n+        return (WeightedMeasurement[]) measurements.toArray(new WeightedMeasurement[measurements.size()]);\n+    }\n+\n+    /** Add a parameter to the problem.\n+     * @param p parameter to add\n+     */\n+    protected void addParameter(EstimatedParameter p) {\n+        parameters.add(p);\n+    }\n+\n+    /**\n+     * Add a new measurement to the set.\n+     * @param m measurement to add\n+     */\n+    protected void addMeasurement(WeightedMeasurement m) {\n+        measurements.add(m);\n+    }\n+\n+    /** Estimated parameters. */\n+    private final List<EstimatedParameter> parameters;\n+\n+    /** Measurements. */\n+    private final List<WeightedMeasurement> measurements;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/WeightedMeasurement.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.io.Serializable;\n+\n+/** \n+ * This class represents measurements in estimation problems.\n+ *\n+ * <p>This abstract class implements all the methods needed to handle\n+ * measurements in a general way. It defines neither the {@link\n+ * #getTheoreticalValue getTheoreticalValue} nor the {@link\n+ * #getPartial getPartial} methods, which should be defined by\n+ * sub-classes according to the specific problem.</p>\n+ *\n+ * <p>The {@link #getTheoreticalValue getTheoreticalValue} and {@link\n+ * #getPartial getPartial} methods must always use the current\n+ * estimate of the parameters set by the solver in the problem. These\n+ * parameters can be retrieved through the {@link\n+ * EstimationProblem#getAllParameters\n+ * EstimationProblem.getAllParameters} method if the measurements are\n+ * independent of the problem, or directly if they are implemented as\n+ * inner classes of the problem.</p>\n+ *\n+ * <p>The instances for which the <code>ignored</code> flag is set\n+ * through the {@link #setIgnored setIgnored} method are ignored by the\n+ * solvers. This can be used to reject wrong measurements at some\n+ * steps of the estimation.</p>\n+ *\n+ * @see EstimationProblem\n+ *\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+\n+public abstract class WeightedMeasurement implements Serializable {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = 4360046376796901941L;\n+\n+    /** \n+   * Simple constructor.\n+   * Build a measurement with the given parameters, and set its ignore\n+   * flag to false.\n+   * @param weight weight of the measurement in the least squares problem\n+   * (two common choices are either to use 1.0 for all measurements, or to\n+   * use a value proportional to the inverse of the variance of the measurement\n+   * type)\n+   * \n+   * @param measuredValue measured value\n+   */\n+  public WeightedMeasurement(double weight, double measuredValue) {\n+    this.weight        = weight;\n+    this.measuredValue = measuredValue;\n+    ignored            = false;\n+  }\n+\n+  /** Simple constructor.\n+   * \n+   * Build a measurement with the given parameters\n+   * \n+   * @param weight weight of the measurement in the least squares problem\n+   * @param measuredValue measured value\n+   * @param ignored true if the measurement should be ignored\n+   */\n+  public WeightedMeasurement(double weight, double measuredValue,\n+                             boolean ignored) {\n+    this.weight        = weight;\n+    this.measuredValue = measuredValue;\n+    this.ignored       = ignored;\n+  }\n+\n+  /** \n+   * Get the weight of the measurement in the least squares problem\n+   * \n+   * @return weight\n+   */\n+  public double getWeight() {\n+    return weight;\n+  }\n+\n+  /** \n+   * Get the measured value\n+   * \n+   * @return measured value\n+   */\n+  public double getMeasuredValue() {\n+    return measuredValue;\n+  }\n+\n+  /** \n+   * Get the residual for this measurement\n+   * The residual is the measured value minus the theoretical value.\n+   * \n+   * @return residual\n+   */\n+  public double getResidual() {\n+    return measuredValue - getTheoreticalValue();\n+  }\n+\n+  /** \n+   * Get the theoretical value expected for this measurement\n+   * <p>The theoretical value is the value expected for this measurement\n+   * if the model and its parameter were all perfectly known.</p>\n+   * <p>The value must be computed using the current estimate of the parameters\n+   * set by the solver in the problem.</p>\n+   * \n+   * @return theoretical value\n+   */\n+  public abstract double getTheoreticalValue();\n+\n+  /** \n+   * Get the partial derivative of the {@link #getTheoreticalValue\n+   * theoretical value} according to the parameter.\n+   * <p>The value must be computed using the current estimate of the parameters\n+   * set by the solver in the problem.</p>\n+   * \n+   * @param parameter parameter against which the partial derivative\n+   * should be computed\n+   * @return partial derivative of the {@link #getTheoreticalValue\n+   * theoretical value}\n+   */\n+  public abstract double getPartial(EstimatedParameter parameter);\n+\n+  /** \n+   * Set the ignore flag to the specified value\n+   * Setting the ignore flag to true allow to reject wrong\n+   * measurements, which sometimes can be detected only rather late.\n+   * \n+   * @param ignored value for the ignore flag\n+   */\n+  public void setIgnored(boolean ignored) {\n+    this.ignored = ignored;\n+  }\n+\n+  /** \n+   * Check if this measurement should be ignored\n+   * \n+   * @return true if the measurement should be ignored\n+   */\n+  public boolean isIgnored() {\n+    return ignored;\n+  }\n+\n+  /** Measurement weight. */\n+  private final double  weight;\n+\n+  /** Value of the measurements. */\n+  private final double  measuredValue;\n+\n+  /** Ignore measurement indicator. */\n+  private       boolean ignored;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/univariate/BrentMinimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math.optimization.univariate;\n+\n+import org.apache.commons.math.FunctionEvaluationException;\n+import org.apache.commons.math.MaxIterationsExceededException;\n+import org.apache.commons.math.analysis.UnivariateRealFunction;\n+\n+/**\n+ * Implements Richard Brent's algorithm (from his book \"Algorithms for\n+ * Minimization without Derivatives\", p. 79) for finding minima of real\n+ * univariate functions.\n+ *  \n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ */\n+public class BrentMinimizer extends UnivariateRealMinimizerImpl {\n+    \n+    /** Serializable version identifier */\n+    private static final long serialVersionUID = 7185472920191999565L;\n+\n+    /**\n+     * Golden section.\n+     */\n+    private static final double c = 0.5 * (3 - Math.sqrt(5));\n+\n+    /**\n+     * Construct a solver.\n+     */\n+    public BrentMinimizer() {\n+        super(100, 1E-10);\n+    }\n+\n+    /**\n+     * Find a minimum in the given interval, start at startValue.\n+     * <p>\n+     * A minimizer may require that the interval brackets a single minimum.\n+     * </p>\n+     * @param f the function to minimize.\n+     * @param min the lower bound for the interval.\n+     * @param max the upper bound for the interval.\n+     * @param startValue this parameter is <em>not</em> used at all\n+     * @return a value where the function is minimum\n+     * @throws MaxIterationsExceededException if the maximum iteration count is exceeded\n+     * or the minimizer detects convergence problems otherwise.\n+     * @throws FunctionEvaluationException if an error occurs evaluating the\n+     * function\n+     * @throws IllegalArgumentException if min > max or the arguments do not\n+     * satisfy the requirements specified by the minimizer\n+     */\n+    public double minimize(final UnivariateRealFunction f,\n+                           final double min, final double max, final double startValue)\n+        throws MaxIterationsExceededException, FunctionEvaluationException {\n+        return minimize(f, min, max);\n+    }\n+    \n+    /** {@inheritDoc} */\n+    public double minimize(final UnivariateRealFunction f,\n+                           final double min, final double max)\n+        throws MaxIterationsExceededException, \n+        FunctionEvaluationException {\n+        clearResult();\n+        return localMin(min, max, relativeAccuracy, absoluteAccuracy, f);\n+    }\n+    \n+    /**\n+     * Find the minimum of the function {@code f} within the interval {@code (a, b)}.\n+     *\n+     * If the function {@code f} is defined on the interval {@code (a, b)}, then\n+     * this method finds an approximation {@code x} to the point at which {@code f}\n+     * attains its minimum.<br/>\n+     * {@code t} and {@code eps} define a tolerance {@code tol = eps |x| + t} and\n+     * {@code f} is never evaluated at two points closer together than {@code tol}.\n+     * {@code eps} should be no smaller than <em>2 macheps</em> and preferable not\n+     * much less than <em>sqrt(macheps)</em>, where <em>macheps</em> is the relative\n+     * machine precision. {@code t} should be positive.\n+     *\n+     * @param f the function to solve\n+     * @param a Lower bound of the interval.\n+     * @param b Higher bound of the interval.\n+     * @param eps Relative accuracy.\n+     * @param t Absolute accuracy.\n+     * @return the point at which the function is minimal.\n+     * @throws MaxIterationsExceededException if the maximum iteration count\n+     * is exceeded.\n+     * @throws FunctionEvaluationException if an error occurs evaluating\n+     * the function. \n+     */\n+    private double localMin(double a, double b, final double eps,\n+                            final double t, final UnivariateRealFunction f)\n+        throws MaxIterationsExceededException, FunctionEvaluationException {\n+        double x = a + c * (b - a);\n+        double v = x;\n+        double w = x;\n+        double e = 0;\n+        double fx = f.value(x);\n+        double fv = fx;\n+        double fw = fx;\n+\n+        int count = 0;\n+        while (count < maximalIterationCount) {\n+            double m = 0.5 * (a + b);\n+            double tol = eps * Math.abs(x) + t;\n+            double t2 = 2 * tol;\n+\n+            // Check stopping criterion.\n+            if (Math.abs(x - m) > t2 - 0.5 * (b - a)) {\n+                double p = 0;\n+                double q = 0;\n+                double r = 0;\n+                double d = 0;\n+                double u = 0;\n+\n+                if (Math.abs(e) > tol) { // Fit parabola.\n+                    r = (x - w) * (fx - fv);\n+                    q = (x - v) * (fx - fw);\n+                    p = (x - v) * q - (x - w) * r;\n+                    q = 2 * (q - r);\n+\n+                    if (q > 0) {\n+                        p = -p;\n+                    } else {\n+                        q = -q;\n+                    }\n+\n+                    r = e;\n+                    e = d;\n+                }\n+\n+                if (Math.abs(p) < Math.abs(0.5 * q * r) &&\n+                    (p < q * (a - x)) && (p < q * (b - x))) { // Parabolic interpolation step.\n+                    d = p / q;\n+                    u = x + d;\n+\n+                    // f must not be evaluated too close to a or b.\n+                    if (((u - a) < t2) || ((b - u) < t2)) {\n+                        d = (x < m) ? tol : -tol;\n+                    }\n+                } else { // Golden section step.\n+                    e = ((x < m) ? b : a) - x;\n+                    d = c * e;\n+                }\n+\n+                // f must not be evaluated too close to a or b.\n+                u = x + ((Math.abs(d) > tol) ? d : ((d > 0) ? tol : -tol));\n+                double fu = f.value(u);\n+\n+                // Update a, b, v, w and x.\n+                if (fu <= fx) {\n+                    if (u < x) {\n+                        b = x;\n+                    } else {\n+                        a = x;\n+                    }\n+                    v = w;\n+                    fv = fw;\n+                    w = x;\n+                    fw = fx;\n+                    x = u;\n+                    fx = fu;\n+                } else {\n+                    if (u < x) {\n+                        a = u;\n+                    } else {\n+                        b = u;\n+                    }\n+                    if ((fu <= fw) || (w == x)) {\n+                        v = w;\n+                        fv = fw;\n+                        w = u;\n+                        fw = fu;\n+                    } else if ((fu <= fv) || (v == x) || (v == w)) {\n+                        v = u;\n+                        fv = fu;\n+                    }\n+                }\n+            } else { // Termination.\n+                setResult(x, fx, count);\n+                return x;\n+            }\n+\n+            ++count;\n+        }\n+\n+        throw new MaxIterationsExceededException(maximalIterationCount);\n+\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/univariate/UnivariateRealMinimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math.optimization.univariate;\n+\n+import org.apache.commons.math.ConvergenceException;\n+import org.apache.commons.math.ConvergingAlgorithm;\n+import org.apache.commons.math.FunctionEvaluationException;\n+import org.apache.commons.math.analysis.UnivariateRealFunction;\n+\n+\n+/**\n+ * Interface for (univariate real) minimization algorithms.\n+ *  \n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ */\n+public interface UnivariateRealMinimizer extends ConvergingAlgorithm {\n+\n+    /**\n+     * Find a minimum in the given interval.\n+     * <p>\n+     * A minimizer may require that the interval brackets a single minimum.\n+     * </p>\n+     * @param f the function to minimize.\n+     * @param min the lower bound for the interval.\n+     * @param max the upper bound for the interval.\n+     * @return a value where the function is minimum\n+     * @throws ConvergenceException if the maximum iteration count is exceeded\n+     * or the minimizer detects convergence problems otherwise.\n+     * @throws FunctionEvaluationException if an error occurs evaluating the\n+     * function\n+     * @throws IllegalArgumentException if min > max or the endpoints do not\n+     * satisfy the requirements specified by the minimizer\n+     */\n+    double minimize(UnivariateRealFunction f, double min, double max)\n+        throws ConvergenceException, FunctionEvaluationException;\n+\n+    /**\n+     * Find a minimum in the given interval, start at startValue.\n+     * <p>\n+     * A minimizer may require that the interval brackets a single minimum.\n+     * </p>\n+     * @param f the function to minimize.\n+     * @param min the lower bound for the interval.\n+     * @param max the upper bound for the interval.\n+     * @param startValue the start value to use\n+     * @return a value where the function is minimum\n+     * @throws ConvergenceException if the maximum iteration count is exceeded\n+     * or the minimizer detects convergence problems otherwise.\n+     * @throws FunctionEvaluationException if an error occurs evaluating the\n+     * function\n+     * @throws IllegalArgumentException if min > max or the arguments do not\n+     * satisfy the requirements specified by the minimizer\n+     */\n+    double minimize(UnivariateRealFunction f, double min, double max, double startValue)\n+        throws ConvergenceException, FunctionEvaluationException;\n+\n+    /**\n+     * Get the result of the last run of the minimizer.\n+     * \n+     * @return the last result.\n+     * @throws IllegalStateException if there is no result available, either\n+     * because no result was yet computed or the last attempt failed.\n+     */\n+    double getResult();\n+\n+    /**\n+     * Get the result of the last run of the minimizer.\n+     * \n+     * @return the value of the function at the last result.\n+     * @throws IllegalStateException if there is no result available, either\n+     * because no result was yet computed or the last attempt failed.\n+     */\n+    double getFunctionValue();\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/univariate/UnivariateRealMinimizerImpl.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.univariate;\n+\n+import org.apache.commons.math.ConvergingAlgorithmImpl;\n+import org.apache.commons.math.MathRuntimeException;\n+\n+/**\n+ * Provide a default implementation for several functions useful to generic\n+ * minimizers.\n+ *  \n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ */\n+public abstract class UnivariateRealMinimizerImpl\n+  extends ConvergingAlgorithmImpl implements UnivariateRealMinimizer {\n+\n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = 4543031162377070699L;\n+\n+    /** Indicates where a root has been computed. */\n+    protected boolean resultComputed = false;\n+\n+    /** The last computed root. */\n+    protected double result;\n+\n+    /** Value of the function at the last computed result. */\n+    protected double functionValue;\n+\n+    /**\n+     * Construct a solver with given iteration count and accuracy.\n+     * \n+     * @param defaultAbsoluteAccuracy maximum absolute error\n+     * @param defaultMaximalIterationCount maximum number of iterations\n+     * @throws IllegalArgumentException if f is null or the \n+     * defaultAbsoluteAccuracy is not valid\n+     */\n+    protected UnivariateRealMinimizerImpl(int defaultMaximalIterationCount,\n+                                          double defaultAbsoluteAccuracy) {\n+        super(defaultMaximalIterationCount, defaultAbsoluteAccuracy);\n+    }\n+\n+    /** Check if a result has been computed.\n+     * @exception IllegalStateException if no result has been computed\n+     */\n+    protected void checkResultComputed() throws IllegalStateException {\n+        if (!resultComputed) {\n+            throw MathRuntimeException.createIllegalStateException(\"no result available\");\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    public double getResult() {\n+        checkResultComputed();\n+        return result;\n+    }\n+\n+    /** {@inheritDoc} */\n+    public double getFunctionValue() {\n+        checkResultComputed();\n+        return functionValue;\n+    }\n+\n+    /**\n+     * Convenience function for implementations.\n+     * \n+     * @param result the result to set\n+     * @param iterationCount the iteration count to set\n+     */\n+    protected final void setResult(double result, int iterationCount) {\n+        this.result = result;\n+        this.iterationCount = iterationCount;\n+        this.resultComputed = true;\n+    }\n+\n+    /**\n+     * Convenience function for implementations.\n+     * \n+     * @param x the result to set\n+     * @param fx the result to set\n+     * @param iterationCount the iteration count to set\n+     */\n+    protected final void setResult(double x, double fx, int iterationCount) {\n+        this.result = x;\n+        this.functionValue = fx;\n+        this.iterationCount = iterationCount;\n+        this.resultComputed = true;\n+    }\n+\n+    /**\n+     * Convenience function for implementations.\n+     */\n+    protected final void clearResult() {\n+        this.resultComputed = false;\n+    }\n+\n+}\n--- a/src/site/resources/userguide/TrajectoryDeterminationProblem.java\n+++ b/src/site/resources/userguide/TrajectoryDeterminationProblem.java\n  * limitations under the License.\n  */\n \n-import org.apache.commons.math.estimation.EstimationException;\n-import org.apache.commons.math.estimation.EstimatedParameter;\n-import org.apache.commons.math.estimation.EstimationProblem;\n-import org.apache.commons.math.estimation.LevenbergMarquardtEstimator;\n-import org.apache.commons.math.estimation.SimpleEstimationProblem;\n-import org.apache.commons.math.estimation.WeightedMeasurement;\n+import org.apache.commons.math.optimization.general.EstimationException;\n+import org.apache.commons.math.optimization.general.EstimatedParameter;\n+import org.apache.commons.math.optimization.general.EstimationProblem;\n+import org.apache.commons.math.optimization.general.LevenbergMarquardtEstimator;\n+import org.apache.commons.math.optimization.general.SimpleEstimationProblem;\n+import org.apache.commons.math.optimization.general.WeightedMeasurement;\n \n public class TrajectoryDeterminationProblem extends SimpleEstimationProblem {\n \n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/direct/MultiDirectionalTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.direct;\n+\n+import org.apache.commons.math.linear.decomposition.NotPositiveDefiniteMatrixException;\n+import org.apache.commons.math.optimization.ConvergenceChecker;\n+import org.apache.commons.math.optimization.ObjectiveException;\n+import org.apache.commons.math.optimization.ObjectiveFunction;\n+import org.apache.commons.math.optimization.PointValuePair;\n+import org.apache.commons.math.ConvergenceException;\n+\n+import junit.framework.*;\n+\n+public class MultiDirectionalTest\n+  extends TestCase {\n+\n+  public MultiDirectionalTest(String name) {\n+    super(name);\n+  }\n+\n+  public void testObjectiveExceptions() throws ConvergenceException {\n+      ObjectiveFunction wrong =\n+          new ObjectiveFunction() {\n+            private static final long serialVersionUID = 4751314470965489371L;\n+            public double objective(double[] x) throws ObjectiveException {\n+                if (x[0] < 0) {\n+                    throw new ObjectiveException(\"{0}\", \"oops\");\n+                } else if (x[0] > 1) {\n+                    throw new ObjectiveException(new RuntimeException(\"oops\"));\n+                } else {\n+                    return x[0] * (1 - x[0]);\n+                }\n+            }\n+      };\n+      try {\n+          new MultiDirectional(1.9, 0.4).optimize(wrong, 10, new ValueChecker(1.0e-3), true,\n+                                                  new double[] { -0.5 }, new double[] { 0.5 });\n+          fail(\"an exception should have been thrown\");\n+      } catch (ObjectiveException ce) {\n+          // expected behavior\n+          assertNull(ce.getCause());\n+      } catch (Exception e) {\n+          fail(\"wrong exception caught: \" + e.getMessage());\n+      } \n+      try {\n+          new MultiDirectional(1.9, 0.4).optimize(wrong, 10, new ValueChecker(1.0e-3), true,\n+                  new double[] { 0.5 }, new double[] { 1.5 });\n+          fail(\"an exception should have been thrown\");\n+      } catch (ObjectiveException ce) {\n+          // expected behavior\n+          assertNotNull(ce.getCause());\n+      } catch (Exception e) {\n+          fail(\"wrong exception caught: \" + e.getMessage());\n+      } \n+  }\n+\n+  public void testMinimizeMaximize()\n+      throws ObjectiveException, ConvergenceException, NotPositiveDefiniteMatrixException {\n+\n+      // the following function has 4 local extrema:\n+      final double xM        = -3.841947088256863675365;\n+      final double yM        = -1.391745200270734924416;\n+      final double xP        =  0.2286682237349059125691;\n+      final double yP        = -yM;\n+      final double valueXmYm =  0.2373295333134216789769; // local  maximum\n+      final double valueXmYp = -valueXmYm;                // local  minimum\n+      final double valueXpYm = -0.7290400707055187115322; // global minimum\n+      final double valueXpYp = -valueXpYm;                // global maximum\n+      ObjectiveFunction fourExtrema = new ObjectiveFunction() {\n+          private static final long serialVersionUID = -7039124064449091152L;\n+          public double objective(double[] variables) {\n+              final double x = variables[0];\n+              final double y = variables[1];\n+              return Math.atan(x) * Math.atan(x + 2) * Math.atan(y) * Math.atan(y) / (x * y);\n+          }\n+      };\n+\n+      MultiDirectional md = new MultiDirectional();\n+\n+      // minimization\n+      md.optimize(fourExtrema, 200, new ValueChecker(1.0e-8), true,\n+                  new double[] { -4, -2 }, new double[] { 1, 2 }, 10, 38821113105892l);\n+      PointValuePair[] optima = md.getOptima();\n+      assertEquals(10, optima.length);\n+      int localCount  = 0;\n+      int globalCount = 0;\n+      for (PointValuePair optimum : optima) {\n+          if (optimum != null) {\n+              if (optimum.getPoint()[0] < 0) {\n+                  // this should be the local minimum\n+                  ++localCount;\n+                  assertEquals(xM,        optimum.getPoint()[0], 1.0e-3);\n+                  assertEquals(yP,        optimum.getPoint()[1], 1.0e-3);\n+                  assertEquals(valueXmYp, optimum.getValue(),     3.0e-8);\n+              } else {\n+                  // this should be the global minimum\n+                  ++globalCount;\n+                  assertEquals(xP,        optimum.getPoint()[0], 1.0e-3);\n+                  assertEquals(yM,        optimum.getPoint()[1], 1.0e-3);\n+                  assertEquals(valueXpYm, optimum.getValue(),     3.0e-8);              \n+              }\n+          }\n+      }\n+      assertTrue(localCount  > 0);\n+      assertTrue(globalCount > 0);\n+      assertTrue(md.getTotalEvaluations() > 1400);\n+      assertTrue(md.getTotalEvaluations() < 1700);\n+\n+      // minimization\n+      md.optimize(fourExtrema, 200, new ValueChecker(1.0e-8), false,\n+                  new double[] { -3.5, -1 }, new double[] { 0.5, 1.5 }, 10, 38821113105892l);\n+      optima = md.getOptima();\n+      assertEquals(10, optima.length);\n+      localCount  = 0;\n+      globalCount = 0;\n+      for (PointValuePair optimum : optima) {\n+          if (optimum != null) {\n+              if (optimum.getPoint()[0] < 0) {\n+                  // this should be the local maximum\n+                  ++localCount;\n+                  assertEquals(xM,        optimum.getPoint()[0], 1.0e-3);\n+                  assertEquals(yM,        optimum.getPoint()[1], 1.0e-3);\n+                  assertEquals(valueXmYm, optimum.getValue(),     4.0e-8);\n+              } else {\n+                  // this should be the global maximum\n+                  ++globalCount;\n+                  assertEquals(xP,        optimum.getPoint()[0], 1.0e-3);\n+                  assertEquals(yP,        optimum.getPoint()[1], 1.0e-3);\n+                  assertEquals(valueXpYp, optimum.getValue(),     4.0e-8);              \n+              }\n+          }\n+      }\n+      assertTrue(localCount  > 0);\n+      assertTrue(globalCount > 0);\n+      assertTrue(md.getTotalEvaluations() > 1400);\n+      assertTrue(md.getTotalEvaluations() < 1700);\n+\n+  }\n+\n+  public void testRosenbrock()\n+    throws ObjectiveException, ConvergenceException {\n+\n+    ObjectiveFunction rosenbrock =\n+      new ObjectiveFunction() {\n+        private static final long serialVersionUID = -9044950469615237490L;\n+        public double objective(double[] x) {\n+          ++count;\n+          double a = x[1] - x[0] * x[0];\n+          double b = 1.0 - x[0];\n+          return 100 * a * a + b * b;\n+        }\n+      };\n+\n+    count = 0;\n+    PointValuePair optimum =\n+      new MultiDirectional().optimize(rosenbrock, 100, new ValueChecker(1.0e-3), true,\n+                                      new double[][] {\n+                                        { -1.2,  1.0 }, { 0.9, 1.2 } , {  3.5, -2.3 }\n+                                      });\n+\n+    assertTrue(count > 60);\n+    assertTrue(optimum.getValue() > 0.01);\n+\n+  }\n+\n+  public void testPowell()\n+    throws ObjectiveException, ConvergenceException {\n+\n+    ObjectiveFunction powell =\n+      new ObjectiveFunction() {\n+        private static final long serialVersionUID = -832162886102041840L;\n+        public double objective(double[] x) {\n+          ++count;\n+          double a = x[0] + 10 * x[1];\n+          double b = x[2] - x[3];\n+          double c = x[1] - 2 * x[2];\n+          double d = x[0] - x[3];\n+          return a * a + 5 * b * b + c * c * c * c + 10 * d * d * d * d;\n+        }\n+      };\n+\n+    count = 0;\n+    PointValuePair optimum =\n+      new MultiDirectional().optimize(powell, 1000, new ValueChecker(1.0e-3), true,\n+                                      new double[] {  3.0, -1.0, 0.0, 1.0 },\n+                                      new double[] {  4.0,  0.0, 1.0, 2.0 });\n+    assertTrue(count > 850);\n+    assertTrue(optimum.getValue() > 0.015);\n+\n+  }\n+\n+  private static class ValueChecker implements ConvergenceChecker {\n+\n+    public ValueChecker(double threshold) {\n+      this.threshold = threshold;\n+    }\n+\n+    public boolean converged(PointValuePair[] simplex) {\n+      PointValuePair smallest = simplex[0];\n+      PointValuePair largest  = simplex[simplex.length - 1];\n+      return (largest.getValue() - smallest.getValue()) < threshold;\n+    }\n+\n+    private double threshold;\n+\n+  };\n+\n+  public static Test suite() {\n+    return new TestSuite(MultiDirectionalTest.class);\n+  }\n+\n+  private int count;\n+\n+}\n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/direct/NelderMeadTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.direct;\n+\n+import org.apache.commons.math.linear.decomposition.NotPositiveDefiniteMatrixException;\n+import org.apache.commons.math.optimization.ConvergenceChecker;\n+import org.apache.commons.math.optimization.ObjectiveException;\n+import org.apache.commons.math.optimization.ObjectiveFunction;\n+import org.apache.commons.math.optimization.PointValuePair;\n+import org.apache.commons.math.ConvergenceException;\n+import org.apache.commons.math.random.JDKRandomGenerator;\n+import org.apache.commons.math.random.RandomGenerator;\n+import org.apache.commons.math.random.RandomVectorGenerator;\n+import org.apache.commons.math.random.UncorrelatedRandomVectorGenerator;\n+import org.apache.commons.math.random.UniformRandomGenerator;\n+\n+import junit.framework.*;\n+\n+public class NelderMeadTest\n+  extends TestCase {\n+\n+  public NelderMeadTest(String name) {\n+    super(name);\n+  }\n+\n+  public void testObjectiveExceptions() throws ConvergenceException {\n+      ObjectiveFunction wrong =\n+          new ObjectiveFunction() {\n+            private static final long serialVersionUID = 2624035220997628868L;\n+            public double objective(double[] x) throws ObjectiveException {\n+                if (x[0] < 0) {\n+                    throw new ObjectiveException(\"{0}\", \"oops\");\n+                } else if (x[0] > 1) {\n+                    throw new ObjectiveException(new RuntimeException(\"oops\"));\n+                } else {\n+                    return x[0] * (1 - x[0]);\n+                }\n+            }\n+      };\n+      try {\n+          new NelderMead(0.9, 1.9, 0.4, 0.6).optimize(wrong, 10, new ValueChecker(1.0e-3), true,\n+                                                      new double[] { -0.5 }, new double[] { 0.5 });\n+          fail(\"an exception should have been thrown\");\n+      } catch (ObjectiveException ce) {\n+          // expected behavior\n+          assertNull(ce.getCause());\n+      } catch (Exception e) {\n+          fail(\"wrong exception caught: \" + e.getMessage());\n+      } \n+      try {\n+          new NelderMead(0.9, 1.9, 0.4, 0.6).optimize(wrong, 10, new ValueChecker(1.0e-3), true,\n+                                                      new double[] { 0.5 }, new double[] { 1.5 });\n+          fail(\"an exception should have been thrown\");\n+      } catch (ObjectiveException ce) {\n+          // expected behavior\n+          assertNotNull(ce.getCause());\n+      } catch (Exception e) {\n+          fail(\"wrong exception caught: \" + e.getMessage());\n+      } \n+  }\n+\n+  public void testMinimizeMaximize()\n+      throws ObjectiveException, ConvergenceException, NotPositiveDefiniteMatrixException {\n+\n+      // the following function has 4 local extrema:\n+      final double xM        = -3.841947088256863675365;\n+      final double yM        = -1.391745200270734924416;\n+      final double xP        =  0.2286682237349059125691;\n+      final double yP        = -yM;\n+      final double valueXmYm =  0.2373295333134216789769; // local  maximum\n+      final double valueXmYp = -valueXmYm;                // local  minimum\n+      final double valueXpYm = -0.7290400707055187115322; // global minimum\n+      final double valueXpYp = -valueXpYm;                // global maximum\n+      ObjectiveFunction fourExtrema = new ObjectiveFunction() {\n+        private static final long serialVersionUID = -7039124064449091152L;\n+        public double objective(double[] variables) {\n+              final double x = variables[0];\n+              final double y = variables[1];\n+              return Math.atan(x) * Math.atan(x + 2) * Math.atan(y) * Math.atan(y) / (x * y);\n+          }\n+      };\n+\n+      NelderMead nm = new NelderMead();\n+\n+      // minimization\n+      nm.optimize(fourExtrema, 100, new ValueChecker(1.0e-8), true,\n+                  new double[] { -5, -5 }, new double[] { 5, 5 }, 10, 38821113105892l);\n+      PointValuePair[] optima = nm.getOptima();\n+      assertEquals(10, optima.length);\n+      int localCount  = 0;\n+      int globalCount = 0;\n+      for (PointValuePair optimum : optima) {\n+          if (optimum != null) {\n+              if (optimum.getPoint()[0] < 0) {\n+                  // this should be the local minimum\n+                  ++localCount;\n+                  assertEquals(xM,        optimum.getPoint()[0], 1.0e-3);\n+                  assertEquals(yP,        optimum.getPoint()[1], 1.0e-3);\n+                  assertEquals(valueXmYp, optimum.getValue(),     2.0e-8);\n+              } else {\n+                  // this should be the global minimum\n+                  ++globalCount;\n+                  assertEquals(xP,        optimum.getPoint()[0], 1.0e-3);\n+                  assertEquals(yM,        optimum.getPoint()[1], 1.0e-3);\n+                  assertEquals(valueXpYm, optimum.getValue(),     2.0e-8);              \n+              }\n+          }\n+      }\n+      assertTrue(localCount  > 0);\n+      assertTrue(globalCount > 0);\n+      assertTrue(nm.getTotalEvaluations() > 600);\n+      assertTrue(nm.getTotalEvaluations() < 800);\n+\n+      // minimization\n+      nm.optimize(fourExtrema, 100, new ValueChecker(1.0e-8), false,\n+                  new double[] { -5, -5 }, new double[] { 5, 5 }, 10, 38821113105892l);\n+      optima = nm.getOptima();\n+      assertEquals(10, optima.length);\n+      localCount  = 0;\n+      globalCount = 0;\n+      for (PointValuePair optimum : optima) {\n+          if (optimum != null) {\n+              if (optimum.getPoint()[0] < 0) {\n+                  // this should be the local maximum\n+                  ++localCount;\n+                  assertEquals(xM,        optimum.getPoint()[0], 1.0e-3);\n+                  assertEquals(yM,        optimum.getPoint()[1], 1.0e-3);\n+                  assertEquals(valueXmYm, optimum.getValue(),     2.0e-8);\n+              } else {\n+                  // this should be the global maximum\n+                  ++globalCount;\n+                  assertEquals(xP,        optimum.getPoint()[0], 1.0e-3);\n+                  assertEquals(yP,        optimum.getPoint()[1], 1.0e-3);\n+                  assertEquals(valueXpYp, optimum.getValue(),     2.0e-8);              \n+              }\n+          }\n+      }\n+      assertTrue(localCount  > 0);\n+      assertTrue(globalCount > 0);\n+      assertTrue(nm.getTotalEvaluations() > 600);\n+      assertTrue(nm.getTotalEvaluations() < 800);\n+\n+  }\n+\n+  public void testRosenbrock()\n+    throws ObjectiveException, ConvergenceException, NotPositiveDefiniteMatrixException {\n+\n+    ObjectiveFunction rosenbrock =\n+      new ObjectiveFunction() {\n+        private static final long serialVersionUID = -7039124064449091152L;\n+        public double objective(double[] x) {\n+          ++count;\n+          double a = x[1] - x[0] * x[0];\n+          double b = 1.0 - x[0];\n+          return 100 * a * a + b * b;\n+        }\n+      };\n+\n+    count = 0;\n+    NelderMead nm = new NelderMead();\n+    try {\n+      nm.optimize(rosenbrock, 100, new ValueChecker(1.0e-3), true,\n+                  new double[][] {\n+                    { -1.2, 1.0 }, { 3.5, -2.3 }, { 0.4, 1.5 }\n+                  }, 1, 5384353l);\n+      fail(\"an exception should have been thrown\");\n+    } catch (ConvergenceException ce) {\n+        // expected behavior\n+    } catch (Exception e) {\n+        e.printStackTrace(System.err);\n+        fail(\"wrong exception caught: \" + e.getMessage());\n+    }\n+\n+    count = 0;\n+    PointValuePair optimum =\n+        nm.optimize(rosenbrock, 100, new ValueChecker(1.0e-3), true,\n+                    new double[][] {\n+                      { -1.2, 1.0 }, { 0.9, 1.2 }, { 3.5, -2.3 }\n+                    }, 10, 1642738l);\n+\n+    assertTrue(count > 700);\n+    assertTrue(count < 800);\n+    assertEquals(0.0, optimum.getValue(), 5.0e-5);\n+    assertEquals(1.0, optimum.getPoint()[0], 0.01);\n+    assertEquals(1.0, optimum.getPoint()[1], 0.01);\n+\n+    PointValuePair[] minima = nm.getOptima();\n+    assertEquals(10, minima.length);\n+    assertNotNull(minima[0]);\n+    assertNull(minima[minima.length - 1]);\n+    for (int i = 0; i < minima.length; ++i) {\n+        if (minima[i] == null) {\n+            if ((i + 1) < minima.length) {\n+                assertTrue(minima[i+1] == null);\n+            }\n+        } else {\n+            if (i > 0) {\n+                assertTrue(minima[i-1].getValue() <= minima[i].getValue());\n+            }\n+        }\n+    }\n+\n+    RandomGenerator rg = new JDKRandomGenerator();\n+    rg.setSeed(64453353l);\n+    RandomVectorGenerator rvg =\n+        new UncorrelatedRandomVectorGenerator(new double[] { 0.9, 1.1 },\n+                                              new double[] { 0.2, 0.2 },\n+                                              new UniformRandomGenerator(rg));\n+    optimum =\n+        nm.optimize(rosenbrock, 100, new ValueChecker(1.0e-3), true, rvg);\n+    assertEquals(0.0, optimum.getValue(), 2.0e-4);\n+    optimum =\n+        nm.optimize(rosenbrock, 100, new ValueChecker(1.0e-3), true, rvg, 3);\n+    assertEquals(0.0, optimum.getValue(), 3.0e-5);\n+\n+  }\n+\n+  public void testPowell()\n+    throws ObjectiveException, ConvergenceException {\n+\n+    ObjectiveFunction powell =\n+      new ObjectiveFunction() {\n+        private static final long serialVersionUID = -7681075710859391520L;\n+        public double objective(double[] x) {\n+          ++count;\n+          double a = x[0] + 10 * x[1];\n+          double b = x[2] - x[3];\n+          double c = x[1] - 2 * x[2];\n+          double d = x[0] - x[3];\n+          return a * a + 5 * b * b + c * c * c * c + 10 * d * d * d * d;\n+        }\n+      };\n+\n+    count = 0;\n+    NelderMead nm = new NelderMead();\n+    PointValuePair optimum =\n+      nm.optimize(powell, 200, new ValueChecker(1.0e-3), true,\n+                  new double[] {  3.0, -1.0, 0.0, 1.0 },\n+                  new double[] {  4.0,  0.0, 1.0, 2.0 },\n+                  1, 1642738l);\n+    assertTrue(count < 150);\n+    assertEquals(0.0, optimum.getValue(), 6.0e-4);\n+    assertEquals(0.0, optimum.getPoint()[0], 0.07);\n+    assertEquals(0.0, optimum.getPoint()[1], 0.07);\n+    assertEquals(0.0, optimum.getPoint()[2], 0.07);\n+    assertEquals(0.0, optimum.getPoint()[3], 0.07);\n+\n+  }\n+\n+  private static class ValueChecker implements ConvergenceChecker {\n+\n+    public ValueChecker(double threshold) {\n+      this.threshold = threshold;\n+    }\n+\n+    public boolean converged(PointValuePair[] simplex) {\n+      PointValuePair smallest = simplex[0];\n+      PointValuePair largest  = simplex[simplex.length - 1];\n+      return (largest.getValue() - smallest.getValue()) < threshold;\n+    }\n+\n+    private double threshold;\n+\n+  };\n+\n+  public static Test suite() {\n+    return new TestSuite(NelderMeadTest.class);\n+  }\n+\n+  private int count;\n+\n+}\n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/general/EstimatedParameterTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+\n+import junit.framework.*;\n+\n+public class EstimatedParameterTest\n+  extends TestCase {\n+\n+  public EstimatedParameterTest(String name) {\n+    super(name);\n+  }\n+\n+  public void testConstruction() {\n+\n+    EstimatedParameter p1 = new EstimatedParameter(\"p1\", 1.0);\n+    assertTrue(p1.getName().equals(\"p1\"));\n+    checkValue(p1.getEstimate(), 1.0);\n+    assertTrue(! p1.isBound());\n+\n+    EstimatedParameter p2 = new EstimatedParameter(\"p2\", 2.0, true);\n+    assertTrue(p2.getName().equals(\"p2\"));\n+    checkValue(p2.getEstimate(), 2.0);\n+    assertTrue(p2.isBound());\n+\n+  }\n+\n+  public void testBound() {\n+\n+    EstimatedParameter p = new EstimatedParameter(\"p\", 0.0);\n+    assertTrue(! p.isBound());\n+    p.setBound(true);\n+    assertTrue(p.isBound());\n+    p.setBound(false);\n+    assertTrue(! p.isBound());\n+\n+  }\n+\n+  public void testEstimate() {\n+\n+    EstimatedParameter p = new EstimatedParameter(\"p\", 0.0);\n+    checkValue(p.getEstimate(), 0.0);\n+\n+    for (double e = 0.0; e < 10.0; e += 0.5) {\n+      p.setEstimate(e);\n+      checkValue(p.getEstimate(), e);\n+    }\n+\n+  }\n+\n+  public static Test suite() {\n+    return new TestSuite(EstimatedParameterTest.class);\n+  }\n+\n+  private void checkValue(double value, double expected) {\n+    assertTrue(Math.abs(value - expected) < 1.0e-10);\n+  }\n+\n+}\n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/general/GaussNewtonEstimatorTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+\n+import org.apache.commons.math.optimization.OptimizationException;\n+\n+\n+import junit.framework.Test;\n+import junit.framework.TestCase;\n+import junit.framework.TestSuite;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files. \n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class GaussNewtonEstimatorTest\n+  extends TestCase {\n+\n+  public GaussNewtonEstimatorTest(String name) {\n+    super(name);\n+  }\n+\n+  public void testTrivial() throws OptimizationException {\n+    LinearProblem problem =\n+      new LinearProblem(new LinearMeasurement[] {\n+        new LinearMeasurement(new double[] {2},\n+                              new EstimatedParameter[] {\n+                                 new EstimatedParameter(\"p0\", 0)\n+                              }, 3.0)\n+      });\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals(1.5,\n+                 problem.getUnboundParameters()[0].getEstimate(),\n+                 1.0e-10);\n+   }\n+\n+  public void testQRColumnsPermutation() throws OptimizationException {\n+\n+    EstimatedParameter[] x = {\n+       new EstimatedParameter(\"p0\", 0), new EstimatedParameter(\"p1\", 0)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                            new EstimatedParameter[] { x[0], x[1] },\n+                            4.0),\n+      new LinearMeasurement(new double[] { 2.0 },\n+                            new EstimatedParameter[] { x[1] },\n+                            6.0),\n+      new LinearMeasurement(new double[] { 1.0, -2.0 },\n+                            new EstimatedParameter[] { x[0], x[1] },\n+                            1.0)\n+    });\n+\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals(7.0, x[0].getEstimate(), 1.0e-10);\n+    assertEquals(3.0, x[1].getEstimate(), 1.0e-10);\n+\n+  }\n+\n+  public void testNoDependency() throws OptimizationException {\n+    EstimatedParameter[] p = new EstimatedParameter[] {\n+      new EstimatedParameter(\"p0\", 0),\n+      new EstimatedParameter(\"p1\", 0),\n+      new EstimatedParameter(\"p2\", 0),\n+      new EstimatedParameter(\"p3\", 0),\n+      new EstimatedParameter(\"p4\", 0),\n+      new EstimatedParameter(\"p5\", 0)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[0] }, 0.0),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[1] }, 1.1),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[2] }, 2.2),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[3] }, 3.3),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[4] }, 4.4),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[5] }, 5.5)\n+    });\n+  GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+  estimator.estimate(problem);\n+  assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+  for (int i = 0; i < p.length; ++i) {\n+    assertEquals(0.55 * i, p[i].getEstimate(), 1.0e-10);\n+  }\n+}\n+\n+  public void testOneSet() throws OptimizationException {\n+\n+    EstimatedParameter[] p = {\n+       new EstimatedParameter(\"p0\", 0),\n+       new EstimatedParameter(\"p1\", 0),\n+       new EstimatedParameter(\"p2\", 0)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0 },\n+                            new EstimatedParameter[] { p[0] },\n+                            1.0),\n+      new LinearMeasurement(new double[] { -1.0, 1.0 },\n+                            new EstimatedParameter[] { p[0], p[1] },\n+                            1.0),\n+      new LinearMeasurement(new double[] { -1.0, 1.0 },\n+                            new EstimatedParameter[] { p[1], p[2] },\n+                            1.0)\n+    });\n+\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals(1.0, p[0].getEstimate(), 1.0e-10);\n+    assertEquals(2.0, p[1].getEstimate(), 1.0e-10);\n+    assertEquals(3.0, p[2].getEstimate(), 1.0e-10);\n+\n+  }\n+\n+  public void testTwoSets() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 0),\n+      new EstimatedParameter(\"p1\", 1),\n+      new EstimatedParameter(\"p2\", 2),\n+      new EstimatedParameter(\"p3\", 3),\n+      new EstimatedParameter(\"p4\", 4),\n+      new EstimatedParameter(\"p5\", 5)\n+    };\n+\n+    double epsilon = 1.0e-7;\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+\n+      // 4 elements sub-problem\n+      new LinearMeasurement(new double[] {  2.0,  1.0,  4.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[3] },\n+                            2.0),\n+      new LinearMeasurement(new double[] { -4.0, -2.0,   3.0, -7.0 },\n+                           new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                           -9.0),\n+      new LinearMeasurement(new double[] {  4.0,  1.0,  -2.0,  8.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            2.0),\n+      new LinearMeasurement(new double[] { -3.0, -12.0, -1.0 },\n+                           new EstimatedParameter[] { p[1], p[2], p[3] },\n+                           2.0),\n+\n+      // 2 elements sub-problem\n+      new LinearMeasurement(new double[] { epsilon, 1.0 },\n+                            new EstimatedParameter[] { p[4], p[5] },\n+                            1.0 + epsilon * epsilon),\n+      new LinearMeasurement(new double[] {  1.0, 1.0 },\n+                            new EstimatedParameter[] { p[4], p[5] },\n+                            2.0)\n+\n+    });\n+\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals( 3.0, p[0].getEstimate(), 1.0e-10);\n+    assertEquals( 4.0, p[1].getEstimate(), 1.0e-10);\n+    assertEquals(-1.0, p[2].getEstimate(), 1.0e-10);\n+    assertEquals(-2.0, p[3].getEstimate(), 1.0e-10);\n+    assertEquals( 1.0 + epsilon, p[4].getEstimate(), 1.0e-10);\n+    assertEquals( 1.0 - epsilon, p[5].getEstimate(), 1.0e-10);\n+\n+  }\n+\n+  public void testNonInversible() throws OptimizationException {\n+\n+    EstimatedParameter[] p = {\n+       new EstimatedParameter(\"p0\", 0),\n+       new EstimatedParameter(\"p1\", 0),\n+       new EstimatedParameter(\"p2\", 0)\n+    };\n+    LinearMeasurement[] m = new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] {  1.0, 2.0, -3.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2] },\n+                            1.0),\n+      new LinearMeasurement(new double[] {  2.0, 1.0,  3.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2] },\n+                            1.0),\n+      new LinearMeasurement(new double[] { -3.0, -9.0 },\n+                            new EstimatedParameter[] { p[0], p[2] },\n+                            1.0)\n+    };\n+    LinearProblem problem = new LinearProblem(m);\n+\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    try {\n+      estimator.estimate(problem);\n+      fail(\"an exception should have been caught\");\n+    } catch (OptimizationException ee) {\n+      // expected behavior\n+    } catch (Exception e) {\n+      fail(\"wrong exception type caught\");\n+    }\n+  }\n+\n+  public void testIllConditioned() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 0),\n+      new EstimatedParameter(\"p1\", 1),\n+      new EstimatedParameter(\"p2\", 2),\n+      new EstimatedParameter(\"p3\", 3)\n+    };\n+\n+    LinearProblem problem1 = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 10.0, 7.0,  8.0,  7.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            32.0),\n+      new LinearMeasurement(new double[] {  7.0, 5.0,  6.0,  5.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            23.0),\n+      new LinearMeasurement(new double[] {  8.0, 6.0, 10.0,  9.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            33.0),\n+      new LinearMeasurement(new double[] {  7.0, 5.0,  9.0, 10.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            31.0)\n+    });\n+    GaussNewtonEstimator estimator1 = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    estimator1.estimate(problem1);\n+    assertEquals(0, estimator1.getRMS(problem1), 1.0e-10);\n+    assertEquals(1.0, p[0].getEstimate(), 1.0e-10);\n+    assertEquals(1.0, p[1].getEstimate(), 1.0e-10);\n+    assertEquals(1.0, p[2].getEstimate(), 1.0e-10);\n+    assertEquals(1.0, p[3].getEstimate(), 1.0e-10);\n+\n+    LinearProblem problem2 = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 10.0, 7.0,  8.1,  7.2 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            32.0),\n+      new LinearMeasurement(new double[] {  7.08, 5.04,  6.0,  5.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            23.0),\n+      new LinearMeasurement(new double[] {  8.0, 5.98, 9.89,  9.0 },\n+                             new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            33.0),\n+      new LinearMeasurement(new double[] {  6.99, 4.99,  9.0, 9.98 },\n+                             new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            31.0)\n+    });\n+    GaussNewtonEstimator estimator2 = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    estimator2.estimate(problem2);\n+    assertEquals(0, estimator2.getRMS(problem2), 1.0e-10);\n+    assertEquals(-81.0, p[0].getEstimate(), 1.0e-8);\n+    assertEquals(137.0, p[1].getEstimate(), 1.0e-8);\n+    assertEquals(-34.0, p[2].getEstimate(), 1.0e-8);\n+    assertEquals( 22.0, p[3].getEstimate(), 1.0e-8);\n+\n+  }\n+\n+  public void testMoreEstimatedParametersSimple() throws OptimizationException {\n+\n+    EstimatedParameter[] p = {\n+       new EstimatedParameter(\"p0\", 7),\n+       new EstimatedParameter(\"p1\", 6),\n+       new EstimatedParameter(\"p2\", 5),\n+       new EstimatedParameter(\"p3\", 4)\n+     };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 3.0, 2.0 },\n+                             new EstimatedParameter[] { p[0], p[1] },\n+                             7.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0, 1.0 },\n+                             new EstimatedParameter[] { p[1], p[2], p[3] },\n+                             3.0),\n+      new LinearMeasurement(new double[] { 2.0, 1.0 },\n+                             new EstimatedParameter[] { p[0], p[2] },\n+                             5.0)\n+    });\n+\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    try {\n+        estimator.estimate(problem);\n+        fail(\"an exception should have been caught\");\n+    } catch (OptimizationException ee) {\n+        // expected behavior\n+    } catch (Exception e) {\n+        fail(\"wrong exception type caught\");\n+    }\n+\n+  }\n+\n+  public void testMoreEstimatedParametersUnsorted() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 2),\n+      new EstimatedParameter(\"p1\", 2),\n+      new EstimatedParameter(\"p2\", 2),\n+      new EstimatedParameter(\"p3\", 2),\n+      new EstimatedParameter(\"p4\", 2),\n+      new EstimatedParameter(\"p5\", 2)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0, 1.0 },\n+                           new EstimatedParameter[] { p[0], p[1] },\n+                           3.0),\n+      new LinearMeasurement(new double[] { 1.0, 1.0, 1.0 },\n+                           new EstimatedParameter[] { p[2], p[3], p[4] },\n+                           12.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                           new EstimatedParameter[] { p[4], p[5] },\n+                           -1.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0, 1.0 },\n+                           new EstimatedParameter[] { p[3], p[2], p[5] },\n+                           7.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                           new EstimatedParameter[] { p[4], p[3] },\n+                           1.0)\n+    });\n+\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    try {\n+        estimator.estimate(problem);\n+        fail(\"an exception should have been caught\");\n+    } catch (OptimizationException ee) {\n+        // expected behavior\n+    } catch (Exception e) {\n+        fail(\"wrong exception type caught\");\n+    }\n+\n+  }\n+\n+  public void testRedundantEquations() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 1),\n+      new EstimatedParameter(\"p1\", 1)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0, 1.0 },\n+                             new EstimatedParameter[] { p[0], p[1] },\n+                             3.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                             new EstimatedParameter[] { p[0], p[1] },\n+                             1.0),\n+      new LinearMeasurement(new double[] { 1.0, 3.0 },\n+                             new EstimatedParameter[] { p[0], p[1] },\n+                             5.0)\n+    });\n+\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    EstimatedParameter[] all = problem.getAllParameters();\n+    for (int i = 0; i < all.length; ++i) {\n+        assertEquals(all[i].getName().equals(\"p0\") ? 2.0 : 1.0,\n+                     all[i].getEstimate(), 1.0e-10);\n+    }\n+\n+  }\n+\n+  public void testInconsistentEquations() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 1),\n+      new EstimatedParameter(\"p1\", 1)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0, 1.0 },\n+                            new EstimatedParameter[] { p[0], p[1] },\n+                            3.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                            new EstimatedParameter[] { p[0], p[1] },\n+                            1.0),\n+      new LinearMeasurement(new double[] { 1.0, 3.0 },\n+                            new EstimatedParameter[] { p[0], p[1] },\n+                            4.0)\n+    });\n+\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    estimator.estimate(problem);\n+    assertTrue(estimator.getRMS(problem) > 0.1);\n+\n+  }\n+\n+  public void testBoundParameters() throws OptimizationException {\n+      EstimatedParameter[] p = {\n+        new EstimatedParameter(\"unbound0\", 2, false),\n+        new EstimatedParameter(\"unbound1\", 2, false),\n+        new EstimatedParameter(\"bound\",    2, true)\n+      };\n+      LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+        new LinearMeasurement(new double[] { 1.0, 1.0, 1.0 },\n+                              new EstimatedParameter[] { p[0], p[1], p[2] },\n+                              3.0),\n+        new LinearMeasurement(new double[] { 1.0, -1.0, 1.0 },\n+                              new EstimatedParameter[] { p[0], p[1], p[2] },\n+                              1.0),\n+        new LinearMeasurement(new double[] { 1.0, 3.0, 2.0 },\n+                              new EstimatedParameter[] { p[0], p[1], p[2] },\n+                              7.0)\n+      });\n+\n+      GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+      estimator.estimate(problem);\n+      assertTrue(estimator.getRMS(problem) < 1.0e-10);\n+      double[][] covariances = estimator.getCovariances(problem);\n+      int i0 = 0, i1 = 1;\n+      if (problem.getUnboundParameters()[0].getName().endsWith(\"1\")) {\n+          i0 = 1;\n+          i1 = 0;\n+      }\n+      assertEquals(11.0 / 24, covariances[i0][i0], 1.0e-10);\n+      assertEquals(-3.0 / 24, covariances[i0][i1], 1.0e-10);\n+      assertEquals(-3.0 / 24, covariances[i1][i0], 1.0e-10);\n+      assertEquals( 3.0 / 24, covariances[i1][i1], 1.0e-10);\n+\n+      double[] errors = estimator.guessParametersErrors(problem);\n+      assertEquals(0, errors[i0], 1.0e-10);\n+      assertEquals(0, errors[i1], 1.0e-10);\n+\n+  }\n+\n+  public void testMaxIterations() {\n+      Circle circle = new Circle(98.680, 47.345);\n+      circle.addPoint( 30.0,  68.0);\n+      circle.addPoint( 50.0,  -6.0);\n+      circle.addPoint(110.0, -20.0);\n+      circle.addPoint( 35.0,  15.0);\n+      circle.addPoint( 45.0,  97.0);\n+      try {\n+        GaussNewtonEstimator estimator = new GaussNewtonEstimator(4, 1.0e-14, 1.0e-14);\n+        estimator.estimate(circle);\n+        fail(\"an exception should have been caught\");\n+      } catch (OptimizationException ee) {\n+        // expected behavior\n+      } catch (Exception e) {\n+        fail(\"wrong exception type caught\");\n+      }\n+    }\n+\n+  public void testCircleFitting() throws OptimizationException {\n+      Circle circle = new Circle(98.680, 47.345);\n+      circle.addPoint( 30.0,  68.0);\n+      circle.addPoint( 50.0,  -6.0);\n+      circle.addPoint(110.0, -20.0);\n+      circle.addPoint( 35.0,  15.0);\n+      circle.addPoint( 45.0,  97.0);\n+      GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-10, 1.0e-10);\n+      estimator.estimate(circle);\n+      double rms = estimator.getRMS(circle);\n+      assertEquals(1.768262623567235,  Math.sqrt(circle.getM()) * rms,  1.0e-10);\n+      assertEquals(69.96016176931406, circle.getRadius(), 1.0e-10);\n+      assertEquals(96.07590211815305, circle.getX(),      1.0e-10);\n+      assertEquals(48.13516790438953, circle.getY(),      1.0e-10);\n+    }\n+\n+  public void testCircleFittingBadInit() throws OptimizationException {\n+    Circle circle = new Circle(-12, -12);\n+    double[][] points = new double[][] {\n+      {-0.312967,  0.072366}, {-0.339248,  0.132965}, {-0.379780,  0.202724},\n+      {-0.390426,  0.260487}, {-0.361212,  0.328325}, {-0.346039,  0.392619},\n+      {-0.280579,  0.444306}, {-0.216035,  0.470009}, {-0.149127,  0.493832},\n+      {-0.075133,  0.483271}, {-0.007759,  0.452680}, { 0.060071,  0.410235},\n+      { 0.103037,  0.341076}, { 0.118438,  0.273884}, { 0.131293,  0.192201},\n+      { 0.115869,  0.129797}, { 0.072223,  0.058396}, { 0.022884,  0.000718},\n+      {-0.053355, -0.020405}, {-0.123584, -0.032451}, {-0.216248, -0.032862},\n+      {-0.278592, -0.005008}, {-0.337655,  0.056658}, {-0.385899,  0.112526},\n+      {-0.405517,  0.186957}, {-0.415374,  0.262071}, {-0.387482,  0.343398},\n+      {-0.347322,  0.397943}, {-0.287623,  0.458425}, {-0.223502,  0.475513},\n+      {-0.135352,  0.478186}, {-0.061221,  0.483371}, { 0.003711,  0.422737},\n+      { 0.065054,  0.375830}, { 0.108108,  0.297099}, { 0.123882,  0.222850},\n+      { 0.117729,  0.134382}, { 0.085195,  0.056820}, { 0.029800, -0.019138},\n+      {-0.027520, -0.072374}, {-0.102268, -0.091555}, {-0.200299, -0.106578},\n+      {-0.292731, -0.091473}, {-0.356288, -0.051108}, {-0.420561,  0.014926},\n+      {-0.471036,  0.074716}, {-0.488638,  0.182508}, {-0.485990,  0.254068},\n+      {-0.463943,  0.338438}, {-0.406453,  0.404704}, {-0.334287,  0.466119},\n+      {-0.254244,  0.503188}, {-0.161548,  0.495769}, {-0.075733,  0.495560},\n+      { 0.001375,  0.434937}, { 0.082787,  0.385806}, { 0.115490,  0.323807},\n+      { 0.141089,  0.223450}, { 0.138693,  0.131703}, { 0.126415,  0.049174},\n+      { 0.066518, -0.010217}, {-0.005184, -0.070647}, {-0.080985, -0.103635},\n+      {-0.177377, -0.116887}, {-0.260628, -0.100258}, {-0.335756, -0.056251},\n+      {-0.405195, -0.000895}, {-0.444937,  0.085456}, {-0.484357,  0.175597},\n+      {-0.472453,  0.248681}, {-0.438580,  0.347463}, {-0.402304,  0.422428},\n+      {-0.326777,  0.479438}, {-0.247797,  0.505581}, {-0.152676,  0.519380},\n+      {-0.071754,  0.516264}, { 0.015942,  0.472802}, { 0.076608,  0.419077},\n+      { 0.127673,  0.330264}, { 0.159951,  0.262150}, { 0.153530,  0.172681},\n+      { 0.140653,  0.089229}, { 0.078666,  0.024981}, { 0.023807, -0.037022},\n+      {-0.048837, -0.077056}, {-0.127729, -0.075338}, {-0.221271, -0.067526}\n+    };\n+    for (int i = 0; i < points.length; ++i) {\n+      circle.addPoint(points[i][0], points[i][1]);\n+    }\n+    GaussNewtonEstimator estimator = new GaussNewtonEstimator(100, 1.0e-6, 1.0e-6);\n+    try {\n+        estimator.estimate(circle);\n+        fail(\"an exception should have been caught\");\n+    } catch (OptimizationException ee) {\n+        // expected behavior\n+    } catch (Exception e) {\n+        fail(\"wrong exception type caught\");\n+    }\n+}\n+\n+  private static class LinearProblem extends SimpleEstimationProblem {\n+\n+    public LinearProblem(LinearMeasurement[] measurements) {\n+      HashSet<EstimatedParameter> set = new HashSet<EstimatedParameter>();\n+      for (int i = 0; i < measurements.length; ++i) {\n+        addMeasurement(measurements[i]);\n+        EstimatedParameter[] parameters = measurements[i].getParameters();\n+        for (int j = 0; j < parameters.length; ++j) {\n+          set.add(parameters[j]);\n+        }\n+      }\n+      for (EstimatedParameter p : set) {\n+        addParameter(p);\n+      }\n+    }\n+\n+  }\n+\n+  private static class LinearMeasurement extends WeightedMeasurement {\n+\n+    public LinearMeasurement(double[] factors, EstimatedParameter[] parameters,\n+                             double setPoint) {\n+      super(1.0, setPoint, true);\n+      this.factors = factors;\n+      this.parameters = parameters;\n+      setIgnored(false);\n+    }\n+\n+    public double getTheoreticalValue() {\n+      double v = 0;\n+      for (int i = 0; i < factors.length; ++i) {\n+        v += factors[i] * parameters[i].getEstimate();\n+      }\n+      return v;\n+    }\n+\n+    public double getPartial(EstimatedParameter parameter) {\n+      for (int i = 0; i < parameters.length; ++i) {\n+        if (parameters[i] == parameter) {\n+          return factors[i];\n+        }\n+      }\n+      return 0;\n+    }\n+\n+    public EstimatedParameter[] getParameters() {\n+      return parameters;\n+    }\n+\n+    private double[] factors;\n+    private EstimatedParameter[] parameters;\n+    private static final long serialVersionUID = -3922448707008868580L;\n+\n+  }\n+\n+  private static class Circle implements EstimationProblem {\n+\n+    public Circle(double cx, double cy) {\n+      this.cx = new EstimatedParameter(\"cx\", cx);\n+      this.cy = new EstimatedParameter(new EstimatedParameter(\"cy\", cy));\n+      points  = new ArrayList<PointModel>();\n+    }\n+\n+    public void addPoint(double px, double py) {\n+      points.add(new PointModel(px, py));\n+    }\n+\n+    public int getM() {\n+      return points.size();\n+    }\n+\n+    public WeightedMeasurement[] getMeasurements() {\n+      return (WeightedMeasurement[]) points.toArray(new PointModel[points.size()]);\n+    }\n+\n+    public EstimatedParameter[] getAllParameters() {\n+      return new EstimatedParameter[] { cx, cy };\n+    }\n+\n+    public EstimatedParameter[] getUnboundParameters() {\n+      return new EstimatedParameter[] { cx, cy };\n+    }\n+\n+    public double getPartialRadiusX() {\n+      double dRdX = 0;\n+      for (PointModel point : points) {\n+        dRdX += point.getPartialDiX();\n+      }\n+      return dRdX / points.size();\n+    }\n+\n+    public double getPartialRadiusY() {\n+      double dRdY = 0;\n+      for (PointModel point : points) {\n+        dRdY += point.getPartialDiY();\n+      }\n+      return dRdY / points.size();\n+    }\n+\n+   public double getRadius() {\n+      double r = 0;\n+      for (PointModel point : points) {\n+        r += point.getCenterDistance();\n+      }\n+      return r / points.size();\n+    }\n+\n+    public double getX() {\n+      return cx.getEstimate();\n+    }\n+\n+    public double getY() {\n+      return cy.getEstimate();\n+    }\n+\n+    private class PointModel extends WeightedMeasurement {\n+\n+      public PointModel(double px, double py) {\n+        super(1.0, 0.0);\n+        this.px = px;\n+        this.py = py;\n+      }\n+\n+      public double getPartial(EstimatedParameter parameter) {\n+        if (parameter == cx) {\n+          return getPartialDiX() - getPartialRadiusX();\n+        } else if (parameter == cy) {\n+          return getPartialDiY() - getPartialRadiusY();\n+        }\n+        return 0;\n+      }\n+\n+      public double getCenterDistance() {\n+        double dx = px - cx.getEstimate();\n+        double dy = py - cy.getEstimate();\n+        return Math.sqrt(dx * dx + dy * dy);\n+      }\n+\n+      public double getPartialDiX() {\n+        return (cx.getEstimate() - px) / getCenterDistance();\n+      }\n+\n+      public double getPartialDiY() {\n+        return (cy.getEstimate() - py) / getCenterDistance();\n+      }\n+\n+      public double getTheoreticalValue() {\n+        return getCenterDistance() - getRadius();\n+      }\n+\n+      private double px;\n+      private double py;\n+      private static final long serialVersionUID = 1L;\n+\n+    }\n+\n+    private EstimatedParameter cx;\n+    private EstimatedParameter cy;\n+    private ArrayList<PointModel> points;\n+\n+  }\n+\n+  public static Test suite() {\n+    return new TestSuite(GaussNewtonEstimatorTest.class);\n+  }\n+\n+}\n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/general/LevenbergMarquardtEstimatorTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+\n+import org.apache.commons.math.optimization.OptimizationException;\n+\n+\n+import junit.framework.Test;\n+import junit.framework.TestCase;\n+import junit.framework.TestSuite;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files. \n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class LevenbergMarquardtEstimatorTest\n+  extends TestCase {\n+\n+  public LevenbergMarquardtEstimatorTest(String name) {\n+    super(name);\n+  }\n+\n+  public void testTrivial() throws OptimizationException {\n+    LinearProblem problem =\n+      new LinearProblem(new LinearMeasurement[] {\n+        new LinearMeasurement(new double[] {2},\n+                              new EstimatedParameter[] {\n+                                 new EstimatedParameter(\"p0\", 0)\n+                              }, 3.0)\n+      });\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    try {\n+        estimator.guessParametersErrors(problem);\n+        fail(\"an exception should have been thrown\");\n+    } catch (OptimizationException ee) {\n+        // expected behavior\n+    } catch (Exception e) {\n+        fail(\"wrong exception caught\");\n+    }\n+    assertEquals(1.5,\n+                 problem.getUnboundParameters()[0].getEstimate(),\n+                 1.0e-10);\n+   }\n+\n+  public void testQRColumnsPermutation() throws OptimizationException {\n+\n+    EstimatedParameter[] x = {\n+       new EstimatedParameter(\"p0\", 0), new EstimatedParameter(\"p1\", 0)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                            new EstimatedParameter[] { x[0], x[1] },\n+                            4.0),\n+      new LinearMeasurement(new double[] { 2.0 },\n+                            new EstimatedParameter[] { x[1] },\n+                            6.0),\n+      new LinearMeasurement(new double[] { 1.0, -2.0 },\n+                            new EstimatedParameter[] { x[0], x[1] },\n+                            1.0)\n+    });\n+\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals(7.0, x[0].getEstimate(), 1.0e-10);\n+    assertEquals(3.0, x[1].getEstimate(), 1.0e-10);\n+\n+  }\n+\n+  public void testNoDependency() throws OptimizationException {\n+    EstimatedParameter[] p = new EstimatedParameter[] {\n+      new EstimatedParameter(\"p0\", 0),\n+      new EstimatedParameter(\"p1\", 0),\n+      new EstimatedParameter(\"p2\", 0),\n+      new EstimatedParameter(\"p3\", 0),\n+      new EstimatedParameter(\"p4\", 0),\n+      new EstimatedParameter(\"p5\", 0)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[0] }, 0.0),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[1] }, 1.1),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[2] }, 2.2),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[3] }, 3.3),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[4] }, 4.4),\n+      new LinearMeasurement(new double[] {2}, new EstimatedParameter[] { p[5] }, 5.5)\n+    });\n+  LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+  estimator.estimate(problem);\n+  assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+  for (int i = 0; i < p.length; ++i) {\n+    assertEquals(0.55 * i, p[i].getEstimate(), 1.0e-10);\n+  }\n+}\n+\n+  public void testOneSet() throws OptimizationException {\n+\n+    EstimatedParameter[] p = {\n+       new EstimatedParameter(\"p0\", 0),\n+       new EstimatedParameter(\"p1\", 0),\n+       new EstimatedParameter(\"p2\", 0)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0 },\n+                            new EstimatedParameter[] { p[0] },\n+                            1.0),\n+      new LinearMeasurement(new double[] { -1.0, 1.0 },\n+                            new EstimatedParameter[] { p[0], p[1] },\n+                            1.0),\n+      new LinearMeasurement(new double[] { -1.0, 1.0 },\n+                            new EstimatedParameter[] { p[1], p[2] },\n+                            1.0)\n+    });\n+\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals(1.0, p[0].getEstimate(), 1.0e-10);\n+    assertEquals(2.0, p[1].getEstimate(), 1.0e-10);\n+    assertEquals(3.0, p[2].getEstimate(), 1.0e-10);\n+\n+  }\n+\n+  public void testTwoSets() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 0),\n+      new EstimatedParameter(\"p1\", 1),\n+      new EstimatedParameter(\"p2\", 2),\n+      new EstimatedParameter(\"p3\", 3),\n+      new EstimatedParameter(\"p4\", 4),\n+      new EstimatedParameter(\"p5\", 5)\n+    };\n+\n+    double epsilon = 1.0e-7;\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+\n+      // 4 elements sub-problem\n+      new LinearMeasurement(new double[] {  2.0,  1.0,  4.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[3] },\n+                            2.0),\n+      new LinearMeasurement(new double[] { -4.0, -2.0,   3.0, -7.0 },\n+                           new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                           -9.0),\n+      new LinearMeasurement(new double[] {  4.0,  1.0,  -2.0,  8.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            2.0),\n+      new LinearMeasurement(new double[] { -3.0, -12.0, -1.0 },\n+                           new EstimatedParameter[] { p[1], p[2], p[3] },\n+                           2.0),\n+\n+      // 2 elements sub-problem\n+      new LinearMeasurement(new double[] { epsilon, 1.0 },\n+                            new EstimatedParameter[] { p[4], p[5] },\n+                            1.0 + epsilon * epsilon),\n+      new LinearMeasurement(new double[] {  1.0, 1.0 },\n+                            new EstimatedParameter[] { p[4], p[5] },\n+                            2.0)\n+\n+    });\n+\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals( 3.0, p[0].getEstimate(), 1.0e-10);\n+    assertEquals( 4.0, p[1].getEstimate(), 1.0e-10);\n+    assertEquals(-1.0, p[2].getEstimate(), 1.0e-10);\n+    assertEquals(-2.0, p[3].getEstimate(), 1.0e-10);\n+    assertEquals( 1.0 + epsilon, p[4].getEstimate(), 1.0e-10);\n+    assertEquals( 1.0 - epsilon, p[5].getEstimate(), 1.0e-10);\n+\n+  }\n+\n+  public void testNonInversible() throws OptimizationException {\n+\n+    EstimatedParameter[] p = {\n+       new EstimatedParameter(\"p0\", 0),\n+       new EstimatedParameter(\"p1\", 0),\n+       new EstimatedParameter(\"p2\", 0)\n+    };\n+    LinearMeasurement[] m = new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] {  1.0, 2.0, -3.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2] },\n+                            1.0),\n+      new LinearMeasurement(new double[] {  2.0, 1.0,  3.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2] },\n+                            1.0),\n+      new LinearMeasurement(new double[] { -3.0, -9.0 },\n+                            new EstimatedParameter[] { p[0], p[2] },\n+                            1.0)\n+    };\n+    LinearProblem problem = new LinearProblem(m);\n+\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    double initialCost = estimator.getRMS(problem);\n+    estimator.estimate(problem);\n+    assertTrue(estimator.getRMS(problem) < initialCost);\n+    assertTrue(Math.sqrt(m.length) * estimator.getRMS(problem) > 0.6);\n+    try {\n+        estimator.getCovariances(problem);\n+        fail(\"an exception should have been thrown\");\n+    } catch (OptimizationException ee) {\n+        // expected behavior\n+    } catch (Exception e) {\n+        fail(\"wrong exception caught\");\n+    }\n+   double dJ0 = 2 * (m[0].getResidual() * m[0].getPartial(p[0])\n+                    + m[1].getResidual() * m[1].getPartial(p[0])\n+                    + m[2].getResidual() * m[2].getPartial(p[0]));\n+    double dJ1 = 2 * (m[0].getResidual() * m[0].getPartial(p[1])\n+                    + m[1].getResidual() * m[1].getPartial(p[1]));\n+    double dJ2 = 2 * (m[0].getResidual() * m[0].getPartial(p[2])\n+                    + m[1].getResidual() * m[1].getPartial(p[2])\n+                    + m[2].getResidual() * m[2].getPartial(p[2]));\n+    assertEquals(0, dJ0, 1.0e-10);\n+    assertEquals(0, dJ1, 1.0e-10);\n+    assertEquals(0, dJ2, 1.0e-10);\n+\n+  }\n+\n+  public void testIllConditioned() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 0),\n+      new EstimatedParameter(\"p1\", 1),\n+      new EstimatedParameter(\"p2\", 2),\n+      new EstimatedParameter(\"p3\", 3)\n+    };\n+\n+    LinearProblem problem1 = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 10.0, 7.0,  8.0,  7.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            32.0),\n+      new LinearMeasurement(new double[] {  7.0, 5.0,  6.0,  5.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            23.0),\n+      new LinearMeasurement(new double[] {  8.0, 6.0, 10.0,  9.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            33.0),\n+      new LinearMeasurement(new double[] {  7.0, 5.0,  9.0, 10.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            31.0)\n+    });\n+    LevenbergMarquardtEstimator estimator1 = new LevenbergMarquardtEstimator();\n+    estimator1.estimate(problem1);\n+    assertEquals(0, estimator1.getRMS(problem1), 1.0e-10);\n+    assertEquals(1.0, p[0].getEstimate(), 1.0e-10);\n+    assertEquals(1.0, p[1].getEstimate(), 1.0e-10);\n+    assertEquals(1.0, p[2].getEstimate(), 1.0e-10);\n+    assertEquals(1.0, p[3].getEstimate(), 1.0e-10);\n+\n+    LinearProblem problem2 = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 10.0, 7.0,  8.1,  7.2 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            32.0),\n+      new LinearMeasurement(new double[] {  7.08, 5.04,  6.0,  5.0 },\n+                            new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            23.0),\n+      new LinearMeasurement(new double[] {  8.0, 5.98, 9.89,  9.0 },\n+                             new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            33.0),\n+      new LinearMeasurement(new double[] {  6.99, 4.99,  9.0, 9.98 },\n+                             new EstimatedParameter[] { p[0], p[1], p[2], p[3] },\n+                            31.0)\n+    });\n+    LevenbergMarquardtEstimator estimator2 = new LevenbergMarquardtEstimator();\n+    estimator2.estimate(problem2);\n+    assertEquals(0, estimator2.getRMS(problem2), 1.0e-10);\n+    assertEquals(-81.0, p[0].getEstimate(), 1.0e-8);\n+    assertEquals(137.0, p[1].getEstimate(), 1.0e-8);\n+    assertEquals(-34.0, p[2].getEstimate(), 1.0e-8);\n+    assertEquals( 22.0, p[3].getEstimate(), 1.0e-8);\n+\n+  }\n+\n+  public void testMoreEstimatedParametersSimple() throws OptimizationException {\n+\n+    EstimatedParameter[] p = {\n+       new EstimatedParameter(\"p0\", 7),\n+       new EstimatedParameter(\"p1\", 6),\n+       new EstimatedParameter(\"p2\", 5),\n+       new EstimatedParameter(\"p3\", 4)\n+     };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 3.0, 2.0 },\n+                             new EstimatedParameter[] { p[0], p[1] },\n+                             7.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0, 1.0 },\n+                             new EstimatedParameter[] { p[1], p[2], p[3] },\n+                             3.0),\n+      new LinearMeasurement(new double[] { 2.0, 1.0 },\n+                             new EstimatedParameter[] { p[0], p[2] },\n+                             5.0)\n+    });\n+\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+\n+  }\n+\n+  public void testMoreEstimatedParametersUnsorted() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 2),\n+      new EstimatedParameter(\"p1\", 2),\n+      new EstimatedParameter(\"p2\", 2),\n+      new EstimatedParameter(\"p3\", 2),\n+      new EstimatedParameter(\"p4\", 2),\n+      new EstimatedParameter(\"p5\", 2)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0, 1.0 },\n+                           new EstimatedParameter[] { p[0], p[1] },\n+                           3.0),\n+      new LinearMeasurement(new double[] { 1.0, 1.0, 1.0 },\n+                           new EstimatedParameter[] { p[2], p[3], p[4] },\n+                           12.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                           new EstimatedParameter[] { p[4], p[5] },\n+                           -1.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0, 1.0 },\n+                           new EstimatedParameter[] { p[3], p[2], p[5] },\n+                           7.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                           new EstimatedParameter[] { p[4], p[3] },\n+                           1.0)\n+    });\n+\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals(3.0, p[2].getEstimate(), 1.0e-10);\n+    assertEquals(4.0, p[3].getEstimate(), 1.0e-10);\n+    assertEquals(5.0, p[4].getEstimate(), 1.0e-10);\n+    assertEquals(6.0, p[5].getEstimate(), 1.0e-10);\n+\n+  }\n+\n+  public void testRedundantEquations() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 1),\n+      new EstimatedParameter(\"p1\", 1)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0, 1.0 },\n+                             new EstimatedParameter[] { p[0], p[1] },\n+                             3.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                             new EstimatedParameter[] { p[0], p[1] },\n+                             1.0),\n+      new LinearMeasurement(new double[] { 1.0, 3.0 },\n+                             new EstimatedParameter[] { p[0], p[1] },\n+                             5.0)\n+    });\n+\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(problem);\n+    assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    assertEquals(2.0, p[0].getEstimate(), 1.0e-10);\n+    assertEquals(1.0, p[1].getEstimate(), 1.0e-10);\n+\n+  }\n+\n+  public void testInconsistentEquations() throws OptimizationException {\n+    EstimatedParameter[] p = {\n+      new EstimatedParameter(\"p0\", 1),\n+      new EstimatedParameter(\"p1\", 1)\n+    };\n+    LinearProblem problem = new LinearProblem(new LinearMeasurement[] {\n+      new LinearMeasurement(new double[] { 1.0, 1.0 },\n+                            new EstimatedParameter[] { p[0], p[1] },\n+                            3.0),\n+      new LinearMeasurement(new double[] { 1.0, -1.0 },\n+                            new EstimatedParameter[] { p[0], p[1] },\n+                            1.0),\n+      new LinearMeasurement(new double[] { 1.0, 3.0 },\n+                            new EstimatedParameter[] { p[0], p[1] },\n+                            4.0)\n+    });\n+\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(problem);\n+    assertTrue(estimator.getRMS(problem) > 0.1);\n+\n+  }\n+\n+  public void testControlParameters() throws OptimizationException {\n+      Circle circle = new Circle(98.680, 47.345);\n+      circle.addPoint( 30.0,  68.0);\n+      circle.addPoint( 50.0,  -6.0);\n+      circle.addPoint(110.0, -20.0);\n+      circle.addPoint( 35.0,  15.0);\n+      circle.addPoint( 45.0,  97.0);\n+      checkEstimate(circle, 0.1, 10, 1.0e-14, 1.0e-16, 1.0e-10, false);\n+      checkEstimate(circle, 0.1, 10, 1.0e-15, 1.0e-17, 1.0e-10, true);\n+      checkEstimate(circle, 0.1,  5, 1.0e-15, 1.0e-16, 1.0e-10, true);\n+      circle.addPoint(300, -300);\n+      checkEstimate(circle, 0.1, 20, 1.0e-18, 1.0e-16, 1.0e-10, true);\n+  }\n+\n+  private void checkEstimate(EstimationProblem problem,\n+                             double initialStepBoundFactor, int maxCostEval,\n+                             double costRelativeTolerance, double parRelativeTolerance,\n+                             double orthoTolerance, boolean shouldFail) {\n+      try {\n+        LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+        estimator.setInitialStepBoundFactor(initialStepBoundFactor);\n+        estimator.setMaxCostEval(maxCostEval);\n+        estimator.setCostRelativeTolerance(costRelativeTolerance);\n+        estimator.setParRelativeTolerance(parRelativeTolerance);\n+        estimator.setOrthoTolerance(orthoTolerance);\n+        estimator.estimate(problem);\n+        assertTrue(! shouldFail);\n+      } catch (OptimizationException ee) {\n+        assertTrue(shouldFail);\n+      } catch (Exception e) {\n+        fail(\"wrong exception type caught\");\n+      }\n+    }\n+\n+  public void testCircleFitting() throws OptimizationException {\n+      Circle circle = new Circle(98.680, 47.345);\n+      circle.addPoint( 30.0,  68.0);\n+      circle.addPoint( 50.0,  -6.0);\n+      circle.addPoint(110.0, -20.0);\n+      circle.addPoint( 35.0,  15.0);\n+      circle.addPoint( 45.0,  97.0);\n+      LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+      estimator.estimate(circle);\n+      assertTrue(estimator.getCostEvaluations() < 10);\n+      assertTrue(estimator.getJacobianEvaluations() < 10);\n+      double rms = estimator.getRMS(circle);\n+      assertEquals(1.768262623567235,  Math.sqrt(circle.getM()) * rms,  1.0e-10);\n+      assertEquals(69.96016176931406, circle.getRadius(), 1.0e-10);\n+      assertEquals(96.07590211815305, circle.getX(),      1.0e-10);\n+      assertEquals(48.13516790438953, circle.getY(),      1.0e-10);\n+      double[][] cov = estimator.getCovariances(circle);\n+      assertEquals(1.839, cov[0][0], 0.001);\n+      assertEquals(0.731, cov[0][1], 0.001);\n+      assertEquals(cov[0][1], cov[1][0], 1.0e-14);\n+      assertEquals(0.786, cov[1][1], 0.001);\n+      double[] errors = estimator.guessParametersErrors(circle);\n+      assertEquals(1.384, errors[0], 0.001);\n+      assertEquals(0.905, errors[1], 0.001);\n+  \n+      // add perfect measurements and check errors are reduced\n+      double cx = circle.getX();\n+      double cy = circle.getY();\n+      double  r = circle.getRadius();\n+      for (double d= 0; d < 2 * Math.PI; d += 0.01) {\n+          circle.addPoint(cx + r * Math.cos(d), cy + r * Math.sin(d));\n+      }\n+      estimator = new LevenbergMarquardtEstimator();\n+      estimator.estimate(circle);\n+      cov = estimator.getCovariances(circle);\n+      assertEquals(0.004, cov[0][0], 0.001);\n+      assertEquals(6.40e-7, cov[0][1], 1.0e-9);\n+      assertEquals(cov[0][1], cov[1][0], 1.0e-14);\n+      assertEquals(0.003, cov[1][1], 0.001);\n+      errors = estimator.guessParametersErrors(circle);\n+      assertEquals(0.004, errors[0], 0.001);\n+      assertEquals(0.004, errors[1], 0.001);\n+\n+  }\n+\n+  public void testCircleFittingBadInit() throws OptimizationException {\n+    Circle circle = new Circle(-12, -12);\n+    double[][] points = new double[][] {\n+      {-0.312967,  0.072366}, {-0.339248,  0.132965}, {-0.379780,  0.202724},\n+      {-0.390426,  0.260487}, {-0.361212,  0.328325}, {-0.346039,  0.392619},\n+      {-0.280579,  0.444306}, {-0.216035,  0.470009}, {-0.149127,  0.493832},\n+      {-0.075133,  0.483271}, {-0.007759,  0.452680}, { 0.060071,  0.410235},\n+      { 0.103037,  0.341076}, { 0.118438,  0.273884}, { 0.131293,  0.192201},\n+      { 0.115869,  0.129797}, { 0.072223,  0.058396}, { 0.022884,  0.000718},\n+      {-0.053355, -0.020405}, {-0.123584, -0.032451}, {-0.216248, -0.032862},\n+      {-0.278592, -0.005008}, {-0.337655,  0.056658}, {-0.385899,  0.112526},\n+      {-0.405517,  0.186957}, {-0.415374,  0.262071}, {-0.387482,  0.343398},\n+      {-0.347322,  0.397943}, {-0.287623,  0.458425}, {-0.223502,  0.475513},\n+      {-0.135352,  0.478186}, {-0.061221,  0.483371}, { 0.003711,  0.422737},\n+      { 0.065054,  0.375830}, { 0.108108,  0.297099}, { 0.123882,  0.222850},\n+      { 0.117729,  0.134382}, { 0.085195,  0.056820}, { 0.029800, -0.019138},\n+      {-0.027520, -0.072374}, {-0.102268, -0.091555}, {-0.200299, -0.106578},\n+      {-0.292731, -0.091473}, {-0.356288, -0.051108}, {-0.420561,  0.014926},\n+      {-0.471036,  0.074716}, {-0.488638,  0.182508}, {-0.485990,  0.254068},\n+      {-0.463943,  0.338438}, {-0.406453,  0.404704}, {-0.334287,  0.466119},\n+      {-0.254244,  0.503188}, {-0.161548,  0.495769}, {-0.075733,  0.495560},\n+      { 0.001375,  0.434937}, { 0.082787,  0.385806}, { 0.115490,  0.323807},\n+      { 0.141089,  0.223450}, { 0.138693,  0.131703}, { 0.126415,  0.049174},\n+      { 0.066518, -0.010217}, {-0.005184, -0.070647}, {-0.080985, -0.103635},\n+      {-0.177377, -0.116887}, {-0.260628, -0.100258}, {-0.335756, -0.056251},\n+      {-0.405195, -0.000895}, {-0.444937,  0.085456}, {-0.484357,  0.175597},\n+      {-0.472453,  0.248681}, {-0.438580,  0.347463}, {-0.402304,  0.422428},\n+      {-0.326777,  0.479438}, {-0.247797,  0.505581}, {-0.152676,  0.519380},\n+      {-0.071754,  0.516264}, { 0.015942,  0.472802}, { 0.076608,  0.419077},\n+      { 0.127673,  0.330264}, { 0.159951,  0.262150}, { 0.153530,  0.172681},\n+      { 0.140653,  0.089229}, { 0.078666,  0.024981}, { 0.023807, -0.037022},\n+      {-0.048837, -0.077056}, {-0.127729, -0.075338}, {-0.221271, -0.067526}\n+    };\n+    for (int i = 0; i < points.length; ++i) {\n+      circle.addPoint(points[i][0], points[i][1]);\n+    }\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.estimate(circle);\n+    assertTrue(estimator.getCostEvaluations() < 15);\n+    assertTrue(estimator.getJacobianEvaluations() < 10);\n+    assertEquals( 0.030184491196225207, estimator.getRMS(circle), 1.0e-9);\n+    assertEquals( 0.2922350065939634,   circle.getRadius(), 1.0e-9);\n+    assertEquals(-0.15173845023862165,  circle.getX(),      1.0e-8);\n+    assertEquals( 0.20750021499570379,  circle.getY(),      1.0e-8);\n+  }\n+\n+  public void testMath199() {\n+      try {\n+          QuadraticProblem problem = new QuadraticProblem();\n+          problem.addPoint (0, -3.182591015485607, 0.0);\n+          problem.addPoint (1, -2.5581184967730577, 4.4E-323);\n+          problem.addPoint (2, -2.1488478161387325, 1.0);\n+          problem.addPoint (3, -1.9122489313410047, 4.4E-323);\n+          problem.addPoint (4, 1.7785661310051026, 0.0);\n+          new LevenbergMarquardtEstimator().estimate(problem);\n+          fail(\"an exception should have been thrown\");\n+      } catch (OptimizationException ee) {\n+          // expected behavior\n+      }\n+\n+  }\n+\n+  private static class LinearProblem implements EstimationProblem {\n+\n+    public LinearProblem(LinearMeasurement[] measurements) {\n+      this.measurements = measurements;\n+    }\n+\n+    public WeightedMeasurement[] getMeasurements() {\n+      return measurements;\n+    }\n+\n+    public EstimatedParameter[] getUnboundParameters() {\n+      return getAllParameters();\n+    }\n+\n+    public EstimatedParameter[] getAllParameters() {\n+      HashSet<EstimatedParameter> set = new HashSet<EstimatedParameter>();\n+      for (int i = 0; i < measurements.length; ++i) {\n+        EstimatedParameter[] parameters = measurements[i].getParameters();\n+        for (int j = 0; j < parameters.length; ++j) {\n+          set.add(parameters[j]);\n+        }\n+      }\n+      return (EstimatedParameter[]) set.toArray(new EstimatedParameter[set.size()]);\n+    }\n+  \n+    private LinearMeasurement[] measurements;\n+\n+  }\n+\n+  private static class LinearMeasurement extends WeightedMeasurement {\n+\n+    public LinearMeasurement(double[] factors, EstimatedParameter[] parameters,\n+                             double setPoint) {\n+      super(1.0, setPoint);\n+      this.factors = factors;\n+      this.parameters = parameters;\n+    }\n+\n+    public double getTheoreticalValue() {\n+      double v = 0;\n+      for (int i = 0; i < factors.length; ++i) {\n+        v += factors[i] * parameters[i].getEstimate();\n+      }\n+      return v;\n+    }\n+\n+    public double getPartial(EstimatedParameter parameter) {\n+      for (int i = 0; i < parameters.length; ++i) {\n+        if (parameters[i] == parameter) {\n+          return factors[i];\n+        }\n+      }\n+      return 0;\n+    }\n+\n+    public EstimatedParameter[] getParameters() {\n+      return parameters;\n+    }\n+\n+    private double[] factors;\n+    private EstimatedParameter[] parameters;\n+    private static final long serialVersionUID = -3922448707008868580L;\n+\n+  }\n+\n+  private static class Circle implements EstimationProblem {\n+\n+    public Circle(double cx, double cy) {\n+      this.cx = new EstimatedParameter(\"cx\", cx);\n+      this.cy = new EstimatedParameter(\"cy\", cy);\n+      points  = new ArrayList<PointModel>();\n+    }\n+\n+    public void addPoint(double px, double py) {\n+      points.add(new PointModel(px, py));\n+    }\n+\n+    public int getM() {\n+      return points.size();\n+    }\n+\n+    public WeightedMeasurement[] getMeasurements() {\n+      return (WeightedMeasurement[]) points.toArray(new PointModel[points.size()]);\n+    }\n+\n+    public EstimatedParameter[] getAllParameters() {\n+      return new EstimatedParameter[] { cx, cy };\n+    }\n+\n+    public EstimatedParameter[] getUnboundParameters() {\n+      return new EstimatedParameter[] { cx, cy };\n+    }\n+\n+    public double getPartialRadiusX() {\n+      double dRdX = 0;\n+      for (PointModel point : points) {\n+        dRdX += point.getPartialDiX();\n+      }\n+      return dRdX / points.size();\n+    }\n+\n+    public double getPartialRadiusY() {\n+      double dRdY = 0;\n+      for (PointModel point : points) {\n+        dRdY += point.getPartialDiY();\n+      }\n+      return dRdY / points.size();\n+    }\n+\n+   public double getRadius() {\n+      double r = 0;\n+      for (PointModel point : points) {\n+        r += point.getCenterDistance();\n+      }\n+      return r / points.size();\n+    }\n+\n+    public double getX() {\n+      return cx.getEstimate();\n+    }\n+\n+    public double getY() {\n+      return cy.getEstimate();\n+    }\n+\n+    private class PointModel extends WeightedMeasurement {\n+\n+      public PointModel(double px, double py) {\n+        super(1.0, 0.0);\n+        this.px = px;\n+        this.py = py;\n+      }\n+\n+      public double getPartial(EstimatedParameter parameter) {\n+        if (parameter == cx) {\n+          return getPartialDiX() - getPartialRadiusX();\n+        } else if (parameter == cy) {\n+          return getPartialDiY() - getPartialRadiusY();\n+        }\n+        return 0;\n+      }\n+\n+      public double getCenterDistance() {\n+        double dx = px - cx.getEstimate();\n+        double dy = py - cy.getEstimate();\n+        return Math.sqrt(dx * dx + dy * dy);\n+      }\n+\n+      public double getPartialDiX() {\n+        return (cx.getEstimate() - px) / getCenterDistance();\n+      }\n+\n+      public double getPartialDiY() {\n+        return (cy.getEstimate() - py) / getCenterDistance();\n+      }\n+\n+      public double getTheoreticalValue() {\n+        return getCenterDistance() - getRadius();\n+      }\n+\n+      private double px;\n+      private double py;\n+      private static final long serialVersionUID = 1L;\n+\n+    }\n+\n+    private EstimatedParameter cx;\n+    private EstimatedParameter cy;\n+    private ArrayList<PointModel> points;\n+\n+  }\n+\n+  private static class QuadraticProblem extends SimpleEstimationProblem {\n+\n+      private EstimatedParameter a;\n+      private EstimatedParameter b;\n+      private EstimatedParameter c;\n+\n+      public QuadraticProblem() {\n+          a = new EstimatedParameter(\"a\", 0.0);\n+          b = new EstimatedParameter(\"b\", 0.0);\n+          c = new EstimatedParameter(\"c\", 0.0);\n+          addParameter(a);\n+          addParameter(b);\n+          addParameter(c);\n+      }\n+\n+      public void addPoint(double x, double y, double w) {\n+          addMeasurement(new LocalMeasurement(x, y, w));\n+      }\n+\n+      public double getA() {\n+          return a.getEstimate();\n+      }\n+\n+      public double getB() {\n+          return b.getEstimate();\n+      }\n+\n+      public double getC() {\n+          return c.getEstimate();\n+      }\n+\n+      public double theoreticalValue(double x) {\n+          return ( (a.getEstimate() * x + b.getEstimate() ) * x + c.getEstimate());\n+      }\n+\n+      private double partial(double x, EstimatedParameter parameter) {\n+          if (parameter == a) {\n+              return x * x;\n+          } else if (parameter == b) {\n+              return x;\n+          } else {\n+              return 1.0;\n+          }\n+      }\n+\n+      private class LocalMeasurement extends WeightedMeasurement {\n+\n+        private static final long serialVersionUID = 1555043155023729130L;\n+        private final double x;\n+\n+          // constructor\n+          public LocalMeasurement(double x, double y, double w) {\n+              super(w, y);\n+              this.x = x;\n+          }\n+\n+          public double getTheoreticalValue() {\n+              return theoreticalValue(x);\n+          }\n+\n+          public double getPartial(EstimatedParameter parameter) {\n+              return partial(x, parameter);\n+          }\n+\n+      }\n+  }\n+\n+  public static Test suite() {\n+    return new TestSuite(LevenbergMarquardtEstimatorTest.class);\n+  }\n+\n+}\n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/general/MinpackTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.util.Arrays;\n+\n+import org.apache.commons.math.optimization.OptimizationException;\n+\n+\n+import junit.framework.*;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files. \n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class MinpackTest\n+  extends TestCase {\n+\n+  public MinpackTest(String name) {\n+    super(name);\n+  }\n+\n+  public void testMinpackLinearFullRank()\n+    throws OptimizationException {\n+    minpackTest(new LinearFullRankFunction(10, 5, 1.0,\n+                                           5.0, 2.23606797749979), false);\n+    minpackTest(new LinearFullRankFunction(50, 5, 1.0,\n+                                           8.06225774829855, 6.70820393249937), false);\n+  }\n+\n+  public void testMinpackLinearRank1()\n+    throws OptimizationException {\n+    minpackTest(new LinearRank1Function(10, 5, 1.0,\n+                                        291.521868819476, 1.4638501094228), false);\n+    minpackTest(new LinearRank1Function(50, 5, 1.0,\n+                                        3101.60039334535, 3.48263016573496), false);\n+  }\n+\n+  public void testMinpackLinearRank1ZeroColsAndRows()\n+    throws OptimizationException {\n+    minpackTest(new LinearRank1ZeroColsAndRowsFunction(10, 5, 1.0), false);\n+    minpackTest(new LinearRank1ZeroColsAndRowsFunction(50, 5, 1.0), false);\n+  }\n+\n+  public void testMinpackRosenbrok()\n+    throws OptimizationException {\n+    minpackTest(new RosenbrockFunction(new double[] { -1.2, 1.0 },\n+                                       Math.sqrt(24.2)), false);\n+    minpackTest(new RosenbrockFunction(new double[] { -12.0, 10.0 },\n+                                       Math.sqrt(1795769.0)), false);\n+    minpackTest(new RosenbrockFunction(new double[] { -120.0, 100.0 },\n+                                       11.0 * Math.sqrt(169000121.0)), false);\n+  }\n+\n+  public void testMinpackHelicalValley()\n+    throws OptimizationException {\n+    minpackTest(new HelicalValleyFunction(new double[] { -1.0, 0.0, 0.0 },\n+                                          50.0), false);\n+    minpackTest(new HelicalValleyFunction(new double[] { -10.0, 0.0, 0.0 },\n+                                          102.95630140987), false);\n+    minpackTest(new HelicalValleyFunction(new double[] { -100.0, 0.0, 0.0},\n+                                          991.261822123701), false);\n+  }\n+    \n+  public void testMinpackPowellSingular()\n+    throws OptimizationException {\n+    minpackTest(new PowellSingularFunction(new double[] { 3.0, -1.0, 0.0, 1.0 },\n+                                           14.6628782986152), false);\n+    minpackTest(new PowellSingularFunction(new double[] { 30.0, -10.0, 0.0, 10.0 },\n+                                           1270.9838708654), false);\n+    minpackTest(new PowellSingularFunction(new double[] { 300.0, -100.0, 0.0, 100.0 },\n+                                           126887.903284750), false);\n+  }\n+    \n+  public void testMinpackFreudensteinRoth()\n+    throws OptimizationException {\n+    minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n+                                             20.0124960961895, 6.99887517584575,\n+                                             new double[] {\n+                                               11.4124844654993,\n+                                               -0.896827913731509\n+                                             }), false);\n+    minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n+                                             12432.833948863, 6.9988751744895,\n+                                             new double[] {\n+                                               11.4130046614746,\n+                                               -0.896796038685958\n+                                             }), false);\n+    minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n+                                             11426454.595762, 6.99887517242903,\n+                                             new double[] {\n+                                               11.4127817857886,\n+                                               -0.89680510749204\n+                                             }), false);\n+  }\n+    \n+  public void testMinpackBard()\n+    throws OptimizationException {\n+    minpackTest(new BardFunction(1.0, 6.45613629515967, 0.0906359603390466,\n+                                 new double[] {\n+                                   0.0824105765758334,\n+                                   1.1330366534715,\n+                                   2.34369463894115\n+                                 }), false);\n+    minpackTest(new BardFunction(10.0, 36.1418531596785, 4.17476870138539,\n+                                 new double[] {\n+                                   0.840666673818329,\n+                                   -158848033.259565,\n+                                   -164378671.653535\n+                                 }), false);\n+    minpackTest(new BardFunction(100.0, 384.114678637399, 4.17476870135969,\n+                                 new double[] {\n+                                   0.840666673867645,\n+                                   -158946167.205518,\n+                                   -164464906.857771\n+                                 }), false);\n+  }\n+    \n+  public void testMinpackKowalikOsborne()\n+    throws OptimizationException {\n+    minpackTest(new KowalikOsborneFunction(new double[] { 0.25, 0.39, 0.415, 0.39 },\n+                                           0.0728915102882945,\n+                                           0.017535837721129,\n+                                           new double[] {\n+                                             0.192807810476249,\n+                                             0.191262653354071,\n+                                             0.123052801046931,\n+                                             0.136053221150517\n+                                           }), false);\n+    minpackTest(new KowalikOsborneFunction(new double[] { 2.5, 3.9, 4.15, 3.9 },\n+                                           2.97937007555202,\n+                                           0.032052192917937,\n+                                           new double[] {\n+                                             728675.473768287,\n+                                             -14.0758803129393,\n+                                             -32977797.7841797,\n+                                             -20571594.1977912\n+                                           }), false);\n+    minpackTest(new KowalikOsborneFunction(new double[] { 25.0, 39.0, 41.5, 39.0 },\n+                                           29.9590617016037,\n+                                           0.0175364017658228,\n+                                           new double[] {\n+                                             0.192948328597594,\n+                                             0.188053165007911,\n+                                             0.122430604321144,\n+                                             0.134575665392506\n+                                           }), true);\n+  }\n+    \n+  public void testMinpackMeyer()\n+    throws OptimizationException {\n+    minpackTest(new MeyerFunction(new double[] { 0.02, 4000.0, 250.0 },\n+                                  41153.4665543031, 9.37794514651874,\n+                                  new double[] {\n+                                    0.00560963647102661,\n+                                    6181.34634628659,\n+                                    345.223634624144\n+                                  }), false);\n+    minpackTest(new MeyerFunction(new double[] { 0.2, 40000.0, 2500.0 },\n+                                  4168216.89130846, 792.917871779501,\n+                                  new double[] {\n+                                    1.42367074157994e-11,\n+                                    33695.7133432541,\n+                                    901.268527953801\n+                                  }), true);\n+  }\n+    \n+  public void testMinpackWatson()\n+    throws OptimizationException {\n+  \n+    minpackTest(new WatsonFunction(6, 0.0,\n+                                   5.47722557505166, 0.0478295939097601,\n+                                   new double[] {\n+                                     -0.0157249615083782, 1.01243488232965,\n+                                     -0.232991722387673,  1.26043101102818,\n+                                     -1.51373031394421,   0.99299727291842\n+                                   }), false);\n+    minpackTest(new WatsonFunction(6, 10.0,\n+                                   6433.12578950026, 0.0478295939096951,\n+                                   new double[] {\n+                                     -0.0157251901386677, 1.01243485860105,\n+                                     -0.232991545843829,  1.26042932089163,\n+                                     -1.51372776706575,   0.99299573426328\n+                                   }), false);\n+    minpackTest(new WatsonFunction(6, 100.0,\n+                                   674256.040605213, 0.047829593911544,\n+                                   new double[] {\n+                                    -0.0157247019712586, 1.01243490925658,\n+                                    -0.232991922761641,  1.26043292929555,\n+                                    -1.51373320452707,   0.99299901922322\n+                                   }), false);\n+\n+    minpackTest(new WatsonFunction(9, 0.0,\n+                                   5.47722557505166, 0.00118311459212420,\n+                                   new double[] {\n+                                    -0.153070644166722e-4, 0.999789703934597,\n+                                     0.0147639634910978,   0.146342330145992,\n+                                     1.00082109454817,    -2.61773112070507,\n+                                     4.10440313943354,    -3.14361226236241,\n+                                     1.05262640378759\n+                                   }), false);\n+    minpackTest(new WatsonFunction(9, 10.0,\n+                                   12088.127069307, 0.00118311459212513,\n+                                   new double[] {\n+                                   -0.153071334849279e-4, 0.999789703941234,\n+                                    0.0147639629786217,   0.146342334818836,\n+                                    1.00082107321386,    -2.61773107084722,\n+                                    4.10440307655564,    -3.14361222178686,\n+                                    1.05262639322589\n+                                   }), false);\n+    minpackTest(new WatsonFunction(9, 100.0,\n+                                   1269109.29043834, 0.00118311459212384,\n+                                   new double[] {\n+                                    -0.153069523352176e-4, 0.999789703958371,\n+                                     0.0147639625185392,   0.146342341096326,\n+                                     1.00082104729164,    -2.61773101573645,\n+                                     4.10440301427286,    -3.14361218602503,\n+                                     1.05262638516774\n+                                   }), false);\n+\n+    minpackTest(new WatsonFunction(12, 0.0,\n+                                   5.47722557505166, 0.217310402535861e-4,\n+                                   new double[] {\n+                                    -0.660266001396382e-8, 1.00000164411833,\n+                                    -0.000563932146980154, 0.347820540050756,\n+                                    -0.156731500244233,    1.05281515825593,\n+                                    -3.24727109519451,     7.2884347837505,\n+                                   -10.271848098614,       9.07411353715783,\n+                                    -4.54137541918194,     1.01201187975044\n+                                   }), false);\n+    minpackTest(new WatsonFunction(12, 10.0,\n+                                   19220.7589790951, 0.217310402518509e-4,\n+                                   new double[] {\n+                                    -0.663710223017410e-8, 1.00000164411787,\n+                                    -0.000563932208347327, 0.347820540486998,\n+                                    -0.156731503955652,    1.05281517654573,\n+                                    -3.2472711515214,      7.28843489430665,\n+                                   -10.2718482369638,      9.07411364383733,\n+                                    -4.54137546533666,     1.01201188830857\n+                                   }), false);\n+    minpackTest(new WatsonFunction(12, 100.0,\n+                                   2018918.04462367, 0.217310402539845e-4,\n+                                   new double[] {\n+                                    -0.663806046485249e-8, 1.00000164411786,\n+                                    -0.000563932210324959, 0.347820540503588,\n+                                    -0.156731504091375,    1.05281517718031,\n+                                    -3.24727115337025,     7.28843489775302,\n+                                   -10.2718482410813,      9.07411364688464,\n+                                    -4.54137546660822,     1.0120118885369\n+                                   }), false);\n+\n+  }\n+    \n+  public void testMinpackBox3Dimensional()\n+  throws OptimizationException {\n+    minpackTest(new Box3DimensionalFunction(10, new double[] { 0.0, 10.0, 20.0 },\n+                                            32.1115837449572), false);\n+  }\n+    \n+  public void testMinpackJennrichSampson()\n+    throws OptimizationException {\n+    minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n+                                            64.5856498144943, 11.1517793413499,\n+                                            new double[] {\n+                                             0.257819926636811, 0.257829976764542\n+                                            }), false);\n+  }\n+\n+  public void testMinpackBrownDennis()\n+    throws OptimizationException {\n+    minpackTest(new BrownDennisFunction(20,\n+                                        new double[] { 25.0, 5.0, -5.0, -1.0 },\n+                                        2815.43839161816, 292.954288244866,\n+                                        new double[] {\n+                                         -11.59125141003, 13.2024883984741,\n+                                         -0.403574643314272, 0.236736269844604\n+                                        }), false);\n+    minpackTest(new BrownDennisFunction(20,\n+                                        new double[] { 250.0, 50.0, -50.0, -10.0 },\n+                                        555073.354173069, 292.954270581415,\n+                                        new double[] {\n+                                         -11.5959274272203, 13.2041866926242,\n+                                         -0.403417362841545, 0.236771143410386\n+                                       }), false);\n+    minpackTest(new BrownDennisFunction(20,\n+                                        new double[] { 2500.0, 500.0, -500.0, -100.0 },\n+                                        61211252.2338581, 292.954306151134,\n+                                        new double[] {\n+                                         -11.5902596937374, 13.2020628854665,\n+                                         -0.403688070279258, 0.236665033746463\n+                                        }), false);\n+  }\n+    \n+  public void testMinpackChebyquad()\n+    throws OptimizationException {\n+    minpackTest(new ChebyquadFunction(1, 8, 1.0,\n+                                      1.88623796907732, 1.88623796907732,\n+                                      new double[] { 0.5 }), false);\n+    minpackTest(new ChebyquadFunction(1, 8, 10.0,\n+                                      5383344372.34005, 1.88424820499951,\n+                                      new double[] { 0.9817314924684 }), false);\n+    minpackTest(new ChebyquadFunction(1, 8, 100.0,\n+                                      0.118088726698392e19, 1.88424820499347,\n+                                      new double[] { 0.9817314852934 }), false);\n+    minpackTest(new ChebyquadFunction(8, 8, 1.0,\n+                                      0.196513862833975, 0.0593032355046727,\n+                                      new double[] {\n+                                        0.0431536648587336, 0.193091637843267,\n+                                        0.266328593812698,  0.499999334628884,\n+                                        0.500000665371116,  0.733671406187302,\n+                                        0.806908362156733,  0.956846335141266\n+                                      }), false);\n+    minpackTest(new ChebyquadFunction(9, 9, 1.0,\n+                                      0.16994993465202, 0.0,\n+                                      new double[] {\n+                                        0.0442053461357828, 0.199490672309881,\n+                                        0.23561910847106,   0.416046907892598,\n+                                        0.5,                0.583953092107402,\n+                                        0.764380891528940,  0.800509327690119,\n+                                        0.955794653864217\n+                                      }), false);\n+    minpackTest(new ChebyquadFunction(10, 10, 1.0,\n+                                      0.183747831178711, 0.0806471004038253,\n+                                      new double[] {\n+                                        0.0596202671753563, 0.166708783805937,\n+                                        0.239171018813509,  0.398885290346268,\n+                                        0.398883667870681,  0.601116332129320,\n+                                        0.60111470965373,   0.760828981186491,\n+                                        0.833291216194063,  0.940379732824644\n+                                      }), false);\n+  }\n+    \n+  public void testMinpackBrownAlmostLinear()\n+    throws OptimizationException {\n+    minpackTest(new BrownAlmostLinearFunction(10, 0.5,\n+                                              16.5302162063499, 0.0,\n+                                              new double[] {\n+                                                0.979430303349862, 0.979430303349862,\n+                                                0.979430303349862, 0.979430303349862,\n+                                                0.979430303349862, 0.979430303349862,\n+                                                0.979430303349862, 0.979430303349862,\n+                                                0.979430303349862, 1.20569696650138\n+                                              }), false);\n+    minpackTest(new BrownAlmostLinearFunction(10, 5.0,\n+                                              9765624.00089211, 0.0,\n+                                              new double[] {\n+                                               0.979430303349865, 0.979430303349865,\n+                                               0.979430303349865, 0.979430303349865,\n+                                               0.979430303349865, 0.979430303349865,\n+                                               0.979430303349865, 0.979430303349865,\n+                                               0.979430303349865, 1.20569696650135\n+                                              }), false);  \n+    minpackTest(new BrownAlmostLinearFunction(10, 50.0,\n+                                              0.9765625e17, 0.0,\n+                                              new double[] {\n+                                                1.0, 1.0, 1.0, 1.0, 1.0,\n+                                                1.0, 1.0, 1.0, 1.0, 1.0\n+                                              }), false);\n+    minpackTest(new BrownAlmostLinearFunction(30, 0.5,\n+                                              83.476044467848, 0.0,\n+                                              new double[] {\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 0.997754216442807,\n+                                                0.997754216442807, 1.06737350671578\n+                                              }), false);\n+    minpackTest(new BrownAlmostLinearFunction(40, 0.5,\n+                                              128.026364472323, 0.0,\n+                                              new double[] {\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                1.00000000000002, 1.00000000000002,\n+                                                0.999999999999121\n+                                              }), false);\n+    }\n+    \n+  public void testMinpackOsborne1()\n+    throws OptimizationException {\n+      minpackTest(new Osborne1Function(new double[] { 0.5, 1.5, -1.0, 0.01, 0.02, },\n+                                       0.937564021037838, 0.00739249260904843,\n+                                       new double[] {\n+                                         0.375410049244025, 1.93584654543108,\n+                                        -1.46468676748716, 0.0128675339110439,\n+                                         0.0221227011813076\n+                                       }), false);\n+    }\n+    \n+  public void testMinpackOsborne2()\n+    throws OptimizationException {\n+      \n+    minpackTest(new Osborne2Function(new double[] {\n+                                       1.3, 0.65, 0.65, 0.7, 0.6,\n+                                       3.0, 5.0, 7.0, 2.0, 4.5, 5.5\n+                                     },\n+                                     1.44686540984712, 0.20034404483314,\n+                                     new double[] {\n+                                       1.30997663810096,  0.43155248076,\n+                                       0.633661261602859, 0.599428560991695,\n+                                       0.754179768272449, 0.904300082378518,\n+                                       1.36579949521007, 4.82373199748107,\n+                                       2.39868475104871, 4.56887554791452,\n+                                       5.67534206273052\n+                                     }), false);\n+  }\n+\n+  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n+    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n+    estimator.setMaxCostEval(100 * (function.getN() + 1));\n+    estimator.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n+    estimator.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n+    estimator.setOrthoTolerance(2.22044604926e-16);\n+    assertTrue(function.checkTheoreticalStartCost(estimator.getRMS(function)));\n+    try {\n+      estimator.estimate(function);\n+      assertFalse(exceptionExpected);\n+    } catch (OptimizationException lsse) {\n+      assertTrue(exceptionExpected);\n+    }\n+    assertTrue(function.checkTheoreticalMinCost(estimator.getRMS(function)));\n+    assertTrue(function.checkTheoreticalMinParams());\n+  }\n+\n+  private static abstract class MinpackFunction implements EstimationProblem {\n+ \n+    protected MinpackFunction(int m,\n+                              double[] startParams,\n+                              double   theoreticalStartCost,\n+                              double   theoreticalMinCost,\n+                              double[] theoreticalMinParams) {\n+      this.m = m;\n+      this.n = startParams.length;\n+      parameters = new EstimatedParameter[n];\n+      for (int i = 0; i < n; ++i) {\n+        parameters[i] = new EstimatedParameter(\"p\" + i, startParams[i]);\n+      }\n+      this.theoreticalStartCost = theoreticalStartCost;\n+      this.theoreticalMinCost   = theoreticalMinCost;\n+      this.theoreticalMinParams = theoreticalMinParams;\n+      this.costAccuracy         = 1.0e-8;\n+      this.paramsAccuracy       = 1.0e-5;\n+    }\n+\n+    protected static double[] buildArray(int n, double x) {\n+      double[] array = new double[n];\n+      Arrays.fill(array, x);\n+      return array;\n+    }\n+\n+    protected void setCostAccuracy(double costAccuracy) {\n+      this.costAccuracy = costAccuracy;\n+    }\n+\n+    protected void setParamsAccuracy(double paramsAccuracy) {\n+      this.paramsAccuracy = paramsAccuracy;\n+    }\n+\n+    public int getN() {\n+      return parameters.length;\n+    }\n+\n+    public boolean checkTheoreticalStartCost(double rms) {\n+      double threshold = costAccuracy * (1.0 + theoreticalStartCost);\n+      return Math.abs(Math.sqrt(m) * rms - theoreticalStartCost) <= threshold;\n+    }\n+\n+    public boolean checkTheoreticalMinCost(double rms) {\n+      double threshold = costAccuracy * (1.0 + theoreticalMinCost);\n+     return Math.abs(Math.sqrt(m) * rms - theoreticalMinCost) <= threshold;\n+    }\n+\n+    public boolean checkTheoreticalMinParams() {\n+      if (theoreticalMinParams != null) {\n+        for (int i = 0; i < theoreticalMinParams.length; ++i) {\n+          double mi = theoreticalMinParams[i];\n+          double vi = parameters[i].getEstimate();\n+          if (Math.abs(mi - vi) > (paramsAccuracy * (1.0 + Math.abs(mi)))) {\n+            return false;\n+          }\n+        }\n+      }\n+      return true;\n+    }\n+ \n+    public WeightedMeasurement[] getMeasurements() {\n+      WeightedMeasurement[] measurements = new WeightedMeasurement[m];\n+      for (int i = 0; i < m; ++i) {\n+        measurements[i] = new MinpackMeasurement(i);\n+      }\n+      return measurements;\n+    }\n+\n+    public EstimatedParameter[] getUnboundParameters() {\n+      return parameters;\n+    }\n+\n+    public EstimatedParameter[] getAllParameters() {\n+      return parameters;\n+    }\n+\n+    protected abstract double[][] getJacobian();\n+\n+    protected abstract double[] getResiduals();\n+\n+    private class MinpackMeasurement extends WeightedMeasurement {\n+\n+      public MinpackMeasurement(int index) {\n+        super(1.0, 0.0);\n+        this.index = index;\n+      }\n+\n+      public double getTheoreticalValue() {\n+        // this is obviously NOT efficient as we recompute the whole vector\n+        // each time we need only one element, but it is only for test\n+        // purposes and is simpler to check.\n+        // This implementation should NOT be taken as an example, it is ugly!\n+        return getResiduals()[index];\n+      }\n+\n+      public double getPartial(EstimatedParameter parameter) {\n+        // this is obviously NOT efficient as we recompute the whole jacobian\n+        // each time we need only one element, but it is only for test\n+        // purposes and is simpler to check.\n+        // This implementation should NOT be taken as an example, it is ugly!\n+        for (int j = 0; j < n; ++j) {\n+          if (parameter == parameters[j]) {\n+            return getJacobian()[index][j];\n+          }\n+        }\n+        return 0;\n+      }\n+\n+      private int index;\n+      private static final long serialVersionUID = 1L;\n+\n+    }\n+\n+    protected int                  n;\n+    protected int                  m;\n+    protected EstimatedParameter[] parameters;\n+    protected double               theoreticalStartCost;\n+    protected double               theoreticalMinCost;\n+    protected double[]             theoreticalMinParams;\n+    protected double               costAccuracy;\n+    protected double               paramsAccuracy;\n+\n+  }\n+\n+  private static class LinearFullRankFunction extends MinpackFunction {\n+\n+    public LinearFullRankFunction(int m, int n, double x0,\n+                                  double theoreticalStartCost,\n+                                  double theoreticalMinCost) {\n+      super(m, buildArray(n, x0), theoreticalStartCost,\n+            theoreticalMinCost, buildArray(n, -1.0));\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double t = 2.0 / m;\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        jacobian[i] = new double[n];\n+        for (int j = 0; j < n; ++j) {\n+          jacobian[i][j] = (i == j) ? (1 - t) : -t;\n+        }\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double sum = 0;\n+      for (int i = 0; i < n; ++i) {\n+        sum += parameters[i].getEstimate();\n+      }\n+      double t  = 1 + 2 * sum / m;\n+      double[] f = new double[m];\n+      for (int i = 0; i < n; ++i) {\n+        f[i] = parameters[i].getEstimate() - t;\n+      }\n+      Arrays.fill(f, n, m, -t);\n+      return f;\n+    }\n+\n+  }\n+\n+  private static class LinearRank1Function extends MinpackFunction {\n+\n+    public LinearRank1Function(int m, int n, double x0,\n+                                  double theoreticalStartCost,\n+                                  double theoreticalMinCost) {\n+      super(m, buildArray(n, x0), theoreticalStartCost, theoreticalMinCost, null);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        jacobian[i] = new double[n];\n+        for (int j = 0; j < n; ++j) {\n+          jacobian[i][j] = (i + 1) * (j + 1);\n+        }\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double[] f = new double[m];\n+      double sum = 0;\n+      for (int i = 0; i < n; ++i) {\n+        sum += (i + 1) * parameters[i].getEstimate();\n+      }\n+      for (int i = 0; i < m; ++i) {\n+        f[i] = (i + 1) * sum - 1;\n+      }\n+      return f;\n+    }\n+\n+  }\n+\n+  private static class LinearRank1ZeroColsAndRowsFunction extends MinpackFunction {\n+\n+    public LinearRank1ZeroColsAndRowsFunction(int m, int n, double x0) {\n+      super(m, buildArray(n, x0),\n+            Math.sqrt(m + (n+1)*(n-2)*(m-2)*(m-1) * ((n+1)*(n-2)*(2*m-3) - 12) / 24.0),\n+            Math.sqrt((m * (m + 3) - 6) / (2.0 * (2 * m - 3))),\n+            null);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        jacobian[i] = new double[n];\n+        jacobian[i][0] = 0;\n+        for (int j = 1; j < (n - 1); ++j) {\n+          if (i == 0) {\n+            jacobian[i][j] = 0;\n+          } else if (i != (m - 1)) {\n+            jacobian[i][j] = i * (j + 1);\n+          } else {\n+            jacobian[i][j] = 0;\n+          }\n+        }\n+        jacobian[i][n - 1] = 0;\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double[] f = new double[m];\n+      double sum = 0;\n+      for (int i = 1; i < (n - 1); ++i) {\n+        sum += (i + 1) * parameters[i].getEstimate();\n+      }\n+      for (int i = 0; i < (m - 1); ++i) {\n+        f[i] = i * sum - 1;\n+      }\n+      f[m - 1] = -1;\n+      return f;\n+    }\n+\n+  }\n+\n+  private static class RosenbrockFunction extends MinpackFunction {\n+\n+    public RosenbrockFunction(double[] startParams, double theoreticalStartCost) {\n+      super(2, startParams, theoreticalStartCost, 0.0, buildArray(2, 1.0));\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double x1 = parameters[0].getEstimate();\n+      return new double[][] { { -20 * x1, 10 }, { -1, 0 } };\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      return new double[] { 10 * (x2 - x1 * x1), 1 - x1 };\n+    }\n+\n+  }\n+\n+  private static class HelicalValleyFunction extends MinpackFunction {\n+\n+    public HelicalValleyFunction(double[] startParams,\n+                                 double theoreticalStartCost) {\n+      super(3, startParams, theoreticalStartCost, 0.0,\n+            new double[] { 1.0, 0.0, 0.0 });\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double tmpSquare = x1 * x1 + x2 * x2;\n+      double tmp1 = twoPi * tmpSquare;\n+      double tmp2 = Math.sqrt(tmpSquare);\n+      return new double[][] {\n+        {  100 * x2 / tmp1, -100 * x1 / tmp1, 10 },\n+        { 10 * x1 / tmp2, 10 * x2 / tmp2, 0 },\n+        { 0, 0, 1 }\n+      };\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double x3 = parameters[2].getEstimate();\n+      double tmp1;\n+      if (x1 == 0) {\n+        tmp1 = (x2 >= 0) ? 0.25 : -0.25;\n+      } else {\n+        tmp1 = Math.atan(x2 / x1) / twoPi;\n+        if (x1 < 0) {\n+          tmp1 += 0.5;\n+        }\n+      }\n+      double tmp2 = Math.sqrt(x1 * x1 + x2 * x2);\n+      return new double[] {\n+        10.0 * (x3 - 10 * tmp1),\n+        10.0 * (tmp2 - 1),\n+        x3\n+      };\n+    }\n+\n+    private static final double twoPi = 2.0 * Math.PI;\n+\n+  }\n+\n+  private static class PowellSingularFunction extends MinpackFunction {\n+\n+    public PowellSingularFunction(double[] startParams,\n+                                  double theoreticalStartCost) {\n+      super(4, startParams, theoreticalStartCost, 0.0, buildArray(4, 0.0));\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double x3 = parameters[2].getEstimate();\n+      double x4 = parameters[3].getEstimate();\n+      return new double[][] {\n+        { 1, 10, 0, 0 },\n+        { 0, 0, sqrt5, -sqrt5 },\n+        { 0, 2 * (x2 - 2 * x3), -4 * (x2 - 2 * x3), 0 },\n+        { 2 * sqrt10 * (x1 - x4), 0, 0, -2 * sqrt10 * (x1 - x4) }\n+      };\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double x3 = parameters[2].getEstimate();\n+      double x4 = parameters[3].getEstimate();\n+      return new double[] {\n+        x1 + 10 * x2,\n+        sqrt5 * (x3 - x4),\n+        (x2 - 2 * x3) * (x2 - 2 * x3),\n+        sqrt10 * (x1 - x4) * (x1 - x4)\n+      };\n+    }\n+\n+    private static final double sqrt5  = Math.sqrt( 5.0);\n+    private static final double sqrt10 = Math.sqrt(10.0);\n+\n+  }\n+\n+  private static class FreudensteinRothFunction extends MinpackFunction {\n+\n+    public FreudensteinRothFunction(double[] startParams,\n+                                    double theoreticalStartCost,\n+                                    double theoreticalMinCost,\n+                                    double[] theoreticalMinParams) {\n+      super(2, startParams, theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double x2 = parameters[1].getEstimate();\n+      return new double[][] {\n+        { 1, x2 * (10 - 3 * x2) -  2 },\n+        { 1, x2 * ( 2 + 3 * x2) - 14, }\n+      };\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      return new double[] {\n+       -13.0 + x1 + ((5.0 - x2) * x2 -  2.0) * x2,\n+       -29.0 + x1 + ((1.0 + x2) * x2 - 14.0) * x2\n+      };\n+    }\n+\n+  }\n+\n+  private static class BardFunction extends MinpackFunction {\n+\n+    public BardFunction(double x0,\n+                        double theoreticalStartCost,\n+                        double theoreticalMinCost,\n+                        double[] theoreticalMinParams) {\n+      super(15, buildArray(3, x0), theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double   x2 = parameters[1].getEstimate();\n+      double   x3 = parameters[2].getEstimate();\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        double tmp1 = i  + 1;\n+        double tmp2 = 15 - i;\n+        double tmp3 = (i <= 7) ? tmp1 : tmp2;\n+        double tmp4 = x2 * tmp2 + x3 * tmp3;\n+        tmp4 *= tmp4;\n+        jacobian[i] = new double[] { -1, tmp1 * tmp2 / tmp4, tmp1 * tmp3 / tmp4 };\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double   x1 = parameters[0].getEstimate();\n+      double   x2 = parameters[1].getEstimate();\n+      double   x3 = parameters[2].getEstimate();\n+      double[] f = new double[m];\n+      for (int i = 0; i < m; ++i) {\n+        double tmp1 = i + 1;\n+        double tmp2 = 15 - i;\n+        double tmp3 = (i <= 7) ? tmp1 : tmp2;\n+        f[i] = y[i] - (x1 + tmp1 / (x2 * tmp2 + x3 * tmp3));\n+      }\n+      return f;\n+    }\n+\n+    private static final double[] y = {\n+      0.14, 0.18, 0.22, 0.25, 0.29,\n+      0.32, 0.35, 0.39, 0.37, 0.58,\n+      0.73, 0.96, 1.34, 2.10, 4.39\n+    };\n+\n+  }\n+\n+  private static class KowalikOsborneFunction extends MinpackFunction {\n+\n+    public KowalikOsborneFunction(double[] startParams,\n+                                  double theoreticalStartCost,\n+                                  double theoreticalMinCost,\n+                                  double[] theoreticalMinParams) {\n+      super(11, startParams, theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+      if (theoreticalStartCost > 20.0) {\n+        setCostAccuracy(2.0e-4);\n+        setParamsAccuracy(5.0e-3);\n+      }\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double   x1 = parameters[0].getEstimate();\n+      double   x2 = parameters[1].getEstimate();\n+      double   x3 = parameters[2].getEstimate();\n+      double   x4 = parameters[3].getEstimate();\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        double tmp = v[i] * (v[i] + x3) + x4;\n+        double j1  = -v[i] * (v[i] + x2) / tmp;\n+        double j2  = -v[i] * x1 / tmp;\n+        double j3  = j1 * j2;\n+        double j4  = j3 / v[i];\n+        jacobian[i] = new double[] { j1, j2, j3, j4 };\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double x3 = parameters[2].getEstimate();\n+      double x4 = parameters[3].getEstimate();\n+      double[] f = new double[m];\n+      for (int i = 0; i < m; ++i) {\n+        f[i] = y[i] - x1 * (v[i] * (v[i] + x2)) / (v[i] * (v[i] + x3) + x4);\n+      }\n+      return f;\n+    }\n+\n+    private static final double[] v = {\n+      4.0, 2.0, 1.0, 0.5, 0.25, 0.167, 0.125, 0.1, 0.0833, 0.0714, 0.0625\n+    };\n+\n+    private static final double[] y = {\n+      0.1957, 0.1947, 0.1735, 0.1600, 0.0844, 0.0627,\n+      0.0456, 0.0342, 0.0323, 0.0235, 0.0246\n+    };\n+\n+  }\n+\n+  private static class MeyerFunction extends MinpackFunction {\n+\n+    public MeyerFunction(double[] startParams,\n+                         double theoreticalStartCost,\n+                         double theoreticalMinCost,\n+                         double[] theoreticalMinParams) {\n+      super(16, startParams, theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+      if (theoreticalStartCost > 1.0e6) {\n+        setCostAccuracy(7.0e-3);\n+        setParamsAccuracy(2.0e-2);\n+      }\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double   x1 = parameters[0].getEstimate();\n+      double   x2 = parameters[1].getEstimate();\n+      double   x3 = parameters[2].getEstimate();\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        double temp = 5.0 * (i + 1) + 45.0 + x3;\n+        double tmp1 = x2 / temp;\n+        double tmp2 = Math.exp(tmp1);\n+        double tmp3 = x1 * tmp2 / temp;\n+        jacobian[i] = new double[] { tmp2, tmp3, -tmp1 * tmp3 };\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double x3 = parameters[2].getEstimate();\n+      double[] f = new double[m];\n+      for (int i = 0; i < m; ++i) {\n+        f[i] = x1 * Math.exp(x2 / (5.0 * (i + 1) + 45.0 + x3)) - y[i];\n+      }\n+     return f;\n+    }\n+\n+    private static final double[] y = {\n+      34780.0, 28610.0, 23650.0, 19630.0,\n+      16370.0, 13720.0, 11540.0,  9744.0,\n+       8261.0,  7030.0,  6005.0,  5147.0,\n+       4427.0,  3820.0,  3307.0,  2872.0                  \n+    };\n+\n+  }\n+\n+  private static class WatsonFunction extends MinpackFunction {\n+\n+    public WatsonFunction(int n, double x0,\n+                          double theoreticalStartCost,\n+                          double theoreticalMinCost,\n+                          double[] theoreticalMinParams) {\n+      super(31, buildArray(n, x0), theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+\n+      double[][] jacobian = new double[m][];\n+\n+      for (int i = 0; i < (m - 2); ++i) {\n+        double div = (i + 1) / 29.0;\n+        double s2  = 0.0;\n+        double dx  = 1.0;\n+        for (int j = 0; j < n; ++j) {\n+          s2 += dx * parameters[j].getEstimate();\n+          dx *= div;\n+        }\n+        double temp= 2 * div * s2;\n+        dx = 1.0 / div;\n+        jacobian[i] = new double[n];\n+        for (int j = 0; j < n; ++j) {\n+          jacobian[i][j] = dx * (j - temp);\n+          dx *= div;\n+        }\n+      }\n+\n+      jacobian[m - 2]    = new double[n];\n+      jacobian[m - 2][0] = 1;\n+\n+      jacobian[m - 1]   = new double[n];\n+      jacobian[m - 1][0]= -2 * parameters[0].getEstimate();\n+      jacobian[m - 1][1]= 1;\n+\n+      return jacobian;\n+\n+    }\n+\n+    protected double[] getResiduals() {\n+     double[] f = new double[m];\n+     for (int i = 0; i < (m - 2); ++i) {\n+       double div = (i + 1) / 29.0;\n+       double s1 = 0;\n+       double dx = 1;\n+       for (int j = 1; j < n; ++j) {\n+         s1 += j * dx * parameters[j].getEstimate();\n+         dx *= div;\n+       }\n+       double s2 =0;\n+       dx =1;\n+       for (int j = 0; j < n; ++j) {\n+         s2 += dx * parameters[j].getEstimate();\n+         dx *= div;\n+       }\n+       f[i] = s1 - s2 * s2 - 1;\n+     }\n+\n+     double x1 = parameters[0].getEstimate();\n+     double x2 = parameters[1].getEstimate();\n+     f[m - 2] = x1;\n+     f[m - 1] = x2 - x1 * x1 - 1;\n+\n+     return f;\n+\n+    }\n+\n+  }\n+\n+  private static class Box3DimensionalFunction extends MinpackFunction {\n+\n+    public Box3DimensionalFunction(int m, double[] startParams,\n+                                   double theoreticalStartCost) {\n+      super(m, startParams, theoreticalStartCost,\n+            0.0, new double[] { 1.0, 10.0, 1.0 });\n+   }\n+\n+    protected double[][] getJacobian() {\n+      double   x1 = parameters[0].getEstimate();\n+      double   x2 = parameters[1].getEstimate();\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        double tmp = (i + 1) / 10.0;\n+        jacobian[i] = new double[] {\n+          -tmp * Math.exp(-tmp * x1),\n+           tmp * Math.exp(-tmp * x2),\n+          Math.exp(-i - 1) - Math.exp(-tmp)\n+        };\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double x3 = parameters[2].getEstimate();\n+      double[] f = new double[m];\n+      for (int i = 0; i < m; ++i) {\n+        double tmp = (i + 1) / 10.0;\n+        f[i] = Math.exp(-tmp * x1) - Math.exp(-tmp * x2)\n+             + (Math.exp(-i - 1) - Math.exp(-tmp)) * x3;\n+      }\n+      return f;\n+    }\n+\n+  }\n+\n+  private static class JennrichSampsonFunction extends MinpackFunction {\n+\n+    public JennrichSampsonFunction(int m, double[] startParams,\n+                                   double theoreticalStartCost,\n+                                   double theoreticalMinCost,\n+                                   double[] theoreticalMinParams) {\n+      super(m, startParams, theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double   x1 = parameters[0].getEstimate();\n+      double   x2 = parameters[1].getEstimate();\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        double t = i + 1;\n+        jacobian[i] = new double[] { -t * Math.exp(t * x1), -t * Math.exp(t * x2) };\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double[] f = new double[m];\n+      for (int i = 0; i < m; ++i) {\n+        double temp = i + 1;\n+        f[i] = 2 + 2 * temp - Math.exp(temp * x1) - Math.exp(temp * x2);\n+      }\n+      return f;\n+    }\n+\n+  }\n+\n+  private static class BrownDennisFunction extends MinpackFunction {\n+\n+    public BrownDennisFunction(int m, double[] startParams,\n+                               double theoreticalStartCost,\n+                               double theoreticalMinCost,\n+                               double[] theoreticalMinParams) {\n+      super(m, startParams, theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double   x1 = parameters[0].getEstimate();\n+      double   x2 = parameters[1].getEstimate();\n+      double   x3 = parameters[2].getEstimate();\n+      double   x4 = parameters[3].getEstimate();\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        double temp = (i + 1) / 5.0;\n+        double ti   = Math.sin(temp);\n+        double tmp1 = x1 + temp * x2 - Math.exp(temp);\n+        double tmp2 = x3 + ti   * x4 - Math.cos(temp);\n+        jacobian[i] = new double[] {\n+          2 * tmp1, 2 * temp * tmp1, 2 * tmp2, 2 * ti * tmp2\n+        };\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double x3 = parameters[2].getEstimate();\n+      double x4 = parameters[3].getEstimate();\n+      double[] f = new double[m];\n+      for (int i = 0; i < m; ++i) {\n+        double temp = (i + 1) / 5.0;\n+        double tmp1 = x1 + temp * x2 - Math.exp(temp);\n+        double tmp2 = x3 + Math.sin(temp) * x4 - Math.cos(temp);\n+        f[i] = tmp1 * tmp1 + tmp2 * tmp2;\n+      }\n+      return f;\n+    }\n+\n+  }\n+\n+  private static class ChebyquadFunction extends MinpackFunction {\n+\n+    private static double[] buildChebyquadArray(int n, double factor) {\n+      double[] array = new double[n];\n+      double inv = factor / (n + 1);\n+      for (int i = 0; i < n; ++i) {\n+        array[i] = (i + 1) * inv;\n+      }\n+      return array;\n+    }\n+\n+    public ChebyquadFunction(int n, int m, double factor,\n+                             double theoreticalStartCost,\n+                             double theoreticalMinCost,\n+                             double[] theoreticalMinParams) {\n+      super(m, buildChebyquadArray(n, factor), theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        jacobian[i] = new double[n];\n+      }\n+\n+      double dx = 1.0 / n;\n+      for (int j = 0; j < n; ++j) {\n+        double tmp1 = 1;\n+        double tmp2 = 2 * parameters[j].getEstimate() - 1;\n+        double temp = 2 * tmp2;\n+        double tmp3 = 0;\n+        double tmp4 = 2;\n+        for (int i = 0; i < m; ++i) {\n+          jacobian[i][j] = dx * tmp4;\n+          double ti = 4 * tmp2 + temp * tmp4 - tmp3;\n+          tmp3 = tmp4;\n+          tmp4 = ti;\n+          ti   = temp * tmp2 - tmp1;\n+          tmp1 = tmp2;\n+          tmp2 = ti;\n+        }\n+      }\n+\n+      return jacobian;\n+\n+    }\n+\n+    protected double[] getResiduals() {\n+\n+      double[] f = new double[m];\n+\n+      for (int j = 0; j < n; ++j) {\n+        double tmp1 = 1;\n+        double tmp2 = 2 * parameters[j].getEstimate() - 1;\n+        double temp = 2 * tmp2;\n+        for (int i = 0; i < m; ++i) {\n+          f[i] += tmp2;\n+          double ti = temp * tmp2 - tmp1;\n+          tmp1 = tmp2;\n+          tmp2 = ti;\n+        }\n+      }\n+\n+      double dx = 1.0 / n;\n+      boolean iev = false;\n+      for (int i = 0; i < m; ++i) {\n+        f[i] *= dx;\n+        if (iev) {\n+          f[i] += 1.0 / (i * (i + 2));\n+        }\n+        iev = ! iev;\n+      }\n+\n+      return f;\n+\n+    }\n+\n+  }\n+\n+  private static class BrownAlmostLinearFunction extends MinpackFunction {\n+\n+    public BrownAlmostLinearFunction(int m, double factor,\n+                                     double theoreticalStartCost,\n+                                     double theoreticalMinCost,\n+                                     double[] theoreticalMinParams) {\n+      super(m, buildArray(m, factor), theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        jacobian[i] = new double[n];\n+      }\n+\n+      double prod = 1;\n+      for (int j = 0; j < n; ++j) {\n+        prod *= parameters[j].getEstimate();\n+        for (int i = 0; i < n; ++i) {\n+          jacobian[i][j] = 1;\n+        }\n+        jacobian[j][j] = 2;\n+      }\n+\n+      for (int j = 0; j < n; ++j) {\n+        EstimatedParameter vj = parameters[j];\n+        double temp = vj.getEstimate();\n+        if (temp == 0) {\n+          temp = 1;\n+          prod = 1;\n+          for (int k = 0; k < n; ++k) {\n+            if (k != j) {\n+              prod *= parameters[k].getEstimate();\n+            }\n+          }\n+        }\n+        jacobian[n - 1][j] = prod / temp;\n+      }\n+\n+      return jacobian;\n+\n+    }\n+\n+    protected double[] getResiduals() {\n+      double[] f = new double[m];\n+      double sum  = -(n + 1);\n+      double prod = 1;\n+      for (int j = 0; j < n; ++j) {\n+        sum  += parameters[j].getEstimate();\n+        prod *= parameters[j].getEstimate();\n+      }\n+      for (int i = 0; i < n; ++i) {\n+        f[i] = parameters[i].getEstimate() + sum;\n+      }\n+      f[n - 1] = prod - 1;\n+      return f;\n+    }\n+\n+  }\n+\n+  private static class Osborne1Function extends MinpackFunction {\n+\n+    public Osborne1Function(double[] startParams,\n+                            double theoreticalStartCost,\n+                            double theoreticalMinCost,\n+                            double[] theoreticalMinParams) {\n+      super(33, startParams, theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double   x2 = parameters[1].getEstimate();\n+      double   x3 = parameters[2].getEstimate();\n+      double   x4 = parameters[3].getEstimate();\n+      double   x5 = parameters[4].getEstimate();\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        double temp = 10.0 * i;\n+        double tmp1 = Math.exp(-temp * x4);\n+        double tmp2 = Math.exp(-temp * x5);\n+        jacobian[i] = new double[] {\n+          -1, -tmp1, -tmp2, temp * x2 * tmp1, temp * x3 * tmp2\n+        };\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x1 = parameters[0].getEstimate();\n+      double x2 = parameters[1].getEstimate();\n+      double x3 = parameters[2].getEstimate();\n+      double x4 = parameters[3].getEstimate();\n+      double x5 = parameters[4].getEstimate();\n+      double[] f = new double[m];\n+      for (int i = 0; i < m; ++i) {\n+        double temp = 10.0 * i;\n+        double tmp1 = Math.exp(-temp * x4);\n+        double tmp2 = Math.exp(-temp * x5);\n+        f[i] = y[i] - (x1 + x2 * tmp1 + x3 * tmp2);\n+      }\n+      return f;\n+    }\n+\n+    private static final double[] y = {\n+      0.844, 0.908, 0.932, 0.936, 0.925, 0.908, 0.881, 0.850, 0.818, 0.784, 0.751,\n+      0.718, 0.685, 0.658, 0.628, 0.603, 0.580, 0.558, 0.538, 0.522, 0.506, 0.490,\n+      0.478, 0.467, 0.457, 0.448, 0.438, 0.431, 0.424, 0.420, 0.414, 0.411, 0.406\n+    };\n+\n+  }\n+\n+  private static class Osborne2Function extends MinpackFunction {\n+\n+    public Osborne2Function(double[] startParams,\n+                            double theoreticalStartCost,\n+                            double theoreticalMinCost,\n+                            double[] theoreticalMinParams) {\n+      super(65, startParams, theoreticalStartCost,\n+            theoreticalMinCost, theoreticalMinParams);\n+    }\n+\n+    protected double[][] getJacobian() {\n+      double   x01 = parameters[0].getEstimate();\n+      double   x02 = parameters[1].getEstimate();\n+      double   x03 = parameters[2].getEstimate();\n+      double   x04 = parameters[3].getEstimate();\n+      double   x05 = parameters[4].getEstimate();\n+      double   x06 = parameters[5].getEstimate();\n+      double   x07 = parameters[6].getEstimate();\n+      double   x08 = parameters[7].getEstimate();\n+      double   x09 = parameters[8].getEstimate();\n+      double   x10 = parameters[9].getEstimate();\n+      double   x11 = parameters[10].getEstimate();\n+      double[][] jacobian = new double[m][];\n+      for (int i = 0; i < m; ++i) {\n+        double temp = i / 10.0;\n+        double tmp1 = Math.exp(-x05 * temp);\n+        double tmp2 = Math.exp(-x06 * (temp - x09) * (temp - x09));\n+        double tmp3 = Math.exp(-x07 * (temp - x10) * (temp - x10));\n+        double tmp4 = Math.exp(-x08 * (temp - x11) * (temp - x11));\n+        jacobian[i] = new double[] {\n+          -tmp1,\n+          -tmp2,\n+          -tmp3,\n+          -tmp4,\n+          temp * x01 * tmp1,\n+          x02 * (temp - x09) * (temp - x09) * tmp2,\n+          x03 * (temp - x10) * (temp - x10) * tmp3,\n+          x04 * (temp - x11) * (temp - x11) * tmp4,\n+          -2 * x02 * x06 * (temp - x09) * tmp2,\n+          -2 * x03 * x07 * (temp - x10) * tmp3,\n+          -2 * x04 * x08 * (temp - x11) * tmp4\n+        };\n+      }\n+      return jacobian;\n+    }\n+\n+    protected double[] getResiduals() {\n+      double x01 = parameters[0].getEstimate();\n+      double x02 = parameters[1].getEstimate();\n+      double x03 = parameters[2].getEstimate();\n+      double x04 = parameters[3].getEstimate();\n+      double x05 = parameters[4].getEstimate();\n+      double x06 = parameters[5].getEstimate();\n+      double x07 = parameters[6].getEstimate();\n+      double x08 = parameters[7].getEstimate();\n+      double x09 = parameters[8].getEstimate();\n+      double x10 = parameters[9].getEstimate();\n+      double x11 = parameters[10].getEstimate();\n+      double[] f = new double[m];\n+      for (int i = 0; i < m; ++i) {\n+        double temp = i / 10.0;\n+        double tmp1 = Math.exp(-x05 * temp);\n+        double tmp2 = Math.exp(-x06 * (temp - x09) * (temp - x09));\n+        double tmp3 = Math.exp(-x07 * (temp - x10) * (temp - x10));\n+        double tmp4 = Math.exp(-x08 * (temp - x11) * (temp - x11));\n+        f[i] = y[i] - (x01 * tmp1 + x02 * tmp2 + x03 * tmp3 + x04 * tmp4);\n+      }\n+      return f;\n+    }\n+\n+    private static final double[] y = {\n+      1.366, 1.191, 1.112, 1.013, 0.991,\n+      0.885, 0.831, 0.847, 0.786, 0.725,\n+      0.746, 0.679, 0.608, 0.655, 0.616,\n+      0.606, 0.602, 0.626, 0.651, 0.724,\n+      0.649, 0.649, 0.694, 0.644, 0.624,\n+      0.661, 0.612, 0.558, 0.533, 0.495,\n+      0.500, 0.423, 0.395, 0.375, 0.372,\n+      0.391, 0.396, 0.405, 0.428, 0.429,\n+      0.523, 0.562, 0.607, 0.653, 0.672,\n+      0.708, 0.633, 0.668, 0.645, 0.632,\n+      0.591, 0.559, 0.597, 0.625, 0.739,\n+      0.710, 0.729, 0.720, 0.636, 0.581,\n+      0.428, 0.292, 0.162, 0.098, 0.054\n+    };\n+\n+  }\n+\n+  public static Test suite() {\n+    return new TestSuite(MinpackTest.class);\n+  }\n+\n+}\n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/general/WeightedMeasurementTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+\n+import junit.framework.*;\n+\n+public class WeightedMeasurementTest\n+  extends TestCase {\n+\n+  public WeightedMeasurementTest(String name) {\n+    super(name);\n+    p1 = null;\n+    p2 = null;\n+  }\n+\n+  public void testConstruction() {\n+    WeightedMeasurement m = new MyMeasurement(3.0, theoretical() + 0.1, this);\n+    checkValue(m.getWeight(), 3.0);\n+    checkValue(m.getMeasuredValue(), theoretical() + 0.1);\n+  }\n+\n+  public void testIgnored() {\n+    WeightedMeasurement m = new MyMeasurement(3.0, theoretical() + 0.1, this);\n+    assertTrue(!m.isIgnored());\n+    m.setIgnored(true);\n+    assertTrue(m.isIgnored());\n+    m.setIgnored(false);\n+    assertTrue(!m.isIgnored());\n+  }\n+\n+  public void testTheory() {\n+    WeightedMeasurement m = new MyMeasurement(3.0, theoretical() + 0.1, this);\n+    checkValue(m.getTheoreticalValue(), theoretical());\n+    checkValue(m.getResidual(), 0.1);\n+\n+    double oldP1 = p1.getEstimate();\n+    p1.setEstimate(oldP1 + m.getResidual() / m.getPartial(p1));\n+    checkValue(m.getResidual(), 0.0);\n+    p1.setEstimate(oldP1);\n+    checkValue(m.getResidual(), 0.1);\n+\n+    double oldP2 = p2.getEstimate();\n+    p2.setEstimate(oldP2 + m.getResidual() / m.getPartial(p2));\n+    checkValue(m.getResidual(), 0.0);\n+    p2.setEstimate(oldP2);\n+    checkValue(m.getResidual(), 0.1);\n+\n+  }\n+\n+  public static Test suite() {\n+    return new TestSuite(WeightedMeasurementTest.class);\n+  }\n+\n+  public void setUp() {\n+    p1 = new EstimatedParameter(\"p1\", 1.0);\n+    p2 = new EstimatedParameter(\"p2\", 2.0);\n+  }\n+\n+  public void tearDown() {\n+    p1 = null;\n+    p2 = null;\n+  }\n+\n+  private void checkValue(double value, double expected) {\n+   assertTrue(Math.abs(value - expected) < 1.0e-10);\n+  }\n+\n+  private double theoretical() {\n+   return 3 * p1.getEstimate() - p2.getEstimate();\n+  }\n+\n+  private double partial(EstimatedParameter p) {\n+    if (p == p1) {\n+      return 3.0;\n+    } else if (p == p2) {\n+      return -1.0;\n+    } else {\n+      return 0.0;\n+    }\n+  }\n+\n+  private static class MyMeasurement\n+    extends WeightedMeasurement {\n+\n+    public MyMeasurement(double weight, double measuredValue,\n+                         WeightedMeasurementTest testInstance) {\n+      super(weight, measuredValue);\n+      this.testInstance = testInstance;\n+    }\n+\n+    public double getTheoreticalValue() {\n+      return testInstance.theoretical();\n+    }\n+\n+    public double getPartial(EstimatedParameter p) {\n+      return testInstance.partial(p);\n+    }\n+\n+    private transient WeightedMeasurementTest testInstance;\n+\n+    private static final long serialVersionUID = -246712922500792332L;\n+\n+  }\n+\n+  private EstimatedParameter p1;\n+  private EstimatedParameter p2;\n+\n+}\n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/univariate/BrentMinimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math.optimization.univariate;\n+\n+import junit.framework.Test;\n+import junit.framework.TestCase;\n+import junit.framework.TestSuite;\n+\n+import org.apache.commons.math.MathException;\n+import org.apache.commons.math.analysis.QuinticFunction;\n+import org.apache.commons.math.analysis.SinFunction;\n+import org.apache.commons.math.analysis.UnivariateRealFunction;\n+\n+/**\n+ * @version $Revision$ $Date$ \n+ */\n+public final class BrentMinimizerTest extends TestCase {\n+\n+    public BrentMinimizerTest(String name) {\n+        super(name);\n+    }\n+\n+    public static Test suite() {\n+        TestSuite suite = new TestSuite(BrentMinimizerTest.class);\n+        suite.setName(\"BrentMinimizer Tests\");\n+        return suite;\n+    }\n+\n+    public void testSinMin() throws MathException {\n+        UnivariateRealFunction f = new SinFunction();\n+        UnivariateRealMinimizer minimizer = new BrentMinimizer();\n+        assertEquals(3 * Math.PI / 2, minimizer.minimize(f, 4, 5), 70 * minimizer.getAbsoluteAccuracy());\n+        assertTrue(minimizer.getIterationCount() <= 50);\n+        assertEquals(3 * Math.PI / 2, minimizer.minimize(f, 1, 5), 70 * minimizer.getAbsoluteAccuracy());\n+        assertTrue(minimizer.getIterationCount() <= 50);\n+    }\n+\n+   public void testQuinticMin() throws MathException {\n+        // The quintic function has zeros at 0, +-0.5 and +-1.\n+        // The function has extrema (first derivative is zero) at 0.27195613 and 0.82221643,\n+        UnivariateRealFunction f = new QuinticFunction();\n+        UnivariateRealMinimizer minimizer = new BrentMinimizer();\n+        assertEquals(-0.27195613, minimizer.minimize(f, -0.3, -0.2), 1.0e-8);\n+        assertEquals( 0.82221643, minimizer.minimize(f,  0.3,  0.9), 1.0e-8);\n+        assertTrue(minimizer.getIterationCount() <= 50);\n+\n+        // search in a large interval\n+        assertEquals(-0.27195613, minimizer.minimize(f, -1.0, 0.2), 1.0e-8);\n+        assertTrue(minimizer.getIterationCount() <= 50);\n+\n+   }\n+    \n+    public void testMinEndpoints() throws Exception {\n+        UnivariateRealFunction f = new SinFunction();\n+        UnivariateRealMinimizer solver = new BrentMinimizer();\n+        \n+        // endpoint is minimum\n+        double result = solver.minimize(f, 3 * Math.PI / 2, 5);\n+        assertEquals(3 * Math.PI / 2, result, 70 * solver.getAbsoluteAccuracy());\n+\n+        result = solver.minimize(f, 4, 3 * Math.PI / 2);\n+        assertEquals(3 * Math.PI / 2, result, 70 * solver.getAbsoluteAccuracy());\n+\n+    }\n+    \n+}", "timestamp": 1235675859, "metainfo": ""}