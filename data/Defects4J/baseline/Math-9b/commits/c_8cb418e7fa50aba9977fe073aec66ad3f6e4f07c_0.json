{"sha": "8cb418e7fa50aba9977fe073aec66ad3f6e4f07c", "log": "adapted the Gauss-Newton optimizer to the new top-level optimization interfaces  ", "commit": "\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/AbstractLeastSquaresOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import org.apache.commons.math.linear.InvalidMatrixException;\n+import org.apache.commons.math.linear.MatrixUtils;\n+import org.apache.commons.math.linear.RealMatrix;\n+import org.apache.commons.math.linear.decomposition.LUDecompositionImpl;\n+import org.apache.commons.math.optimization.ObjectiveException;\n+import org.apache.commons.math.optimization.OptimizationException;\n+import org.apache.commons.math.optimization.SimpleVectorialValueChecker;\n+import org.apache.commons.math.optimization.VectorialConvergenceChecker;\n+import org.apache.commons.math.optimization.VectorialDifferentiableObjectiveFunction;\n+import org.apache.commons.math.optimization.VectorialDifferentiableOptimizer;\n+import org.apache.commons.math.optimization.VectorialPointValuePair;\n+\n+/**\n+ * Base class for implementing estimators.\n+ * <p>This base class handles the boilerplates methods associated to thresholds\n+ * settings, jacobian and error estimation.</p>\n+ * @version $Revision$ $Date$\n+ * @since 1.2\n+ *\n+ */\n+public abstract class AbstractLeastSquaresOptimizer implements VectorialDifferentiableOptimizer {\n+\n+    /** Serializable version identifier */\n+    private static final long serialVersionUID = -3080152374642370722L;\n+\n+    /** Default maximal number of objective function evaluations allowed. */\n+    public static final int DEFAULT_MAX_EVALUATIONS = 100;\n+\n+    /** Number of evaluations already performed for the current start. */\n+    private int objectiveEvaluations;\n+\n+    /** Number of jacobian evaluations. */\n+    private int jacobianEvaluations;\n+\n+    /** Maximal number of evaluations allowed. */\n+    private int maxEvaluations;\n+\n+    /** Convergence checker. */\n+    protected VectorialConvergenceChecker checker;\n+\n+    /** \n+     * Jacobian matrix.\n+     * <p>This matrix is in canonical form just after the calls to\n+     * {@link #updateJacobian()}, but may be modified by the solver\n+     * in the derived class (the {@link LevenbergMarquardtEstimator\n+     * Levenberg-Marquardt estimator} does this).</p>\n+     */\n+    protected double[][] jacobian;\n+\n+    /** Number of columns of the jacobian matrix. */\n+    protected int cols;\n+\n+    /** Number of rows of the jacobian matrix. */\n+    protected int rows;\n+\n+    /** Objective function. */\n+    private VectorialDifferentiableObjectiveFunction f;\n+\n+    /** Target value for the objective functions at optimum. */\n+    protected double[] target;\n+\n+    /** Weight for the least squares cost computation. */\n+    protected double[] weights;\n+\n+    /** Current variables set. */\n+    protected double[] variables;\n+\n+    /** Current objective function value. */\n+    protected double[] objective;\n+\n+    /** Cost value (square root of the sum of the residuals). */\n+    protected double cost;\n+\n+    /** Simple constructor with default settings.\n+     * <p>The convergence check is set to a {@link SimpleVectorialValueChecker}\n+     * and the maximal number of evaluation is set to its default value.</p>\n+     */\n+    protected AbstractLeastSquaresOptimizer() {\n+        setConvergenceChecker(new SimpleVectorialValueChecker());\n+        setMaxEvaluations(DEFAULT_MAX_EVALUATIONS);\n+    }\n+\n+    /** {@inheritDoc} */\n+    public void setMaxEvaluations(int maxEvaluations) {\n+        this.maxEvaluations = maxEvaluations;\n+    }\n+\n+    /** {@inheritDoc} */\n+    public int getMaxEvaluations() {\n+        return maxEvaluations;\n+    }\n+\n+    /** {@inheritDoc} */\n+    public int getEvaluations() {\n+        return objectiveEvaluations;\n+    }\n+\n+    /** {@inheritDoc} */\n+    public void setConvergenceChecker(VectorialConvergenceChecker checker) {\n+        this.checker = checker;\n+    }\n+\n+    /** {@inheritDoc} */\n+    public VectorialConvergenceChecker getConvergenceChecker() {\n+        return checker;\n+    }\n+\n+    /** \n+     * Update the jacobian matrix.\n+     * @exception ObjectiveException if the function jacobian\n+     * cannot be evaluated or its dimension doesn't match problem dimension\n+     */\n+    protected void updateJacobian() throws ObjectiveException {\n+        incrementJacobianEvaluationsCounter();\n+        jacobian = f.jacobian(variables, objective);\n+        if (jacobian.length != rows) {\n+            throw new ObjectiveException(\"dimension mismatch {0} != {1}\",\n+                                         jacobian.length, rows);\n+        }\n+        for (int i = 0; i < rows; i++) {\n+            final double[] ji = jacobian[i];\n+            final double factor = -Math.sqrt(weights[i]);\n+            for (int j = 0; j < cols; ++j) {\n+                ji[j] *= factor;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Increment the jacobian evaluations counter.\n+     */\n+    protected final void incrementJacobianEvaluationsCounter() {\n+        ++jacobianEvaluations;\n+    }\n+\n+    /** \n+     * Update the residuals array and cost function value.\n+     * @exception ObjectiveException if the function cannot be evaluated\n+     * or its dimension doesn't match problem dimension\n+     * @exception OptimizationException if the number of cost evaluations\n+     * exceeds the maximum allowed\n+     */\n+    protected void updateResidualsAndCost()\n+        throws ObjectiveException, OptimizationException {\n+\n+        if (++objectiveEvaluations > maxEvaluations) {\n+            throw new OptimizationException(\n+                    \"maximal number of evaluations exceeded ({0})\",\n+                    objectiveEvaluations);\n+        }\n+\n+        objective = f.objective(variables);\n+        if (objective.length != rows) {\n+            throw new ObjectiveException(\"dimension mismatch {0} != {1}\",\n+                                         objective.length, rows);\n+        }\n+        cost = 0;\n+        for (int i = 0, index = 0; i < rows; i++, index += cols) {\n+            final double residual = objective[i] - target[i];\n+            cost += weights[i] * residual * residual;\n+        }\n+        cost = Math.sqrt(cost);\n+\n+    }\n+\n+    /** \n+     * Get the Root Mean Square value.\n+     * Get the Root Mean Square value, i.e. the root of the arithmetic\n+     * mean of the square of all weighted residuals. This is related to the\n+     * criterion that is minimized by the estimator as follows: if\n+     * <em>c</em> if the criterion, and <em>n</em> is the number of\n+     * measurements, then the RMS is <em>sqrt (c/n)</em>.\n+     * \n+     * @return RMS value\n+     */\n+    public double getRMS() {\n+        double criterion = 0;\n+        for (int i = 0; i < rows; ++i) {\n+            final double residual = objective[i] - target[i];\n+            criterion += weights[i] * residual * residual;\n+        }\n+        return Math.sqrt(criterion / rows);\n+    }\n+\n+    /**\n+     * Get the Chi-Square value.\n+     * @return chi-square value\n+     */\n+    public double getChiSquare() {\n+        double chiSquare = 0;\n+        for (int i = 0; i < rows; ++i) {\n+            final double residual = objective[i] - target[i];\n+            chiSquare += residual * residual / weights[i];\n+        }\n+        return chiSquare;\n+    }\n+\n+    /**\n+     * Get the covariance matrix of unbound estimated parameters.\n+     * @return covariance matrix\n+     * @exception ObjectiveException if the function jacobian cannot\n+     * be evaluated\n+     * @exception OptimizationException if the covariance matrix\n+     * cannot be computed (singular problem)\n+     */\n+    public double[][] getCovariances()\n+        throws ObjectiveException, OptimizationException {\n+\n+        // set up the jacobian\n+        updateJacobian();\n+\n+        // compute transpose(J).J, avoiding building big intermediate matrices\n+        double[][] jTj = new double[cols][cols];\n+        for (int i = 0; i < cols; ++i) {\n+            final double[] ji = jacobian[i];\n+            for (int j = i; j < cols; ++j) {\n+                final double[] jj = jacobian[j];\n+                double sum = 0;\n+                for (int k = 0; k < rows; ++k) {\n+                    sum += ji[k] * jj[k];\n+                }\n+                jTj[i][j] = sum;\n+                jTj[j][i] = sum;\n+            }\n+        }\n+\n+        try {\n+            // compute the covariances matrix\n+            RealMatrix inverse =\n+                new LUDecompositionImpl(MatrixUtils.createRealMatrix(jTj)).getSolver().getInverse();\n+            return inverse.getData();\n+        } catch (InvalidMatrixException ime) {\n+            throw new OptimizationException(\"unable to compute covariances: singular problem\");\n+        }\n+\n+    }\n+\n+    /**\n+     * Guess the errors in unbound estimated parameters.\n+     * <p>Guessing is covariance-based, it only gives rough order of magnitude.</p>\n+     * @return errors in estimated parameters\n+     * @exception ObjectiveException if the function jacobian cannot b evaluated\n+     * @exception OptimizationException if the covariances matrix cannot be computed\n+     * or the number of degrees of freedom is not positive (number of measurements\n+     * lesser or equal to number of parameters)\n+     */\n+    public double[] guessParametersErrors()\n+        throws ObjectiveException, OptimizationException {\n+        if (rows <= cols) {\n+            throw new OptimizationException(\n+                    \"no degrees of freedom ({0} measurements, {1} parameters)\",\n+                    rows, cols);\n+        }\n+        double[] errors = new double[cols];\n+        final double c = Math.sqrt(getChiSquare() / (rows - cols));\n+        double[][] covar = getCovariances();\n+        for (int i = 0; i < errors.length; ++i) {\n+            errors[i] = Math.sqrt(covar[i][i]) * c;\n+        }\n+        return errors;\n+    }\n+\n+    /** {@inheritDoc} */\n+    public VectorialPointValuePair optimize(final VectorialDifferentiableObjectiveFunction f,\n+                                            final double[] target, final double[] weights,\n+                                            final double[] startPoint)\n+        throws ObjectiveException, OptimizationException, IllegalArgumentException {\n+\n+        if (target.length != weights.length) {\n+            throw new OptimizationException(\"dimension mismatch {0} != {1}\",\n+                                            target.length, weights.length);\n+        }\n+\n+        // reset counters\n+        objectiveEvaluations = 0;\n+        jacobianEvaluations  = 0;\n+\n+        // store least squares problem characteristics\n+        this.f         = f;\n+        this.target    = target;\n+        this.weights   = weights;\n+        this.variables = startPoint.clone();\n+\n+        // arrays shared with the other private methods\n+        rows      = target.length;\n+        cols      = variables.length;\n+        jacobian  = new double[rows][cols];\n+\n+        cost = Double.POSITIVE_INFINITY;\n+\n+        return doOptimize();\n+\n+    }\n+\n+    /** Perform the bulk of optimization algorithm.\n+     */\n+    abstract protected VectorialPointValuePair doOptimize()\n+    throws ObjectiveException, OptimizationException, IllegalArgumentException;\n+\n+}\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/optimization/general/GaussNewtonOptimizer.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import org.apache.commons.math.linear.DenseRealMatrix;\n+import org.apache.commons.math.linear.InvalidMatrixException;\n+import org.apache.commons.math.linear.RealMatrix;\n+import org.apache.commons.math.linear.decomposition.DecompositionSolver;\n+import org.apache.commons.math.linear.decomposition.LUDecompositionImpl;\n+import org.apache.commons.math.linear.decomposition.QRDecompositionImpl;\n+import org.apache.commons.math.optimization.ObjectiveException;\n+import org.apache.commons.math.optimization.OptimizationException;\n+import org.apache.commons.math.optimization.SimpleVectorialValueChecker;\n+import org.apache.commons.math.optimization.VectorialPointValuePair;\n+\n+/** \n+ * Gauss-Newton least-squares solver.\n+ * <p>\n+ * This class solve a least-square problem by solving the normal equations\n+ * of the linearized problem at each iteration. Either LU decomposition or\n+ * QR decomposition can be used to solve the normal equations. LU decomposition\n+ * is faster but QR decomposition is more robust for difficult problems.\n+ * </p>\n+ *\n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ *\n+ */\n+\n+public class GaussNewtonOptimizer extends AbstractLeastSquaresOptimizer {\n+\n+    /** Serializable version identifier */\n+    private static final long serialVersionUID = 7011643996279553223L;\n+\n+    /** Indicator for using LU decomposition. */\n+    private final boolean useLU;\n+\n+    /** Simple constructor with default settings.\n+     * <p>The convergence check is set to a {@link SimpleVectorialValueChecker}\n+     * and the maximal number of evaluation is set to\n+     * {@link AbstractLeastSquaresOptimizer#DEFAULT_MAX_EVALUATIONS}.\n+     * @param useLU if true, the normal equations will be solved using LU\n+     * decomposition, otherwise it will be solved using QR decomposition\n+     */\n+    public GaussNewtonOptimizer(final boolean useLU) {\n+        this.useLU = useLU;\n+    }\n+\n+    /** {@inheritDoc} */\n+    public VectorialPointValuePair doOptimize()\n+        throws ObjectiveException, OptimizationException, IllegalArgumentException {\n+\n+        // iterate until convergence is reached\n+        VectorialPointValuePair current = null;\n+        boolean converged = false;\n+        for (int iteration = 1; ! converged; ++iteration) {\n+\n+            // evaluate the objective function and its jacobian\n+            VectorialPointValuePair previous = current;\n+            updateResidualsAndCost();\n+            updateJacobian();\n+            current = new VectorialPointValuePair(variables, objective);\n+\n+            // build the linear problem\n+            final double[]   b = new double[cols];\n+            final double[][] a = new double[cols][cols];\n+            for (int i = 0; i < rows; ++i) {\n+\n+                final double[] grad   = jacobian[i];\n+                final double weight   = weights[i];\n+                final double residual = objective[i] - target[i];\n+\n+                // compute the normal equation\n+                final double wr = weight * residual;\n+                for (int j = 0; j < cols; ++j) {\n+                    b[j] += wr * grad[j];\n+                }\n+\n+                // build the contribution matrix for measurement i\n+                for (int k = 0; k < cols; ++k) {\n+                    double[] ak = a[k];\n+                    double wgk = weight * grad[k];\n+                    for (int l = 0; l < cols; ++l) {\n+                        ak[l] += wgk * grad[l];\n+                    }\n+                }\n+\n+            }\n+\n+            try {\n+\n+                // solve the linearized least squares problem\n+                RealMatrix mA = new DenseRealMatrix(a);\n+                DecompositionSolver solver = useLU ?\n+                        new LUDecompositionImpl(mA).getSolver() :\n+                        new QRDecompositionImpl(mA).getSolver();\n+                final double[] dX = solver.solve(b);\n+\n+                // update the estimated parameters\n+                for (int i = 0; i < cols; ++i) {\n+                    variables[i] += dX[i];\n+                }\n+\n+            } catch(InvalidMatrixException e) {\n+                throw new OptimizationException(\"unable to solve: singular problem\");\n+            }\n+\n+            // check convergence\n+            if (previous != null) {\n+                converged = checker.converged(++iteration, previous, current);\n+            }\n+\n+        }\n+\n+        // we have converged\n+        return current;\n+\n+    }\n+\n+}\n--- /dev/null\n+++ b/src/test/org/apache/commons/math/optimization/general/GaussNewtonOptimizerTest.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.optimization.general;\n+\n+import java.awt.geom.Point2D;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+\n+import junit.framework.Test;\n+import junit.framework.TestCase;\n+import junit.framework.TestSuite;\n+\n+import org.apache.commons.math.linear.DenseRealMatrix;\n+import org.apache.commons.math.linear.RealMatrix;\n+import org.apache.commons.math.optimization.ObjectiveException;\n+import org.apache.commons.math.optimization.OptimizationException;\n+import org.apache.commons.math.optimization.SimpleVectorialValueChecker;\n+import org.apache.commons.math.optimization.VectorialDifferentiableObjectiveFunction;\n+import org.apache.commons.math.optimization.VectorialPointValuePair;\n+\n+/**\n+ * <p>Some of the unit tests are re-implementations of the MINPACK <a\n+ * href=\"http://www.netlib.org/minpack/ex/file17\">file17</a> and <a\n+ * href=\"http://www.netlib.org/minpack/ex/file22\">file22</a> test files. \n+ * The redistribution policy for MINPACK is available <a\n+ * href=\"http://www.netlib.org/minpack/disclaimer\">here</a>, for\n+ * convenience, it is reproduced below.</p>\n+\n+ * <table border=\"0\" width=\"80%\" cellpadding=\"10\" align=\"center\" bgcolor=\"#E0E0E0\">\n+ * <tr><td>\n+ *    Minpack Copyright Notice (1999) University of Chicago.\n+ *    All rights reserved\n+ * </td></tr>\n+ * <tr><td>\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions\n+ * are met:\n+ * <ol>\n+ *  <li>Redistributions of source code must retain the above copyright\n+ *      notice, this list of conditions and the following disclaimer.</li>\n+ * <li>Redistributions in binary form must reproduce the above\n+ *     copyright notice, this list of conditions and the following\n+ *     disclaimer in the documentation and/or other materials provided\n+ *     with the distribution.</li>\n+ * <li>The end-user documentation included with the redistribution, if any,\n+ *     must include the following acknowledgment:\n+ *     <code>This product includes software developed by the University of\n+ *           Chicago, as Operator of Argonne National Laboratory.</code>\n+ *     Alternately, this acknowledgment may appear in the software itself,\n+ *     if and wherever such third-party acknowledgments normally appear.</li>\n+ * <li><strong>WARRANTY DISCLAIMER. THE SOFTWARE IS SUPPLIED \"AS IS\"\n+ *     WITHOUT WARRANTY OF ANY KIND. THE COPYRIGHT HOLDER, THE\n+ *     UNITED STATES, THE UNITED STATES DEPARTMENT OF ENERGY, AND\n+ *     THEIR EMPLOYEES: (1) DISCLAIM ANY WARRANTIES, EXPRESS OR\n+ *     IMPLIED, INCLUDING BUT NOT LIMITED TO ANY IMPLIED WARRANTIES\n+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE\n+ *     OR NON-INFRINGEMENT, (2) DO NOT ASSUME ANY LEGAL LIABILITY\n+ *     OR RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR\n+ *     USEFULNESS OF THE SOFTWARE, (3) DO NOT REPRESENT THAT USE OF\n+ *     THE SOFTWARE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS, (4)\n+ *     DO NOT WARRANT THAT THE SOFTWARE WILL FUNCTION\n+ *     UNINTERRUPTED, THAT IT IS ERROR-FREE OR THAT ANY ERRORS WILL\n+ *     BE CORRECTED.</strong></li>\n+ * <li><strong>LIMITATION OF LIABILITY. IN NO EVENT WILL THE COPYRIGHT\n+ *     HOLDER, THE UNITED STATES, THE UNITED STATES DEPARTMENT OF\n+ *     ENERGY, OR THEIR EMPLOYEES: BE LIABLE FOR ANY INDIRECT,\n+ *     INCIDENTAL, CONSEQUENTIAL, SPECIAL OR PUNITIVE DAMAGES OF\n+ *     ANY KIND OR NATURE, INCLUDING BUT NOT LIMITED TO LOSS OF\n+ *     PROFITS OR LOSS OF DATA, FOR ANY REASON WHATSOEVER, WHETHER\n+ *     SUCH LIABILITY IS ASSERTED ON THE BASIS OF CONTRACT, TORT\n+ *     (INCLUDING NEGLIGENCE OR STRICT LIABILITY), OR OTHERWISE,\n+ *     EVEN IF ANY OF SAID PARTIES HAS BEEN WARNED OF THE\n+ *     POSSIBILITY OF SUCH LOSS OR DAMAGES.</strong></li>\n+ * <ol></td></tr>\n+ * </table>\n+\n+ * @author Argonne National Laboratory. MINPACK project. March 1980 (original fortran minpack tests)\n+ * @author Burton S. Garbow (original fortran minpack tests)\n+ * @author Kenneth E. Hillstrom (original fortran minpack tests)\n+ * @author Jorge J. More (original fortran minpack tests)\n+ * @author Luc Maisonobe (non-minpack tests and minpack tests Java translation)\n+ */\n+public class GaussNewtonOptimizerTest\n+extends TestCase {\n+\n+    public GaussNewtonOptimizerTest(String name) {\n+        super(name);\n+    }\n+\n+    public void testTrivial() throws ObjectiveException, OptimizationException {\n+        LinearProblem problem =\n+            new LinearProblem(new double[][] { { 2 } }, new double[] { 3 });\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(problem, problem.target, new double[] { 1 }, new double[] { 0 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        assertEquals(1.5, optimum.getPoint()[0], 1.0e-10);\n+    }\n+\n+    public void testColumnsPermutation() throws ObjectiveException, OptimizationException {\n+\n+        LinearProblem problem =\n+            new LinearProblem(new double[][] { { 1.0, -1.0 }, { 0.0, 2.0 }, { 1.0, -2.0 } },\n+                              new double[] { 4.0, 6.0, 1.0 });\n+\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1 }, new double[] { 0, 0 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        assertEquals(7.0, optimum.getPoint()[0], 1.0e-10);\n+        assertEquals(3.0, optimum.getPoint()[1], 1.0e-10);\n+\n+    }\n+\n+    public void testNoDependency() throws ObjectiveException, OptimizationException {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 2, 0, 0, 0, 0, 0 },\n+                { 0, 2, 0, 0, 0, 0 },\n+                { 0, 0, 2, 0, 0, 0 },\n+                { 0, 0, 0, 2, 0, 0 },\n+                { 0, 0, 0, 0, 2, 0 },\n+                { 0, 0, 0, 0, 0, 2 }\n+        }, new double[] { 0.0, 1.1, 2.2, 3.3, 4.4, 5.5 });\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1, 1, 1, 1 },\n+                               new double[] { 0, 0, 0, 0, 0, 0 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        for (int i = 0; i < problem.target.length; ++i) {\n+            assertEquals(0.55 * i, optimum.getPoint()[i], 1.0e-10);\n+        }\n+    }\n+\n+    public void testOneSet() throws ObjectiveException, OptimizationException {\n+\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  1,  0, 0 },\n+                { -1,  1, 0 },\n+                {  0, -1, 1 }\n+        }, new double[] { 1, 1, 1});\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1 }, new double[] { 0, 0, 0 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        assertEquals(1.0, optimum.getPoint()[0], 1.0e-10);\n+        assertEquals(2.0, optimum.getPoint()[1], 1.0e-10);\n+        assertEquals(3.0, optimum.getPoint()[2], 1.0e-10);\n+\n+    }\n+\n+    public void testTwoSets() throws ObjectiveException, OptimizationException {\n+        double epsilon = 1.0e-7;\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  2,  1,   0,  4,       0, 0 },\n+                { -4, -2,   3, -7,       0, 0 },\n+                {  4,  1,  -2,  8,       0, 0 },\n+                {  0, -3, -12, -1,       0, 0 },\n+                {  0,  0,   0,  0, epsilon, 1 },\n+                {  0,  0,   0,  0,       1, 1 }\n+        }, new double[] { 2, -9, 2, 2, 1 + epsilon * epsilon, 2});\n+\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1, 1, 1, 1 },\n+                               new double[] { 0, 0, 0, 0, 0, 0 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        assertEquals( 3.0, optimum.getPoint()[0], 1.0e-10);\n+        assertEquals( 4.0, optimum.getPoint()[1], 1.0e-10);\n+        assertEquals(-1.0, optimum.getPoint()[2], 1.0e-10);\n+        assertEquals(-2.0, optimum.getPoint()[3], 1.0e-10);\n+        assertEquals( 1.0 + epsilon, optimum.getPoint()[4], 1.0e-10);\n+        assertEquals( 1.0 - epsilon, optimum.getPoint()[5], 1.0e-10);\n+\n+    }\n+\n+    public void testNonInversible() throws OptimizationException {\n+\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                {  1, 2, -3 },\n+                {  2, 1,  3 },\n+                { -3, 0, -9 }\n+        }, new double[] { 1, 1, 1 });\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        try {\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1 }, new double[] { 0, 0, 0 });\n+            fail(\"an exception should have been caught\");\n+        } catch (OptimizationException ee) {\n+            // expected behavior\n+        } catch (Exception e) {\n+            fail(\"wrong exception type caught\");\n+        }\n+    }\n+\n+    public void testIllConditioned() throws ObjectiveException, OptimizationException {\n+        LinearProblem problem1 = new LinearProblem(new double[][] {\n+                { 10.0, 7.0,  8.0,  7.0 },\n+                {  7.0, 5.0,  6.0,  5.0 },\n+                {  8.0, 6.0, 10.0,  9.0 },\n+                {  7.0, 5.0,  9.0, 10.0 }\n+        }, new double[] { 32, 23, 33, 31 });\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        VectorialPointValuePair optimum1 =\n+            optimizer.optimize(problem1, problem1.target, new double[] { 1, 1, 1, 1 },\n+                               new double[] { 0, 1, 2, 3 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        assertEquals(1.0, optimum1.getPoint()[0], 1.0e-10);\n+        assertEquals(1.0, optimum1.getPoint()[1], 1.0e-10);\n+        assertEquals(1.0, optimum1.getPoint()[2], 1.0e-10);\n+        assertEquals(1.0, optimum1.getPoint()[3], 1.0e-10);\n+\n+        LinearProblem problem2 = new LinearProblem(new double[][] {\n+                { 10.00, 7.00, 8.10, 7.20 },\n+                {  7.08, 5.04, 6.00, 5.00 },\n+                {  8.00, 5.98, 9.89, 9.00 },\n+                {  6.99, 4.99, 9.00, 9.98 }\n+        }, new double[] { 32, 23, 33, 31 });\n+        VectorialPointValuePair optimum2 =\n+            optimizer.optimize(problem2, problem2.target, new double[] { 1, 1, 1, 1 },\n+                               new double[] { 0, 1, 2, 3 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        assertEquals(-81.0, optimum2.getPoint()[0], 1.0e-8);\n+        assertEquals(137.0, optimum2.getPoint()[1], 1.0e-8);\n+        assertEquals(-34.0, optimum2.getPoint()[2], 1.0e-8);\n+        assertEquals( 22.0, optimum2.getPoint()[3], 1.0e-8);\n+\n+    }\n+\n+    public void testMoreEstimatedParametersSimple() throws OptimizationException {\n+\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 3.0, 2.0,  0.0, 0.0 },\n+                { 0.0, 1.0, -1.0, 1.0 },\n+                { 2.0, 0.0,  1.0, 0.0 }\n+        }, new double[] { 7.0, 3.0, 5.0 });\n+\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        try {\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1 },\n+                               new double[] { 7, 6, 5, 4 });\n+            fail(\"an exception should have been caught\");\n+        } catch (OptimizationException ee) {\n+            // expected behavior\n+        } catch (Exception e) {\n+            fail(\"wrong exception type caught\");\n+        }\n+\n+    }\n+\n+    public void testMoreEstimatedParametersUnsorted() throws OptimizationException {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                 { 1.0, 1.0,  0.0,  0.0, 0.0,  0.0 },\n+                 { 0.0, 0.0,  1.0,  1.0, 1.0,  0.0 },\n+                 { 0.0, 0.0,  0.0,  0.0, 1.0, -1.0 },\n+                 { 0.0, 0.0, -1.0,  1.0, 0.0,  1.0 },\n+                 { 0.0, 0.0,  0.0, -1.0, 1.0,  0.0 }\n+        }, new double[] { 3.0, 12.0, -1.0, 7.0, 1.0 });\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        try {\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1, 1, 1 },\n+                               new double[] { 2, 2, 2, 2, 2, 2 });\n+            fail(\"an exception should have been caught\");\n+        } catch (OptimizationException ee) {\n+            // expected behavior\n+        } catch (Exception e) {\n+            fail(\"wrong exception type caught\");\n+        }\n+    }\n+\n+    public void testRedundantEquations() throws ObjectiveException, OptimizationException {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 1.0,  1.0 },\n+                { 1.0, -1.0 },\n+                { 1.0,  3.0 }\n+        }, new double[] { 3.0, 1.0, 5.0 });\n+\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1 },\n+                               new double[] { 1, 1 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        assertEquals(2.0, optimum.getPoint()[0], 1.0e-8);\n+        assertEquals(1.0, optimum.getPoint()[1], 1.0e-8);\n+\n+    }\n+\n+    public void testInconsistentEquations() throws ObjectiveException, OptimizationException {\n+        LinearProblem problem = new LinearProblem(new double[][] {\n+                { 1.0,  1.0 },\n+                { 1.0, -1.0 },\n+                { 1.0,  3.0 }\n+        }, new double[] { 3.0, 1.0, 4.0 });\n+\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        optimizer.optimize(problem, problem.target, new double[] { 1, 1, 1 }, new double[] { 1, 1 });\n+        assertTrue(optimizer.getRMS() > 0.1);\n+\n+    }\n+\n+    public void testInconsistentSizes() throws ObjectiveException, OptimizationException {\n+        LinearProblem problem =\n+            new LinearProblem(new double[][] { { 1, 0 }, { 0, 1 } }, new double[] { -1, 1 });\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(problem, problem.target, new double[] { 1, 1 }, new double[] { 0, 0 });\n+        assertEquals(0, optimizer.getRMS(), 1.0e-10);\n+        assertEquals(-1, optimum.getPoint()[0], 1.0e-10);\n+        assertEquals(+1, optimum.getPoint()[1], 1.0e-10);\n+\n+        try {\n+            optimizer.optimize(problem, problem.target,\n+                               new double[] { 1 },\n+                               new double[] { 0, 0 });\n+            fail(\"an exception should have been thrown\");\n+        } catch (OptimizationException oe) {\n+            // expected behavior\n+        } catch (Exception e) {\n+            fail(\"wrong exception caught\");\n+        }\n+\n+        try {\n+            optimizer.optimize(problem, new double[] { 1 },\n+                               new double[] { 1 },\n+                               new double[] { 0, 0 });\n+            fail(\"an exception should have been thrown\");\n+        } catch (ObjectiveException oe) {\n+            // expected behavior\n+        } catch (Exception e) {\n+            fail(\"wrong exception caught\");\n+        }\n+\n+    }\n+\n+    public void testMaxIterations() {\n+        Circle circle = new Circle();\n+        circle.addPoint( 30.0,  68.0);\n+        circle.addPoint( 50.0,  -6.0);\n+        circle.addPoint(110.0, -20.0);\n+        circle.addPoint( 35.0,  15.0);\n+        circle.addPoint( 45.0,  97.0);\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-15, 1.0e-15));\n+        try {\n+            optimizer.optimize(circle, new double[] { 0, 0, 0, 0, 0 },\n+                               new double[] { 1, 1, 1, 1, 1 },\n+                               new double[] { 98.680, 47.345 });\n+            fail(\"an exception should have been caught\");\n+        } catch (OptimizationException ee) {\n+            // expected behavior\n+        } catch (Exception e) {\n+            fail(\"wrong exception type caught\");\n+        }\n+    }\n+\n+    public void testCircleFitting() throws ObjectiveException, OptimizationException {\n+        Circle circle = new Circle();\n+        circle.addPoint( 30.0,  68.0);\n+        circle.addPoint( 50.0,  -6.0);\n+        circle.addPoint(110.0, -20.0);\n+        circle.addPoint( 35.0,  15.0);\n+        circle.addPoint( 45.0,  97.0);\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-13, 1.0e-13));\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(circle, new double[] { 0, 0, 0, 0, 0 },\n+                               new double[] { 1, 1, 1, 1, 1 },\n+                               new double[] { 98.680, 47.345 });\n+        assertEquals(1.768262623567235,  Math.sqrt(circle.getN()) * optimizer.getRMS(),  1.0e-10);\n+        Point2D.Double center = new Point2D.Double(optimum.getPointRef()[0], optimum.getPointRef()[1]);\n+        assertEquals(69.96016175359975, circle.getRadius(center), 1.0e-10);\n+        assertEquals(96.07590209601095, center.x, 1.0e-10);\n+        assertEquals(48.135167894714,   center.y, 1.0e-10);\n+    }\n+\n+    public void testCircleFittingBadInit() throws ObjectiveException, OptimizationException {\n+        Circle circle = new Circle();\n+        double[][] points = new double[][] {\n+                {-0.312967,  0.072366}, {-0.339248,  0.132965}, {-0.379780,  0.202724},\n+                {-0.390426,  0.260487}, {-0.361212,  0.328325}, {-0.346039,  0.392619},\n+                {-0.280579,  0.444306}, {-0.216035,  0.470009}, {-0.149127,  0.493832},\n+                {-0.075133,  0.483271}, {-0.007759,  0.452680}, { 0.060071,  0.410235},\n+                { 0.103037,  0.341076}, { 0.118438,  0.273884}, { 0.131293,  0.192201},\n+                { 0.115869,  0.129797}, { 0.072223,  0.058396}, { 0.022884,  0.000718},\n+                {-0.053355, -0.020405}, {-0.123584, -0.032451}, {-0.216248, -0.032862},\n+                {-0.278592, -0.005008}, {-0.337655,  0.056658}, {-0.385899,  0.112526},\n+                {-0.405517,  0.186957}, {-0.415374,  0.262071}, {-0.387482,  0.343398},\n+                {-0.347322,  0.397943}, {-0.287623,  0.458425}, {-0.223502,  0.475513},\n+                {-0.135352,  0.478186}, {-0.061221,  0.483371}, { 0.003711,  0.422737},\n+                { 0.065054,  0.375830}, { 0.108108,  0.297099}, { 0.123882,  0.222850},\n+                { 0.117729,  0.134382}, { 0.085195,  0.056820}, { 0.029800, -0.019138},\n+                {-0.027520, -0.072374}, {-0.102268, -0.091555}, {-0.200299, -0.106578},\n+                {-0.292731, -0.091473}, {-0.356288, -0.051108}, {-0.420561,  0.014926},\n+                {-0.471036,  0.074716}, {-0.488638,  0.182508}, {-0.485990,  0.254068},\n+                {-0.463943,  0.338438}, {-0.406453,  0.404704}, {-0.334287,  0.466119},\n+                {-0.254244,  0.503188}, {-0.161548,  0.495769}, {-0.075733,  0.495560},\n+                { 0.001375,  0.434937}, { 0.082787,  0.385806}, { 0.115490,  0.323807},\n+                { 0.141089,  0.223450}, { 0.138693,  0.131703}, { 0.126415,  0.049174},\n+                { 0.066518, -0.010217}, {-0.005184, -0.070647}, {-0.080985, -0.103635},\n+                {-0.177377, -0.116887}, {-0.260628, -0.100258}, {-0.335756, -0.056251},\n+                {-0.405195, -0.000895}, {-0.444937,  0.085456}, {-0.484357,  0.175597},\n+                {-0.472453,  0.248681}, {-0.438580,  0.347463}, {-0.402304,  0.422428},\n+                {-0.326777,  0.479438}, {-0.247797,  0.505581}, {-0.152676,  0.519380},\n+                {-0.071754,  0.516264}, { 0.015942,  0.472802}, { 0.076608,  0.419077},\n+                { 0.127673,  0.330264}, { 0.159951,  0.262150}, { 0.153530,  0.172681},\n+                { 0.140653,  0.089229}, { 0.078666,  0.024981}, { 0.023807, -0.037022},\n+                {-0.048837, -0.077056}, {-0.127729, -0.075338}, {-0.221271, -0.067526}\n+        };\n+        double[] target = new double[points.length];\n+        Arrays.fill(target, 0.0);\n+        double[] weights = new double[points.length];\n+        Arrays.fill(weights, 2.0);\n+        for (int i = 0; i < points.length; ++i) {\n+            circle.addPoint(points[i][0], points[i][1]);\n+        }\n+        GaussNewtonOptimizer optimizer = new GaussNewtonOptimizer(true);\n+        optimizer.setMaxEvaluations(100);\n+        optimizer.setConvergenceChecker(new SimpleVectorialValueChecker(1.0e-6, 1.0e-6));\n+        try {\n+            optimizer.optimize(circle, target, weights, new double[] { -12, -12 });\n+            fail(\"an exception should have been caught\");\n+        } catch (OptimizationException ee) {\n+            // expected behavior\n+        } catch (Exception e) {\n+            fail(\"wrong exception type caught\");\n+        }\n+\n+        VectorialPointValuePair optimum =\n+            optimizer.optimize(circle, target, weights, new double[] { 0, 0 });\n+        assertEquals(-0.1517383071957963, optimum.getPointRef()[0], 1.0e-8);\n+        assertEquals(0.2074999736353867,  optimum.getPointRef()[1], 1.0e-8);\n+        assertEquals(0.04268731682389561, optimizer.getRMS(),       1.0e-8);\n+\n+    }\n+\n+    private static class LinearProblem implements VectorialDifferentiableObjectiveFunction {\n+\n+        private static final long serialVersionUID = 703247177355019415L;\n+        final RealMatrix factors;\n+        final double[] target;\n+        public LinearProblem(double[][] factors, double[] target) {\n+            this.factors = new DenseRealMatrix(factors);\n+            this.target  = target;\n+        }\n+\n+        public double[][] jacobian(double[] variables, double[] value) {\n+            return factors.getData();\n+        }\n+\n+        public double[] objective(double[] variables) {\n+            return factors.operate(variables);\n+        }\n+\n+    }\n+\n+    private static class Circle implements VectorialDifferentiableObjectiveFunction {\n+\n+        private static final long serialVersionUID = -4711170319243817874L;\n+\n+        private ArrayList<Point2D.Double> points;\n+\n+        public Circle() {\n+            points  = new ArrayList<Point2D.Double>();\n+        }\n+\n+        public void addPoint(double px, double py) {\n+            points.add(new Point2D.Double(px, py));\n+        }\n+\n+        public int getN() {\n+            return points.size();\n+        }\n+\n+        public double getRadius(Point2D.Double center) {\n+            double r = 0;\n+            for (Point2D.Double point : points) {\n+                r += point.distance(center);\n+            }\n+            return r / points.size();\n+        }\n+\n+        public double[][] jacobian(double[] variables, double[] value)\n+                throws ObjectiveException, IllegalArgumentException {\n+\n+            int n = points.size();\n+            Point2D.Double center = new Point2D.Double(variables[0], variables[1]);\n+\n+            // gradient of the optimal radius\n+            double dRdX = 0;\n+            double dRdY = 0;\n+            for (Point2D.Double pk : points) {\n+                double dk = pk.distance(center);\n+                dRdX += (center.x - pk.x) / dk;\n+                dRdY += (center.y - pk.y) / dk;\n+            }\n+            dRdX /= n;\n+            dRdY /= n;\n+\n+            // jacobian of the radius residuals\n+            double[][] jacobian = new double[n][2];\n+            for (int i = 0; i < n; ++i) {\n+                Point2D.Double pi = points.get(i);\n+                double di   = pi.distance(center);\n+                jacobian[i][0] = (center.x - pi.x) / di - dRdX;    \n+                jacobian[i][1] = (center.y - pi.y) / di - dRdY;    \n+           }\n+\n+            return jacobian;\n+\n+        }\n+\n+        public double[] objective(double[] variables)\n+                throws ObjectiveException, IllegalArgumentException {\n+\n+            Point2D.Double center = new Point2D.Double(variables[0], variables[1]);\n+            double radius = getRadius(center);\n+\n+            double[] residuals = new double[points.size()];\n+            for (int i = 0; i < residuals.length; ++i) {\n+                residuals[i] = points.get(i).distance(center) - radius;\n+            }\n+\n+            return residuals;\n+\n+        }\n+\n+    }\n+\n+    public static Test suite() {\n+        return new TestSuite(GaussNewtonOptimizerTest.class);\n+    }\n+\n+}", "timestamp": 1237052307, "metainfo": ""}