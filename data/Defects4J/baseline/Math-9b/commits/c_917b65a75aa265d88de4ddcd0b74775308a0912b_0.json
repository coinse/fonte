{"sha": "917b65a75aa265d88de4ddcd0b74775308a0912b", "log": "Corrected Y variance formula and added error variance methods to return what were previously reported as Y variances. JIRA: MATH-392 Reported and patched by Mark Devaney   ", "commit": "\n--- a/src/main/java/org/apache/commons/math/stat/regression/AbstractMultipleLinearRegression.java\n+++ b/src/main/java/org/apache/commons/math/stat/regression/AbstractMultipleLinearRegression.java\n import org.apache.commons.math.linear.Array2DRowRealMatrix;\n import org.apache.commons.math.linear.RealVector;\n import org.apache.commons.math.linear.ArrayRealVector;\n+import org.apache.commons.math.stat.descriptive.moment.Variance;\n \n /**\n  * Abstract base class for implementations of MultipleLinearRegression.\n      */\n     public double[] estimateRegressionParametersStandardErrors() {\n         double[][] betaVariance = estimateRegressionParametersVariance();\n-        double sigma = calculateYVariance();\n+        RealVector residuals = calculateResiduals();\n+        double sigma = calculateErrorVariance();\n         int length = betaVariance[0].length;\n         double[] result = new double[length];\n         for (int i = 0; i < length; i++) {\n     }\n \n     /**\n+     * Estimates the variance of the error.\n+     *\n+     * @return estimate of the error variance\n+     */\n+    public double estimateErrorVariance() {\n+        return calculateErrorVariance();\n+\n+    }\n+\n+    /**\n+     * Estimates the standard error of the regression.\n+     *\n+     * @return regression standard error\n+     */\n+    public double estimateRegressionStandardError() {\n+        return Math.sqrt(estimateErrorVariance());\n+    }\n+\n+    /**\n      * Calculates the beta of multiple linear regression in matrix notation.\n      *\n      * @return beta\n      */\n     protected abstract RealMatrix calculateBetaVariance();\n \n-    /**\n-     * Calculates the Y variance of multiple linear regression.\n+\n+    /**\n+     * Calculates the variance of the y values.\n      *\n      * @return Y variance\n      */\n-    protected abstract double calculateYVariance();\n+    protected double calculateYVariance() {\n+        return new Variance().evaluate(Y.getData());\n+    }\n+\n+    /**\n+     * <p>Calculates the variance of the error term.</p>\n+     * Uses the formula <pre>\n+     * var(u) = u &middot; u / (n - k)\n+     * </pre>\n+     * where n and k are the row and column dimensions of the design\n+     * matrix X.\n+     *\n+     * @return error variance estimate\n+     */\n+    protected double calculateErrorVariance() {\n+        RealVector residuals = calculateResiduals();\n+        return residuals.dotProduct(residuals) /\n+               (X.getRowDimension() - X.getColumnDimension());\n+    }\n \n     /**\n      * Calculates the residuals of multiple linear regression in matrix\n--- a/src/main/java/org/apache/commons/math/stat/regression/GLSMultipleLinearRegression.java\n+++ b/src/main/java/org/apache/commons/math/stat/regression/GLSMultipleLinearRegression.java\n import org.apache.commons.math.linear.RealMatrix;\n import org.apache.commons.math.linear.Array2DRowRealMatrix;\n import org.apache.commons.math.linear.RealVector;\n-\n \n /**\n  * The GLS implementation of the multiple linear regression.\n     }\n \n     /**\n-     * Calculates the variance on the beta by GLS.\n+     * Calculates the variance on the beta.\n      * <pre>\n      *  Var(b)=(X' Omega^-1 X)^-1\n      * </pre>\n         return new LUDecompositionImpl(XTOIX).getSolver().getInverse();\n     }\n \n+\n     /**\n-     * Calculates the variance on the y by GLS.\n+     * Calculates the estimated variance of the error term using the formula\n      * <pre>\n-     *  Var(y)=Tr(u' Omega^-1 u)/(n-k)\n+     *  Var(u) = Tr(u' Omega^-1 u)/(n-k)\n      * </pre>\n-     * @return The Y variance\n+     * where n and k are the row and column dimensions of the design\n+     * matrix X.\n+     *\n+     * @return error variance\n      */\n     @Override\n-    protected double calculateYVariance() {\n+    protected double calculateErrorVariance() {\n         RealVector residuals = calculateResiduals();\n         double t = residuals.dotProduct(getOmegaInverse().operate(residuals));\n         return t / (X.getRowDimension() - X.getColumnDimension());\n+\n     }\n \n }\n--- a/src/main/java/org/apache/commons/math/stat/regression/OLSMultipleLinearRegression.java\n+++ b/src/main/java/org/apache/commons/math/stat/regression/OLSMultipleLinearRegression.java\n  * (R<sup>T</sup>)<sup>-1</sup> R<sup>T</sup> R b = (R<sup>T</sup>)<sup>-1</sup> R<sup>T</sup> Q<sup>T</sup> y <br/>\n  * R b = Q<sup>T</sup> y\n  * </p>\n- * Given Q and R, the last equation is solved by back-subsitution.</p>\n+ * Given Q and R, the last equation is solved by back-substitution.</p>\n  *\n  * @version $Revision$ $Date$\n  * @since 2.0\n         return Rinv.multiply(Rinv.transpose());\n     }\n \n-\n-    /**\n-     * <p>Calculates the variance on the Y by OLS.\n-     * </p>\n-     * <p> Var(y) = Tr(u<sup>T</sup>u)/(n - k)\n-     * </p>\n-     * @return The Y variance\n-     */\n-    @Override\n-    protected double calculateYVariance() {\n-        RealVector residuals = calculateResiduals();\n-        return residuals.dotProduct(residuals) /\n-               (X.getRowDimension() - X.getColumnDimension());\n-    }\n-\n }\n--- a/src/test/java/org/apache/commons/math/stat/regression/GLSMultipleLinearRegressionTest.java\n+++ b/src/test/java/org/apache/commons/math/stat/regression/GLSMultipleLinearRegressionTest.java\n \n import org.junit.Before;\n import org.junit.Test;\n+import org.apache.commons.math.TestUtils;\n+import org.apache.commons.math.stat.StatUtils;\n \n public class GLSMultipleLinearRegressionTest extends MultipleLinearRegressionAbstractTest {\n \n         return y.length;\n     }\n \n+    /**\n+     * test calculateYVariance\n+     */\n+    @Test\n+    public void testYVariance() {\n+\n+        // assumes: y = new double[]{11.0, 12.0, 13.0, 14.0, 15.0, 16.0};\n+\n+        GLSMultipleLinearRegression model = new GLSMultipleLinearRegression();\n+        model.newSampleData(y, x, omega);\n+        TestUtils.assertEquals(model.calculateYVariance(), 3.5, 0);\n+    }\n }\n--- a/src/test/java/org/apache/commons/math/stat/regression/OLSMultipleLinearRegressionTest.java\n+++ b/src/test/java/org/apache/commons/math/stat/regression/OLSMultipleLinearRegressionTest.java\n import org.apache.commons.math.linear.MatrixVisitorException;\n import org.apache.commons.math.linear.RealMatrix;\n import org.apache.commons.math.linear.Array2DRowRealMatrix;\n+import org.apache.commons.math.stat.StatUtils;\n import org.junit.Before;\n import org.junit.Test;\n \n     }\n \n     @Test\n-    public void testPerfectFit() {\n+    public void testPerfectFit() throws Exception {\n         double[] betaHat = regression.estimateRegressionParameters();\n         TestUtils.assertEquals(betaHat,\n                                new double[]{ 11.0, 1.0 / 2.0, 2.0 / 3.0, 3.0 / 4.0, 4.0 / 5.0, 5.0 / 6.0 },\n        assertEquals(0.0,\n                      errors.subtract(referenceVariance).getNorm(),\n                      5.0e-16 * referenceVariance.getNorm());\n+       \n     }\n \n \n      * http://www.itl.nist.gov/div898/strd/lls/data/LINKS/DATA/Longley.dat\n      */\n     @Test\n-    public void testLongly() {\n+    public void testLongly() throws Exception {\n         // Y values are first, then independent vars\n         // Each row is one observation\n         double[] design = new double[] {\n                        0.214274163161675,\n                        0.226073200069370,\n                        455.478499142212}, errors, 1E-6);\n+        \n+        // Check regression standard error against R\n+        assertEquals(304.8540735619638, model.estimateRegressionStandardError(), 1E-10);\n+        \n+        checkVarianceConsistency(model);\n     }\n \n     /**\n      * Data Source: R datasets package\n      */\n     @Test\n-    public void testSwissFertility() {\n+    public void testSwissFertility() throws Exception {\n         double[] design = new double[] {\n             80.2,17.0,15,12,9.96,\n             83.1,45.1,6,9,84.84,\n                 0.27410957467466,\n                 0.19454551679325,\n                 0.03726654773803}, errors, 1E-10);\n+        \n+        // Check regression standard error against R\n+        assertEquals(7.73642194433223, model.estimateRegressionStandardError(), 1E-12);\n+        \n+        checkVarianceConsistency(model);\n     }\n \n     /**\n         double[] hatResiduals = I.subtract(hat).operate(model.Y).getData();\n         TestUtils.assertEquals(residuals, hatResiduals, 10e-12);\n     }\n+\n+    /**\n+     * test calculateYVariance\n+     */\n+    @Test\n+    public void testYVariance() {\n+\n+        // assumes: y = new double[]{11.0, 12.0, 13.0, 14.0, 15.0, 16.0};\n+\n+        OLSMultipleLinearRegression model = new OLSMultipleLinearRegression();\n+        model.newSampleData(y, x);\n+        TestUtils.assertEquals(model.calculateYVariance(), 3.5, 0);\n+    }\n+    \n+    /**\n+     * Verifies that calculateYVariance and calculateResidualVariance return consistent\n+     * values with direct variance computation from Y, residuals, respectively.\n+     */\n+    protected void checkVarianceConsistency(OLSMultipleLinearRegression model) throws Exception {\n+        // Check Y variance consistency\n+        TestUtils.assertEquals(StatUtils.variance(model.Y.getData()), model.calculateYVariance(), 0);\n+        \n+        // Check residual variance consistency\n+        double[] residuals = model.calculateResiduals().getData();\n+        RealMatrix X = model.X;\n+        TestUtils.assertEquals(\n+                StatUtils.variance(model.calculateResiduals().getData()) * (residuals.length - 1),\n+                model.calculateErrorVariance() * (X.getRowDimension() - X.getColumnDimension()), 1E-20);\n+        \n+    }\n }", "timestamp": 1282482815, "metainfo": ""}