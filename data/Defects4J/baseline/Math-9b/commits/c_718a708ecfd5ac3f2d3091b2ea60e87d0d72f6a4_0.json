{"sha": "718a708ecfd5ac3f2d3091b2ea60e87d0d72f6a4", "log": "Added general methods to guess errors on estimated parameters JIRA: MATH-176  ", "commit": "\n--- a/src/java/org/apache/commons/math/MessagesResources_fr.java\n+++ b/src/java/org/apache/commons/math/MessagesResources_fr.java\n     { \"Conversion Exception in Transformation: {0}\",\n       \"Exception de conversion dans une transformation : {0}\" },\n \n+    // org.apache.commons.math.estimation.AbstractEstimator\n+    { \"maximal number of evaluations exceeded ({0})\",\n+      \"nombre maximal d''\\u00e9valuations d\\u00e9pass\\u00e9 ({0})\" },\n+    { \"unable to compute covariances: singular problem\",\n+      \"impossible de calculer les covariances : probl\\u00e8me singulier\"},\n+    { \"no degrees of freedom ({0} measurements, {1} parameters)\",\n+      \"aucun degr\\u00e9 de libert\\u00e9 ({0} mesures, {1} param\\u00e8tres)\" },\n+\n     // org.apache.commons.math.estimation.GaussNewtonEstimator\n-    { \"unable to converge in {0} iterations\",\n-      \"pas de convergence apr\\u00e8s {0} it\\u00e9rations\" },\n+    { \"unable to solve: singular problem\",\n+      \"r\\u00e9solution impossible : probl\\u00e8me singulier\" },\n \n     // org.apache.commons.math.estimation.LevenbergMarquardtEstimator\n     { \"cost relative tolerance is too small ({0}), no further reduction in the sum of squares is possible\",\n       \"trop petite tol\\u00e9rance relative sur les param\\u00e8tres ({0}), aucune am\\u00e9lioration de la solution approximative n''est possible\" },\n     { \"orthogonality tolerance is too small ({0}), solution is orthogonal to the jacobian\",\n       \"trop petite tol\\u00e9rance sur l''orthogonalit\\u00e9 ({0}), la solution est orthogonale \\u00e0 la jacobienne\" },\n-    { \"maximal number of evaluations exceeded ({0})\",\n-      \"nombre maximal d''\\u00e9valuations d\\u00e9pass\\u00e9 ({0})\" },\n \n     // org.apache.commons.math.geometry.CardanEulerSingularityException\n     { \"Cardan angles singularity\",\n--- /dev/null\n+++ b/src/java/org/apache/commons/math/estimation/AbstractEstimator.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.estimation;\n+\n+import java.util.Arrays;\n+\n+import org.apache.commons.math.linear.InvalidMatrixException;\n+import org.apache.commons.math.linear.RealMatrixImpl;\n+\n+public abstract class AbstractEstimator implements Estimator {\n+\n+    /**\n+     * Build an abstract estimator for least squares problems.\n+     */\n+    protected AbstractEstimator() {\n+    }\n+\n+    /**\n+     * Set the maximal number of cost evaluations allowed.\n+     * \n+     * @param maxCostEval maximal number of cost evaluations allowed\n+     * @see #estimate\n+     */\n+    public void setMaxCostEval(int maxCostEval) {\n+        this.maxCostEval = maxCostEval;\n+    }\n+\n+    /**\n+     * Get the number of cost evaluations.\n+     * \n+     * @return number of cost evaluations\n+     * */\n+    public int getCostEvaluations() {\n+        return costEvaluations;\n+    }\n+\n+    /** \n+     * Get the number of jacobian evaluations.\n+     * \n+     * @return number of jacobian evaluations\n+     * */\n+    public int getJacobianEvaluations() {\n+        return jacobianEvaluations;\n+    }\n+\n+    /** \n+     * Update the jacobian matrix.\n+     */\n+    protected void updateJacobian() {\n+        ++jacobianEvaluations;\n+        Arrays.fill(jacobian, 0);\n+        for (int i = 0, index = 0; i < rows; i++) {\n+            WeightedMeasurement wm = measurements[i];\n+            double factor = -Math.sqrt(wm.getWeight());\n+            for (int j = 0; j < cols; ++j) {\n+                jacobian[index++] = factor * wm.getPartial(parameters[j]);\n+            }\n+        }\n+    }\n+\n+    /** \n+     * Update the residuals array and cost function value.\n+     * @exception EstimationException if the number of cost evaluations\n+     * exceeds the maximum allowed\n+     */\n+    protected void updateResidualsAndCost()\n+    throws EstimationException {\n+\n+        if (++costEvaluations > maxCostEval) {\n+            throw new EstimationException(\"maximal number of evaluations exceeded ({0})\",\n+                    new String[] {\n+                    Integer.toString(maxCostEval)\n+            });\n+        }\n+\n+        cost = 0;\n+        for (int i = 0, index = 0; i < rows; i++, index += cols) {\n+            WeightedMeasurement wm = measurements[i];\n+            double residual = wm.getResidual();\n+            residuals[i] = Math.sqrt(wm.getWeight()) * residual;\n+            cost += wm.getWeight() * residual * residual;\n+        }\n+        cost = Math.sqrt(cost);\n+\n+    }\n+\n+    /** \n+     * Get the Root Mean Square value.\n+     * Get the Root Mean Square value, i.e. the root of the arithmetic\n+     * mean of the square of all weighted residuals. This is related to the\n+     * criterion that is minimized by the estimator as follows: if\n+     * <em>c</em> if the criterion, and <em>n</em> is the number of\n+     * measurements, then the RMS is <em>sqrt (c/n)</em>.\n+     * \n+     * @param problem estimation problem\n+     * @return RMS value\n+     */\n+    public double getRMS(EstimationProblem problem) {\n+        WeightedMeasurement[] wm = problem.getMeasurements();\n+        double criterion = 0;\n+        for (int i = 0; i < wm.length; ++i) {\n+            double residual = wm[i].getResidual();\n+            criterion += wm[i].getWeight() * residual * residual;\n+        }\n+        return Math.sqrt(criterion / wm.length);\n+    }\n+\n+    /**\n+     * Get the Chi-Square value.\n+     * @param problem estimation problem\n+     * @return chi-square value\n+     */\n+    public double getChiSquare(EstimationProblem problem) {\n+        WeightedMeasurement[] wm = problem.getMeasurements();\n+        double chiSquare = 0;\n+        for (int i = 0; i < wm.length; ++i) {\n+            double residual = wm[i].getResidual();\n+            chiSquare += residual * residual / wm[i].getWeight();\n+        }\n+        return chiSquare;\n+    }\n+\n+    /**\n+     * Get the covariance matrix of estimated parameters.\n+     * @param problem estimation problem\n+     * @return covariance matrix\n+     * @exception EstimationException if the covariance matrix\n+     * cannot be computed (singular problem)\n+     */\n+    public double[][] getCovariances(EstimationProblem problem)\n+      throws EstimationException {\n+ \n+        // set up the jacobian\n+        updateJacobian();\n+\n+        // compute transpose(J).J, avoiding building big intermediate matrices\n+        final int rows = problem.getMeasurements().length;\n+        final int cols = problem.getAllParameters().length;\n+        final int max  = cols * rows;\n+        double[][] jTj = new double[cols][cols];\n+        for (int i = 0; i < cols; ++i) {\n+            for (int j = i; j < cols; ++j) {\n+                double sum = 0;\n+                for (int k = 0; k < max; k += cols) {\n+                    sum += jacobian[k + i] * jacobian[k + j];\n+                }\n+                jTj[i][j] = sum;\n+                jTj[j][i] = sum;\n+            }\n+        }\n+\n+        try {\n+            // compute the covariances matrix\n+            return new RealMatrixImpl(jTj).inverse().getData();\n+        } catch (InvalidMatrixException ime) {\n+            throw new EstimationException(\"unable to compute covariances: singular problem\",\n+                                          new Object[0]);\n+        }\n+\n+    }\n+\n+    /**\n+     * Guess the errors in estimated parameters.\n+     * <p>Guessing is covariance-based, it only gives rough order of magnitude.</p>\n+     * @param problem estimation problem\n+     * @return errors in estimated parameters\n+     * @exception EstimationException if the covariances matrix cannot be computed\n+     * or the number of degrees of freedom is not positive (number of measurements\n+     * lesser or equal to number of parameters)\n+     */\n+    public double[] guessParametersErrors(EstimationProblem problem)\n+      throws EstimationException {\n+        int m = problem.getMeasurements().length;\n+        int p = problem.getAllParameters().length;\n+        if (m <= p) {\n+            throw new EstimationException(\"no degrees of freedom ({0} measurements, {1} parameters)\",\n+                                          new Object[] { new Integer(m), new Integer(p)});\n+        }\n+        double[] errors = new double[problem.getAllParameters().length];\n+        final double c = Math.sqrt(getChiSquare(problem) / (m - p));\n+        double[][] covar = getCovariances(problem);\n+        for (int i = 0; i < errors.length; ++i) {\n+            errors[i] = Math.sqrt(covar[i][i]) * c;\n+        }\n+        return errors;\n+    }\n+\n+    /**\n+     * Initialization of the common parts of the estimation.\n+     * <p>This method <em>must</em> be called at the start\n+     * of the {@link #estimate(EstimationProblem) estimate}\n+     * method.</p>\n+     * @param problem estimation problem to solve\n+     */\n+    protected void initializeEstimate(EstimationProblem problem) {\n+\n+        // reset counters\n+        costEvaluations     = 0;\n+        jacobianEvaluations = 0;\n+\n+        // retrieve the equations and the parameters\n+        measurements = problem.getMeasurements();\n+        parameters   = problem.getUnboundParameters();\n+\n+        // arrays shared with the other private methods\n+        rows      = measurements.length;\n+        cols      = parameters.length;\n+        jacobian  = new double[rows * cols];\n+        residuals = new double[rows];\n+\n+        cost = Double.POSITIVE_INFINITY;\n+\n+    }\n+\n+    public abstract void estimate(EstimationProblem problem)\n+    throws EstimationException;\n+\n+    /** Array of measurements. */\n+    protected WeightedMeasurement[] measurements;\n+\n+    /** Array of parameters. */\n+    protected EstimatedParameter[] parameters;\n+\n+    /** \n+     * Jacobian matrix.\n+     * <p>This matrix is in canonical form just after the calls to\n+     * {@link #updateJacobian()}, but may be modified by the solver\n+     * in the derived class (the {@link LevenbergMarquardtEstimator\n+     * Levenberg-Marquardt estimator} does this).</p>\n+     */\n+    protected double[] jacobian;\n+\n+    /** Number of columns of the jacobian matrix. */\n+    protected int cols;\n+\n+    /** Number of rows of the jacobian matrix. */\n+    protected int rows;\n+\n+    /** Residuals array.\n+     * <p>This array is in canonical form just after the calls to\n+     * {@link #updateJacobian()}, but may be modified by the solver\n+     * in the derived class (the {@link LevenbergMarquardtEstimator\n+     * Levenberg-Marquardt estimator} does this).</p>\n+     */\n+    protected double[] residuals;\n+\n+    /** Cost value (square root of the sum of the residuals). */\n+    protected double cost;\n+\n+    /** Maximal allowed number of cost evaluations. */\n+    protected int maxCostEval;\n+\n+    /** Number of cost evaluations. */\n+    protected int costEvaluations;\n+\n+    /** Number of jacobian evaluations. */\n+    protected int jacobianEvaluations;\n+\n+}\n--- a/src/java/org/apache/commons/math/estimation/EstimationException.java\n+++ b/src/java/org/apache/commons/math/estimation/EstimationException.java\n extends MathException {\n \n     /** Serializable version identifier. */\n-    private static final long serialVersionUID = -7414806622114810487L;\n+    private static final long serialVersionUID = -573038581493881337L;\n \n     /** \n      * Simple constructor.\n      * @param specifier format specifier (to be translated)\n      * @param parts to insert in the format (no translation)\n      */\n-    public EstimationException(String specifier, String[] parts) {\n+    public EstimationException(String specifier, Object[] parts) {\n         super(specifier, parts);\n     }\n \n-    /** \n-     * Simple constructor.\n-     * Build an exception from a cause\n-     * @param cause cause of this exception\n-     */\n-    public EstimationException(Throwable cause) {\n-        super(cause);\n-    }\n-\n }\n--- a/src/java/org/apache/commons/math/estimation/Estimator.java\n+++ b/src/java/org/apache/commons/math/estimation/Estimator.java\n    * criterion that is minimized by the estimator as follows: if\n    * <em>c</em> is the criterion, and <em>n</em> is the number of\n    * measurements, then the RMS is <em>sqrt (c/n)</em>.\n+   * @see #guessParametersErrors(EstimationProblem)\n    * \n    * @param problem estimation problem\n    * @return RMS value\n    */\n   public double getRMS(EstimationProblem problem);\n- \n+\n+  /**\n+   * Get the covariance matrix of estimated parameters.\n+   * @param problem estimation problem\n+   * @return covariance matrix\n+   * @exception EstimationException if the covariance matrix\n+   * cannot be computed (singular problem)\n+   */\n+  public double[][] getCovariances(EstimationProblem problem)\n+    throws EstimationException;\n+\n+  /**\n+   * Guess the errors in estimated parameters.\n+   * @see #getRMS(EstimationProblem)\n+   * @param problem estimation problem\n+   * @return errors in estimated parameters\n+     * @exception EstimationException if the error cannot be guessed\n+   */\n+  public double[] guessParametersErrors(EstimationProblem problem)\n+    throws EstimationException;\n+\n }\n--- a/src/java/org/apache/commons/math/estimation/GaussNewtonEstimator.java\n+++ b/src/java/org/apache/commons/math/estimation/GaussNewtonEstimator.java\n  *\n  */\n \n-public class GaussNewtonEstimator\n-  implements Estimator, Serializable {\n+public class GaussNewtonEstimator extends AbstractEstimator implements Serializable {\n \n-  /** \n-   * Simple constructor.\n-   *\n-   * <p>This constructor builds an estimator and stores its convergence\n-   * characteristics.</p>\n-   *\n-   * <p>An estimator is considered to have converged whenever either\n-   * the criterion goes below a physical threshold under which\n-   * improvements are considered useless or when the algorithm is\n-   * unable to improve it (even if it is still high). The first\n-   * condition that is met stops the iterations.</p>\n-   *\n-   * <p>The fact an estimator has converged does not mean that the\n-   * model accurately fits the measurements. It only means no better\n-   * solution can be found, it does not mean this one is good. Such an\n-   * analysis is left to the caller.</p>\n-   *\n-   * <p>If neither conditions are fulfilled before a given number of\n-   * iterations, the algorithm is considered to have failed and an\n-   * {@link EstimationException} is thrown.</p>\n-   *\n-   * @param maxIterations maximum number of iterations allowed\n-   * @param convergence criterion threshold below which we do not need\n-   * to improve the criterion anymore\n-   * @param steadyStateThreshold steady state detection threshold, the\n-   * problem has converged has reached a steady state if\n-   * <code>Math.abs (Jn - Jn-1) < Jn * convergence</code>, where\n-   * <code>Jn</code> and <code>Jn-1</code> are the current and\n-   * preceding criterion value (square sum of the weighted residuals\n-   * of considered measurements).\n-   */\n-  public GaussNewtonEstimator(int maxIterations,\n-                               double convergence,\n-                               double steadyStateThreshold) {\n-    this.maxIterations        = maxIterations;\n-    this.steadyStateThreshold = steadyStateThreshold;\n-    this.convergence          = convergence;\n-  }\n+    /** \n+     * Simple constructor.\n+     *\n+     * <p>This constructor builds an estimator and stores its convergence\n+     * characteristics.</p>\n+     *\n+     * <p>An estimator is considered to have converged whenever either\n+     * the criterion goes below a physical threshold under which\n+     * improvements are considered useless or when the algorithm is\n+     * unable to improve it (even if it is still high). The first\n+     * condition that is met stops the iterations.</p>\n+     *\n+     * <p>The fact an estimator has converged does not mean that the\n+     * model accurately fits the measurements. It only means no better\n+     * solution can be found, it does not mean this one is good. Such an\n+     * analysis is left to the caller.</p>\n+     *\n+     * <p>If neither conditions are fulfilled before a given number of\n+     * iterations, the algorithm is considered to have failed and an\n+     * {@link EstimationException} is thrown.</p>\n+     *\n+     * @param maxCostEval maximal number of cost evaluations allowed\n+     * @param convergence criterion threshold below which we do not need\n+     * to improve the criterion anymore\n+     * @param steadyStateThreshold steady state detection threshold, the\n+     * problem has converged has reached a steady state if\n+     * <code>Math.abs (Jn - Jn-1) < Jn * convergence</code>, where\n+     * <code>Jn</code> and <code>Jn-1</code> are the current and\n+     * preceding criterion value (square sum of the weighted residuals\n+     * of considered measurements).\n+     */\n+    public GaussNewtonEstimator(int maxCostEval,\n+            double convergence,\n+            double steadyStateThreshold) {\n+        setMaxCostEval(maxCostEval);\n+        this.steadyStateThreshold = steadyStateThreshold;\n+        this.convergence          = convergence;\n+    }\n \n-  /** \n-   * Solve an estimation problem using a least squares criterion.\n-   *\n-   * <p>This method set the unbound parameters of the given problem\n-   * starting from their current values through several iterations. At\n-   * each step, the unbound parameters are changed in order to\n-   * minimize a weighted least square criterion based on the\n-   * measurements of the problem.</p>\n-   *\n-   * <p>The iterations are stopped either when the criterion goes\n-   * below a physical threshold under which improvement are considered\n-   * useless or when the algorithm is unable to improve it (even if it\n-   * is still high). The first condition that is met stops the\n-   * iterations. If the convergence it nos reached before the maximum\n-   * number of iterations, an {@link EstimationException} is\n-   * thrown.</p>\n-   *\n-   * @param problem estimation problem to solve\n-   * @exception EstimationException if the problem cannot be solved\n-   *\n-   * @see EstimationProblem\n-   *\n-   */\n-  public void estimate(EstimationProblem problem)\n-    throws EstimationException {\n-    int    iterations = 0;\n-    double previous   = 0.0;\n-    double current    = 0.0;\n-\n-    // iterate until convergence is reached\n-    do {\n-\n-      if (++iterations > maxIterations) {\n-        throw new EstimationException (\"unable to converge in {0} iterations\",\n-                                       new String[] {\n-                                         Integer.toString(maxIterations)\n-                                       });\n-      }\n-\n-      // perform one iteration\n-      linearEstimate(problem);\n-\n-      previous = current;\n-      current  = evaluateCriterion(problem);\n-\n-    } while ((iterations < 2)\n-             || (Math.abs(previous - current) > (current * steadyStateThreshold)\n-                 && (Math.abs(current) > convergence)));\n-\n-  }\n-\n-  /** \n-   * Estimate the solution of a linear least square problem.\n-   *\n-   * <p>The Gauss-Newton algorithm is iterative. Each iteration\n-   * consists in solving a linearized least square problem. Several\n-   * iterations are needed for general problems since the\n-   * linearization is only an approximation of the problem\n-   * behaviour. However, for linear problems one iteration is enough\n-   * to get the solution. This method is provided in the public\n-   * interface in order to handle more efficiently these linear\n-   * problems.</p>\n-   *\n-   * @param problem estimation problem to solve\n-   * @exception EstimationException if the problem cannot be solved\n-   *\n-   */\n-  public void linearEstimate(EstimationProblem problem)\n+    /** \n+     * Solve an estimation problem using a least squares criterion.\n+     *\n+     * <p>This method set the unbound parameters of the given problem\n+     * starting from their current values through several iterations. At\n+     * each step, the unbound parameters are changed in order to\n+     * minimize a weighted least square criterion based on the\n+     * measurements of the problem.</p>\n+     *\n+     * <p>The iterations are stopped either when the criterion goes\n+     * below a physical threshold under which improvement are considered\n+     * useless or when the algorithm is unable to improve it (even if it\n+     * is still high). The first condition that is met stops the\n+     * iterations. If the convergence it nos reached before the maximum\n+     * number of iterations, an {@link EstimationException} is\n+     * thrown.</p>\n+     *\n+     * @param problem estimation problem to solve\n+     * @exception EstimationException if the problem cannot be solved\n+     *\n+     * @see EstimationProblem\n+     *\n+     */\n+    public void estimate(EstimationProblem problem)\n     throws EstimationException {\n \n-    EstimatedParameter[]  parameters   = problem.getUnboundParameters();\n-    WeightedMeasurement[] measurements = problem.getMeasurements();\n+        initializeEstimate(problem);\n \n-    // build the linear problem\n-    RealMatrix b              = new RealMatrixImpl(parameters.length, 1);\n-    RealMatrix a              = new RealMatrixImpl(parameters.length, parameters.length);\n-    double[] grad             = new double[parameters.length];\n-    RealMatrixImpl bDecrement = new RealMatrixImpl(parameters.length, 1);\n-    double[][] bDecrementData = bDecrement.getDataRef();\n-    RealMatrixImpl wGradGradT = new RealMatrixImpl(parameters.length, parameters.length);\n-    double[][] wggData        = wGradGradT.getDataRef();\n-    for (int i = 0; i < measurements.length; ++i) {\n-        if (! measurements [i].isIgnored()) {\n+        // work matrices\n+        double[] grad             = new double[parameters.length];\n+        RealMatrixImpl bDecrement = new RealMatrixImpl(parameters.length, 1);\n+        double[][] bDecrementData = bDecrement.getDataRef();\n+        RealMatrixImpl wGradGradT = new RealMatrixImpl(parameters.length, parameters.length);\n+        double[][] wggData        = wGradGradT.getDataRef();\n \n-            double weight   = measurements[i].getWeight();\n-            double residual = measurements[i].getResidual();\n+        // iterate until convergence is reached\n+        double previous = Double.POSITIVE_INFINITY;\n+        do {\n \n-            // compute the normal equation\n-            for (int j = 0; j < parameters.length; ++j) {\n-                grad[j] = measurements[i].getPartial(parameters[j]);\n-                bDecrementData[j][0] = weight * residual * grad[j];\n-            }\n+            // build the linear problem\n+            ++jacobianEvaluations;\n+            RealMatrix b = new RealMatrixImpl(parameters.length, 1);\n+            RealMatrix a = new RealMatrixImpl(parameters.length, parameters.length);\n+            for (int i = 0; i < measurements.length; ++i) {\n+                if (! measurements [i].isIgnored()) {\n \n-            // build the contribution matrix for measurement i\n-            for (int k = 0; k < parameters.length; ++k) {\n-                double[] wggRow = wggData[k];\n-                double gk = grad[k];\n-                for (int l = 0; l < parameters.length; ++l) {\n-                    wggRow[l] =  weight * gk * grad[l];\n+                    double weight   = measurements[i].getWeight();\n+                    double residual = measurements[i].getResidual();\n+\n+                    // compute the normal equation\n+                    for (int j = 0; j < parameters.length; ++j) {\n+                        grad[j] = measurements[i].getPartial(parameters[j]);\n+                        bDecrementData[j][0] = weight * residual * grad[j];\n+                    }\n+\n+                    // build the contribution matrix for measurement i\n+                    for (int k = 0; k < parameters.length; ++k) {\n+                        double[] wggRow = wggData[k];\n+                        double gk = grad[k];\n+                        for (int l = 0; l < parameters.length; ++l) {\n+                            wggRow[l] =  weight * gk * grad[l];\n+                        }\n+                    }\n+\n+                    // update the matrices\n+                    a = a.add(wGradGradT);\n+                    b = b.add(bDecrement);\n+\n                 }\n             }\n \n-            // update the matrices\n-            a = a.add(wGradGradT);\n-            b = b.add(bDecrement);\n+            try {\n \n-        }\n+                // solve the linearized least squares problem\n+                RealMatrix dX = a.solve(b);\n+\n+                // update the estimated parameters\n+                for (int i = 0; i < parameters.length; ++i) {\n+                    parameters[i].setEstimate(parameters[i].getEstimate() + dX.getEntry(i, 0));\n+                }\n+\n+            } catch(InvalidMatrixException e) {\n+                throw new EstimationException(\"unable to solve: singular problem\", new Object[0]);\n+            }\n+\n+\n+            previous = cost;\n+            updateResidualsAndCost();\n+\n+        } while ((getCostEvaluations() < 2)\n+                || (Math.abs(previous - cost) > (cost * steadyStateThreshold)\n+                        && (Math.abs(cost) > convergence)));\n+\n     }\n \n-    try {\n+    private double steadyStateThreshold;\n+    private double convergence;\n \n-      // solve the linearized least squares problem\n-      RealMatrix dX = a.solve(b);\n-\n-      // update the estimated parameters\n-      for (int i = 0; i < parameters.length; ++i) {\n-        parameters[i].setEstimate(parameters[i].getEstimate() + dX.getEntry(i, 0));\n-      }\n-\n-    } catch(InvalidMatrixException e) {\n-      throw new EstimationException(e);\n-    }\n-\n-  }\n-\n-  private double evaluateCriterion(EstimationProblem problem) {\n-    double criterion = 0.0;\n-    WeightedMeasurement[] measurements = problem.getMeasurements();\n-\n-    for (int i = 0; i < measurements.length; ++i) {\n-      double residual = measurements[i].getResidual();\n-      criterion      += measurements[i].getWeight() * residual * residual;\n-    }\n-\n-    return criterion;\n-\n-  }\n-\n-  /** \n-   * Get the Root Mean Square value.\n-   * Get the Root Mean Square value, i.e. the root of the arithmetic\n-   * mean of the square of all weighted residuals. This is related to the\n-   * criterion that is minimized by the estimator as follows: if\n-   * <em>c</em> if the criterion, and <em>n</em> is the number of\n-   * measurements, then the RMS is <em>sqrt (c/n)</em>.\n-   * @param problem estimation problem\n-   * @return RMS value\n-   */\n-  public double getRMS(EstimationProblem problem) {\n-    double criterion = evaluateCriterion(problem);\n-    int n = problem.getMeasurements().length;\n-    return Math.sqrt(criterion / n);\n-  }\n-\n-  private int    maxIterations;\n-  private double steadyStateThreshold;\n-  private double convergence;\n-\n-  private static final long serialVersionUID = -7606628156644194170L;\n+    private static final long serialVersionUID = 5485001826076289109L;\n \n }\n--- a/src/java/org/apache/commons/math/estimation/LevenbergMarquardtEstimator.java\n+++ b/src/java/org/apache/commons/math/estimation/LevenbergMarquardtEstimator.java\n \n import java.io.Serializable;\n import java.util.Arrays;\n+\n \n /** \n  * This class solves a least squares problem.\n  * @author Kenneth E. Hillstrom (original fortran)\n  * @author Jorge J. More (original fortran)\n  */\n-public class LevenbergMarquardtEstimator implements Serializable, Estimator {\n+public class LevenbergMarquardtEstimator extends AbstractEstimator implements Serializable {\n \n   /** \n    * Build an estimator for least squares problems.\n    * </p>\n    */\n   public LevenbergMarquardtEstimator() {\n+\n+    // set up the superclass with a default  max cost evaluations setting\n+    setMaxCostEval(1000);\n+\n     // default values for the tuning parameters\n     setInitialStepBoundFactor(100.0);\n-    setMaxCostEval(1000);\n     setCostRelativeTolerance(1.0e-10);\n     setParRelativeTolerance(1.0e-10);\n     setOrthoTolerance(1.0e-10);\n+\n   }\n \n   /** \n   }\n \n   /** \n-   * Set the maximal number of cost evaluations.\n-   * \n-   * @param maxCostEval maximal number of cost evaluations\n-   * @see #estimate\n-  */\n-  public void setMaxCostEval(int maxCostEval) {\n-    this.maxCostEval = maxCostEval;\n-  }\n-\n-  /** \n    * Set the desired relative error in the sum of squares.\n    * \n    * @param costRelativeTolerance desired relative error in the sum of squares\n    */\n   public void setOrthoTolerance(double orthoTolerance) {\n     this.orthoTolerance = orthoTolerance;\n-  }\n-\n-  /** \n-   * Get the number of cost evaluations.\n-   * \n-   * @return number of cost evaluations\n-   * */\n-  public int getCostEvaluations() {\n-    return costEvaluations;\n-  }\n-\n-  /** \n-   * Get the number of jacobian evaluations.\n-   * \n-   * @return number of jacobian evaluations\n-   * */\n-  public int getJacobianEvaluations() {\n-    return jacobianEvaluations;\n-  }\n-\n-  /** \n-   * Update the jacobian matrix.\n-   */\n-  private void updateJacobian() {\n-    ++jacobianEvaluations;\n-    Arrays.fill(jacobian, 0);\n-    for (int i = 0, index = 0; i < rows; i++) {\n-      WeightedMeasurement wm = measurements[i];\n-      double factor = -Math.sqrt(wm.getWeight());\n-      for (int j = 0; j < cols; ++j) {\n-        jacobian[index++] = factor * wm.getPartial(parameters[j]);\n-      }\n-    }\n-  }\n-\n-  /** \n-   * Update the residuals array and cost function value.\n-   */\n-  private void updateResidualsAndCost() {\n-    ++costEvaluations;\n-    cost = 0;\n-    for (int i = 0, index = 0; i < rows; i++, index += cols) {\n-      WeightedMeasurement wm = measurements[i];\n-      double residual = wm.getResidual();\n-      residuals[i] = Math.sqrt(wm.getWeight()) * residual;\n-      cost += wm.getWeight() * residual * residual;\n-    }\n-    cost = Math.sqrt(cost);\n-  }\n-\n-  /** \n-   * Get the Root Mean Square value.\n-   * Get the Root Mean Square value, i.e. the root of the arithmetic\n-   * mean of the square of all weighted residuals. This is related to the\n-   * criterion that is minimized by the estimator as follows: if\n-   * <em>c</em> if the criterion, and <em>n</em> is the number of\n-   * measurements, then the RMS is <em>sqrt (c/n)</em>.\n-   * \n-   * @param problem estimation problem\n-   * @return RMS value\n-   */\n-  public double getRMS(EstimationProblem problem) {\n-    WeightedMeasurement[] wm = problem.getMeasurements();\n-    double criterion = 0;\n-    for (int i = 0; i < wm.length; ++i) {\n-      double residual = wm[i].getResidual();\n-      criterion += wm[i].getWeight() * residual * residual;\n-    }\n-    return Math.sqrt(criterion / wm.length);\n   }\n \n   /** \n    * reached with the specified algorithm settings or if there are more variables\n    * than equations\n    * @see #setInitialStepBoundFactor\n-   * @see #setMaxCostEval\n    * @see #setCostRelativeTolerance\n    * @see #setParRelativeTolerance\n    * @see #setOrthoTolerance\n   public void estimate(EstimationProblem problem)\n     throws EstimationException {\n \n-    // retrieve the equations and the parameters\n-    measurements = problem.getMeasurements();\n-    parameters   = problem.getUnboundParameters();\n+    initializeEstimate(problem);\n \n     // arrays shared with the other private methods\n-    rows        = measurements.length;\n-    cols        = parameters.length;\n     solvedCols  = Math.min(rows, cols);\n-    jacobian    = new double[rows * cols];\n     diagR       = new double[cols];\n     jacNorm     = new double[cols];\n     beta        = new double[cols];\n     permutation = new int[cols];\n     lmDir       = new double[cols];\n-    residuals   = new double[rows];\n \n     // local variables\n     double   delta   = 0, xNorm = 0;\n     updateResidualsAndCost();\n     \n     // outer loop\n-    lmPar               = 0;\n-    costEvaluations     = 0;\n-    jacobianEvaluations = 0;\n+    lmPar = 0;\n     boolean firstIteration = true;\n-    while (costEvaluations < maxCostEval) {\n+    while (true) {\n \n       // compute the Q.R. decomposition of the jacobian matrix\n       updateJacobian();\n \n         // tests for termination and stringent tolerances\n         // (2.2204e-16 is the machine epsilon for IEEE754)\n-        if (costEvaluations >= maxCostEval) {\n-          break;\n-        }\n         if ((Math.abs(actRed) <= 2.2204e-16)\n             && (preRed <= 2.2204e-16)\n             && (ratio <= 2.0)) {\n           throw new EstimationException(\"cost relative tolerance is too small ({0}),\"\n                                       + \" no further reduction in the\"\n                                       + \" sum of squares is possible\",\n-                                        new String[] {\n-                                          Double.toString(costRelativeTolerance)\n-                                        });\n+                                        new Object[] { new Double(costRelativeTolerance) });\n         } else if (delta <= 2.2204e-16 * xNorm) {\n           throw new EstimationException(\"parameters relative tolerance is too small\"\n                                       + \" ({0}), no further improvement in\"\n                                       + \" the approximate solution is possible\",\n-                                        new String[] {\n-                                          Double.toString(parRelativeTolerance)\n-                                        });\n+                                        new Object[] { new Double(parRelativeTolerance) });\n         } else if (maxCosine <= 2.2204e-16)  {\n           throw new EstimationException(\"orthogonality tolerance is too small ({0}),\"\n                                       + \" solution is orthogonal to the jacobian\",\n-                                        new String[] {\n-                                          Double.toString(orthoTolerance)\n-                                        });\n-        }\n-\n-      }\n-\n-    }\n-\n-    throw new EstimationException(\"maximal number of evaluations exceeded ({0})\",\n-                                  new String[] {\n-                                    Integer.toString(maxCostEval)\n-                                  });\n+                                        new Object[] { new Double(orthoTolerance) });\n+        }\n+\n+      }\n+\n+    }\n \n   }\n \n     }\n   }\n \n-  /** Array of measurements. */\n-  private WeightedMeasurement[] measurements;\n-\n-  /** Array of parameters. */\n-  private EstimatedParameter[] parameters;\n-\n-  /** \n-   * Jacobian matrix.\n-   * <p>Depending on the computation phase, this matrix is either in\n-   * canonical form (just after the calls to updateJacobian) or in\n-   * Q.R. decomposed form (after calls to qrDecomposition)</p>\n-   */\n-  private double[] jacobian;\n-\n-  /** Number of columns of the jacobian matrix. */\n-  private int cols;\n-\n   /** Number of solved variables. */\n   private int solvedCols;\n \n-  /** Number of rows of the jacobian matrix. */\n-  private int rows;\n-\n   /** Diagonal elements of the R matrix in the Q.R. decomposition. */\n   private double[] diagR;\n \n   /** Parameters evolution direction associated with lmPar. */\n   private double[] lmDir;\n \n-  /** Residuals array.\n-   * <p>Depending on the computation phase, this array is either in\n-   * canonical form (just after the calls to updateResiduals) or in\n-   * premultiplied by Qt form (just after calls to qTy)</p>\n-   */\n-  private double[] residuals;\n-\n-  /** Cost value (square root of the sum of the residuals). */\n-  private double cost;\n-\n   /** Positive input variable used in determining the initial step bound. */\n   private double initialStepBoundFactor;\n-\n-  /** Maximal number of cost evaluations. */\n-  private int maxCostEval;\n-\n-  /** Number of cost evaluations. */\n-  private int costEvaluations;\n-\n-  /** Number of jacobian evaluations. */\n-  private int jacobianEvaluations;\n \n   /** Desired relative error in the sum of squares. */\n   private double costRelativeTolerance;\n    * and the columns of the jacobian. */\n   private double orthoTolerance;\n \n-  private static final long serialVersionUID = 5387476316105068340L;\n+  private static final long serialVersionUID = -5705952631533171019L;\n \n }\n--- a/src/test/org/apache/commons/math/estimation/LevenbergMarquardtEstimatorTest.java\n+++ b/src/test/org/apache/commons/math/estimation/LevenbergMarquardtEstimatorTest.java\n     LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n     estimator.estimate(problem);\n     assertEquals(0, estimator.getRMS(problem), 1.0e-10);\n+    try {\n+        estimator.guessParametersErrors(problem);\n+        fail(\"an exception should have been thrown\");\n+    } catch (EstimationException ee) {\n+        // expected behavior\n+    } catch (Exception e) {\n+        fail(\"wrong exception caught\");\n+    }\n     assertEquals(1.5,\n                  problem.getUnboundParameters()[0].getEstimate(),\n                  1.0e-10);\n     estimator.estimate(problem);\n     assertTrue(estimator.getRMS(problem) < initialCost);\n     assertTrue(Math.sqrt(m.length) * estimator.getRMS(problem) > 0.6);\n-    double dJ0 = 2 * (m[0].getResidual() * m[0].getPartial(p[0])\n+    try {\n+        estimator.getCovariances(problem);\n+        fail(\"an exception should have been thrown\");\n+    } catch (EstimationException ee) {\n+        // expected behavior\n+    } catch (Exception e) {\n+        fail(\"wrong exception caught\");\n+    }\n+   double dJ0 = 2 * (m[0].getResidual() * m[0].getPartial(p[0])\n                     + m[1].getResidual() * m[1].getPartial(p[0])\n                     + m[2].getResidual() * m[2].getPartial(p[0]));\n     double dJ1 = 2 * (m[0].getResidual() * m[0].getPartial(p[1])\n       assertEquals(69.96016176931406, circle.getRadius(), 1.0e-10);\n       assertEquals(96.07590211815305, circle.getX(),      1.0e-10);\n       assertEquals(48.13516790438953, circle.getY(),      1.0e-10);\n-    }\n+      double[][] cov = estimator.getCovariances(circle);\n+      assertEquals(1.839, cov[0][0], 0.001);\n+      assertEquals(0.731, cov[0][1], 0.001);\n+      assertEquals(cov[0][1], cov[1][0], 1.0e-14);\n+      assertEquals(0.786, cov[1][1], 0.001);\n+      double[] errors = estimator.guessParametersErrors(circle);\n+      assertEquals(1.384, errors[0], 0.001);\n+      assertEquals(0.905, errors[1], 0.001);\n+  \n+      // add perfect measurements and check errors are reduced\n+      double cx = circle.getX();\n+      double cy = circle.getY();\n+      double  r = circle.getRadius();\n+      for (double d= 0; d < 2 * Math.PI; d += 0.01) {\n+          circle.addPoint(cx + r * Math.cos(d), cy + r * Math.sin(d));\n+      }\n+      estimator = new LevenbergMarquardtEstimator();\n+      estimator.estimate(circle);\n+      cov = estimator.getCovariances(circle);\n+      assertEquals(0.004, cov[0][0], 0.001);\n+      assertEquals(6.40e-7, cov[0][1], 1.0e-9);\n+      assertEquals(cov[0][1], cov[1][0], 1.0e-14);\n+      assertEquals(0.003, cov[1][1], 0.001);\n+      errors = estimator.guessParametersErrors(circle);\n+      assertEquals(0.004, errors[0], 0.001);\n+      assertEquals(0.004, errors[1], 0.001);\n+\n+  }\n \n   public void testCircleFittingBadInit() throws EstimationException {\n     Circle circle = new Circle(-12, -12);", "timestamp": 1200782896, "metainfo": ""}