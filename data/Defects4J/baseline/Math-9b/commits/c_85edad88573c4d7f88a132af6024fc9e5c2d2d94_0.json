{"sha": "85edad88573c4d7f88a132af6024fc9e5c2d2d94", "log": "fixed properties  ", "commit": "\n--- a/src/java/org/apache/commons/math/stat/clustering/Clusterable.java\n+++ b/src/java/org/apache/commons/math/stat/clustering/Clusterable.java\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.commons.math.stat.clustering;\n-\n-import java.util.Collection;\n-\n-/**\n- * Interface for points that can be clustered together.\n- * @param <T> the type of point that can be clustered\n- * @version $Revision$ $Date$\n- * @since 2.0\n- */\n-public interface Clusterable<T> {\n-\n-    /**\n-     * Returns the distance from the given point.\n-     * \n-     * @param p the point to compute the distance from\n-     * @return the distance from the given point\n-     */\n-    double distanceFrom(T p);\n-\n-    /**\n-     * Returns the centroid of the given Collection of points.\n-     * \n-     * @param p the Collection of points to compute the centroid of\n-     * @return the centroid of the given Collection of Points\n-     */\n-    T centroidOf(Collection<T> p);\n-\n-}\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.math.stat.clustering;\n+\n+import java.util.Collection;\n+\n+/**\n+ * Interface for points that can be clustered together.\n+ * @param <T> the type of point that can be clustered\n+ * @version $Revision$ $Date$\n+ * @since 2.0\n+ */\n+public interface Clusterable<T> {\n+\n+    /**\n+     * Returns the distance from the given point.\n+     * \n+     * @param p the point to compute the distance from\n+     * @return the distance from the given point\n+     */\n+    double distanceFrom(T p);\n+\n+    /**\n+     * Returns the centroid of the given Collection of points.\n+     * \n+     * @param p the Collection of points to compute the centroid of\n+     * @return the centroid of the given Collection of Points\n+     */\n+    T centroidOf(Collection<T> p);\n+\n+}\n--- a/src/java/org/apache/commons/math/util/OpenIntToFieldHashMap.java\n+++ b/src/java/org/apache/commons/math/util/OpenIntToFieldHashMap.java\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.commons.math.util;\n-\n-import java.io.IOException;\n-import java.io.ObjectInputStream;\n-import java.io.Serializable;\n-import java.lang.reflect.Array;\n-import java.util.ConcurrentModificationException;\n-import java.util.NoSuchElementException;\n-\n-import org.apache.commons.math.Field;\n-import org.apache.commons.math.FieldElement;\n-import org.apache.commons.math.MathRuntimeException;\n-\n-/**\n- * Open addressed map from int to FieldElement.\n- * <p>This class provides a dedicated map from integers to FieldElements with a\n- * much smaller memory overhead than standard <code>java.util.Map</code>.</p>\n- * <p>This class is not synchronized. The specialized iterators returned by\n- * {@link #iterator()} are fail-fast: they throw a\n- * <code>ConcurrentModificationException</code> when they detect the map has been\n- * modified during iteration.</p>\n- * @param <T> the type of the field elements\n- * @version $Revision: 746578 $ $Date: 2009-02-21 12:01:14 -0800 (Sat, 21 Feb 2009) $\n- * @since 2.0\n- */\n-public class OpenIntToFieldHashMap<T extends FieldElement<T>> implements Serializable {\n-    \n-    /** Serializable version identifier. */\n-    private static final long serialVersionUID = -9179080286849120720L;\n-\n-    /** Load factor for the map. */\n-    private static final float LOAD_FACTOR = 0.5f;\n-\n-    /** Default starting size.\n-     * <p>This must be a power of two for bit mask to work properly. </p>\n-     */\n-    private static final int DEFAULT_EXPECTED_SIZE = 16;\n-\n-    /** Multiplier for size growth when map fills up.\n-     * <p>This must be a power of two for bit mask to work properly. </p>\n-     */\n-    private static final int RESIZE_MULTIPLIER = 2;\n-\n-    /** Number of bits to perturb the index when probing for collision resolution. */\n-    private static final int PERTURB_SHIFT = 5;\n-\n-    /** Status indicator for free table entries. */\n-    protected static final byte FREE    = 0;\n-\n-    /** Status indicator for full table entries. */\n-    protected static final byte FULL    = 1;\n-\n-    /** Status indicator for removed table entries. */\n-    protected static final byte REMOVED = 2;\n-\n-    /** Field to which the elements belong. */\n-    private final Field<T> field;\n-    \n-    /** Keys table. */\n-    private int[] keys;\n-\n-    /** Values table. */\n-    private T[] values;\n-\n-    /** States table. */\n-    private byte[] states;\n-\n-    /** Return value for missing entries. */\n-    private final T missingEntries;\n-\n-    /** Current size of the map. */\n-    private int size;\n-\n-    /** Bit mask for hash values. */\n-    private int mask;\n-\n-    /** Modifications count. */\n-    private transient int count;\n-\n-    /**\n-     * Build an empty map with default size and using zero for missing entries.\n-     * @param field field to which the elements belong\n-     */\n-    public OpenIntToFieldHashMap(final Field<T>field) {\n-        this(field, DEFAULT_EXPECTED_SIZE, field.getZero());\n-    }\n-\n-    /**\n-     * Build an empty map with default size\n-     * @param field field to which the elements belong\n-     * @param missingEntries value to return when a missing entry is fetched\n-     */\n-    public OpenIntToFieldHashMap(final Field<T>field, final T missingEntries) {\n-        this(field,DEFAULT_EXPECTED_SIZE, missingEntries);\n-    }\n-\n-    /**\n-     * Build an empty map with specified size and using zero for missing entries.\n-     * @param field field to which the elements belong\n-     * @param expectedSize expected number of elements in the map\n-     */\n-    public OpenIntToFieldHashMap(final Field<T> field,final int expectedSize) {\n-        this(field,expectedSize, field.getZero());\n-    }\n-\n-    /**\n-     * Build an empty map with specified size.\n-     * @param field field to which the elements belong\n-     * @param expectedSize expected number of elements in the map\n-     * @param missingEntries value to return when a missing entry is fetched\n-     */\n-    public OpenIntToFieldHashMap(final Field<T> field,final int expectedSize,\n-                                  final T missingEntries) {\n-        this.field = field;\n-        final int capacity = computeCapacity(expectedSize);\n-        keys   = new int[capacity];\n-        values = buildArray(capacity);\n-        states = new byte[capacity];\n-        this.missingEntries = missingEntries;\n-        mask   = capacity - 1;\n-    }\n-\n-    /**\n-     * Copy constructor.\n-     * @param source map to copy\n-     */\n-    public OpenIntToFieldHashMap(final OpenIntToFieldHashMap<T> source) {\n-        field = source.field;\n-        final int length = source.keys.length;\n-        keys = new int[length];\n-        System.arraycopy(source.keys, 0, keys, 0, length);\n-        values = buildArray(length);\n-        System.arraycopy(source.values, 0, values, 0, length);\n-        states = new byte[length];\n-        System.arraycopy(source.states, 0, states, 0, length);\n-        missingEntries = source.missingEntries;\n-        size  = source.size;\n-        mask  = source.mask;\n-        count = source.count;\n-    }\n-\n-    /**\n-     * Compute the capacity needed for a given size.\n-     * @param expectedSize expected size of the map\n-     * @return capacity to use for the specified size\n-     */\n-    private static int computeCapacity(final int expectedSize) {\n-        if (expectedSize == 0) {\n-            return 1;\n-        }\n-        final int capacity   = (int) Math.ceil(expectedSize / LOAD_FACTOR);\n-        final int powerOfTwo = Integer.highestOneBit(capacity);\n-        if (powerOfTwo == capacity) {\n-            return capacity;\n-        }\n-        return nextPowerOfTwo(capacity);\n-    }\n-\n-    /**\n-     * Find the smallest power of two greater than the input value\n-     * @param i input value\n-     * @return smallest power of two greater than the input value\n-     */\n-    private static int nextPowerOfTwo(final int i) {\n-        return Integer.highestOneBit(i) << 1;\n-    }\n-\n-    /**\n-     * Get the stored value associated with the given key\n-     * @param key key associated with the data\n-     * @return data associated with the key\n-     */\n-    public T get(final int key) {\n-\n-        final int hash  = hashOf(key);\n-        int index = hash & mask;\n-        if (containsKey(key, index)) {\n-            return values[index];\n-        }\n-\n-        if (states[index] == FREE) {\n-            return missingEntries;\n-        }\n-\n-        for (int perturb = perturb(hash), j = index; states[index] != FREE; perturb >>= PERTURB_SHIFT) {\n-            j = probe(perturb, j);\n-            index = j & mask;\n-            if (containsKey(key, index)) {\n-                return values[index];\n-            }\n-        }\n-\n-        return missingEntries;\n-\n-    }\n-\n-    /**\n-     * Check if a value is associated with a key.\n-     * @param key key to check\n-     * @return true if a value is associated with key\n-     */\n-    public boolean containsKey(final int key) {\n-\n-        final int hash  = hashOf(key);\n-        int index = hash & mask;\n-        if (containsKey(key, index)) {\n-            return true;\n-        }\n-\n-        if (states[index] == FREE) {\n-            return false;\n-        }\n-\n-        for (int perturb = perturb(hash), j = index; states[index] != FREE; perturb >>= PERTURB_SHIFT) {\n-            j = probe(perturb, j);\n-            index = j & mask;\n-            if (containsKey(key, index)) {\n-                return true;\n-            }\n-        }\n-\n-        return false;\n-\n-    }\n-\n-    /**\n-     * Get an iterator over map elements.\n-     * <p>The specialized iterators returned are fail-fast: they throw a\n-     * <code>ConcurrentModificationException</code> when they detect the map\n-     * has been modified during iteration.</p>\n-     * @return iterator over the map elements\n-     */\n-    public Iterator iterator() {\n-        return new Iterator();\n-    }\n-\n-    /**\n-     * Perturb the hash for starting probing.\n-     * @param hash initial hash\n-     * @return perturbed hash\n-     */\n-    private static int perturb(final int hash) {\n-        return hash & 0x7fffffff;\n-    }\n-\n-    /**\n-     * Find the index at which a key should be inserted\n-     * @param key key to lookup\n-     * @return index at which key should be inserted\n-     */\n-    private int findInsertionIndex(final int key) {\n-        return findInsertionIndex(keys, states, key, mask);\n-    }\n-\n-    /**\n-     * Find the index at which a key should be inserted\n-     * @param keys keys table\n-     * @param states states table\n-     * @param key key to lookup\n-     * @param mask bit mask for hash values\n-     * @return index at which key should be inserted\n-     */\n-    private static int findInsertionIndex(final int[] keys, final byte[] states,\n-                                          final int key, final int mask) {\n-        final int hash = hashOf(key);\n-        int index = hash & mask;\n-        if (states[index] == FREE) {\n-            return index;\n-        } else if (states[index] == FULL && keys[index] == key) {\n-            return changeIndexSign(index);\n-        }\n-\n-        int perturb = perturb(hash);\n-        int j = index;\n-        if (states[index] == FULL) {\n-            while (true) {\n-                j = probe(perturb, j);\n-                index = j & mask;\n-                perturb >>= PERTURB_SHIFT;\n-                \n-                if (states[index] != FULL || keys[index] == key) {\n-                    break;\n-                }\n-            }\n-        }\n-\n-        if (states[index] == FREE) {\n-            return index;\n-        } else if (states[index] == FULL) {\n-            // due to the loop exit condition,\n-            // if (states[index] == FULL) then keys[index] == key\n-            return changeIndexSign(index);\n-        }\n-\n-        final int firstRemoved = index;\n-        while (true) {\n-            j = probe(perturb, j);\n-            index = j & mask;\n-\n-            if (states[index] == FREE) {\n-                return firstRemoved;\n-            } else if (states[index] == FULL && keys[index] == key) {\n-                return changeIndexSign(index);\n-            }\n-\n-            perturb >>= PERTURB_SHIFT;\n-\n-        }\n-\n-    }\n-\n-    /**\n-     * Compute next probe for collision resolution\n-     * @param perturb perturbed hash\n-     * @param j previous probe\n-     * @return next probe\n-     */\n-    private static int probe(final int perturb, final int j) {\n-        return (j << 2) + j + perturb + 1;\n-    }\n-\n-    /**\n-     * Change the index sign\n-     * @param index initial index\n-     * @return changed index\n-     */\n-    private static int changeIndexSign(final int index) {\n-        return -index - 1;\n-    }\n-\n-    /**\n-     * Get the number of elements stored in the map.\n-     * @return number of elements stored in the map\n-     */\n-    public int size() {\n-        return size;\n-    }\n-\n-    \n-    /**\n-     * Remove the value associated with a key.\n-     * @param key key to which the value is associated\n-     * @return removed value\n-     */\n-    public T remove(final int key) {\n-\n-        final int hash  = hashOf(key);\n-        int index = hash & mask;\n-        if (containsKey(key, index)) {\n-            return doRemove(index);\n-        }\n-\n-        if (states[index] == FREE) {\n-            return missingEntries;\n-        }\n-\n-        for (int perturb = perturb(hash), j = index; states[index] != FREE; perturb >>= PERTURB_SHIFT) {\n-            j = probe(perturb, j);\n-            index = j & mask;\n-            if (containsKey(key, index)) {\n-                return doRemove(index);\n-            }\n-        }\n-\n-        return missingEntries;\n-\n-    }\n-\n-    /**\n-     * Check if the tables contain an element associated with specified key\n-     * at specified index.\n-     * @param key key to check\n-     * @param index index to check\n-     * @return true if an element is associated with key at index\n-     */\n-    private boolean containsKey(final int key, final int index) {\n-        return (key != 0 || states[index] == FULL) && keys[index] == key;\n-    }\n-\n-    /**\n-     * Remove an element at specified index.\n-     * @param index index of the element to remove\n-     * @return removed value\n-     */\n-    private T doRemove(int index) {\n-        keys[index]   = 0;\n-        states[index] = REMOVED;\n-        final T previous = values[index];\n-        values[index] = missingEntries;\n-        --size;\n-        ++count;\n-        return previous;\n-    }\n-\n-    /**\n-     * Put a value associated with a key in the map.\n-     * @param key key to which value is associated\n-     * @param value value to put in the map\n-     * @return previous value associated with the key\n-     */\n-    public T put(final int key, final T value) {\n-        int index = findInsertionIndex(key);\n-        T previous = missingEntries;\n-        boolean newMapping = true;\n-        if (index < 0) {\n-            index = changeIndexSign(index);\n-            previous = values[index];\n-            newMapping = false;\n-        }\n-        keys[index]   = key;\n-        states[index] = FULL;\n-        values[index] = value;\n-        if (newMapping) {\n-            ++size;\n-            if (shouldGrowTable()) {\n-                growTable();\n-            }\n-            ++count;\n-        }\n-        return previous;\n-\n-    }\n-\n-    /**\n-     * Grow the tables.\n-     */\n-    private void growTable() {\n-\n-        final int oldLength      = states.length;\n-        final int[] oldKeys      = keys;\n-        final T[] oldValues = values;\n-        final byte[] oldStates   = states;\n-\n-        final int newLength = RESIZE_MULTIPLIER * oldLength;\n-        final int[] newKeys = new int[newLength];\n-        final T[] newValues = buildArray(newLength);\n-        final byte[] newStates = new byte[newLength];\n-        final int newMask = newLength - 1;\n-        for (int i = 0; i < oldLength; ++i) {\n-            if (oldStates[i] == FULL) {\n-                final int key = oldKeys[i];\n-                final int index = findInsertionIndex(newKeys, newStates, key, newMask);\n-                newKeys[index]   = key;\n-                newValues[index] = oldValues[i];\n-                newStates[index] = FULL;\n-            }\n-        }\n-\n-        mask   = newMask;\n-        keys   = newKeys;\n-        values = newValues;\n-        states = newStates;\n-\n-    }\n-\n-    /**\n-     * Check if tables should grow due to increased size.\n-     * @return true if  tables should grow\n-     */\n-    private boolean shouldGrowTable() {\n-        return size > (mask + 1) * LOAD_FACTOR;\n-    }\n-\n-    /**\n-     * Compute the hash value of a key\n-     * @param key key to hash\n-     * @return hash value of the key\n-     */\n-    private static int hashOf(final int key) {\n-        final int h = key ^ ((key >>> 20) ^ (key >>> 12));\n-        return h ^ (h >>> 7) ^ (h >>> 4);\n-    }\n-\n-    \n-    /** Iterator class for the map. */\n-    public class Iterator {\n-\n-        /** Reference modification count. */\n-        private final int referenceCount;\n-\n-        /** Index of current element. */\n-        private int current;\n-\n-        /** Index of next element. */\n-        private int next;\n-\n-        /**\n-         * Simple constructor.\n-         */\n-        private Iterator() {\n-\n-            // preserve the modification count of the map to detect concurrent modifications later\n-            referenceCount = count;\n-\n-            // initialize current index\n-            next = -1;\n-            try {\n-                advance();\n-            } catch (NoSuchElementException nsee) {\n-                // ignored\n-            }\n-\n-        }\n-\n-        /**\n-         * Check if there is a next element in the map.\n-         * @return true if there is a next element\n-         */\n-        public boolean hasNext() {\n-            return next >= 0;\n-        }\n-\n-        /**\n-         * Get the key of current entry.\n-         * @return key of current entry\n-         * @exception ConcurrentModificationException if the map is modified during iteration\n-         * @exception NoSuchElementException if there is no element left in the map\n-         */\n-        public int key()\n-            throws ConcurrentModificationException, NoSuchElementException {\n-            if (referenceCount != count) {\n-                throw MathRuntimeException.createConcurrentModificationException(\"map has been modified while iterating\");\n-            }\n-            if (current < 0) {\n-                throw MathRuntimeException.createNoSuchElementException(\"iterator exhausted\");\n-            }\n-            return keys[current];\n-        }\n-\n-        /**\n-         * Get the value of current entry.\n-         * @return value of current entry\n-         * @exception ConcurrentModificationException if the map is modified during iteration\n-         * @exception NoSuchElementException if there is no element left in the map\n-         */\n-        public T value()\n-            throws ConcurrentModificationException, NoSuchElementException {\n-            if (referenceCount != count) {\n-                throw MathRuntimeException.createConcurrentModificationException(\"map has been modified while iterating\");\n-            }\n-            if (current < 0) {\n-                throw MathRuntimeException.createNoSuchElementException(\"iterator exhausted\");\n-            }\n-            return values[current];\n-        }\n-\n-        /**\n-         * Advance iterator one step further.\n-         * @exception ConcurrentModificationException if the map is modified during iteration\n-         * @exception NoSuchElementException if there is no element left in the map\n-         */\n-        public void advance()\n-            throws ConcurrentModificationException, NoSuchElementException {\n-\n-            if (referenceCount != count) {\n-                throw MathRuntimeException.createConcurrentModificationException(\"map has been modified while iterating\");\n-            }\n-\n-            // advance on step\n-            current = next;\n-\n-            // prepare next step\n-            try {\n-                while (states[++next] != FULL) {\n-                    // nothing to do\n-                }\n-            } catch (ArrayIndexOutOfBoundsException e) {\n-                next = -2;\n-                if (current < 0) {\n-                    throw MathRuntimeException.createNoSuchElementException(\"iterator exhausted\");\n-                }\n-            }\n-\n-        }\n-\n-    }\n-\n-    /**\n-     * Read a serialized object.\n-     * @param stream input stream\n-     * @throws IOException if object cannot be read\n-     * @throws ClassNotFoundException if the class corresponding\n-     * to the serialized object cannot be found\n-     */\n-    private void readObject(final ObjectInputStream stream)\n-        throws IOException, ClassNotFoundException {\n-        stream.defaultReadObject();\n-        count = 0;\n-    }\n-\n-    /** Build an array of elements.\n-     * @param length size of the array to build\n-     * @return a new array\n-     */\n-    @SuppressWarnings(\"unchecked\")\n-    private T[] buildArray(final int length) {\n-        return (T[]) Array.newInstance(field.getZero().getClass(), length);\n-    }\n-\n-}\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math.util;\n+\n+import java.io.IOException;\n+import java.io.ObjectInputStream;\n+import java.io.Serializable;\n+import java.lang.reflect.Array;\n+import java.util.ConcurrentModificationException;\n+import java.util.NoSuchElementException;\n+\n+import org.apache.commons.math.Field;\n+import org.apache.commons.math.FieldElement;\n+import org.apache.commons.math.MathRuntimeException;\n+\n+/**\n+ * Open addressed map from int to FieldElement.\n+ * <p>This class provides a dedicated map from integers to FieldElements with a\n+ * much smaller memory overhead than standard <code>java.util.Map</code>.</p>\n+ * <p>This class is not synchronized. The specialized iterators returned by\n+ * {@link #iterator()} are fail-fast: they throw a\n+ * <code>ConcurrentModificationException</code> when they detect the map has been\n+ * modified during iteration.</p>\n+ * @param <T> the type of the field elements\n+ * @version $Revision: 746578 $ $Date: 2009-02-21 12:01:14 -0800 (Sat, 21 Feb 2009) $\n+ * @since 2.0\n+ */\n+public class OpenIntToFieldHashMap<T extends FieldElement<T>> implements Serializable {\n+    \n+    /** Serializable version identifier. */\n+    private static final long serialVersionUID = -9179080286849120720L;\n+\n+    /** Load factor for the map. */\n+    private static final float LOAD_FACTOR = 0.5f;\n+\n+    /** Default starting size.\n+     * <p>This must be a power of two for bit mask to work properly. </p>\n+     */\n+    private static final int DEFAULT_EXPECTED_SIZE = 16;\n+\n+    /** Multiplier for size growth when map fills up.\n+     * <p>This must be a power of two for bit mask to work properly. </p>\n+     */\n+    private static final int RESIZE_MULTIPLIER = 2;\n+\n+    /** Number of bits to perturb the index when probing for collision resolution. */\n+    private static final int PERTURB_SHIFT = 5;\n+\n+    /** Status indicator for free table entries. */\n+    protected static final byte FREE    = 0;\n+\n+    /** Status indicator for full table entries. */\n+    protected static final byte FULL    = 1;\n+\n+    /** Status indicator for removed table entries. */\n+    protected static final byte REMOVED = 2;\n+\n+    /** Field to which the elements belong. */\n+    private final Field<T> field;\n+    \n+    /** Keys table. */\n+    private int[] keys;\n+\n+    /** Values table. */\n+    private T[] values;\n+\n+    /** States table. */\n+    private byte[] states;\n+\n+    /** Return value for missing entries. */\n+    private final T missingEntries;\n+\n+    /** Current size of the map. */\n+    private int size;\n+\n+    /** Bit mask for hash values. */\n+    private int mask;\n+\n+    /** Modifications count. */\n+    private transient int count;\n+\n+    /**\n+     * Build an empty map with default size and using zero for missing entries.\n+     * @param field field to which the elements belong\n+     */\n+    public OpenIntToFieldHashMap(final Field<T>field) {\n+        this(field, DEFAULT_EXPECTED_SIZE, field.getZero());\n+    }\n+\n+    /**\n+     * Build an empty map with default size\n+     * @param field field to which the elements belong\n+     * @param missingEntries value to return when a missing entry is fetched\n+     */\n+    public OpenIntToFieldHashMap(final Field<T>field, final T missingEntries) {\n+        this(field,DEFAULT_EXPECTED_SIZE, missingEntries);\n+    }\n+\n+    /**\n+     * Build an empty map with specified size and using zero for missing entries.\n+     * @param field field to which the elements belong\n+     * @param expectedSize expected number of elements in the map\n+     */\n+    public OpenIntToFieldHashMap(final Field<T> field,final int expectedSize) {\n+        this(field,expectedSize, field.getZero());\n+    }\n+\n+    /**\n+     * Build an empty map with specified size.\n+     * @param field field to which the elements belong\n+     * @param expectedSize expected number of elements in the map\n+     * @param missingEntries value to return when a missing entry is fetched\n+     */\n+    public OpenIntToFieldHashMap(final Field<T> field,final int expectedSize,\n+                                  final T missingEntries) {\n+        this.field = field;\n+        final int capacity = computeCapacity(expectedSize);\n+        keys   = new int[capacity];\n+        values = buildArray(capacity);\n+        states = new byte[capacity];\n+        this.missingEntries = missingEntries;\n+        mask   = capacity - 1;\n+    }\n+\n+    /**\n+     * Copy constructor.\n+     * @param source map to copy\n+     */\n+    public OpenIntToFieldHashMap(final OpenIntToFieldHashMap<T> source) {\n+        field = source.field;\n+        final int length = source.keys.length;\n+        keys = new int[length];\n+        System.arraycopy(source.keys, 0, keys, 0, length);\n+        values = buildArray(length);\n+        System.arraycopy(source.values, 0, values, 0, length);\n+        states = new byte[length];\n+        System.arraycopy(source.states, 0, states, 0, length);\n+        missingEntries = source.missingEntries;\n+        size  = source.size;\n+        mask  = source.mask;\n+        count = source.count;\n+    }\n+\n+    /**\n+     * Compute the capacity needed for a given size.\n+     * @param expectedSize expected size of the map\n+     * @return capacity to use for the specified size\n+     */\n+    private static int computeCapacity(final int expectedSize) {\n+        if (expectedSize == 0) {\n+            return 1;\n+        }\n+        final int capacity   = (int) Math.ceil(expectedSize / LOAD_FACTOR);\n+        final int powerOfTwo = Integer.highestOneBit(capacity);\n+        if (powerOfTwo == capacity) {\n+            return capacity;\n+        }\n+        return nextPowerOfTwo(capacity);\n+    }\n+\n+    /**\n+     * Find the smallest power of two greater than the input value\n+     * @param i input value\n+     * @return smallest power of two greater than the input value\n+     */\n+    private static int nextPowerOfTwo(final int i) {\n+        return Integer.highestOneBit(i) << 1;\n+    }\n+\n+    /**\n+     * Get the stored value associated with the given key\n+     * @param key key associated with the data\n+     * @return data associated with the key\n+     */\n+    public T get(final int key) {\n+\n+        final int hash  = hashOf(key);\n+        int index = hash & mask;\n+        if (containsKey(key, index)) {\n+            return values[index];\n+        }\n+\n+        if (states[index] == FREE) {\n+            return missingEntries;\n+        }\n+\n+        for (int perturb = perturb(hash), j = index; states[index] != FREE; perturb >>= PERTURB_SHIFT) {\n+            j = probe(perturb, j);\n+            index = j & mask;\n+            if (containsKey(key, index)) {\n+                return values[index];\n+            }\n+        }\n+\n+        return missingEntries;\n+\n+    }\n+\n+    /**\n+     * Check if a value is associated with a key.\n+     * @param key key to check\n+     * @return true if a value is associated with key\n+     */\n+    public boolean containsKey(final int key) {\n+\n+        final int hash  = hashOf(key);\n+        int index = hash & mask;\n+        if (containsKey(key, index)) {\n+            return true;\n+        }\n+\n+        if (states[index] == FREE) {\n+            return false;\n+        }\n+\n+        for (int perturb = perturb(hash), j = index; states[index] != FREE; perturb >>= PERTURB_SHIFT) {\n+            j = probe(perturb, j);\n+            index = j & mask;\n+            if (containsKey(key, index)) {\n+                return true;\n+            }\n+        }\n+\n+        return false;\n+\n+    }\n+\n+    /**\n+     * Get an iterator over map elements.\n+     * <p>The specialized iterators returned are fail-fast: they throw a\n+     * <code>ConcurrentModificationException</code> when they detect the map\n+     * has been modified during iteration.</p>\n+     * @return iterator over the map elements\n+     */\n+    public Iterator iterator() {\n+        return new Iterator();\n+    }\n+\n+    /**\n+     * Perturb the hash for starting probing.\n+     * @param hash initial hash\n+     * @return perturbed hash\n+     */\n+    private static int perturb(final int hash) {\n+        return hash & 0x7fffffff;\n+    }\n+\n+    /**\n+     * Find the index at which a key should be inserted\n+     * @param key key to lookup\n+     * @return index at which key should be inserted\n+     */\n+    private int findInsertionIndex(final int key) {\n+        return findInsertionIndex(keys, states, key, mask);\n+    }\n+\n+    /**\n+     * Find the index at which a key should be inserted\n+     * @param keys keys table\n+     * @param states states table\n+     * @param key key to lookup\n+     * @param mask bit mask for hash values\n+     * @return index at which key should be inserted\n+     */\n+    private static int findInsertionIndex(final int[] keys, final byte[] states,\n+                                          final int key, final int mask) {\n+        final int hash = hashOf(key);\n+        int index = hash & mask;\n+        if (states[index] == FREE) {\n+            return index;\n+        } else if (states[index] == FULL && keys[index] == key) {\n+            return changeIndexSign(index);\n+        }\n+\n+        int perturb = perturb(hash);\n+        int j = index;\n+        if (states[index] == FULL) {\n+            while (true) {\n+                j = probe(perturb, j);\n+                index = j & mask;\n+                perturb >>= PERTURB_SHIFT;\n+                \n+                if (states[index] != FULL || keys[index] == key) {\n+                    break;\n+                }\n+            }\n+        }\n+\n+        if (states[index] == FREE) {\n+            return index;\n+        } else if (states[index] == FULL) {\n+            // due to the loop exit condition,\n+            // if (states[index] == FULL) then keys[index] == key\n+            return changeIndexSign(index);\n+        }\n+\n+        final int firstRemoved = index;\n+        while (true) {\n+            j = probe(perturb, j);\n+            index = j & mask;\n+\n+            if (states[index] == FREE) {\n+                return firstRemoved;\n+            } else if (states[index] == FULL && keys[index] == key) {\n+                return changeIndexSign(index);\n+            }\n+\n+            perturb >>= PERTURB_SHIFT;\n+\n+        }\n+\n+    }\n+\n+    /**\n+     * Compute next probe for collision resolution\n+     * @param perturb perturbed hash\n+     * @param j previous probe\n+     * @return next probe\n+     */\n+    private static int probe(final int perturb, final int j) {\n+        return (j << 2) + j + perturb + 1;\n+    }\n+\n+    /**\n+     * Change the index sign\n+     * @param index initial index\n+     * @return changed index\n+     */\n+    private static int changeIndexSign(final int index) {\n+        return -index - 1;\n+    }\n+\n+    /**\n+     * Get the number of elements stored in the map.\n+     * @return number of elements stored in the map\n+     */\n+    public int size() {\n+        return size;\n+    }\n+\n+    \n+    /**\n+     * Remove the value associated with a key.\n+     * @param key key to which the value is associated\n+     * @return removed value\n+     */\n+    public T remove(final int key) {\n+\n+        final int hash  = hashOf(key);\n+        int index = hash & mask;\n+        if (containsKey(key, index)) {\n+            return doRemove(index);\n+        }\n+\n+        if (states[index] == FREE) {\n+            return missingEntries;\n+        }\n+\n+        for (int perturb = perturb(hash), j = index; states[index] != FREE; perturb >>= PERTURB_SHIFT) {\n+            j = probe(perturb, j);\n+            index = j & mask;\n+            if (containsKey(key, index)) {\n+                return doRemove(index);\n+            }\n+        }\n+\n+        return missingEntries;\n+\n+    }\n+\n+    /**\n+     * Check if the tables contain an element associated with specified key\n+     * at specified index.\n+     * @param key key to check\n+     * @param index index to check\n+     * @return true if an element is associated with key at index\n+     */\n+    private boolean containsKey(final int key, final int index) {\n+        return (key != 0 || states[index] == FULL) && keys[index] == key;\n+    }\n+\n+    /**\n+     * Remove an element at specified index.\n+     * @param index index of the element to remove\n+     * @return removed value\n+     */\n+    private T doRemove(int index) {\n+        keys[index]   = 0;\n+        states[index] = REMOVED;\n+        final T previous = values[index];\n+        values[index] = missingEntries;\n+        --size;\n+        ++count;\n+        return previous;\n+    }\n+\n+    /**\n+     * Put a value associated with a key in the map.\n+     * @param key key to which value is associated\n+     * @param value value to put in the map\n+     * @return previous value associated with the key\n+     */\n+    public T put(final int key, final T value) {\n+        int index = findInsertionIndex(key);\n+        T previous = missingEntries;\n+        boolean newMapping = true;\n+        if (index < 0) {\n+            index = changeIndexSign(index);\n+            previous = values[index];\n+            newMapping = false;\n+        }\n+        keys[index]   = key;\n+        states[index] = FULL;\n+        values[index] = value;\n+        if (newMapping) {\n+            ++size;\n+            if (shouldGrowTable()) {\n+                growTable();\n+            }\n+            ++count;\n+        }\n+        return previous;\n+\n+    }\n+\n+    /**\n+     * Grow the tables.\n+     */\n+    private void growTable() {\n+\n+        final int oldLength      = states.length;\n+        final int[] oldKeys      = keys;\n+        final T[] oldValues = values;\n+        final byte[] oldStates   = states;\n+\n+        final int newLength = RESIZE_MULTIPLIER * oldLength;\n+        final int[] newKeys = new int[newLength];\n+        final T[] newValues = buildArray(newLength);\n+        final byte[] newStates = new byte[newLength];\n+        final int newMask = newLength - 1;\n+        for (int i = 0; i < oldLength; ++i) {\n+            if (oldStates[i] == FULL) {\n+                final int key = oldKeys[i];\n+                final int index = findInsertionIndex(newKeys, newStates, key, newMask);\n+                newKeys[index]   = key;\n+                newValues[index] = oldValues[i];\n+                newStates[index] = FULL;\n+            }\n+        }\n+\n+        mask   = newMask;\n+        keys   = newKeys;\n+        values = newValues;\n+        states = newStates;\n+\n+    }\n+\n+    /**\n+     * Check if tables should grow due to increased size.\n+     * @return true if  tables should grow\n+     */\n+    private boolean shouldGrowTable() {\n+        return size > (mask + 1) * LOAD_FACTOR;\n+    }\n+\n+    /**\n+     * Compute the hash value of a key\n+     * @param key key to hash\n+     * @return hash value of the key\n+     */\n+    private static int hashOf(final int key) {\n+        final int h = key ^ ((key >>> 20) ^ (key >>> 12));\n+        return h ^ (h >>> 7) ^ (h >>> 4);\n+    }\n+\n+    \n+    /** Iterator class for the map. */\n+    public class Iterator {\n+\n+        /** Reference modification count. */\n+        private final int referenceCount;\n+\n+        /** Index of current element. */\n+        private int current;\n+\n+        /** Index of next element. */\n+        private int next;\n+\n+        /**\n+         * Simple constructor.\n+         */\n+        private Iterator() {\n+\n+            // preserve the modification count of the map to detect concurrent modifications later\n+            referenceCount = count;\n+\n+            // initialize current index\n+            next = -1;\n+            try {\n+                advance();\n+            } catch (NoSuchElementException nsee) {\n+                // ignored\n+            }\n+\n+        }\n+\n+        /**\n+         * Check if there is a next element in the map.\n+         * @return true if there is a next element\n+         */\n+        public boolean hasNext() {\n+            return next >= 0;\n+        }\n+\n+        /**\n+         * Get the key of current entry.\n+         * @return key of current entry\n+         * @exception ConcurrentModificationException if the map is modified during iteration\n+         * @exception NoSuchElementException if there is no element left in the map\n+         */\n+        public int key()\n+            throws ConcurrentModificationException, NoSuchElementException {\n+            if (referenceCount != count) {\n+                throw MathRuntimeException.createConcurrentModificationException(\"map has been modified while iterating\");\n+            }\n+            if (current < 0) {\n+                throw MathRuntimeException.createNoSuchElementException(\"iterator exhausted\");\n+            }\n+            return keys[current];\n+        }\n+\n+        /**\n+         * Get the value of current entry.\n+         * @return value of current entry\n+         * @exception ConcurrentModificationException if the map is modified during iteration\n+         * @exception NoSuchElementException if there is no element left in the map\n+         */\n+        public T value()\n+            throws ConcurrentModificationException, NoSuchElementException {\n+            if (referenceCount != count) {\n+                throw MathRuntimeException.createConcurrentModificationException(\"map has been modified while iterating\");\n+            }\n+            if (current < 0) {\n+                throw MathRuntimeException.createNoSuchElementException(\"iterator exhausted\");\n+            }\n+            return values[current];\n+        }\n+\n+        /**\n+         * Advance iterator one step further.\n+         * @exception ConcurrentModificationException if the map is modified during iteration\n+         * @exception NoSuchElementException if there is no element left in the map\n+         */\n+        public void advance()\n+            throws ConcurrentModificationException, NoSuchElementException {\n+\n+            if (referenceCount != count) {\n+                throw MathRuntimeException.createConcurrentModificationException(\"map has been modified while iterating\");\n+            }\n+\n+            // advance on step\n+            current = next;\n+\n+            // prepare next step\n+            try {\n+                while (states[++next] != FULL) {\n+                    // nothing to do\n+                }\n+            } catch (ArrayIndexOutOfBoundsException e) {\n+                next = -2;\n+                if (current < 0) {\n+                    throw MathRuntimeException.createNoSuchElementException(\"iterator exhausted\");\n+                }\n+            }\n+\n+        }\n+\n+    }\n+\n+    /**\n+     * Read a serialized object.\n+     * @param stream input stream\n+     * @throws IOException if object cannot be read\n+     * @throws ClassNotFoundException if the class corresponding\n+     * to the serialized object cannot be found\n+     */\n+    private void readObject(final ObjectInputStream stream)\n+        throws IOException, ClassNotFoundException {\n+        stream.defaultReadObject();\n+        count = 0;\n+    }\n+\n+    /** Build an array of elements.\n+     * @param length size of the array to build\n+     * @return a new array\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    private T[] buildArray(final int length) {\n+        return (T[]) Array.newInstance(field.getZero().getClass(), length);\n+    }\n+\n+}\n--- a/src/test/org/apache/commons/math/linear/SparseFieldVectorTest.java\n+++ b/src/test/org/apache/commons/math/linear/SparseFieldVectorTest.java\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- * \n- *      http://www.apache.org/licenses/LICENSE-2.0\n- * \n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.commons.math.linear;\n-\n-\n-import org.apache.commons.math.fraction.Fraction;\n-import org.apache.commons.math.fraction.FractionConversionException;\n-import org.apache.commons.math.fraction.FractionField;\n-\n-\n-import junit.framework.TestCase;\n-\n-/**\n- * Test cases for the {@link SparseFieldVector} class.\n- *\n- * @version $Revision: 728186 $ $Date: 2009-04-20 11:42:11 -0700 (Mon, 20 Apr 2009) $\n- */\n-public class SparseFieldVectorTest extends TestCase {\n-\n-    // \n-    protected Fraction[][] ma1 = {{new Fraction(1), new Fraction(2), new Fraction(3)}, {new Fraction(4), new Fraction(5), new Fraction(6)}, {new Fraction(7), new Fraction(8), new Fraction(9)}};\n-    protected Fraction[] vec1 = {new Fraction(1), new Fraction(2), new Fraction(3)};\n-    protected Fraction[] vec2 = {new Fraction(4), new Fraction(5), new Fraction(6)};\n-    protected Fraction[] vec3 = {new Fraction(7), new Fraction(8), new Fraction(9)};\n-    protected Fraction[] vec4 = {new Fraction(1), new Fraction(2), new Fraction(3), new Fraction(4), new Fraction(5), new Fraction(6), new Fraction(7), new Fraction(8), new Fraction(9)};\n-    protected Fraction[] vec_null = {new Fraction(0), new Fraction(0), new Fraction(0)};\n-    protected Fraction[] dvec1 = {new Fraction(1), new Fraction(2), new Fraction(3), new Fraction(4), new Fraction(5), new Fraction(6), new Fraction(7), new Fraction(8),new Fraction(9)};\n-    protected Fraction[][] mat1 = {{new Fraction(1), new Fraction(2), new Fraction(3)}, {new Fraction(4), new Fraction(5), new Fraction(6)},{ new Fraction(7), new Fraction(8), new Fraction(9)}};\n-\n-    // tolerances\n-    protected double entryTolerance = 10E-16;\n-    protected double normTolerance = 10E-14;\n-\n-    protected FractionField field = FractionField.getInstance();\n-\n-    public void testMapFunctions() throws FractionConversionException { \n-        SparseFieldVector<Fraction> v1 = new SparseFieldVector<Fraction>(field,vec1);\n-\n-        //octave =  v1 .+ 2.0\n-        FieldVector<Fraction> v_mapAdd = v1.mapAdd(new Fraction(2));\n-        Fraction[] result_mapAdd = {new Fraction(3), new Fraction(4), new Fraction(5)};\n-        assertEquals(\"compare vectors\" ,result_mapAdd,v_mapAdd.getData());\n-\n-        //octave =  v1 .+ 2.0\n-        FieldVector<Fraction> v_mapAddToSelf = v1.copy();\n-        v_mapAddToSelf.mapAddToSelf(new Fraction(2));\n-        Fraction[] result_mapAddToSelf = {new Fraction(3), new Fraction(4), new Fraction(5)};\n-        assertEquals(\"compare vectors\" ,result_mapAddToSelf,v_mapAddToSelf.getData());\n-\n-        //octave =  v1 .- 2.0\n-        FieldVector<Fraction> v_mapSubtract = v1.mapSubtract(new Fraction(2));\n-        Fraction[] result_mapSubtract = {new Fraction(-1), new Fraction(0), new Fraction(1)};\n-        assertEquals(\"compare vectors\" ,result_mapSubtract,v_mapSubtract.getData());\n-\n-        //octave =  v1 .- 2.0\n-        FieldVector<Fraction> v_mapSubtractToSelf = v1.copy();\n-        v_mapSubtractToSelf.mapSubtractToSelf(new Fraction(2));\n-        Fraction[] result_mapSubtractToSelf = {new Fraction(-1), new Fraction(0), new Fraction(1)};\n-        assertEquals(\"compare vectors\" ,result_mapSubtractToSelf,v_mapSubtractToSelf.getData());\n-\n-        //octave =  v1 .* 2.0\n-        FieldVector<Fraction> v_mapMultiply = v1.mapMultiply(new Fraction(2));\n-        Fraction[] result_mapMultiply = {new Fraction(2), new Fraction(4), new Fraction(6)};\n-        assertEquals(\"compare vectors\" ,result_mapMultiply,v_mapMultiply.getData());\n-\n-        //octave =  v1 .* 2.0\n-        FieldVector<Fraction> v_mapMultiplyToSelf = v1.copy();\n-        v_mapMultiplyToSelf.mapMultiplyToSelf(new Fraction(2));\n-        Fraction[] result_mapMultiplyToSelf = {new Fraction(2), new Fraction(4), new Fraction(6)};\n-        assertEquals(\"compare vectors\" ,result_mapMultiplyToSelf,v_mapMultiplyToSelf.getData());\n-\n-        //octave =  v1 ./ 2.0\n-        FieldVector<Fraction> v_mapDivide = v1.mapDivide(new Fraction(2));\n-        Fraction[] result_mapDivide = {new Fraction(.5d), new Fraction(1), new Fraction(1.5d)};\n-        assertEquals(\"compare vectors\" ,result_mapDivide,v_mapDivide.getData());\n-\n-        //octave =  v1 ./ 2.0\n-        FieldVector<Fraction> v_mapDivideToSelf = v1.copy();\n-        v_mapDivideToSelf.mapDivideToSelf(new Fraction(2));\n-        Fraction[] result_mapDivideToSelf = {new Fraction(.5d), new Fraction(1), new Fraction(1.5d)};\n-        assertEquals(\"compare vectors\" ,result_mapDivideToSelf,v_mapDivideToSelf.getData());\n-\n-        //octave =  v1 .^-1\n-        FieldVector<Fraction> v_mapInv = v1.mapInv();\n-        Fraction[] result_mapInv = {new Fraction(1),new Fraction(0.5d),new Fraction(3.333333333333333e-01d)};\n-        assertEquals(\"compare vectors\" ,result_mapInv,v_mapInv.getData());\n-\n-        //octave =  v1 .^-1\n-        FieldVector<Fraction> v_mapInvToSelf = v1.copy();\n-        v_mapInvToSelf.mapInvToSelf();\n-        Fraction[] result_mapInvToSelf = {new Fraction(1),new Fraction(0.5d),new Fraction(3.333333333333333e-01d)};\n-        assertEquals(\"compare vectors\" ,result_mapInvToSelf,v_mapInvToSelf.getData());\n-\n-\n-    }\n-\n-    public void testBasicFunctions() throws FractionConversionException { \n-        SparseFieldVector<Fraction> v1 = new SparseFieldVector<Fraction>(field,vec1);\n-        SparseFieldVector<Fraction> v2 = new SparseFieldVector<Fraction>(field,vec2);\n-\n-        SparseFieldVector<Fraction> v2_t = new SparseFieldVector<Fraction>(field,vec2); \n-\n-        //octave =  v1 + v2\n-        FieldVector<Fraction> v_add = v1.add(v2);\n-        Fraction[] result_add = {new Fraction(5), new Fraction(7), new Fraction(9)};\n-        assertEquals(\"compare vect\" ,v_add.getData(),result_add);\n-\n-        SparseFieldVector<Fraction> vt2 = new SparseFieldVector<Fraction>(field,vec2);\n-        FieldVector<Fraction> v_add_i = v1.add(vt2);\n-        Fraction[] result_add_i = {new Fraction(5), new Fraction(7), new Fraction(9)};\n-        assertEquals(\"compare vect\" ,v_add_i.getData(),result_add_i);\n-\n-        //octave =  v1 - v2\n-        SparseFieldVector<Fraction> v_subtract = v1.subtract(v2);\n-        Fraction[] result_subtract = {new Fraction(-3), new Fraction(-3), new Fraction(-3)};\n-        assertClose(\"compare vect\" ,v_subtract.getData(),result_subtract,normTolerance);\n-\n-        FieldVector<Fraction> v_subtract_i = v1.subtract(vt2);\n-        Fraction[] result_subtract_i = {new Fraction(-3), new Fraction(-3), new Fraction(-3)};\n-        assertClose(\"compare vect\" ,v_subtract_i.getData(),result_subtract_i,normTolerance);\n-\n-        // octave v1 .* v2\n-        FieldVector<Fraction>  v_ebeMultiply = v1.ebeMultiply(v2);\n-        Fraction[] result_ebeMultiply = {new Fraction(4), new Fraction(10), new Fraction(18)};\n-        assertClose(\"compare vect\" ,v_ebeMultiply.getData(),result_ebeMultiply,normTolerance);\n-\n-        FieldVector<Fraction>  v_ebeMultiply_2 = v1.ebeMultiply(v2_t);\n-        Fraction[] result_ebeMultiply_2 = {new Fraction(4), new Fraction(10), new Fraction(18)};\n-        assertClose(\"compare vect\" ,v_ebeMultiply_2.getData(),result_ebeMultiply_2,normTolerance);\n-\n-        // octave v1 ./ v2\n-        FieldVector<Fraction>  v_ebeDivide = v1.ebeDivide(v2);\n-        Fraction[] result_ebeDivide = {new Fraction(0.25d), new Fraction(0.4d), new Fraction(0.5d)};\n-        assertClose(\"compare vect\" ,v_ebeDivide.getData(),result_ebeDivide,normTolerance);\n-\n-        FieldVector<Fraction>  v_ebeDivide_2 = v1.ebeDivide(v2_t);\n-        Fraction[] result_ebeDivide_2 = {new Fraction(0.25d), new Fraction(0.4d), new Fraction(0.5d)};\n-        assertClose(\"compare vect\" ,v_ebeDivide_2.getData(),result_ebeDivide_2,normTolerance);\n-\n-        // octave  dot(v1,v2)\n-        Fraction dot =  v1.dotProduct(v2);\n-        assertEquals(\"compare val \",new Fraction(32), dot);\n-\n-        // octave  dot(v1,v2_t)\n-        Fraction dot_2 =  v1.dotProduct(v2_t);\n-        assertEquals(\"compare val \",new Fraction(32), dot_2);\n-\n-        FieldMatrix<Fraction> m_outerProduct = v1.outerProduct(v2);\n-        assertEquals(\"compare val \",new Fraction(4), m_outerProduct.getEntry(0,0));\n-\n-        FieldMatrix<Fraction> m_outerProduct_2 = v1.outerProduct(v2_t);\n-        assertEquals(\"compare val \",new Fraction(4), m_outerProduct_2.getEntry(0,0));\n-\n-    }\n-\n-\n-    public void testMisc() { \n-        SparseFieldVector<Fraction> v1 = new SparseFieldVector<Fraction>(field,vec1);\n-\n-        String out1 = v1.toString();\n-        assertTrue(\"some output \",  out1.length()!=0);\n-        try {\n-            v1.checkVectorDimensions(2); \n-            fail(\"IllegalArgumentException expected\");\n-        } catch (IllegalArgumentException ex) {\n-            // expected behavior\n-        } catch (Exception e) {\n-            fail(\"wrong exception caught\");\n-        }     \n-\n-\n-    }\n-\n-    public void testPredicates() {\n-\n-        SparseFieldVector<Fraction> v = new SparseFieldVector<Fraction>(field, new Fraction[] { new Fraction(0), new Fraction(1), new Fraction(2) });\n-\n-        v.setEntry(0, field.getZero());\n-        assertEquals(v, new SparseFieldVector<Fraction>(field, new Fraction[] { new Fraction(0), new Fraction(1), new Fraction(2) }));\n-        assertNotSame(v, new SparseFieldVector<Fraction>(field, new Fraction[] { new Fraction(0), new Fraction(1), new Fraction(2), new Fraction(3) }));\n-\n-    }\n-\n-    /** verifies that two vectors are close (sup norm) */\n-    protected void assertEquals(String msg, Fraction[] m, Fraction[] n) {\n-        if (m.length != n.length) {\n-            fail(\"vectors have different lengths\");\n-        }\n-        for (int i = 0; i < m.length; i++) {\n-            assertEquals(msg + \" \" +  i + \" elements differ\", m[i],n[i]);\n-        }\n-    }\n-\n-    /** verifies that two vectors are close (sup norm) */\n-    protected void assertClose(String msg, Fraction[] m, Fraction[] n, double tolerance) {\n-        if (m.length != n.length) {\n-            fail(\"vectors have different lengths\");\n-        }\n-        for (int i = 0; i < m.length; i++) {\n-            assertEquals(msg + \" \" +  i + \" elements differ\", m[i].doubleValue(),n[i].doubleValue(), tolerance);\n-        }\n-    }\n-\n-}\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.commons.math.linear;\n+\n+\n+import org.apache.commons.math.fraction.Fraction;\n+import org.apache.commons.math.fraction.FractionConversionException;\n+import org.apache.commons.math.fraction.FractionField;\n+\n+\n+import junit.framework.TestCase;\n+\n+/**\n+ * Test cases for the {@link SparseFieldVector} class.\n+ *\n+ * @version $Revision: 728186 $ $Date: 2009-04-20 11:42:11 -0700 (Mon, 20 Apr 2009) $\n+ */\n+public class SparseFieldVectorTest extends TestCase {\n+\n+    // \n+    protected Fraction[][] ma1 = {{new Fraction(1), new Fraction(2), new Fraction(3)}, {new Fraction(4), new Fraction(5), new Fraction(6)}, {new Fraction(7), new Fraction(8), new Fraction(9)}};\n+    protected Fraction[] vec1 = {new Fraction(1), new Fraction(2), new Fraction(3)};\n+    protected Fraction[] vec2 = {new Fraction(4), new Fraction(5), new Fraction(6)};\n+    protected Fraction[] vec3 = {new Fraction(7), new Fraction(8), new Fraction(9)};\n+    protected Fraction[] vec4 = {new Fraction(1), new Fraction(2), new Fraction(3), new Fraction(4), new Fraction(5), new Fraction(6), new Fraction(7), new Fraction(8), new Fraction(9)};\n+    protected Fraction[] vec_null = {new Fraction(0), new Fraction(0), new Fraction(0)};\n+    protected Fraction[] dvec1 = {new Fraction(1), new Fraction(2), new Fraction(3), new Fraction(4), new Fraction(5), new Fraction(6), new Fraction(7), new Fraction(8),new Fraction(9)};\n+    protected Fraction[][] mat1 = {{new Fraction(1), new Fraction(2), new Fraction(3)}, {new Fraction(4), new Fraction(5), new Fraction(6)},{ new Fraction(7), new Fraction(8), new Fraction(9)}};\n+\n+    // tolerances\n+    protected double entryTolerance = 10E-16;\n+    protected double normTolerance = 10E-14;\n+\n+    protected FractionField field = FractionField.getInstance();\n+\n+    public void testMapFunctions() throws FractionConversionException { \n+        SparseFieldVector<Fraction> v1 = new SparseFieldVector<Fraction>(field,vec1);\n+\n+        //octave =  v1 .+ 2.0\n+        FieldVector<Fraction> v_mapAdd = v1.mapAdd(new Fraction(2));\n+        Fraction[] result_mapAdd = {new Fraction(3), new Fraction(4), new Fraction(5)};\n+        assertEquals(\"compare vectors\" ,result_mapAdd,v_mapAdd.getData());\n+\n+        //octave =  v1 .+ 2.0\n+        FieldVector<Fraction> v_mapAddToSelf = v1.copy();\n+        v_mapAddToSelf.mapAddToSelf(new Fraction(2));\n+        Fraction[] result_mapAddToSelf = {new Fraction(3), new Fraction(4), new Fraction(5)};\n+        assertEquals(\"compare vectors\" ,result_mapAddToSelf,v_mapAddToSelf.getData());\n+\n+        //octave =  v1 .- 2.0\n+        FieldVector<Fraction> v_mapSubtract = v1.mapSubtract(new Fraction(2));\n+        Fraction[] result_mapSubtract = {new Fraction(-1), new Fraction(0), new Fraction(1)};\n+        assertEquals(\"compare vectors\" ,result_mapSubtract,v_mapSubtract.getData());\n+\n+        //octave =  v1 .- 2.0\n+        FieldVector<Fraction> v_mapSubtractToSelf = v1.copy();\n+        v_mapSubtractToSelf.mapSubtractToSelf(new Fraction(2));\n+        Fraction[] result_mapSubtractToSelf = {new Fraction(-1), new Fraction(0), new Fraction(1)};\n+        assertEquals(\"compare vectors\" ,result_mapSubtractToSelf,v_mapSubtractToSelf.getData());\n+\n+        //octave =  v1 .* 2.0\n+        FieldVector<Fraction> v_mapMultiply = v1.mapMultiply(new Fraction(2));\n+        Fraction[] result_mapMultiply = {new Fraction(2), new Fraction(4), new Fraction(6)};\n+        assertEquals(\"compare vectors\" ,result_mapMultiply,v_mapMultiply.getData());\n+\n+        //octave =  v1 .* 2.0\n+        FieldVector<Fraction> v_mapMultiplyToSelf = v1.copy();\n+        v_mapMultiplyToSelf.mapMultiplyToSelf(new Fraction(2));\n+        Fraction[] result_mapMultiplyToSelf = {new Fraction(2), new Fraction(4), new Fraction(6)};\n+        assertEquals(\"compare vectors\" ,result_mapMultiplyToSelf,v_mapMultiplyToSelf.getData());\n+\n+        //octave =  v1 ./ 2.0\n+        FieldVector<Fraction> v_mapDivide = v1.mapDivide(new Fraction(2));\n+        Fraction[] result_mapDivide = {new Fraction(.5d), new Fraction(1), new Fraction(1.5d)};\n+        assertEquals(\"compare vectors\" ,result_mapDivide,v_mapDivide.getData());\n+\n+        //octave =  v1 ./ 2.0\n+        FieldVector<Fraction> v_mapDivideToSelf = v1.copy();\n+        v_mapDivideToSelf.mapDivideToSelf(new Fraction(2));\n+        Fraction[] result_mapDivideToSelf = {new Fraction(.5d), new Fraction(1), new Fraction(1.5d)};\n+        assertEquals(\"compare vectors\" ,result_mapDivideToSelf,v_mapDivideToSelf.getData());\n+\n+        //octave =  v1 .^-1\n+        FieldVector<Fraction> v_mapInv = v1.mapInv();\n+        Fraction[] result_mapInv = {new Fraction(1),new Fraction(0.5d),new Fraction(3.333333333333333e-01d)};\n+        assertEquals(\"compare vectors\" ,result_mapInv,v_mapInv.getData());\n+\n+        //octave =  v1 .^-1\n+        FieldVector<Fraction> v_mapInvToSelf = v1.copy();\n+        v_mapInvToSelf.mapInvToSelf();\n+        Fraction[] result_mapInvToSelf = {new Fraction(1),new Fraction(0.5d),new Fraction(3.333333333333333e-01d)};\n+        assertEquals(\"compare vectors\" ,result_mapInvToSelf,v_mapInvToSelf.getData());\n+\n+\n+    }\n+\n+    public void testBasicFunctions() throws FractionConversionException { \n+        SparseFieldVector<Fraction> v1 = new SparseFieldVector<Fraction>(field,vec1);\n+        SparseFieldVector<Fraction> v2 = new SparseFieldVector<Fraction>(field,vec2);\n+\n+        SparseFieldVector<Fraction> v2_t = new SparseFieldVector<Fraction>(field,vec2); \n+\n+        //octave =  v1 + v2\n+        FieldVector<Fraction> v_add = v1.add(v2);\n+        Fraction[] result_add = {new Fraction(5), new Fraction(7), new Fraction(9)};\n+        assertEquals(\"compare vect\" ,v_add.getData(),result_add);\n+\n+        SparseFieldVector<Fraction> vt2 = new SparseFieldVector<Fraction>(field,vec2);\n+        FieldVector<Fraction> v_add_i = v1.add(vt2);\n+        Fraction[] result_add_i = {new Fraction(5), new Fraction(7), new Fraction(9)};\n+        assertEquals(\"compare vect\" ,v_add_i.getData(),result_add_i);\n+\n+        //octave =  v1 - v2\n+        SparseFieldVector<Fraction> v_subtract = v1.subtract(v2);\n+        Fraction[] result_subtract = {new Fraction(-3), new Fraction(-3), new Fraction(-3)};\n+        assertClose(\"compare vect\" ,v_subtract.getData(),result_subtract,normTolerance);\n+\n+        FieldVector<Fraction> v_subtract_i = v1.subtract(vt2);\n+        Fraction[] result_subtract_i = {new Fraction(-3), new Fraction(-3), new Fraction(-3)};\n+        assertClose(\"compare vect\" ,v_subtract_i.getData(),result_subtract_i,normTolerance);\n+\n+        // octave v1 .* v2\n+        FieldVector<Fraction>  v_ebeMultiply = v1.ebeMultiply(v2);\n+        Fraction[] result_ebeMultiply = {new Fraction(4), new Fraction(10), new Fraction(18)};\n+        assertClose(\"compare vect\" ,v_ebeMultiply.getData(),result_ebeMultiply,normTolerance);\n+\n+        FieldVector<Fraction>  v_ebeMultiply_2 = v1.ebeMultiply(v2_t);\n+        Fraction[] result_ebeMultiply_2 = {new Fraction(4), new Fraction(10), new Fraction(18)};\n+        assertClose(\"compare vect\" ,v_ebeMultiply_2.getData(),result_ebeMultiply_2,normTolerance);\n+\n+        // octave v1 ./ v2\n+        FieldVector<Fraction>  v_ebeDivide = v1.ebeDivide(v2);\n+        Fraction[] result_ebeDivide = {new Fraction(0.25d), new Fraction(0.4d), new Fraction(0.5d)};\n+        assertClose(\"compare vect\" ,v_ebeDivide.getData(),result_ebeDivide,normTolerance);\n+\n+        FieldVector<Fraction>  v_ebeDivide_2 = v1.ebeDivide(v2_t);\n+        Fraction[] result_ebeDivide_2 = {new Fraction(0.25d), new Fraction(0.4d), new Fraction(0.5d)};\n+        assertClose(\"compare vect\" ,v_ebeDivide_2.getData(),result_ebeDivide_2,normTolerance);\n+\n+        // octave  dot(v1,v2)\n+        Fraction dot =  v1.dotProduct(v2);\n+        assertEquals(\"compare val \",new Fraction(32), dot);\n+\n+        // octave  dot(v1,v2_t)\n+        Fraction dot_2 =  v1.dotProduct(v2_t);\n+        assertEquals(\"compare val \",new Fraction(32), dot_2);\n+\n+        FieldMatrix<Fraction> m_outerProduct = v1.outerProduct(v2);\n+        assertEquals(\"compare val \",new Fraction(4), m_outerProduct.getEntry(0,0));\n+\n+        FieldMatrix<Fraction> m_outerProduct_2 = v1.outerProduct(v2_t);\n+        assertEquals(\"compare val \",new Fraction(4), m_outerProduct_2.getEntry(0,0));\n+\n+    }\n+\n+\n+    public void testMisc() { \n+        SparseFieldVector<Fraction> v1 = new SparseFieldVector<Fraction>(field,vec1);\n+\n+        String out1 = v1.toString();\n+        assertTrue(\"some output \",  out1.length()!=0);\n+        try {\n+            v1.checkVectorDimensions(2); \n+            fail(\"IllegalArgumentException expected\");\n+        } catch (IllegalArgumentException ex) {\n+            // expected behavior\n+        } catch (Exception e) {\n+            fail(\"wrong exception caught\");\n+        }     \n+\n+\n+    }\n+\n+    public void testPredicates() {\n+\n+        SparseFieldVector<Fraction> v = new SparseFieldVector<Fraction>(field, new Fraction[] { new Fraction(0), new Fraction(1), new Fraction(2) });\n+\n+        v.setEntry(0, field.getZero());\n+        assertEquals(v, new SparseFieldVector<Fraction>(field, new Fraction[] { new Fraction(0), new Fraction(1), new Fraction(2) }));\n+        assertNotSame(v, new SparseFieldVector<Fraction>(field, new Fraction[] { new Fraction(0), new Fraction(1), new Fraction(2), new Fraction(3) }));\n+\n+    }\n+\n+    /** verifies that two vectors are close (sup norm) */\n+    protected void assertEquals(String msg, Fraction[] m, Fraction[] n) {\n+        if (m.length != n.length) {\n+            fail(\"vectors have different lengths\");\n+        }\n+        for (int i = 0; i < m.length; i++) {\n+            assertEquals(msg + \" \" +  i + \" elements differ\", m[i],n[i]);\n+        }\n+    }\n+\n+    /** verifies that two vectors are close (sup norm) */\n+    protected void assertClose(String msg, Fraction[] m, Fraction[] n, double tolerance) {\n+        if (m.length != n.length) {\n+            fail(\"vectors have different lengths\");\n+        }\n+        for (int i = 0; i < m.length; i++) {\n+            assertEquals(msg + \" \" +  i + \" elements differ\", m[i].doubleValue(),n[i].doubleValue(), tolerance);\n+        }\n+    }\n+\n+}", "timestamp": 1249071066, "metainfo": ""}