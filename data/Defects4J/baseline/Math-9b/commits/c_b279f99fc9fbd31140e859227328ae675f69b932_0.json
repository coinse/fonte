{"sha": "b279f99fc9fbd31140e859227328ae675f69b932", "log": "Javadoc, remove trailing spaces.  JIRA: MATH-607.  ", "commit": "\n--- a/src/main/java/org/apache/commons/math/stat/regression/MillerUpdatingRegression.java\n+++ b/src/main/java/org/apache/commons/math/stat/regression/MillerUpdatingRegression.java\n  */\n public class MillerUpdatingRegression implements UpdatingMultipleLinearRegression {\n \n+    /** number of variables in regression */\n     private final int nvars;\n+    /** diagonals of cross products matrix */\n     private final double[] d;\n+    /** the elements of the R`Y */\n     private final double[] rhs;\n+    /** the off diagonal portion of the R matrix */\n     private final double[] r;\n+    /** the tolerance for each of the variables */\n     private final double[] tol;\n+    /** residual sum of squares for all nested regressions */\n     private final double[] rss;\n+    /** order of the regressors */\n     private final int[] vorder;\n+    /** scratch space for tolerance calc */\n     private final double[] work_tolset;\n+    /** number of observations entered */\n     private long nobs = 0;\n+    /** sum of squared errors of largest regression */\n     private double sserr = 0.0;\n+    /** has rss been called? */\n     private boolean rss_set = false;\n+    /** has the tolerance setting method been called */\n     private boolean tol_set = false;\n+    /** flags for variables with linear dependency problems */\n     private final boolean[] lindep;\n+    /** singular x values */\n     private final double[] x_sing;\n+    /** workspace for singularity method */\n     private final double[] work_sing;\n+    /** summation of Y variable */\n     private double sumy = 0.0;\n+    /** summation of squared Y values */\n     private double sumsqy = 0.0;\n+    /** boolean flag whether a regression constant is added */\n     private boolean hasIntercept;\n+    /** zero tolerance */\n     private final double epsilon;\n+    /** error message */\n+    private String nvarsMessage = \"Attempting to include more variables in regression than exist in model\";\n+    /** error message */\n+    private String nobsVsNvarsMessage = \"Number of observations not greater than the number of number of variables\";\n \n     /**\n      *  Set the default constructor to private access\n         this.epsilon = Double.NaN;\n     }\n \n+    /**\n+     * This is the augmented constructor for the MillerUpdatingRegression class\n+     *\n+     * @param numberOfVariables number of regressors to expect, not including constant\n+     * @param includeConstant include a constant automatically\n+     * @param errorTolerance  zero tolerance, how machine zero is determined\n+     */\n     public MillerUpdatingRegression(int numberOfVariables, boolean includeConstant, double errorTolerance) {\n         if (numberOfVariables < 1) {\n             throw new IllegalArgumentException(\"NumberOfVariables must be greater than or equal to one\");\n         return;\n     }\n \n+    /**\n+     * Primary constructor for the MillerUpdatingRegression\n+     *\n+     * @param numberOfVariables maximum number of potential regressors\n+     * @param includeConstant include a constant automatically\n+     */\n     public MillerUpdatingRegression(int numberOfVariables, boolean includeConstant) {\n         this(numberOfVariables, includeConstant, MathUtils.EPSILON);\n     }\n \n+    /**\n+     * A getter method which determines whether a constant is included\n+     * @return true regression has an intercept, false no intercept\n+     */\n     public boolean hasIntercept() {\n         return this.hasIntercept;\n     }\n \n+    /**\n+     * Gets the number of observations added to the regression model\n+     * @return number of observations\n+     */\n     public long getN() {\n         return this.nobs;\n     }\n \n+    /**\n+     * Adds an observation to the regression model\n+     * @param x the array with regressor values\n+     * @param y  the value of dependent variable given these regressors\n+     */\n     public void addObservation(final double[] x, final double y) {\n \n         if ((!this.hasIntercept && x.length != nvars) ||\n \n     }\n \n+    /**\n+     * Adds multiplier observations to the model\n+     * @param x observations on the regressors\n+     * @param y observations on the regressand\n+     */\n     public void addObservations(double[][] x, double[] y) {\n         if (x.length != y.length) {\n             throw new IllegalArgumentException(\"Lengths of x and y matrices must be equal\");\n         return;\n     }\n \n-    /*\n+    /**\n      * The include method is where the QR decomposition occurs. This statement forms all\n      * intermediate data which will be used for all derivative measures.\n      * According to the miller paper, note that in the original implementation the x vector\n      * is overwritten. In this implementation, the include method is passed a copy of the\n      * original data vector so that there is no contamination of the data. Additionally,\n-     * this method differs slighlty from gentleman's method, in that the assumption is\n+     * this method differs slightly from Gentleman's method, in that the assumption is\n      * of dense design matrices, there is some advantage in using the original gentleman algorithm\n      * on sparse matrices.\n+     *\n+     * @param x observations on the regressors\n+     * @param wi weight of the this observation (-1,1)\n+     * @param yi observation on the regressand\n      */\n     private void include(final double[] x, final double wi, final double yi) {\n         int nextr = 0;\n             d[i] = dpi;\n             for (int k = i + 1; k < nvars; k++) {\n                 xk = x[k];\n-\n                 x[k] = smartAdd(xk, -xi * r[nextr]);\n                 if (di != 0.0) {\n                     r[nextr] = smartAdd(di * r[nextr], (_w * xi) * xk) / dpi;\n         return;\n     }\n \n+    /**\n+     * Adds to number a and b such that the contamination due to\n+     * numerical smallness of one addend does not corrupt the sum\n+     * @param a - an addend\n+     * @param b - an addend\n+     * @return the sum of the a and b\n+     */\n     private double smartAdd(double a, double b) {\n         double _a = FastMath.abs(a);\n         double _b = FastMath.abs(b);\n         }\n     }\n \n-    /*\n-     * As the name suggest clear, wipes the internals and reoders everything in the\n+    /**\n+     * As the name suggests,  clear wipes the internals and reorders everything in the\n      * canonical order.\n      */\n     public void clear() {\n-        Arrays.fill(d, 0.0);\n-        Arrays.fill(rhs, 0.0);\n-        Arrays.fill(r, 0.0);\n-        Arrays.fill(tol, 0.0);\n-        Arrays.fill(rss, 0.0);\n+        Arrays.fill(this.d, 0.0);\n+        Arrays.fill(this.rhs, 0.0);\n+        Arrays.fill(this.r, 0.0);\n+        Arrays.fill(this.tol, 0.0);\n+        Arrays.fill(this.rss, 0.0);\n         Arrays.fill(this.work_tolset, 0.0);\n         Arrays.fill(this.work_sing, 0.0);\n         Arrays.fill(this.x_sing, 0.0);\n-        Arrays.fill(lindep, false);\n+        Arrays.fill(this.lindep, false);\n         for (int i = 0; i < nvars; i++) {\n-            vorder[i] = i;\n-        }\n-\n-        nobs = 0;\n-        sserr = 0.0;\n-        sumy = 0.0;\n-        sumsqy = 0.0;\n-        rss_set = false;\n-        tol_set = false;\n+            this.vorder[i] = i;\n+        }\n+        this.nobs = 0;\n+        this.sserr = 0.0;\n+        this.sumy = 0.0;\n+        this.sumsqy = 0.0;\n+        this.rss_set = false;\n+        this.tol_set = false;\n         return;\n     }\n \n-    /*\n-     * This sets up tolerances for singularity testing\n+    /**\n+     * This sets up tolerances for singularity testing.\n      */\n     private void tolset() {\n         int pos;\n         return;\n     }\n \n-    /*\n-     * The regcf methods conducts the linear regression and extracts the\n+    /**\n+     * The regcf method conducts the linear regression and extracts the\n      * parameter vector. Notice that the algorithm can do subset regression\n      * with no alteration.\n+     *\n+     * @param nreq how many of the regressors to include (either in canonical\n+     * order, or in the current reordered state)\n+     * @return an array with the estimated slope coefficients\n      */\n     private double[] regcf(int nreq) {\n         int nextr;\n                 ret[i] = rhs[i];\n                 nextr = i * (nvars + nvars - i - 1) / 2;\n                 for (int j = i + 1; j < nreq; j++) {\n-\n                     ret[i] = smartAdd(ret[i], -r[nextr] * ret[j]);\n-\n                     ++nextr;\n                 }\n             }\n         return ret;\n     }\n \n-    /*\n+    /**\n      * The method which checks for singularities and then eliminates the offending\n-     * columns\n+     * columns.\n      */\n     private void singcheck() {\n         double temp;\n         double y;\n         double weight;\n         int pos;\n-\n         for (int i = 0; i < nvars; i++) {\n             work_sing[i] = Math.sqrt(d[i]);\n         }\n-\n         for (int col = 0; col < nvars; col++) {\n             // Set elements within R to zero if they are less than tol(col) in\n             // absolute value after being scaled by the square root of their row\n         return;\n     }\n \n-    /*\n+    /**\n      * Calculates the sum of squared errors for the full regression\n-     * and all subsets in the following manner:\n+     * and all subsets in the following manner: <pre>\n      * rss[] ={\n      * ResidualSumOfSquares_allNvars,\n      * ResidualSumOfSquares_FirstNvars-1,\n      * ResidualSumOfSquares_FirstNvars-2,\n-     * ..., ResidualSumOfSquares_FirstVariable}\n+     * ..., ResidualSumOfSquares_FirstVariable} </pre>\n      */\n     private void ss() {\n         double total = sserr;\n         return;\n     }\n \n-    /*\n+    /**\n      * Calculates the cov matrix assuming only the first nreq variables are\n      * included in the calculation. The returned array contains a symmetric\n      * matrix stored in lower triangular form. The matrix will have\n-     * ( nreq + 1 ) * nreq / 2 elements. For illustration\n+     * ( nreq + 1 ) * nreq / 2 elements. For illustration <pre>\n      * cov =\n      * {\n      *  cov_00,\n      *  cov_10, cov_11,\n      *  cov_20, cov_21, cov22,\n      *  ...\n-     * }\n+     * } </pre>\n+     *\n+     * @param nreq how many of the regressors to include (either in canonical\n+     * order, or in the current reordered state)\n+     * @return an array with the variance covariance of the included\n+     * regressors in lower triangular form\n      */\n     private double[] cov(int nreq) {\n         if (this.nobs <= nreq) {\n         return covmat;\n     }\n \n-    /*\n+    /**\n      * This internal method calculates the inverse of the upper-triangular portion\n      * of the R matrix.\n+     * @param rinv  the storage for the inverse of r\n+     * @param nreq how many of the regressors to include (either in canonical\n+     * order, or in the current reordered state)\n      */\n     private void inverse(double[] rinv, int nreq) {\n         int pos = nreq * (nreq - 1) / 2 - 1;\n         return;\n     }\n \n-    /*\n-     * In the original algorithm only the partial correlations of the regressors\n-     * is returned to the user. In this implementation, we have\n+    /**\n+     * <p>In the original algorithm only the partial correlations of the regressors\n+     * is returned to the user. In this implementation, we have <pre>\n      * corr =\n      * {\n      *   corrxx - lower triangular\n      *   corrxy - bottom row of the matrix\n      * }\n+     * Replaces subroutines PCORR and COR of:\n+     * ALGORITHM AS274  APPL. STATIST. (1992) VOL.41, NO. 2 </pre></p>\n+     *\n+     * <p>Calculate partial correlations after the variables in rows\n+     * 1, 2, ..., IN have been forced into the regression.\n+     * If IN = 1, and the first row of R represents a constant in the\n+     * model, then the usual simple correlations are returned.</p>\n+     *\n+     * <p>If IN = 0, the value returned in array CORMAT for the correlation\n+     * of variables Xi & Xj is: <pre>\n+     * sum ( Xi.Xj ) / Sqrt ( sum (Xi^2) . sum (Xj^2) )</pre></p>\n+     *\n+     * <p>On return, array CORMAT contains the upper triangle of the matrix of\n+     * partial correlations stored by rows, excluding the 1's on the diagonal.\n+     * e.g. if IN = 2, the consecutive elements returned are:\n+     * (3,4) (3,5) ... (3,ncol), (4,5) (4,6) ... (4,ncol), etc.\n+     * Array YCORR stores the partial correlations with the Y-variable\n+     * starting with YCORR(IN+1) = partial correlation with the variable in\n+     * position (IN+1). </p>\n+     *\n+     * @param in how many of the regressors to include (either in canonical\n+     * order, or in the current reordered state)\n+     * @return an array with the partial correlations of the remainder of\n+     * regressors with each other and the regressand, in lower triangular form\n      */\n     public double[] getPartialCorrelations(int in) {\n-        /*\n-        Replaces subroutines PCORR and COR of:\n-        ALGORITHM AS274  APPL. STATIST. (1992) VOL.41, NO. 2\n-\n-        Calculate partial correlations after the variables in rows\n-        1, 2, ..., IN have been forced into the regression.\n-        If IN = 1, and the first row of R represents a constant in the\n-        model, then the usual simple correlations are returned.\n-\n-        If IN = 0, the value returned in array CORMAT for the correlation\n-        of variables Xi & Xj is:\n-        sum ( Xi.Xj ) / Sqrt ( sum (Xi^2) . sum (Xj^2) )\n-\n-        On return, array CORMAT contains the upper triangle of the matrix of\n-        partial correlations stored by rows, excluding the 1's on the diagonal.\n-        e.g. if IN = 2, the consecutive elements returned are:\n-        (3,4) (3,5) ... (3,ncol), (4,5) (4,6) ... (4,ncol), etc.\n-        Array YCORR stores the partial correlations with the Y-variable\n-        starting with YCORR(IN+1) = partial correlation with the variable in\n-        position (IN+1).\n-\n-        --------------------------------------------------------------------------*/\n         double[] output = new double[(nvars - in + 1) * (nvars - in) / 2];\n         int base_pos;\n         int pos;\n     }\n \n     /**\n-     * ALGORITHM AS274 APPL. STATIST. (1992) VOL.41, NO. 2\n+     * ALGORITHM AS274 APPL. STATIST. (1992) VOL.41, NO. 2.\n      * Move variable from position FROM to position TO in an\n      * orthogonal reduction produced by AS75.1.\n      *\n         }\n     }\n \n+    /**\n+     * <p>ALGORITHM AS274  APPL. STATIST. (1992) VOL.41, NO. 2</p>\n+     *\n+     * <p> Re-order the variables in an orthogonal reduction produced by\n+     * AS75.1 so that the N variables in LIST start at position POS1,\n+     * though will not necessarily be in the same order as in LIST.\n+     * Any variables in VORDER before position POS1 are not moved.\n+     * Auxiliary routine called: VMOVE. </p>\n+     *\n+     * <p>This internal method reorders the regressors.</p>\n+     *\n+     * @param list the regressors to move\n+     * @param pos1 where the list will be placed\n+     * @return -1 error, 0 everything ok\n+     */\n     private int reorderRegressors(int[] list, int pos1) {\n-\n-//     ALGORITHM AS274  APPL. STATIST. (1992) VOL.41, NO. 2\n-\n-//     Re-order the variables in an orthogonal reduction produced by\n-//     AS75.1 so that the N variables in LIST start at position POS1,\n-//     though will not necessarily be in the same order as in LIST.\n-//     Any variables in VORDER before position POS1 are not moved.\n-\n-//     Auxiliary routine called: VMOVE\n-//\n-//--------------------------------------------------------------------------\n-\n         int next;\n         int i;\n         int l;\n         return 0;\n     }\n \n-    /*\n-     * Gets the diagonal of the Hat matrix also known as the leverage matrix\n-     *\n-     *\n-     * @returns the diagonal element of the hatmatrix\n+    /**\n+     * Gets the diagonal of the Hat matrix also known as the leverage matrix.\n+     *\n+     * @param  row_data returns the diagonal of the hat matrix for this observation\n+     * @return the diagonal element of the hatmatrix\n      */\n     public double getDiagonalOfHatMatrix(double[] row_data) {\n         double[] wk = new double[this.nvars];\n         return hii;\n     }\n \n-    /*\n-     * Gets the order of the regressors, useful if sometype of reording\n+    /**\n+     * Gets the order of the regressors, useful if some type of reordering\n      * has been called. Calling regress with int[]{} args will trigger\n-     * a reordering\n-     * @returns int[] with the current order of the regressors\n-     */\n-    public int[] getOrderOfRegressors() {\n+     * a reordering.\n+     *\n+     * @return int[] with the current order of the regressors\n+     */\n+    public int[] getOrderOfRegressors(){\n         return MathUtils.copyOf(vorder);\n     }\n \n-\n+    /**\n+     * Conducts a regression on the data in the model, using all regressors.\n+     *\n+     * @return RegressionResults the structure holding all regression results\n+     * @exception  MathException - thrown if number of observations is\n+     * less than the number of variables\n+     */\n     public RegressionResults regress() throws MathException {\n         return regress(this.nvars);\n     }\n \n-    public RegressionResults regress(int numberOfRegressors) throws MathException {\n+    /**\n+     * Conducts a regression on the data in the model, using a subset of regressors.\n+     *\n+     * @param numberOfRegressors many of the regressors to include (either in canonical\n+     * order, or in the current reordered state)\n+     * @return RegressionResults the structure holding all regression results\n+     * @exception  MathException - thrown if number of observations is\n+     * less than the number of variables or number of regressors requested\n+     * is greater than the regressors in the model\n+     */\n+    public RegressionResults regress(int numberOfRegressors) throws MathException{\n         if (this.nobs <= numberOfRegressors) {\n-            Localizable outMsg = new DummyLocalizable(\"Number of observations not \" +\n-                     \"greater than the number of number of variables\");\n+            Localizable outMsg = new DummyLocalizable(nobsVsNvarsMessage);\n             throw new MathException(outMsg, (Object) null);\n         }\n         if( numberOfRegressors > this.nvars ){\n-            Localizable outMsg = new DummyLocalizable(\"Number of variables requested \" +\n-                    \"in regression greater than the number of number of variables\");\n+            Localizable outMsg = new DummyLocalizable(nvarsMessage);\n             throw new MathException(outMsg, (Object) null);\n         }\n         this.tolset();\n         }\n     }\n \n+    /**\n+     * Conducts a regression on the data in the model, using regressors in array\n+     * Calling this method will change the internal order of the regressors\n+     * and care is required in interpreting the hatmatrix.\n+     *\n+     * @param  variablesToInclude array of variables to include in regression\n+     * @return RegressionResults the structure holding all regression results\n+     * @exception  MathException - thrown if number of observations is\n+     * less than the number of variables or\n+     * number of regressors requested\n+     * is greater than the regressors in the model or\n+     * a regress or index in regressor array does not exist\n+     */\n     public RegressionResults regress(int[] variablesToInclude) throws MathException {\n         if (variablesToInclude.length > this.nvars) {\n-            Localizable outMsg = new DummyLocalizable(\"Number of variables in included list \" +\n-                    \"greater than the number of number of variables\");\n+            Localizable outMsg = new DummyLocalizable(nvarsMessage);\n             throw new MathException(outMsg, (Object) null);\n         }\n         if (this.nobs <= this.nvars) {\n-            Localizable outMsg = new DummyLocalizable(\"Number of observations not \" +\n-                    \"greater than the number of number of variables\");\n+            Localizable outMsg = new DummyLocalizable(nobsVsNvarsMessage);\n             throw new MathException(outMsg, (Object) null);\n         }\n         Arrays.sort(variablesToInclude);", "timestamp": 1311270965, "metainfo": ""}