{"sha": "d7e94581d784067fccddd34e19ae46aea526f9fa", "log": "This patch reduces the amount of intermediate garbage significantly. PR: SANDBOX-166 Contributed by: Ortwin Gl\u00fcck Reviewed by: Henri Yandell  ", "commit": "\n--- a/src/java/org/apache/commons/csv/CSVParser.java\n+++ b/src/java/org/apache/commons/csv/CSVParser.java\n import java.io.InputStream;\n import java.io.InputStreamReader;\n import java.io.Reader;\n-import java.util.Vector;\n+import java.util.ArrayList;\n \n \n /**\n   protected static final int TT_EOF = 1;\n   /** Token with content when end of a line is reached. */\n   protected static final int TT_EORECORD = 2;\n+\n+  /** Immutable empty String array. */\n+  private static final String[] EMPTY_STRING_ARRAY = new String[0];\n    \n   // the input stream\n   private ExtendedBufferedReader in;\n \n   private CSVStrategy strategy;\n   \n+  // the following objects are shared to reduce garbage \n+  /** A record buffer for getLine(). Grows as necessary and is reused. */\n+  private ArrayList record = new ArrayList();\n+  private Token reusableToken = new Token();\n+  private CharBuffer wsBuf = new CharBuffer();\n+  private CharBuffer code = new CharBuffer(4);\n+\n+  \n   /**\n    * Token is an internal token representation.\n    * \n    */\n   class Token {\n     /** Token type, see TT_xxx constants. */\n-    int type;\n+    int type = TT_INVALID;\n     /** The content buffer. */\n-    StringBuffer content;\n+    CharBuffer content = new CharBuffer(INITIAL_TOKEN_LENGTH);\n     /** Token ready flag: indicates a valid token with content (ready for the parser). */\n     boolean isReady;\n-    /** Initializes an empty token. */\n-    Token() {\n-      content = new StringBuffer(INITIAL_TOKEN_LENGTH);\n-      type = TT_INVALID;\n-      isReady = false;\n+    \n+    Token reset() {\n+        content.clear();\n+        type = TT_INVALID;\n+        isReady = false;\n+        return this;\n     }\n   }\n   \n    * @throws IOException on parse error or input read-failure\n    */\n   public String[][] getAllValues() throws IOException {\n-    Vector records = new Vector();\n+    ArrayList records = new ArrayList();\n     String[] values;\n     String[][] ret = null;\n     while ((values = getLine()) != null)  {\n    * @throws IOException on parse error or input read-failure\n    */\n   public String[] getLine() throws IOException {\n-    Vector record = new Vector();\n-    String[] ret = new String[0];\n-    Token tkn;\n-    while ((tkn = nextToken()).type == TT_TOKEN) {\n-      record.add(tkn.content.toString());  \n-    }\n-    // did we reached eorecord or eof ?\n-    switch (tkn.type) {\n-      case TT_EORECORD:\n-        record.add(tkn.content.toString());\n-        break;\n-      case TT_EOF:\n-        if (tkn.isReady) {\n-          record.add(tkn.content.toString());\n-        } else {\n-          ret = null;\n+    String[] ret = EMPTY_STRING_ARRAY;\n+    record.clear();\n+    while (true) {\n+        reusableToken.reset();\n+        nextToken(reusableToken);\n+        switch (reusableToken.type) {\n+            case TT_TOKEN:\n+                record.add(reusableToken.content.toString());\n+                break;\n+            case TT_EORECORD:\n+                record.add(reusableToken.content.toString());\n+                break;\n+            case TT_EOF:\n+                if (reusableToken.isReady) {\n+                    record.add(reusableToken.content.toString());\n+                } else {\n+                    ret = null;\n+                }\n+                break;\n+            case TT_INVALID:\n+            default:\n+                // error: throw IOException\n+                throw new IOException(\"(line \" + getLineNumber() + \") invalid parse sequence\");\n+            // unreachable: break;\n         }\n-        break;\n-      case TT_INVALID:\n-      default:\n-        // error: throw IOException\n-        throw new IOException(\n-          \"(line \" + getLineNumber() \n-          + \") invalid parse sequence\");\n-        // unreachable: break;\n-    }\n-    if (record.size() > 0) {\n-      ret = new String[record.size()];\n-      record.toArray(ret);\n+        if (reusableToken.type != TT_TOKEN) break;\n+    }\n+    if (!record.isEmpty()) {\n+      ret = (String[]) record.toArray(new String[record.size()]);\n     }\n     return ret;\n   }\n   //  the lexer(s)\n   // ======================================================\n  \n+  /**\n+   * Convenience method for <code>nextToken(null)</code>.\n+   */\n+  protected Token nextToken() throws IOException {\n+      return nextToken(new Token());\n+  }\n+  \n  /**\n    * Returns the next token.\n    * \n    * A token corresponds to a term, a record change or an\n    * end-of-file indicator.\n    * \n+   * @param tkn an existing Token object to reuse. The caller is responsible to initialize the\n+   * Token.\n    * @return the next token found\n    * @throws IOException on stream access error\n    */\n-  protected Token nextToken() throws IOException {\n-    Token tkn = new Token();\n-    StringBuffer wsBuf = new StringBuffer();\n+  protected Token nextToken(Token tkn) throws IOException {\n+    wsBuf.clear(); // resuse\n     \n     // get the last read char (required for empty line detection)\n     int lastChar = in.readAgain();\n       if (!strategy.isCommentingDisabled() && c == strategy.getCommentStart()) {\n         // ignore everything till end of line and continue (incr linecount)\n         in.readLine();\n-        tkn = nextToken();\n+        tkn = nextToken(tkn.reset());\n       } else if (c == strategy.getDelimiter()) {\n         // empty token return TT_TOKEN(\"\")\n         tkn.type = TT_TOKEN;\n         tkn.isReady = true;\n       } else if (eol) {\n         // empty token return TT_EORECORD(\"\")\n-        tkn.content.append(\"\");\n+        //noop: tkn.content.append(\"\");\n         tkn.type = TT_EORECORD;\n         tkn.isReady = true;\n       } else if (c == strategy.getEncapsulator()) {\n         encapsulatedTokenLexer(tkn, c);\n       } else if (isEndOfFile(c)) {\n         // end of file return TT_EOF()\n-        tkn.content.append(\"\");\n+        //noop: tkn.content.append(\"\");\n         tkn.type = TT_EOF;\n         tkn.isReady = true;\n       } else {\n         // next token must be a simple token\n         // add removed blanks when not ignoring whitespace chars...\n         if (!strategy.getIgnoreLeadingWhitespaces()) {\n-          tkn.content.append(wsBuf.toString());\n+          tkn.content.append(wsBuf);\n         }\n         simpleTokenLexer(tkn, c);\n       }\n    * @throws IOException on stream access error\n    */\n   private Token simpleTokenLexer(Token tkn, int c) throws IOException {\n-    StringBuffer wsBuf = new StringBuffer();\n+    wsBuf.clear();\n     while (!tkn.isReady) {\n       if (isEndOfLine(c)) {\n         // end of record\n       } else {\n         // prepend whitespaces (if we have)\n         if (wsBuf.length() > 0) {\n-          // for J2SDK 1.3 compatibility we use toString()\n-          tkn.content.append(wsBuf.toString());\n-          wsBuf.delete(0, wsBuf.length());\n+          tkn.content.append(wsBuf);\n+          wsBuf.clear();\n         }\n         tkn.content.append((char) c);\n       }\n     int ret = 0;\n     // ignore 'u' (assume c==\\ now) and read 4 hex digits\n     c = in.read();\n-    StringBuffer code = new StringBuffer(4);\n+    code.clear();\n     try {\n       for (int i = 0; i < 4; i++) {\n         c  = in.read();\n--- a/src/java/org/apache/commons/csv/ExtendedBufferedReader.java\n+++ b/src/java/org/apache/commons/csv/ExtendedBufferedReader.java\n   private int lastChar = UNDEFINED;\n   /** the line counter */\n   private int lineCounter = 0;\n+  private CharBuffer line = new CharBuffer();\n+  \n   /**\n    * Created extended buffered reader using default buffer-size\n    *\n    if (lookaheadChar == UNDEFINED) {\n      lookaheadChar = super.read();\n    }\n-   StringBuffer ret = new StringBuffer(\"\");\n+   line.clear(); // reuse\n    while (lookaheadChar != c && lookaheadChar != END_OF_STREAM) {\n-     ret.append((char) lookaheadChar);\n+     line.append((char) lookaheadChar);\n      if (lookaheadChar == '\\n') {\n        lineCounter++;\n      } \n      lastChar = lookaheadChar;\n      lookaheadChar = super.read();\n    }\n-   return ret.toString();    \n+   return line.toString();    \n  }\n  \n  /**\n       lookaheadChar = super.read(); \n     }\n     \n-    StringBuffer ret = new StringBuffer(\"\");\n+    line.clear(); //reuse\n     \n     // return null if end of stream has been reached\n     if (lookaheadChar == END_OF_STREAM) {\n         lookaheadChar = super.read();\n       }\n       lineCounter++;\n-      return ret.toString();\n+      return line.toString();\n     }\n     \n     // create the rest-of-line return and update the lookahead\n-    ret.append(String.valueOf(laChar));\n-    String restOfLine = super.readLine();\n+    line.append(laChar);\n+    String restOfLine = super.readLine(); // TODO involves copying\n     lastChar = lookaheadChar;\n     lookaheadChar = super.read();\n     if (restOfLine != null) {\n-      ret.append(restOfLine);\n+      line.append(restOfLine);\n     }\n     lineCounter++;\n-    return ret.toString();\n+    return line.toString();\n   }\n   \n   /**", "timestamp": 1155200478, "metainfo": ""}