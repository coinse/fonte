{"sha": "5a925ff1fffefd0d2ee11f4c8dfe860791f09965", "log": "Another baseline  ", "commit": "\n--- /dev/null\n+++ b/src/test/java/org/apache/commons/csv/CSVLexer1306667.java\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.commons.csv;\n+\n+import java.io.IOException;\n+\n+import static org.apache.commons.csv.Token.Type.*;\n+\n+class CSVLexer1306667 extends Lexer {\n+\n+    // ctor needs to be public so can be called dynamically by PerformanceTest class\n+    public CSVLexer1306667(CSVFormat format, ExtendedBufferedReader in) {\n+        super(format, in);\n+    }\n+    \n+    /**\n+     * Returns the next token.\n+     * <p/>\n+     * A token corresponds to a term, a record change or an end-of-file indicator.\n+     *\n+     * @param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n+     * @return the next token found\n+     * @throws java.io.IOException on stream access error\n+     */\n+    @Override\n+    Token nextToken(Token tkn) throws IOException {\n+\n+        // get the last read char (required for empty line detection)\n+        int lastChar = in.readAgain();\n+\n+        //  read the next char and set eol\n+        int c = in.read();\n+\n+        /* note: unfortunately isEndOfLine may consumes a character silently.\n+        *       this has no effect outside of the method. so a simple workaround\n+        *       is to call 'readAgain' on the stream...\n+        */\n+        boolean eol = isEndOfLine(c);\n+        c = in.readAgain();\n+\n+        //  empty line detection: eol AND (last char was EOL or beginning)\n+        if (emptyLinesIgnored) {\n+            while (eol && isStartOfLine(lastChar)) {\n+                // go on char ahead ...\n+                lastChar = c;\n+                c = in.read();\n+                eol = isEndOfLine(c);\n+                c = in.readAgain();\n+                // reached end of file without any content (empty line at the end)\n+                if (isEndOfFile(c)) {\n+                    tkn.type = EOF;\n+                    // don't set tkn.isReady here because no content\n+                    return tkn;\n+                }\n+            }\n+        }\n+\n+        // did we reach eof during the last iteration already ? EOF\n+        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n+            tkn.type = EOF;\n+            // don't set tkn.isReady here because no content\n+            return tkn;\n+        }\n+\n+        if (isStartOfLine(lastChar) && isCommentStart(c)) {\n+            in.readLine();\n+            tkn.type = COMMENT;\n+            return tkn;\n+        }\n+\n+        //  important: make sure a new char gets consumed in each iteration\n+        while (tkn.type == INVALID) {\n+            // ignore whitespaces at beginning of a token\n+            if (surroundingSpacesIgnored) {\n+                while (isWhitespace(c) && !eol) {\n+                    c = in.read();\n+                    eol = isEndOfLine(c);\n+                }\n+            }\n+            \n+            // ok, start of token reached: encapsulated, or token\n+            if (isDelimiter(c)) {\n+                // empty token return TOKEN(\"\")\n+                tkn.type = TOKEN;\n+            } else if (eol) {\n+                // empty token return EORECORD(\"\")\n+                //noop: tkn.content.append(\"\");\n+                tkn.type = EORECORD;\n+            } else if (isEncapsulator(c)) {\n+                // consume encapsulated token\n+                encapsulatedTokenLexer(tkn);\n+            } else if (isEndOfFile(c)) {\n+                // end of file return EOF()\n+                //noop: tkn.content.append(\"\");\n+                tkn.type = EOF;\n+                tkn.isReady = true; // there is data at EOF\n+            } else {\n+                // next token must be a simple token\n+                // add removed blanks when not ignoring whitespace chars...\n+                simpleTokenLexer(tkn, c);\n+            }\n+        }\n+        return tkn;\n+    }\n+\n+    /**\n+     * A simple token lexer\n+     * <p/>\n+     * Simple token are tokens which are not surrounded by encapsulators.\n+     * A simple token might contain escaped delimiters (as \\, or \\;). The\n+     * token is finished when one of the following conditions become true:\n+     * <ul>\n+     *   <li>end of line has been reached (EORECORD)</li>\n+     *   <li>end of stream has been reached (EOF)</li>\n+     *   <li>an unescaped delimiter has been reached (TOKEN)</li>\n+     * </ul>\n+     *\n+     * @param tkn the current token\n+     * @param c   the current character\n+     * @return the filled token\n+     * @throws IOException on stream access error\n+     */\n+    private Token simpleTokenLexer(Token tkn, int c) throws IOException {\n+        // Faster to use while(true)+break than while(tkn.type == INVALID)\n+        while (true) {\n+            if (isEndOfLine(c)) {\n+                tkn.type = EORECORD;\n+                break;\n+            } else if (isEndOfFile(c)) {\n+                tkn.type = EOF;\n+                tkn.isReady = true; // There is data at EOF\n+                break;\n+            } else if (isDelimiter(c)) {\n+                tkn.type = TOKEN;\n+                break;\n+            } else if (isEscape(c)) {\n+                tkn.content.append((char) readEscape());\n+                c = in.read(); // continue\n+            } else {\n+                tkn.content.append((char) c);\n+                c = in.read(); // continue\n+            }\n+        }\n+\n+        if (surroundingSpacesIgnored) {\n+            trimTrailingSpaces(tkn.content);\n+        }\n+\n+        return tkn;\n+    }\n+\n+    /**\n+     * An encapsulated token lexer\n+     * <p/>\n+     * Encapsulated tokens are surrounded by the given encapsulating-string.\n+     * The encapsulator itself might be included in the token using a\n+     * doubling syntax (as \"\", '') or using escaping (as in \\\", \\').\n+     * Whitespaces before and after an encapsulated token are ignored.\n+     *\n+     * @param tkn the current token\n+     * @return a valid token object\n+     * @throws IOException on invalid state\n+     */\n+    private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n+        // save current line\n+        int startLineNumber = getLineNumber();\n+        // ignore the given delimiter\n+        // assert c == delimiter;\n+        int c;\n+        while (true) {\n+            c = in.read();\n+            \n+            if (isEscape(c)) {\n+                tkn.content.append((char) readEscape());\n+            } else if (isEncapsulator(c)) {\n+                if (isEncapsulator(in.lookAhead())) {\n+                    // double or escaped encapsulator -> add single encapsulator to token\n+                    c = in.read();\n+                    tkn.content.append((char) c);\n+                } else {\n+                    // token finish mark (encapsulator) reached: ignore whitespace till delimiter\n+                    while (true) {\n+                        c = in.read();\n+                        if (isDelimiter(c)) {\n+                            tkn.type = TOKEN;\n+                            return tkn;\n+                        } else if (isEndOfFile(c)) {\n+                            tkn.type = EOF;\n+                            tkn.isReady = true; // There is data at EOF\n+                            return tkn;\n+                        } else if (isEndOfLine(c)) {\n+                            // ok eo token reached\n+                            tkn.type = EORECORD;\n+                            return tkn;\n+                        } else if (!isWhitespace(c)) {\n+                            // error invalid char between token and next delimiter\n+                            throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n+                        }\n+                    }\n+                }\n+            } else if (isEndOfFile(c)) {\n+                // error condition (end of file before end of token)\n+                throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n+            } else {\n+                // consume character\n+                tkn.content.append((char) c);\n+            }\n+        }\n+    }\n+\n+}", "timestamp": 1333046960, "metainfo": ""}