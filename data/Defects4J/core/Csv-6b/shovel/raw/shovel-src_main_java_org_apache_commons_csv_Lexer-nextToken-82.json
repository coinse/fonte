{
  "origin": "codeshovel",
  "repositoryName": "Csv-6b",
  "repositoryPath": "/tmp/Csv-6b//.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Lexer.java",
  "functionName": "nextToken",
  "functionId": "nextToken___token-Token(modifiers-final)",
  "sourceFilePath": "src/main/java/org/apache/commons/csv/Lexer.java",
  "functionAnnotation": "",
  "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
  "functionStartLine": 82,
  "functionEndLine": 164,
  "numCommitsSeen": 198,
  "timeTaken": 2821,
  "changeHistory": [
    "8e18054f3b6cd6fa619853354678d4d528345315",
    "65f6f1dfe8c1fde8c122b5a074d1e3498eb048c0",
    "7b168ebbbe06468b380e6f3e25c3448df9f748b3",
    "fcc0d15c7b541191f14b0861d945cbbeba770d10",
    "530b0382691b6af6340f194956f6e79ae3249662",
    "93a07b9b8f9e4fa82e6f306d57d71d5268d7dacf",
    "c4014b6b38c9f661a12557db7ee464e158f386f7",
    "350d34d5cfe45c4e7036422e0e2e0f6039eb6f98",
    "2a8ce4a11cf42683d7abf06c591b4c0f1e8928e1",
    "9f6d3f541330670df684d01b8b6fae67f474bb90",
    "992c0645e0b4d9436593f39c3bcff77328adb37c",
    "3655efcedbf804408a433cbbd25eef3fc91c675a",
    "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
    "8608520aa13bec03cdcb8d4273116e81004321ba",
    "93fc1f9363d911cb0a974f993d9266a89a63c41e",
    "bf06bed9b8905ccf5409179263707074167ccfc4",
    "787ab08db9230c67220ef453de211159e317d4e2",
    "8462234502ff4c6543e54e3e7b542029182bdcd3",
    "3fd45b544159e19165ecd3e4a8f5517ac2dd5c50",
    "7addc8f6889d3d1f4e5fe3bcb1c0f8161a6fefb9",
    "e922bf949aa055fe1da03056f202b80d17506791",
    "05b5c8ef488d5d230d665b9d488ca572bec5dc0c",
    "93089b260cd2030d69b3f7113ed643b9af1adcaa",
    "7c2cfeaf5884b9dd698309f5a10e80a1ba6705b0",
    "0a0f3bbd365c470c2ae86b1cf383838bfaab77e1",
    "911433707587a42727da375e1ec0e53dc909ac8d",
    "38741a48c692ae2fc13cd2445e77ace6ecea1156",
    "dd26201ac47f60cd9e18800726cc28660b81bdaf",
    "9ebd0d94254b468765f6c558bb10ca018a418444",
    "1299ddfe3fec5000f68c203a7f61e9af02955296",
    "fa07dea5850eb11bb7b4dc06823802156b89baaf",
    "83e4a903b18c43a10caa551c50ece4e251a0f674",
    "65ab9db952daebf62fc092c90f7f74cbb25b8c0f",
    "38670dbe9232dc9b56d6464c42293e745974cf60",
    "3cb5801a985c0d6a9ca3dc794b4e89a292b4a9c6",
    "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a",
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512",
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79",
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8",
    "42476f4b08fe4b075aa36f688f0801857f3635d9",
    "cacb79dab96cc98209cf14bf1b1fc6eb6f357c88",
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8",
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
    "c6bdecabd82eebc9efce450aa4057b668984479e",
    "6b422c82bdb39da4ca3ee4e0f8d2fbe0e8a28d46",
    "4dfc8ed0747f5d7cd10ba35621add0fe4891a545",
    "02b21463e68e7b3d5f3d9980746d131a08a08eed",
    "b55fb21d78e30748ae19f1c8d16902439643799a",
    "d7e94581d784067fccddd34e19ae46aea526f9fa",
    "f6f9fc1d480e85839c80d0890fa5ebed74971dc7",
    "eac54a225bc974157e914cf66cfa598171022018",
    "f047581f9526aad1c9c9e624710a4e860f88ecaa",
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8",
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955"
  ],
  "changeHistoryShort": {
    "8e18054f3b6cd6fa619853354678d4d528345315": "Ybodychange",
    "65f6f1dfe8c1fde8c122b5a074d1e3498eb048c0": "Yfilerename",
    "7b168ebbbe06468b380e6f3e25c3448df9f748b3": "Yannotationchange",
    "fcc0d15c7b541191f14b0861d945cbbeba770d10": "Ybodychange",
    "530b0382691b6af6340f194956f6e79ae3249662": "Ybodychange",
    "93a07b9b8f9e4fa82e6f306d57d71d5268d7dacf": "Ybodychange",
    "c4014b6b38c9f661a12557db7ee464e158f386f7": "Ybodychange",
    "350d34d5cfe45c4e7036422e0e2e0f6039eb6f98": "Ybodychange",
    "2a8ce4a11cf42683d7abf06c591b4c0f1e8928e1": "Ybodychange",
    "9f6d3f541330670df684d01b8b6fae67f474bb90": "Ybodychange",
    "992c0645e0b4d9436593f39c3bcff77328adb37c": "Ybodychange",
    "3655efcedbf804408a433cbbd25eef3fc91c675a": "Ybodychange",
    "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc": "Ymultichange(Ybodychange,Yparametermetachange)",
    "8608520aa13bec03cdcb8d4273116e81004321ba": "Ymultichange(Yparameterchange,Ybodychange,Ydocchange)",
    "93fc1f9363d911cb0a974f993d9266a89a63c41e": "Ymultichange(Ybodychange,Ydocchange)",
    "bf06bed9b8905ccf5409179263707074167ccfc4": "Yformatchange",
    "787ab08db9230c67220ef453de211159e317d4e2": "Ybodychange",
    "8462234502ff4c6543e54e3e7b542029182bdcd3": "Ybodychange",
    "3fd45b544159e19165ecd3e4a8f5517ac2dd5c50": "Ybodychange",
    "7addc8f6889d3d1f4e5fe3bcb1c0f8161a6fefb9": "Ybodychange",
    "e922bf949aa055fe1da03056f202b80d17506791": "Ybodychange",
    "05b5c8ef488d5d230d665b9d488ca572bec5dc0c": "Ybodychange",
    "93089b260cd2030d69b3f7113ed643b9af1adcaa": "Ybodychange",
    "7c2cfeaf5884b9dd698309f5a10e80a1ba6705b0": "Ybodychange",
    "0a0f3bbd365c470c2ae86b1cf383838bfaab77e1": "Ybodychange",
    "911433707587a42727da375e1ec0e53dc909ac8d": "Ybodychange",
    "38741a48c692ae2fc13cd2445e77ace6ecea1156": "Ybodychange",
    "dd26201ac47f60cd9e18800726cc28660b81bdaf": "Ybodychange",
    "9ebd0d94254b468765f6c558bb10ca018a418444": "Ybodychange",
    "1299ddfe3fec5000f68c203a7f61e9af02955296": "Ybodychange",
    "fa07dea5850eb11bb7b4dc06823802156b89baaf": "Ybodychange",
    "83e4a903b18c43a10caa551c50ece4e251a0f674": "Ybodychange",
    "65ab9db952daebf62fc092c90f7f74cbb25b8c0f": "Yannotationchange",
    "38670dbe9232dc9b56d6464c42293e745974cf60": "Ymultichange(Ymovefromfile,Ydocchange)",
    "3cb5801a985c0d6a9ca3dc794b4e89a292b4a9c6": "Ybodychange",
    "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a": "Ybodychange",
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512": "Ydocchange",
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79": "Ybodychange",
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8": "Ybodychange",
    "42476f4b08fe4b075aa36f688f0801857f3635d9": "Ybodychange",
    "cacb79dab96cc98209cf14bf1b1fc6eb6f357c88": "Ymodifierchange",
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8": "Yfilerename",
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8": "Ymultichange(Ybodychange,Ydocchange)",
    "c6bdecabd82eebc9efce450aa4057b668984479e": "Ybodychange",
    "6b422c82bdb39da4ca3ee4e0f8d2fbe0e8a28d46": "Ybodychange",
    "4dfc8ed0747f5d7cd10ba35621add0fe4891a545": "Ybodychange",
    "02b21463e68e7b3d5f3d9980746d131a08a08eed": "Ybodychange",
    "b55fb21d78e30748ae19f1c8d16902439643799a": "Ybodychange",
    "d7e94581d784067fccddd34e19ae46aea526f9fa": "Ymultichange(Yparameterchange,Ybodychange,Ydocchange)",
    "f6f9fc1d480e85839c80d0890fa5ebed74971dc7": "Ybodychange",
    "eac54a225bc974157e914cf66cfa598171022018": "Ybodychange",
    "f047581f9526aad1c9c9e624710a4e860f88ecaa": "Ymultichange(Ybodychange,Ydocchange)",
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8": "Yfilerename",
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8e18054f3b6cd6fa619853354678d4d528345315": {
      "type": "Ybodychange",
      "commitMessage": "Better ivar name.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1585096 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "4/5/14, 7:06 AM",
      "commitName": "8e18054f3b6cd6fa619853354678d4d528345315",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "8/10/13, 4:46 AM",
      "commitNameOld": "5a30b37043f6ca88fc3ca93b2c5f81744995e663",
      "commitAuthorOld": "Benedikt Ritter",
      "daysBetweenCommits": 238.1,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(final Token token) throws IOException {\n    int lastChar \u003d reader.getLastChar();\n    int c \u003d reader.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d reader.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String line \u003d reader.readLine();\n        if (line \u003d\u003d null) {\n            token.type \u003d EOF;\n            return token;\n        }\n        final String comment \u003d line.trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d reader.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isQuoteChar(c)) {\n            parseEncapsulatedToken(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            parseSimpleToken(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/Lexer.java",
      "functionStartLine": 82,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,52 +1,52 @@\n Token nextToken(final Token token) throws IOException {\n-    int lastChar \u003d in.getLastChar();\n-    int c \u003d in.read();\n+    int lastChar \u003d reader.getLastChar();\n+    int c \u003d reader.read();\n     boolean eol \u003d readEndOfLine(c);\n     if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n-            c \u003d in.read();\n+            c \u003d reader.read();\n             eol \u003d readEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n-        final String line \u003d in.readLine();\n+        final String line \u003d reader.readLine();\n         if (line \u003d\u003d null) {\n             token.type \u003d EOF;\n             return token;\n         }\n         final String comment \u003d line.trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n-                c \u003d in.read();\n+                c \u003d reader.read();\n                 eol \u003d readEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isQuoteChar(c)) {\n             parseEncapsulatedToken(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             parseSimpleToken(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "65f6f1dfe8c1fde8c122b5a074d1e3498eb048c0": {
      "type": "Yfilerename",
      "commitMessage": "Package private classes are not prefixed with \"CSV\": CSVLexer -\u003e Lexer.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1511462 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "8/7/13, 1:00 PM",
      "commitName": "65f6f1dfe8c1fde8c122b5a074d1e3498eb048c0",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "8/7/13, 11:25 AM",
      "commitNameOld": "643b628af4ebfdb1075d4e8eaadf0dc803a4b25c",
      "commitAuthorOld": "Benedikt Ritter",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String line \u003d in.readLine();\n        if (line \u003d\u003d null) {\n            token.type \u003d EOF;\n            return token;\n        }\n        final String comment \u003d line.trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isQuoteChar(c)) {\n            parseEncapsulatedToken(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            parseSimpleToken(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/Lexer.java",
      "functionStartLine": 82,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/main/java/org/apache/commons/csv/CSVLexer.java",
        "newPath": "src/main/java/org/apache/commons/csv/Lexer.java"
      }
    },
    "7b168ebbbe06468b380e6f3e25c3448df9f748b3": {
      "type": "Yannotationchange",
      "commitMessage": "Merge Lexer with CSVLexer\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1511006 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "8/6/13, 8:44 AM",
      "commitName": "7b168ebbbe06468b380e6f3e25c3448df9f748b3",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "7/31/13, 7:04 PM",
      "commitNameOld": "fcc0d15c7b541191f14b0861d945cbbeba770d10",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 5.57,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String line \u003d in.readLine();\n        if (line \u003d\u003d null) {\n            token.type \u003d EOF;\n            return token;\n        }\n        final String comment \u003d line.trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isQuoteChar(c)) {\n            parseEncapsulatedToken(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            parseSimpleToken(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 85,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,53 +1,52 @@\n-@Override\n Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.getLastChar();\n     int c \u003d in.read();\n     boolean eol \u003d readEndOfLine(c);\n     if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d readEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         final String line \u003d in.readLine();\n         if (line \u003d\u003d null) {\n             token.type \u003d EOF;\n             return token;\n         }\n         final String comment \u003d line.trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d readEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isQuoteChar(c)) {\n             parseEncapsulatedToken(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             parseSimpleToken(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {
        "oldValue": "@Override",
        "newValue": ""
      }
    },
    "fcc0d15c7b541191f14b0861d945cbbeba770d10": {
      "type": "Ybodychange",
      "commitMessage": "- Remove trailing spaces.\n- Add missing final keywords.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1509069 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "7/31/13, 7:04 PM",
      "commitName": "fcc0d15c7b541191f14b0861d945cbbeba770d10",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "7/31/13, 8:46 AM",
      "commitNameOld": "a0624779468261996e7e6e5c7a63ba1ce1a3a553",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.43,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String line \u003d in.readLine();\n        if (line \u003d\u003d null) {\n            token.type \u003d EOF;\n            return token;\n        }\n        final String comment \u003d line.trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isQuoteChar(c)) {\n            parseEncapsulatedToken(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            parseSimpleToken(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 52,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,53 +1,53 @@\n @Override\n Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.getLastChar();\n     int c \u003d in.read();\n     boolean eol \u003d readEndOfLine(c);\n     if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d readEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n-        String line \u003d in.readLine();\n+        final String line \u003d in.readLine();\n         if (line \u003d\u003d null) {\n             token.type \u003d EOF;\n             return token;\n         }\n         final String comment \u003d line.trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d readEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isQuoteChar(c)) {\n             parseEncapsulatedToken(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             parseSimpleToken(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "530b0382691b6af6340f194956f6e79ae3249662": {
      "type": "Ybodychange",
      "commitMessage": "Fix possible NPE reported by FindBugs.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1495269 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "6/20/13, 6:49 PM",
      "commitName": "530b0382691b6af6340f194956f6e79ae3249662",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "6/20/13, 6:46 PM",
      "commitNameOld": "93a07b9b8f9e4fa82e6f306d57d71d5268d7dacf",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        String line \u003d in.readLine();\n        if (line \u003d\u003d null) {\n            token.type \u003d EOF;\n            return token;\n        }\n        final String comment \u003d line.trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isQuoteChar(c)) {\n            parseEncapsulatedToken(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            parseSimpleToken(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 52,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,48 +1,53 @@\n @Override\n Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.getLastChar();\n     int c \u003d in.read();\n     boolean eol \u003d readEndOfLine(c);\n     if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d readEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n-        final String comment \u003d in.readLine().trim();\n+        String line \u003d in.readLine();\n+        if (line \u003d\u003d null) {\n+            token.type \u003d EOF;\n+            return token;\n+        }\n+        final String comment \u003d line.trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d readEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isQuoteChar(c)) {\n             parseEncapsulatedToken(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             parseSimpleToken(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "93a07b9b8f9e4fa82e6f306d57d71d5268d7dacf": {
      "type": "Ybodychange",
      "commitMessage": "Better param name.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1495268 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "6/20/13, 6:46 PM",
      "commitName": "93a07b9b8f9e4fa82e6f306d57d71d5268d7dacf",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "5/7/13, 8:12 AM",
      "commitNameOld": "71c69df6dda034e9aa18ad07782ba88643423f58",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 44.44,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isQuoteChar(c)) {\n            parseEncapsulatedToken(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            parseSimpleToken(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 52,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "",
      "extendedDetails": {}
    },
    "c4014b6b38c9f661a12557db7ee464e158f386f7": {
      "type": "Ybodychange",
      "commitMessage": "Method names should start with a verb\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1460136 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/23/13, 5:48 AM",
      "commitName": "c4014b6b38c9f661a12557db7ee464e158f386f7",
      "commitAuthor": "Benedikt Ritter",
      "commitDateOld": "3/20/13, 1:31 AM",
      "commitNameOld": "374cd7b16d1ec48bb68fd748427c4b8942767c6b",
      "commitAuthorOld": "Benedikt Ritter",
      "daysBetweenCommits": 3.18,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isQuoteChar(c)) {\n            parseEncapsulatedToken(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            parseSimpleToken(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 52,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,48 +1,48 @@\n @Override\n Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.getLastChar();\n     int c \u003d in.read();\n     boolean eol \u003d readEndOfLine(c);\n     if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d readEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         final String comment \u003d in.readLine().trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d readEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isQuoteChar(c)) {\n-            encapsulatedTokenLexer(token);\n+            parseEncapsulatedToken(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n-            simpleTokenLexer(token, c);\n+            parseSimpleToken(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "350d34d5cfe45c4e7036422e0e2e0f6039eb6f98": {
      "type": "Ybodychange",
      "commitMessage": "Rename encapsulator to quote char.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1398187 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/14/12, 8:37 PM",
      "commitName": "350d34d5cfe45c4e7036422e0e2e0f6039eb6f98",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "10/14/12, 8:25 PM",
      "commitNameOld": "6eddd544e56b4c376619cad6b279885962293b6d",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isQuoteChar(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 52,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,48 +1,48 @@\n @Override\n Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.getLastChar();\n     int c \u003d in.read();\n     boolean eol \u003d readEndOfLine(c);\n     if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d readEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         final String comment \u003d in.readLine().trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d readEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n-        } else if (isEncapsulator(c)) {\n+        } else if (isQuoteChar(c)) {\n             encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             simpleTokenLexer(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "2a8ce4a11cf42683d7abf06c591b4c0f1e8928e1": {
      "type": "Ybodychange",
      "commitMessage": "Rename method from \"is\" prefix to \"read\" prefix because it is not just a test method, it may actually consume input.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397923 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/13/12, 11:56 AM",
      "commitName": "2a8ce4a11cf42683d7abf06c591b4c0f1e8928e1",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "10/13/12, 10:40 AM",
      "commitNameOld": "9f6d3f541330670df684d01b8b6fae67f474bb90",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.05,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d readEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d readEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d readEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 47,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,48 +1,48 @@\n @Override\n Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.getLastChar();\n     int c \u003d in.read();\n-    boolean eol \u003d isEndOfLine(c);\n+    boolean eol \u003d readEndOfLine(c);\n     if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n-            eol \u003d isEndOfLine(c);\n+            eol \u003d readEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         final String comment \u003d in.readLine().trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n-                eol \u003d isEndOfLine(c);\n+                eol \u003d readEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             simpleTokenLexer(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "9f6d3f541330670df684d01b8b6fae67f474bb90": {
      "type": "Ybodychange",
      "commitMessage": "Rename readAgain() to getLastChar()\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397911 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/13/12, 10:40 AM",
      "commitName": "9f6d3f541330670df684d01b8b6fae67f474bb90",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "10/13/12, 10:28 AM",
      "commitNameOld": "0e7e9deabbddc56abcd0b92bcb50f704b4ed1da4",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.getLastChar();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 47,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,48 +1,48 @@\n @Override\n Token nextToken(final Token token) throws IOException {\n-    int lastChar \u003d in.readAgain();\n+    int lastChar \u003d in.getLastChar();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         final String comment \u003d in.readLine().trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             simpleTokenLexer(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "992c0645e0b4d9436593f39c3bcff77328adb37c": {
      "type": "Ybodychange",
      "commitMessage": "Rename ivar to ignoreEmptyLines to match CSVFormat.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397785 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/12/12, 11:29 PM",
      "commitName": "992c0645e0b4d9436593f39c3bcff77328adb37c",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "10/12/12, 11:28 PM",
      "commitNameOld": "3655efcedbf804408a433cbbd25eef3fc91c675a",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (ignoreEmptyLines) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 47,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,48 +1,48 @@\n @Override\n Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n-    if (emptyLinesIgnored) {\n+    if (ignoreEmptyLines) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         final String comment \u003d in.readLine().trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             simpleTokenLexer(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "3655efcedbf804408a433cbbd25eef3fc91c675a": {
      "type": "Ybodychange",
      "commitMessage": "Rename ivar to ignoreSurroundingSpaces to match CSVFormat.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397784 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/12/12, 11:28 PM",
      "commitName": "3655efcedbf804408a433cbbd25eef3fc91c675a",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "10/11/12, 8:47 AM",
      "commitNameOld": "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 1.61,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (ignoreSurroundingSpaces) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 47,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
      "diff": "@@ -1,48 +1,48 @@\n @Override\n Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         final String comment \u003d in.readLine().trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n-        if (surroundingSpacesIgnored) {\n+        if (ignoreSurroundingSpaces) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             simpleTokenLexer(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc": {
      "type": "Ymultichange(Ybodychange,Yparametermetachange)",
      "commitMessage": "Use final keyword where possible.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397122 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/11/12, 8:47 AM",
      "commitName": "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
      "commitAuthor": "Gary D. Gregory",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "Use final keyword where possible.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397122 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/11/12, 8:47 AM",
          "commitName": "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "10/11/12, 7:02 AM",
          "commitNameOld": "4bc562f47b46372a5ac11498fe5312846dedded4",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 47,
          "functionName": "nextToken",
          "functionAnnotation": "@Override",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
          "diff": "@@ -1,48 +1,48 @@\n @Override\n-Token nextToken(Token token) throws IOException {\n+Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n-        String comment \u003d in.readLine().trim();\n+        final String comment \u003d in.readLine().trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             simpleTokenLexer(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "Use final keyword where possible.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397122 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/11/12, 8:47 AM",
          "commitName": "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "10/11/12, 7:02 AM",
          "commitNameOld": "4bc562f47b46372a5ac11498fe5312846dedded4",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\nToken nextToken(final Token token) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        final String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 47,
          "functionName": "nextToken",
          "functionAnnotation": "@Override",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
          "diff": "@@ -1,48 +1,48 @@\n @Override\n-Token nextToken(Token token) throws IOException {\n+Token nextToken(final Token token) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 token.type \u003d EOF;\n                 return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         token.type \u003d EOF;\n         return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n-        String comment \u003d in.readLine().trim();\n+        final String comment \u003d in.readLine().trim();\n         token.content.append(comment);\n         token.type \u003d COMMENT;\n         return token;\n     }\n     while (token.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             token.type \u003d TOKEN;\n         } else if (eol) {\n             token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n             token.type \u003d EOF;\n             token.isReady \u003d true;\n         } else {\n             simpleTokenLexer(token, c);\n         }\n     }\n     return token;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[token-Token]",
            "newValue": "[token-Token(modifiers-final)]"
          }
        }
      ]
    },
    "8608520aa13bec03cdcb8d4273116e81004321ba": {
      "type": "Ymultichange(Yparameterchange,Ybodychange,Ydocchange)",
      "commitMessage": "Rename pname from \u0027tkn\u0027 to \u0027token\u0027.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383583 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "9/11/12, 12:47 PM",
      "commitName": "8608520aa13bec03cdcb8d4273116e81004321ba",
      "commitAuthor": "Gary D. Gregory",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "Rename pname from \u0027tkn\u0027 to \u0027token\u0027.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383583 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:47 PM",
          "commitName": "8608520aa13bec03cdcb8d4273116e81004321ba",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:47 PM",
          "commitNameOld": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\nToken nextToken(Token token) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 43,
          "functionName": "nextToken",
          "functionAnnotation": "@Override",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
          "diff": "@@ -1,48 +1,48 @@\n @Override\n-Token nextToken(Token tkn) throws IOException {\n+Token nextToken(Token token) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n-                tkn.type \u003d EOF;\n-                return tkn;\n+                token.type \u003d EOF;\n+                return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n-        tkn.type \u003d EOF;\n-        return tkn;\n+        token.type \u003d EOF;\n+        return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         String comment \u003d in.readLine().trim();\n-        tkn.content.append(comment);\n-        tkn.type \u003d COMMENT;\n-        return tkn;\n+        token.content.append(comment);\n+        token.type \u003d COMMENT;\n+        return token;\n     }\n-    while (tkn.type \u003d\u003d INVALID) {\n+    while (token.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n-            tkn.type \u003d TOKEN;\n+            token.type \u003d TOKEN;\n         } else if (eol) {\n-            tkn.type \u003d EORECORD;\n+            token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n-            encapsulatedTokenLexer(tkn);\n+            encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n-            tkn.type \u003d EOF;\n-            tkn.isReady \u003d true;\n+            token.type \u003d EOF;\n+            token.isReady \u003d true;\n         } else {\n-            simpleTokenLexer(tkn, c);\n+            simpleTokenLexer(token, c);\n         }\n     }\n-    return tkn;\n+    return token;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[tkn-Token]",
            "newValue": "[token-Token]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Rename pname from \u0027tkn\u0027 to \u0027token\u0027.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383583 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:47 PM",
          "commitName": "8608520aa13bec03cdcb8d4273116e81004321ba",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:47 PM",
          "commitNameOld": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\nToken nextToken(Token token) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 43,
          "functionName": "nextToken",
          "functionAnnotation": "@Override",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
          "diff": "@@ -1,48 +1,48 @@\n @Override\n-Token nextToken(Token tkn) throws IOException {\n+Token nextToken(Token token) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n-                tkn.type \u003d EOF;\n-                return tkn;\n+                token.type \u003d EOF;\n+                return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n-        tkn.type \u003d EOF;\n-        return tkn;\n+        token.type \u003d EOF;\n+        return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         String comment \u003d in.readLine().trim();\n-        tkn.content.append(comment);\n-        tkn.type \u003d COMMENT;\n-        return tkn;\n+        token.content.append(comment);\n+        token.type \u003d COMMENT;\n+        return token;\n     }\n-    while (tkn.type \u003d\u003d INVALID) {\n+    while (token.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n-            tkn.type \u003d TOKEN;\n+            token.type \u003d TOKEN;\n         } else if (eol) {\n-            tkn.type \u003d EORECORD;\n+            token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n-            encapsulatedTokenLexer(tkn);\n+            encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n-            tkn.type \u003d EOF;\n-            tkn.isReady \u003d true;\n+            token.type \u003d EOF;\n+            token.isReady \u003d true;\n         } else {\n-            simpleTokenLexer(tkn, c);\n+            simpleTokenLexer(token, c);\n         }\n     }\n-    return tkn;\n+    return token;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "Rename pname from \u0027tkn\u0027 to \u0027token\u0027.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383583 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:47 PM",
          "commitName": "8608520aa13bec03cdcb8d4273116e81004321ba",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:47 PM",
          "commitNameOld": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\nToken nextToken(Token token) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                token.type \u003d EOF;\n                return token;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        token.type \u003d EOF;\n        return token;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        String comment \u003d in.readLine().trim();\n        token.content.append(comment);\n        token.type \u003d COMMENT;\n        return token;\n    }\n    while (token.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            token.type \u003d TOKEN;\n        } else if (eol) {\n            token.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(token);\n        } else if (isEndOfFile(c)) {\n            token.type \u003d EOF;\n            token.isReady \u003d true;\n        } else {\n            simpleTokenLexer(token, c);\n        }\n    }\n    return token;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 43,
          "functionName": "nextToken",
          "functionAnnotation": "@Override",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
          "diff": "@@ -1,48 +1,48 @@\n @Override\n-Token nextToken(Token tkn) throws IOException {\n+Token nextToken(Token token) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n-                tkn.type \u003d EOF;\n-                return tkn;\n+                token.type \u003d EOF;\n+                return token;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n-        tkn.type \u003d EOF;\n-        return tkn;\n+        token.type \u003d EOF;\n+        return token;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         String comment \u003d in.readLine().trim();\n-        tkn.content.append(comment);\n-        tkn.type \u003d COMMENT;\n-        return tkn;\n+        token.content.append(comment);\n+        token.type \u003d COMMENT;\n+        return token;\n     }\n-    while (tkn.type \u003d\u003d INVALID) {\n+    while (token.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n-            tkn.type \u003d TOKEN;\n+            token.type \u003d TOKEN;\n         } else if (eol) {\n-            tkn.type \u003d EORECORD;\n+            token.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n-            encapsulatedTokenLexer(tkn);\n+            encapsulatedTokenLexer(token);\n         } else if (isEndOfFile(c)) {\n-            tkn.type \u003d EOF;\n-            tkn.isReady \u003d true;\n+            token.type \u003d EOF;\n+            token.isReady \u003d true;\n         } else {\n-            simpleTokenLexer(tkn, c);\n+            simpleTokenLexer(token, c);\n         }\n     }\n-    return tkn;\n+    return token;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
            "newValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param token an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n"
          }
        }
      ]
    },
    "93fc1f9363d911cb0a974f993d9266a89a63c41e": {
      "type": "Ymultichange(Ybodychange,Ydocchange)",
      "commitMessage": "Fix Checkstyle: Format for 120 line length.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "9/11/12, 12:47 PM",
      "commitName": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
      "commitAuthor": "Gary D. Gregory",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "Fix Checkstyle: Format for 120 line length.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383582 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:47 PM",
          "commitName": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:41 PM",
          "commitNameOld": "42a4812bcefc07e6eb4eb7aaaed926dd08ae093f",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        String comment \u003d in.readLine().trim();\n        tkn.content.append(comment);\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 43,
          "functionName": "nextToken",
          "functionAnnotation": "@Override",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
          "diff": "",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "Fix Checkstyle: Format for 120 line length.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383582 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:47 PM",
          "commitName": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:41 PM",
          "commitNameOld": "42a4812bcefc07e6eb4eb7aaaed926dd08ae093f",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        String comment \u003d in.readLine().trim();\n        tkn.content.append(comment);\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 43,
          "functionName": "nextToken",
          "functionAnnotation": "@Override",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
            "newValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException\n            on stream access error\n"
          }
        }
      ]
    },
    "bf06bed9b8905ccf5409179263707074167ccfc4": {
      "type": "Yformatchange",
      "commitMessage": "Remove trailing spaces.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383577 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "9/11/12, 12:40 PM",
      "commitName": "bf06bed9b8905ccf5409179263707074167ccfc4",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "9/11/12, 12:35 PM",
      "commitNameOld": "6a132b40abbefb97ff58528eab8a8835fb353df1",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        String comment \u003d in.readLine().trim();\n        tkn.content.append(comment);\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "",
      "extendedDetails": {}
    },
    "787ab08db9230c67220ef453de211159e317d4e2": {
      "type": "Ybodychange",
      "commitMessage": "CSV-85 Allow comments to be returned in CSVRecord\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306947 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/29/12, 9:03 AM",
      "commitName": "787ab08db9230c67220ef453de211159e317d4e2",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/29/12, 5:03 AM",
      "commitNameOld": "8462234502ff4c6543e54e3e7b542029182bdcd3",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.17,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        String comment \u003d in.readLine().trim();\n        tkn.content.append(comment);\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,47 +1,48 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n-        in.readLine();\n+        String comment \u003d in.readLine().trim();\n+        tkn.content.append(comment);\n         tkn.type \u003d COMMENT;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "8462234502ff4c6543e54e3e7b542029182bdcd3": {
      "type": "Ybodychange",
      "commitMessage": "We don\u0027t care if trailing LF has been consumed\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306797 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/29/12, 5:03 AM",
      "commitName": "8462234502ff4c6543e54e3e7b542029182bdcd3",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/28/12, 6:24 PM",
      "commitNameOld": "3fd45b544159e19165ecd3e4a8f5517ac2dd5c50",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.44,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        in.readLine();\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,49 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n-    c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n-            c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n         in.readLine();\n         tkn.type \u003d COMMENT;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "3fd45b544159e19165ecd3e4a8f5517ac2dd5c50": {
      "type": "Ybodychange",
      "commitMessage": "Have to check for comment after dealing with empty lines.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306667 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/28/12, 6:24 PM",
      "commitName": "3fd45b544159e19165ecd3e4a8f5517ac2dd5c50",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/28/12, 5:58 PM",
      "commitNameOld": "19ba389fe8194bb6c22102b32e021d8487e1e307",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        in.readLine();\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n-    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n-        in.readLine();\n-        tkn.type \u003d COMMENT;\n-        return tkn;\n-    }\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n+    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n+        in.readLine();\n+        tkn.type \u003d COMMENT;\n+        return tkn;\n+    }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "7addc8f6889d3d1f4e5fe3bcb1c0f8161a6fefb9": {
      "type": "Ybodychange",
      "commitMessage": "Misplaced comment\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306643 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/28/12, 4:35 PM",
      "commitName": "7addc8f6889d3d1f4e5fe3bcb1c0f8161a6fefb9",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/28/12, 6:46 AM",
      "commitNameOld": "e922bf949aa055fe1da03056f202b80d17506791",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.41,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        in.readLine();\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "",
      "extendedDetails": {}
    },
    "e922bf949aa055fe1da03056f202b80d17506791": {
      "type": "Ybodychange",
      "commitMessage": "CSV-84 Clarify comment handling\nFix code so comment only detected at start of a line\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306325 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/28/12, 6:46 AM",
      "commitName": "e922bf949aa055fe1da03056f202b80d17506791",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/28/12, 6:44 AM",
      "commitNameOld": "05b5c8ef488d5d230d665b9d488ca572bec5dc0c",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n        in.readLine();\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,47 +1,49 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n+    if (isStartOfLine(lastChar) \u0026\u0026 isCommentStart(c)) {\n+        in.readLine();\n+        tkn.type \u003d COMMENT;\n+        return tkn;\n+    }\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n-        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED)) {\n+        while (eol \u0026\u0026 isStartOfLine(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n-        if (isCommentStart(c)) {\n-            in.readLine();\n-            tkn.type \u003d COMMENT;\n-        } else if (isDelimiter(c)) {\n+        if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "05b5c8ef488d5d230d665b9d488ca572bec5dc0c": {
      "type": "Ybodychange",
      "commitMessage": "Revert r1306321 - committed wrong file\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306324 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/28/12, 6:44 AM",
      "commitName": "05b5c8ef488d5d230d665b9d488ca572bec5dc0c",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/28/12, 6:40 AM",
      "commitNameOld": "93089b260cd2030d69b3f7113ed643b9af1adcaa",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn.type \u003d COMMENT;\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,49 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n-    if ((lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 isCommentStart(c)) {\n-        in.readLine();\n-        tkn.type \u003d COMMENT;\n-        return tkn;\n-    }\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n-        if (isDelimiter(c)) {\n+        if (isCommentStart(c)) {\n+            in.readLine();\n+            tkn.type \u003d COMMENT;\n+        } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "93089b260cd2030d69b3f7113ed643b9af1adcaa": {
      "type": "Ybodychange",
      "commitMessage": "Add method for detecting start of line\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306321 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/28/12, 6:40 AM",
      "commitName": "93089b260cd2030d69b3f7113ed643b9af1adcaa",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/27/12, 5:34 PM",
      "commitNameOld": "ba26844c7bca3e42036f626cd61de9d40550b76f",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.55,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    if ((lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 isCommentStart(c)) {\n        in.readLine();\n        tkn.type \u003d COMMENT;\n        return tkn;\n    }\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,47 +1,49 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n+    if ((lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 isCommentStart(c)) {\n+        in.readLine();\n+        tkn.type \u003d COMMENT;\n+        return tkn;\n+    }\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n-        if (isCommentStart(c)) {\n-            in.readLine();\n-            tkn.type \u003d COMMENT;\n-        } else if (isDelimiter(c)) {\n+        if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "7c2cfeaf5884b9dd698309f5a10e80a1ba6705b0": {
      "type": "Ybodychange",
      "commitMessage": "lastChar cannot possibly be EOF if it is CR, LF or UNDEFINED\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306073 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/27/12, 5:22 PM",
      "commitName": "7c2cfeaf5884b9dd698309f5a10e80a1ba6705b0",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/27/12, 5:01 PM",
      "commitNameOld": "0a0f3bbd365c470c2ae86b1cf383838bfaab77e1",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn.type \u003d COMMENT;\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,47 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n-        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn.type \u003d COMMENT;\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "0a0f3bbd365c470c2ae86b1cf383838bfaab77e1": {
      "type": "Ybodychange",
      "commitMessage": "CSV-70 Improve readability of CSVLexer\nIntroduce COMMENT type\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306064 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/27/12, 5:01 PM",
      "commitName": "0a0f3bbd365c470c2ae86b1cf383838bfaab77e1",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/27/12, 4:50 PM",
      "commitNameOld": "911433707587a42727da375e1ec0e53dc909ac8d",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn.type \u003d COMMENT;\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,47 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n-            tkn \u003d nextToken(tkn.reset());\n+            tkn.type \u003d COMMENT;\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "911433707587a42727da375e1ec0e53dc909ac8d": {
      "type": "Ybodychange",
      "commitMessage": "CSV-70 Improve readability of CSVLexer\nRemove unnecessary parameters\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306062 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/27/12, 4:50 PM",
      "commitName": "911433707587a42727da375e1ec0e53dc909ac8d",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/26/12, 12:02 PM",
      "commitNameOld": "38741a48c692ae2fc13cd2445e77ace6ecea1156",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 1.2,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,47 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n         if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n-            encapsulatedTokenLexer(tkn, c);\n+            encapsulatedTokenLexer(tkn);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "38741a48c692ae2fc13cd2445e77ace6ecea1156": {
      "type": "Ybodychange",
      "commitMessage": "CSV-54 Confusing semantic of the ignore leading/trailing spaces parameters\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1305494 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/26/12, 12:02 PM",
      "commitName": "38741a48c692ae2fc13cd2445e77ace6ecea1156",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 12:04 PM",
      "commitNameOld": "dd26201ac47f60cd9e18800726cc28660b81bdaf",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 4.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,47 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n-        if (leadingSpacesIgnored) {\n+        if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "dd26201ac47f60cd9e18800726cc28660b81bdaf": {
      "type": "Ybodychange",
      "commitMessage": "CSV-81 Token.Type.isReady could perhaps be removed\nNot removed, but only set on EOF if there is data to return\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303988 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 12:04 PM",
      "commitName": "dd26201ac47f60cd9e18800726cc28660b81bdaf",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 11:23 AM",
      "commitNameOld": "9ebd0d94254b468765f6c558bb10ca018a418444",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (leadingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,49 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n-    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n+    while (tkn.type \u003d\u003d INVALID) {\n         if (leadingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n-            tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n-            tkn.isReady \u003d true;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "9ebd0d94254b468765f6c558bb10ca018a418444": {
      "type": "Ybodychange",
      "commitMessage": "CSV-80 - CSVLexer.nextToken does not need wsBuf\nremove useless wsBuf\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 11:23 AM",
      "commitName": "9ebd0d94254b468765f6c558bb10ca018a418444",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 11:15 AM",
      "commitNameOld": "1299ddfe3fec5000f68c203a7f61e9af02955296",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (leadingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,54 +1,49 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n-    wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (leadingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n-                wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!leadingSpacesIgnored) {\n-                tkn.content.append(wsBuf);\n-            }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "1299ddfe3fec5000f68c203a7f61e9af02955296": {
      "type": "Ybodychange",
      "commitMessage": "Oops - fix bug introduced in r1303933 \n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303948 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 11:15 AM",
      "commitName": "1299ddfe3fec5000f68c203a7f61e9af02955296",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 11:00 AM",
      "commitNameOld": "fa07dea5850eb11bb7b4dc06823802156b89baaf",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (leadingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!leadingSpacesIgnored) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 43,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,54 +1,54 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n-    if (isEndOfFile(lastChar) || (isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n+    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (leadingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!leadingSpacesIgnored) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "fa07dea5850eb11bb7b4dc06823802156b89baaf": {
      "type": "Ybodychange",
      "commitMessage": "CSV-71 - Add convenience Methods to CSVLexer\nUse convenience fields from Lexer parent class; missed one method replacement earlier\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303933 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 11:00 AM",
      "commitName": "fa07dea5850eb11bb7b4dc06823802156b89baaf",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 10:27 AM",
      "commitNameOld": "83e4a903b18c43a10caa551c50ece4e251a0f674",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (leadingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!leadingSpacesIgnored) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 43,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,54 +1,54 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    if (format.isEmptyLinesIgnored()) {\n+    if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n-    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n+    if (isEndOfFile(lastChar) || (isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n-        if (format.isLeadingSpacesIgnored()) {\n+        if (leadingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!format.isLeadingSpacesIgnored()) {\n+            if (!leadingSpacesIgnored) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "83e4a903b18c43a10caa551c50ece4e251a0f674": {
      "type": "Ybodychange",
      "commitMessage": "CSV-71 - Add convenience Methods to CSVLexer\nUse convenience methods from Lexer parent class\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303904 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 10:27 AM",
      "commitName": "83e4a903b18c43a10caa551c50ece4e251a0f674",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 9:32 AM",
      "commitNameOld": "fdfe50842f8ac0a842ba0a220bbd2613178e7a75",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 43,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,54 +1,54 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (format.isEmptyLinesIgnored()) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (format.isLeadingSpacesIgnored()) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n-        if (c \u003d\u003d format.getCommentStart()) {\n+        if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n-        } else if (c \u003d\u003d format.getDelimiter()) {\n+        } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n-        } else if (c \u003d\u003d format.getEncapsulator()) {\n+        } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "65ab9db952daebf62fc092c90f7f74cbb25b8c0f": {
      "type": "Yannotationchange",
      "commitMessage": "Make it easy to provide an alternative lexer if required\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303620 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/21/12, 4:46 PM",
      "commitName": "65ab9db952daebf62fc092c90f7f74cbb25b8c0f",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/21/12, 12:04 PM",
      "commitNameOld": "3ea8118ff3793cc32fcf6d2c93d4f5eda73b374e",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 42,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,53 +1,54 @@\n+@Override\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (format.isEmptyLinesIgnored()) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (format.isLeadingSpacesIgnored()) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d format.getDelimiter()) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {
        "oldValue": "",
        "newValue": "@Override"
      }
    },
    "38670dbe9232dc9b56d6464c42293e745974cf60": {
      "type": "Ymultichange(Ymovefromfile,Ydocchange)",
      "commitMessage": "Moved the lexer in a separate file\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300850 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/15/12, 1:52 AM",
      "commitName": "38670dbe9232dc9b56d6464c42293e745974cf60",
      "commitAuthor": "Emmanuel Bourg",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "Moved the lexer in a separate file\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300850 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/15/12, 1:52 AM",
          "commitName": "38670dbe9232dc9b56d6464c42293e745974cf60",
          "commitAuthor": "Emmanuel Bourg",
          "commitDateOld": "3/14/12, 4:12 PM",
          "commitNameOld": "35b954ed36494f64b27b495ded6e66b409d0ed79",
          "commitAuthorOld": "Emmanuel Bourg",
          "daysBetweenCommits": 0.4,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 92,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
          "diff": "",
          "extendedDetails": {
            "oldPath": "src/main/java/org/apache/commons/csv/CSVParser.java",
            "newPath": "src/main/java/org/apache/commons/csv/CSVLexer.java",
            "oldMethodName": "nextToken",
            "newMethodName": "nextToken"
          }
        },
        {
          "type": "Ydocchange",
          "commitMessage": "Moved the lexer in a separate file\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300850 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/15/12, 1:52 AM",
          "commitName": "38670dbe9232dc9b56d6464c42293e745974cf60",
          "commitAuthor": "Emmanuel Bourg",
          "commitDateOld": "3/14/12, 4:12 PM",
          "commitNameOld": "35b954ed36494f64b27b495ded6e66b409d0ed79",
          "commitAuthorOld": "Emmanuel Bourg",
          "daysBetweenCommits": 0.4,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 92,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n",
            "newValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n"
          }
        }
      ]
    },
    "3cb5801a985c0d6a9ca3dc794b4e89a292b4a9c6": {
      "type": "Ybodychange",
      "commitMessage": "Replaced CharBuffer with StringBuilder (CSV-59)\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300659 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/14/12, 10:42 AM",
      "commitName": "3cb5801a985c0d6a9ca3dc794b4e89a292b4a9c6",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "3/14/12, 6:03 AM",
      "commitNameOld": "18d706032ac850979833165b66439c2c764c3b33",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.19,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 301,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,53 +1,53 @@\n Token nextToken(Token tkn) throws IOException {\n-    wsBuf.clear();\n+    wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (format.isEmptyLinesIgnored()) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (format.isLeadingSpacesIgnored()) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d format.getDelimiter()) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a": {
      "type": "Ybodychange",
      "commitMessage": "Minor performance improvement (~2%)\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1299486 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/11/12, 4:23 PM",
      "commitName": "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "3/8/12, 1:59 AM",
      "commitNameOld": "2ec4c994c0458ef893af9bd518849bec21b2dec4",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 3.56,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 303,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,53 @@\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n-        lastChar \u003d c;\n-        c \u003d in.read();\n-        eol \u003d isEndOfLine(c);\n-        c \u003d in.readAgain();\n-        if (isEndOfFile(c)) {\n-            tkn.type \u003d EOF;\n-            return tkn;\n+    if (format.isEmptyLinesIgnored()) {\n+        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+            lastChar \u003d c;\n+            c \u003d in.read();\n+            eol \u003d isEndOfLine(c);\n+            c \u003d in.readAgain();\n+            if (isEndOfFile(c)) {\n+                tkn.type \u003d EOF;\n+                return tkn;\n+            }\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n-        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n-            wsBuf.append((char) c);\n-            c \u003d in.read();\n-            eol \u003d isEndOfLine(c);\n+        if (format.isLeadingSpacesIgnored()) {\n+            while (isWhitespace(c) \u0026\u0026 !eol) {\n+                wsBuf.append((char) c);\n+                c \u003d in.read();\n+                eol \u003d isEndOfLine(c);\n+            }\n         }\n         if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d format.getDelimiter()) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512": {
      "type": "Ydocchange",
      "commitMessage": "Updated the Javadoc\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1297043 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/5/12, 5:08 AM",
      "commitName": "7bd9d1d970b04a8439fee0bd5224159f57cb2512",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 3:04 PM",
      "commitNameOld": "045dbbbe4ab84618cee8ba27d00b9283ce0a2715",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 116.59,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 287,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "",
      "extendedDetails": {
        "oldValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
        "newValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n"
      }
    },
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79": {
      "type": "Ybodychange",
      "commitMessage": "Turned the token types into an Enum\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199872 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 9:11 AM",
      "commitName": "16bfec07ffd785e5abbabdc4145eeac5cccc2c79",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 8:58 AM",
      "commitNameOld": "cbcfb72912f41d1fac3f6d26ca27406cca94da9e",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 245,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n-            tkn.type \u003d TT_EOF;\n+            tkn.type \u003d EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n-        tkn.type \u003d TT_EOF;\n+        tkn.type \u003d EOF;\n         return tkn;\n     }\n-    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n+    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d format.getDelimiter()) {\n-            tkn.type \u003d TT_TOKEN;\n+            tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n-            tkn.type \u003d TT_EORECORD;\n+            tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n-            tkn.type \u003d TT_EOF;\n+            tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8": {
      "type": "Ybodychange",
      "commitMessage": "Renamed CSVStrategy to CSVFormat\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199842 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 8:54 AM",
      "commitName": "cb99634ab3d6143dffc90938fc68e15c7f9d25b8",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 8:21 AM",
      "commitNameOld": "42476f4b08fe4b075aa36f688f0801857f3635d9",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 246,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (strategy.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n-    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n+    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n-        while (strategy.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n+        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n-        if (c \u003d\u003d strategy.getCommentStart()) {\n+        if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n-        } else if (c \u003d\u003d strategy.getDelimiter()) {\n+        } else if (c \u003d\u003d format.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n-        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n+        } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!strategy.isLeadingSpacesIgnored()) {\n+            if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "42476f4b08fe4b075aa36f688f0801857f3635d9": {
      "type": "Ybodychange",
      "commitMessage": "CSVStrategy is now immutable (SANDBOX-279)\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199827 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 8:21 AM",
      "commitName": "42476f4b08fe4b075aa36f688f0801857f3635d9",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 6:54 AM",
      "commitNameOld": "fc4ccb426eb3934ee1656db9b18c7d797ac6bd1d",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 246,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+    while (strategy.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n-        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n+        while (strategy.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!strategy.getIgnoreLeadingWhitespaces()) {\n+            if (!strategy.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "cacb79dab96cc98209cf14bf1b1fc6eb6f357c88": {
      "type": "Ymodifierchange",
      "commitMessage": "Changed the visibility of the Token types and the protected methods to package private\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199769 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 6:26 AM",
      "commitName": "cacb79dab96cc98209cf14bf1b1fc6eb6f357c88",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 3:17 AM",
      "commitNameOld": "165a5dcaf41b490cd80e90c65738453140c0ef61",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.13,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 317,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n-protected Token nextToken(Token tkn) throws IOException {\n+Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n         while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {
        "oldValue": "[protected]",
        "newValue": "[]"
      }
    },
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8": {
      "type": "Yfilerename",
      "commitMessage": "Moved the directories to match the Maven layout\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199691 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 2:38 AM",
      "commitName": "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "7/20/11, 9:14 AM",
      "commitNameOld": "76cab04936e8b539d983510079419fabeeaecea0",
      "commitAuthorOld": "Stephen Colebourne",
      "daysBetweenCommits": 111.77,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 325,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/commons/csv/CSVParser.java",
        "newPath": "src/main/java/org/apache/commons/csv/CSVParser.java"
      }
    },
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8": {
      "type": "Ymultichange(Ybodychange,Ydocchange)",
      "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2/1/11, 12:46 AM",
      "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
      "commitAuthor": "Jacopo Cappellato",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2/1/11, 12:46 AM",
          "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
          "commitAuthor": "Jacopo Cappellato",
          "commitDateOld": "1/31/11, 2:47 AM",
          "commitNameOld": "c6bdecabd82eebc9efce450aa4057b668984479e",
          "commitAuthorOld": "Jacopo Cappellato",
          "daysBetweenCommits": 0.92,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 325,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2/1/11, 12:46 AM",
          "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
          "commitAuthor": "Jacopo Cappellato",
          "commitDateOld": "1/31/11, 2:47 AM",
          "commitNameOld": "c6bdecabd82eebc9efce450aa4057b668984479e",
          "commitAuthorOld": "Jacopo Cappellato",
          "daysBetweenCommits": 0.92,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 325,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
            "newValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n"
          }
        }
      ]
    },
    "c6bdecabd82eebc9efce450aa4057b668984479e": {
      "type": "Ybodychange",
      "commitMessage": "Fixes for typos in comments and javadoc.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065549 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "1/31/11, 2:47 AM",
      "commitName": "c6bdecabd82eebc9efce450aa4057b668984479e",
      "commitAuthor": "Jacopo Cappellato",
      "commitDateOld": "1/31/11, 12:50 AM",
      "commitNameOld": "58149e21ad7452ed45ce77b8095c0c2c7414d55b",
      "commitAuthorOld": "Jacopo Cappellato",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 305,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "",
      "extendedDetails": {}
    },
    "6b422c82bdb39da4ca3ee4e0f8d2fbe0e8a28d46": {
      "type": "Ybodychange",
      "commitMessage": "Fix for issue reported in SANDBOX-218: CSV reader doesn\u0027t handle older Mac line endings (\\r) that are also used by recent versions of Excel for Mac.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065496 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "1/30/11, 11:10 PM",
      "commitName": "6b422c82bdb39da4ca3ee4e0f8d2fbe0e8a28d46",
      "commitAuthor": "Jacopo Cappellato",
      "commitDateOld": "7/14/10, 6:32 PM",
      "commitNameOld": "4dfc8ed0747f5d7cd10ba35621add0fe4891a545",
      "commitAuthorOld": "Yonik Seeley",
      "daysBetweenCommits": 200.23,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 306,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n protected Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n         while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "4dfc8ed0747f5d7cd10ba35621add0fe4891a545": {
      "type": "Ybodychange",
      "commitMessage": "SANDBOX-313: Endless loops in CSV parser when last line is comment\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@964273 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "7/14/10, 6:32 PM",
      "commitName": "4dfc8ed0747f5d7cd10ba35621add0fe4891a545",
      "commitAuthor": "Yonik Seeley",
      "commitDateOld": "6/16/10, 9:12 AM",
      "commitNameOld": "02b21463e68e7b3d5f3d9980746d131a08a08eed",
      "commitAuthorOld": "Yonik Seeley",
      "daysBetweenCommits": 28.39,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 306,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n protected Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n-    while (!tkn.isReady) {\n+    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n         while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "02b21463e68e7b3d5f3d9980746d131a08a08eed": {
      "type": "Ybodychange",
      "commitMessage": "SANDBOX-322: CSVPrinter overhaul\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@955284 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "6/16/10, 9:12 AM",
      "commitName": "02b21463e68e7b3d5f3d9980746d131a08a08eed",
      "commitAuthor": "Yonik Seeley",
      "commitDateOld": "2/26/08, 12:47 AM",
      "commitNameOld": "1b0ccbe4c7d5a183913063429198e8c51bb768f9",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 841.31,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 306,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n protected Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n-        while (isWhitespace(c) \u0026\u0026 !eol) {\n+        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "b55fb21d78e30748ae19f1c8d16902439643799a": {
      "type": "Ybodychange",
      "commitMessage": "SANDBOX-206: add escape to strategy, turn off backslash-style escaping by default\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@609155 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "1/5/08, 7:37 AM",
      "commitName": "b55fb21d78e30748ae19f1c8d16902439643799a",
      "commitAuthor": "Yonik Seeley",
      "commitDateOld": "7/23/07, 3:25 PM",
      "commitNameOld": "14182380d59abc9c5a18504833c5c93d27fd0f8e",
      "commitAuthorOld": "Matthew Jason Benson",
      "daysBetweenCommits": 165.72,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 302,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n protected Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n-        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n+        if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "d7e94581d784067fccddd34e19ae46aea526f9fa": {
      "type": "Ymultichange(Yparameterchange,Ybodychange,Ydocchange)",
      "commitMessage": "This patch reduces the amount of intermediate garbage significantly.\nPR: SANDBOX-166\nContributed by: Ortwin Glück\nReviewed by: Henri Yandell\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@430322 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "8/10/06, 2:01 AM",
      "commitName": "d7e94581d784067fccddd34e19ae46aea526f9fa",
      "commitAuthor": "Ortwin Glueck",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "This patch reduces the amount of intermediate garbage significantly.\nPR: SANDBOX-166\nContributed by: Ortwin Glück\nReviewed by: Henri Yandell\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@430322 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "8/10/06, 2:01 AM",
          "commitName": "d7e94581d784067fccddd34e19ae46aea526f9fa",
          "commitAuthor": "Ortwin Glueck",
          "commitDateOld": "7/31/06, 11:50 PM",
          "commitNameOld": "ce34196827e6ac834b4c566e1e6fbe863c8e8d1c",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 9.09,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 293,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,49 @@\n-protected Token nextToken() throws IOException {\n-    Token tkn \u003d new Token();\n-    StringBuffer wsBuf \u003d new StringBuffer();\n+protected Token nextToken(Token tkn) throws IOException {\n+    wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n-            tkn \u003d nextToken();\n+            tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n-                tkn.content.append(wsBuf.toString());\n+                tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[tkn-Token]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "This patch reduces the amount of intermediate garbage significantly.\nPR: SANDBOX-166\nContributed by: Ortwin Glück\nReviewed by: Henri Yandell\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@430322 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "8/10/06, 2:01 AM",
          "commitName": "d7e94581d784067fccddd34e19ae46aea526f9fa",
          "commitAuthor": "Ortwin Glueck",
          "commitDateOld": "7/31/06, 11:50 PM",
          "commitNameOld": "ce34196827e6ac834b4c566e1e6fbe863c8e8d1c",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 9.09,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 293,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,49 @@\n-protected Token nextToken() throws IOException {\n-    Token tkn \u003d new Token();\n-    StringBuffer wsBuf \u003d new StringBuffer();\n+protected Token nextToken(Token tkn) throws IOException {\n+    wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n-            tkn \u003d nextToken();\n+            tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n-                tkn.content.append(wsBuf.toString());\n+                tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "This patch reduces the amount of intermediate garbage significantly.\nPR: SANDBOX-166\nContributed by: Ortwin Glück\nReviewed by: Henri Yandell\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@430322 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "8/10/06, 2:01 AM",
          "commitName": "d7e94581d784067fccddd34e19ae46aea526f9fa",
          "commitAuthor": "Ortwin Glueck",
          "commitDateOld": "7/31/06, 11:50 PM",
          "commitNameOld": "ce34196827e6ac834b4c566e1e6fbe863c8e8d1c",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 9.09,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 293,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,49 @@\n-protected Token nextToken() throws IOException {\n-    Token tkn \u003d new Token();\n-    StringBuffer wsBuf \u003d new StringBuffer();\n+protected Token nextToken(Token tkn) throws IOException {\n+    wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n-            tkn \u003d nextToken();\n+            tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n-                tkn.content.append(wsBuf.toString());\n+                tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
            "newValue": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n"
          }
        }
      ]
    },
    "f6f9fc1d480e85839c80d0890fa5ebed74971dc7": {
      "type": "Ybodychange",
      "commitMessage": "Pulled some static methods into a CSVUtils class, switched CSVPrinter to use a CSVStrategy though it doesn\u0027t use it fully yet, added a COMMENTS_DISABLED constant instead of relying on (char) 0. \n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@415323 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "6/19/06, 6:01 AM",
      "commitName": "f6f9fc1d480e85839c80d0890fa5ebed74971dc7",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "6/9/06, 12:57 AM",
      "commitNameOld": "45d972fe5b7807db5f5bb6fed182f107993da5a4",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 10.21,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 273,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,52 +1,52 @@\n protected Token nextToken() throws IOException {\n     Token tkn \u003d new Token();\n     StringBuffer wsBuf \u003d new StringBuffer();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n-        if (c \u003d\u003d strategy.getCommentStart()) {\n+        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken();\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf.toString());\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "eac54a225bc974157e914cf66cfa598171022018": {
      "type": "Ybodychange",
      "commitMessage": "Extracted the strategy concept into its own class\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@399987 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "5/4/06, 11:24 PM",
      "commitName": "eac54a225bc974157e914cf66cfa598171022018",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "3/5/06, 9:11 PM",
      "commitNameOld": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 60.05,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 320,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,52 +1,52 @@\n protected Token nextToken() throws IOException {\n     Token tkn \u003d new Token();\n     StringBuffer wsBuf \u003d new StringBuffer();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n-    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n+    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n-        if (c \u003d\u003d commentStart) {\n+        if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken();\n-        } else if (c \u003d\u003d delimiter) {\n+        } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n-        } else if (c \u003d\u003d encapsulator) {\n+        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!this.ignoreLeadingWhitespaces) {\n+            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf.toString());\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "f047581f9526aad1c9c9e624710a4e860f88ecaa": {
      "type": "Ymultichange(Ybodychange,Ydocchange)",
      "commitMessage": "Javadoc improvements, more unit tests, change of API to a chain style, some bugfixes\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@383468 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/5/06, 9:11 PM",
      "commitName": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
      "commitAuthor": "Henri Yandell",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "Javadoc improvements, more unit tests, change of API to a chain style, some bugfixes\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@383468 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/5/06, 9:11 PM",
          "commitName": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
          "commitAuthor": "Henri Yandell",
          "commitDateOld": "12/16/05, 9:46 PM",
          "commitNameOld": "0e1f0adb716515aba5e98e5690779f2fb73ad716",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 78.98,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d commentStart) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d delimiter) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d encapsulator) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!this.ignoreLeadingWhitespaces) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 335,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,52 @@\n protected Token nextToken() throws IOException {\n     Token tkn \u003d new Token();\n     StringBuffer wsBuf \u003d new StringBuffer();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n-    if (isEndOfFile(lastChar)) {\n+    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d commentStart) {\n             in.readLine();\n             tkn \u003d nextToken();\n         } else if (c \u003d\u003d delimiter) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d encapsulator) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.content.append(\"\");\n-            tkn.type \u003d TT_EORECORD;\n+            tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!this.ignoreLeadingWhitespaces) {\n                 tkn.content.append(wsBuf.toString());\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "Javadoc improvements, more unit tests, change of API to a chain style, some bugfixes\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@383468 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/5/06, 9:11 PM",
          "commitName": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
          "commitAuthor": "Henri Yandell",
          "commitDateOld": "12/16/05, 9:46 PM",
          "commitNameOld": "0e1f0adb716515aba5e98e5690779f2fb73ad716",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 78.98,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d commentStart) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d delimiter) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d encapsulator) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!this.ignoreLeadingWhitespaces) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 335,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,52 @@\n protected Token nextToken() throws IOException {\n     Token tkn \u003d new Token();\n     StringBuffer wsBuf \u003d new StringBuffer();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n-    if (isEndOfFile(lastChar)) {\n+    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d commentStart) {\n             in.readLine();\n             tkn \u003d nextToken();\n         } else if (c \u003d\u003d delimiter) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d encapsulator) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.content.append(\"\");\n-            tkn.type \u003d TT_EORECORD;\n+            tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!this.ignoreLeadingWhitespaces) {\n                 tkn.content.append(wsBuf.toString());\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "Returns the next token \n\na token coresponds to a term, a record change\nor and end-of-file indicator\n",
            "newValue": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n"
          }
        }
      ]
    },
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8": {
      "type": "Yfilerename",
      "commitMessage": "repackaging - directory change\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/trunks-sandbox/csv@357301 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/16/05, 9:42 PM",
      "commitName": "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "12/16/05, 9:41 PM",
      "commitNameOld": "e23e79e0ceacf38d3298e7f5207c4518ad2b5955",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar)) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d commentStart) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d delimiter) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d encapsulator) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else {\n            if (!this.ignoreLeadingWhitespaces) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 303,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token \n\na token coresponds to a term, a record change\nor and end-of-file indicator\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/java/ch/netcetera/wake/core/format/csv/CSVParser.java",
        "newPath": "src/java/org/apache/commons/csv/CSVParser.java"
      }
    },
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955": {
      "type": "Yintroduced",
      "commitMessage": "import of csv parser code, as donated by netcetera [code grant recorded]\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/trunks-sandbox/csv@357300 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/16/05, 9:41 PM",
      "commitName": "e23e79e0ceacf38d3298e7f5207c4518ad2b5955",
      "commitAuthor": "Henri Yandell",
      "diff": "@@ -0,0 +1,52 @@\n+protected Token nextToken() throws IOException {\n+    Token tkn \u003d new Token();\n+    StringBuffer wsBuf \u003d new StringBuffer();\n+    int lastChar \u003d in.readAgain();\n+    int c \u003d in.read();\n+    boolean eol \u003d isEndOfLine(c);\n+    c \u003d in.readAgain();\n+    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+        lastChar \u003d c;\n+        c \u003d in.read();\n+        eol \u003d isEndOfLine(c);\n+        c \u003d in.readAgain();\n+        if (isEndOfFile(c)) {\n+            tkn.type \u003d TT_EOF;\n+            return tkn;\n+        }\n+    }\n+    if (isEndOfFile(lastChar)) {\n+        tkn.type \u003d TT_EOF;\n+        return tkn;\n+    }\n+    while (!tkn.isReady) {\n+        while (isWhitespace(c) \u0026\u0026 !eol) {\n+            wsBuf.append((char) c);\n+            c \u003d in.read();\n+            eol \u003d isEndOfLine(c);\n+        }\n+        if (c \u003d\u003d commentStart) {\n+            in.readLine();\n+            tkn \u003d nextToken();\n+        } else if (c \u003d\u003d delimiter) {\n+            tkn.type \u003d TT_TOKEN;\n+            tkn.isReady \u003d true;\n+        } else if (eol) {\n+            tkn.content.append(\"\");\n+            tkn.type \u003d TT_EORECORD;\n+            tkn.isReady \u003d true;\n+        } else if (c \u003d\u003d encapsulator) {\n+            encapsulatedTokenLexer(tkn, c);\n+        } else if (isEndOfFile(c)) {\n+            tkn.content.append(\"\");\n+            tkn.type \u003d TT_EORECORD;\n+            tkn.isReady \u003d true;\n+        } else {\n+            if (!this.ignoreLeadingWhitespaces) {\n+                tkn.content.append(wsBuf.toString());\n+            }\n+            simpleTokenLexer(tkn, c);\n+        }\n+    }\n+    return tkn;\n+}\n\\ No newline at end of file\n",
      "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar)) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d commentStart) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d delimiter) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d encapsulator) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else {\n            if (!this.ignoreLeadingWhitespaces) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/ch/netcetera/wake/core/format/csv/CSVParser.java",
      "functionStartLine": 303,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token \n\na token coresponds to a term, a record change\nor and end-of-file indicator\n"
    }
  }
}