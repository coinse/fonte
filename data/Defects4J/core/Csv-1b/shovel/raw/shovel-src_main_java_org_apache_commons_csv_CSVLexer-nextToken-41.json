{
  "origin": "codeshovel",
  "repositoryName": "Csv-1b",
  "repositoryPath": "/tmp/Csv-1b//.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CSVLexer.java",
  "functionName": "nextToken",
  "functionId": "nextToken___tkn-Token",
  "sourceFilePath": "src/main/java/org/apache/commons/csv/CSVLexer.java",
  "functionAnnotation": "@Override",
  "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
  "functionStartLine": 41,
  "functionEndLine": 118,
  "numCommitsSeen": 74,
  "timeTaken": 2090,
  "changeHistory": [
    "38741a48c692ae2fc13cd2445e77ace6ecea1156",
    "dd26201ac47f60cd9e18800726cc28660b81bdaf",
    "9ebd0d94254b468765f6c558bb10ca018a418444",
    "1299ddfe3fec5000f68c203a7f61e9af02955296",
    "fa07dea5850eb11bb7b4dc06823802156b89baaf",
    "83e4a903b18c43a10caa551c50ece4e251a0f674",
    "65ab9db952daebf62fc092c90f7f74cbb25b8c0f",
    "38670dbe9232dc9b56d6464c42293e745974cf60",
    "3cb5801a985c0d6a9ca3dc794b4e89a292b4a9c6",
    "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a",
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512",
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79",
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8",
    "42476f4b08fe4b075aa36f688f0801857f3635d9",
    "cacb79dab96cc98209cf14bf1b1fc6eb6f357c88",
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8",
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
    "c6bdecabd82eebc9efce450aa4057b668984479e",
    "6b422c82bdb39da4ca3ee4e0f8d2fbe0e8a28d46",
    "4dfc8ed0747f5d7cd10ba35621add0fe4891a545",
    "02b21463e68e7b3d5f3d9980746d131a08a08eed",
    "b55fb21d78e30748ae19f1c8d16902439643799a",
    "d7e94581d784067fccddd34e19ae46aea526f9fa",
    "f6f9fc1d480e85839c80d0890fa5ebed74971dc7",
    "eac54a225bc974157e914cf66cfa598171022018",
    "f047581f9526aad1c9c9e624710a4e860f88ecaa",
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8",
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955"
  ],
  "changeHistoryShort": {
    "38741a48c692ae2fc13cd2445e77ace6ecea1156": "Ybodychange",
    "dd26201ac47f60cd9e18800726cc28660b81bdaf": "Ybodychange",
    "9ebd0d94254b468765f6c558bb10ca018a418444": "Ybodychange",
    "1299ddfe3fec5000f68c203a7f61e9af02955296": "Ybodychange",
    "fa07dea5850eb11bb7b4dc06823802156b89baaf": "Ybodychange",
    "83e4a903b18c43a10caa551c50ece4e251a0f674": "Ybodychange",
    "65ab9db952daebf62fc092c90f7f74cbb25b8c0f": "Yannotationchange",
    "38670dbe9232dc9b56d6464c42293e745974cf60": "Ymultichange(Ymovefromfile,Ydocchange)",
    "3cb5801a985c0d6a9ca3dc794b4e89a292b4a9c6": "Ybodychange",
    "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a": "Ybodychange",
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512": "Ydocchange",
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79": "Ybodychange",
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8": "Ybodychange",
    "42476f4b08fe4b075aa36f688f0801857f3635d9": "Ybodychange",
    "cacb79dab96cc98209cf14bf1b1fc6eb6f357c88": "Ymodifierchange",
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8": "Yfilerename",
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8": "Ymultichange(Ybodychange,Ydocchange)",
    "c6bdecabd82eebc9efce450aa4057b668984479e": "Ybodychange",
    "6b422c82bdb39da4ca3ee4e0f8d2fbe0e8a28d46": "Ybodychange",
    "4dfc8ed0747f5d7cd10ba35621add0fe4891a545": "Ybodychange",
    "02b21463e68e7b3d5f3d9980746d131a08a08eed": "Ybodychange",
    "b55fb21d78e30748ae19f1c8d16902439643799a": "Ybodychange",
    "d7e94581d784067fccddd34e19ae46aea526f9fa": "Ymultichange(Yparameterchange,Ybodychange,Ydocchange)",
    "f6f9fc1d480e85839c80d0890fa5ebed74971dc7": "Ybodychange",
    "eac54a225bc974157e914cf66cfa598171022018": "Ybodychange",
    "f047581f9526aad1c9c9e624710a4e860f88ecaa": "Ymultichange(Ybodychange,Ydocchange)",
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8": "Yfilerename",
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955": "Yintroduced"
  },
  "changeHistoryDetails": {
    "38741a48c692ae2fc13cd2445e77ace6ecea1156": {
      "type": "Ybodychange",
      "commitMessage": "CSV-54 Confusing semantic of the ignore leading/trailing spaces parameters\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1305494 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/26/12, 12:02 PM",
      "commitName": "38741a48c692ae2fc13cd2445e77ace6ecea1156",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 12:04 PM",
      "commitNameOld": "dd26201ac47f60cd9e18800726cc28660b81bdaf",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 4.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (surroundingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,47 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (tkn.type \u003d\u003d INVALID) {\n-        if (leadingSpacesIgnored) {\n+        if (surroundingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "dd26201ac47f60cd9e18800726cc28660b81bdaf": {
      "type": "Ybodychange",
      "commitMessage": "CSV-81 Token.Type.isReady could perhaps be removed\nNot removed, but only set on EOF if there is data to return\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303988 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 12:04 PM",
      "commitName": "dd26201ac47f60cd9e18800726cc28660b81bdaf",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 11:23 AM",
      "commitNameOld": "9ebd0d94254b468765f6c558bb10ca018a418444",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (tkn.type \u003d\u003d INVALID) {\n        if (leadingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,49 +1,47 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n-    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n+    while (tkn.type \u003d\u003d INVALID) {\n         if (leadingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n-            tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n-            tkn.isReady \u003d true;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "9ebd0d94254b468765f6c558bb10ca018a418444": {
      "type": "Ybodychange",
      "commitMessage": "CSV-80 - CSVLexer.nextToken does not need wsBuf\nremove useless wsBuf\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 11:23 AM",
      "commitName": "9ebd0d94254b468765f6c558bb10ca018a418444",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 11:15 AM",
      "commitNameOld": "1299ddfe3fec5000f68c203a7f61e9af02955296",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (leadingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 41,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,54 +1,49 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n-    wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (leadingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n-                wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!leadingSpacesIgnored) {\n-                tkn.content.append(wsBuf);\n-            }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "1299ddfe3fec5000f68c203a7f61e9af02955296": {
      "type": "Ybodychange",
      "commitMessage": "Oops - fix bug introduced in r1303933 \n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303948 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 11:15 AM",
      "commitName": "1299ddfe3fec5000f68c203a7f61e9af02955296",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 11:00 AM",
      "commitNameOld": "fa07dea5850eb11bb7b4dc06823802156b89baaf",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (leadingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!leadingSpacesIgnored) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 43,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,54 +1,54 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n-    if (isEndOfFile(lastChar) || (isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n+    if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (leadingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!leadingSpacesIgnored) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "fa07dea5850eb11bb7b4dc06823802156b89baaf": {
      "type": "Ybodychange",
      "commitMessage": "CSV-71 - Add convenience Methods to CSVLexer\nUse convenience fields from Lexer parent class; missed one method replacement earlier\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303933 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 11:00 AM",
      "commitName": "fa07dea5850eb11bb7b4dc06823802156b89baaf",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 10:27 AM",
      "commitNameOld": "83e4a903b18c43a10caa551c50ece4e251a0f674",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (emptyLinesIgnored) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (leadingSpacesIgnored) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!leadingSpacesIgnored) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 43,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,54 +1,54 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    if (format.isEmptyLinesIgnored()) {\n+    if (emptyLinesIgnored) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n-    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n+    if (isEndOfFile(lastChar) || (isDelimiter(lastChar) \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n-        if (format.isLeadingSpacesIgnored()) {\n+        if (leadingSpacesIgnored) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!format.isLeadingSpacesIgnored()) {\n+            if (!leadingSpacesIgnored) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "83e4a903b18c43a10caa551c50ece4e251a0f674": {
      "type": "Ybodychange",
      "commitMessage": "CSV-71 - Add convenience Methods to CSVLexer\nUse convenience methods from Lexer parent class\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303904 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 10:27 AM",
      "commitName": "83e4a903b18c43a10caa551c50ece4e251a0f674",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 9:32 AM",
      "commitNameOld": "fdfe50842f8ac0a842ba0a220bbd2613178e7a75",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (isCommentStart(c)) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (isDelimiter(c)) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (isEncapsulator(c)) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 43,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,54 +1,54 @@\n @Override\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (format.isEmptyLinesIgnored()) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (format.isLeadingSpacesIgnored()) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n-        if (c \u003d\u003d format.getCommentStart()) {\n+        if (isCommentStart(c)) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n-        } else if (c \u003d\u003d format.getDelimiter()) {\n+        } else if (isDelimiter(c)) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n-        } else if (c \u003d\u003d format.getEncapsulator()) {\n+        } else if (isEncapsulator(c)) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "65ab9db952daebf62fc092c90f7f74cbb25b8c0f": {
      "type": "Yannotationchange",
      "commitMessage": "Make it easy to provide an alternative lexer if required\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303620 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/21/12, 4:46 PM",
      "commitName": "65ab9db952daebf62fc092c90f7f74cbb25b8c0f",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/21/12, 12:04 PM",
      "commitNameOld": "3ea8118ff3793cc32fcf6d2c93d4f5eda73b374e",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\nToken nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 42,
      "functionName": "nextToken",
      "functionAnnotation": "@Override",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
      "diff": "@@ -1,53 +1,54 @@\n+@Override\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (format.isEmptyLinesIgnored()) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (format.isLeadingSpacesIgnored()) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d format.getDelimiter()) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {
        "oldValue": "",
        "newValue": "@Override"
      }
    },
    "38670dbe9232dc9b56d6464c42293e745974cf60": {
      "type": "Ymultichange(Ymovefromfile,Ydocchange)",
      "commitMessage": "Moved the lexer in a separate file\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300850 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/15/12, 1:52 AM",
      "commitName": "38670dbe9232dc9b56d6464c42293e745974cf60",
      "commitAuthor": "Emmanuel Bourg",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "Moved the lexer in a separate file\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300850 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/15/12, 1:52 AM",
          "commitName": "38670dbe9232dc9b56d6464c42293e745974cf60",
          "commitAuthor": "Emmanuel Bourg",
          "commitDateOld": "3/14/12, 4:12 PM",
          "commitNameOld": "35b954ed36494f64b27b495ded6e66b409d0ed79",
          "commitAuthorOld": "Emmanuel Bourg",
          "daysBetweenCommits": 0.4,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 92,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
          "diff": "",
          "extendedDetails": {
            "oldPath": "src/main/java/org/apache/commons/csv/CSVParser.java",
            "newPath": "src/main/java/org/apache/commons/csv/CSVLexer.java",
            "oldMethodName": "nextToken",
            "newMethodName": "nextToken"
          }
        },
        {
          "type": "Ydocchange",
          "commitMessage": "Moved the lexer in a separate file\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300850 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/15/12, 1:52 AM",
          "commitName": "38670dbe9232dc9b56d6464c42293e745974cf60",
          "commitAuthor": "Emmanuel Bourg",
          "commitDateOld": "3/14/12, 4:12 PM",
          "commitNameOld": "35b954ed36494f64b27b495ded6e66b409d0ed79",
          "commitAuthorOld": "Emmanuel Bourg",
          "daysBetweenCommits": 0.4,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 92,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n",
            "newValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws java.io.IOException on stream access error\n"
          }
        }
      ]
    },
    "3cb5801a985c0d6a9ca3dc794b4e89a292b4a9c6": {
      "type": "Ybodychange",
      "commitMessage": "Replaced CharBuffer with StringBuilder (CSV-59)\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300659 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/14/12, 10:42 AM",
      "commitName": "3cb5801a985c0d6a9ca3dc794b4e89a292b4a9c6",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "3/14/12, 6:03 AM",
      "commitNameOld": "18d706032ac850979833165b66439c2c764c3b33",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.19,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.setLength(0);\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 301,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,53 +1,53 @@\n Token nextToken(Token tkn) throws IOException {\n-    wsBuf.clear();\n+    wsBuf.setLength(0);\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     if (format.isEmptyLinesIgnored()) {\n         while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n             lastChar \u003d c;\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n             c \u003d in.readAgain();\n             if (isEndOfFile(c)) {\n                 tkn.type \u003d EOF;\n                 return tkn;\n             }\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         if (format.isLeadingSpacesIgnored()) {\n             while (isWhitespace(c) \u0026\u0026 !eol) {\n                 wsBuf.append((char) c);\n                 c \u003d in.read();\n                 eol \u003d isEndOfLine(c);\n             }\n         }\n         if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d format.getDelimiter()) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a": {
      "type": "Ybodychange",
      "commitMessage": "Minor performance improvement (~2%)\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1299486 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/11/12, 4:23 PM",
      "commitName": "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "3/8/12, 1:59 AM",
      "commitNameOld": "2ec4c994c0458ef893af9bd518849bec21b2dec4",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 3.56,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    if (format.isEmptyLinesIgnored()) {\n        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n            lastChar \u003d c;\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n            c \u003d in.readAgain();\n            if (isEndOfFile(c)) {\n                tkn.type \u003d EOF;\n                return tkn;\n            }\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        if (format.isLeadingSpacesIgnored()) {\n            while (isWhitespace(c) \u0026\u0026 !eol) {\n                wsBuf.append((char) c);\n                c \u003d in.read();\n                eol \u003d isEndOfLine(c);\n            }\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 303,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,53 @@\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n-        lastChar \u003d c;\n-        c \u003d in.read();\n-        eol \u003d isEndOfLine(c);\n-        c \u003d in.readAgain();\n-        if (isEndOfFile(c)) {\n-            tkn.type \u003d EOF;\n-            return tkn;\n+    if (format.isEmptyLinesIgnored()) {\n+        while (eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+            lastChar \u003d c;\n+            c \u003d in.read();\n+            eol \u003d isEndOfLine(c);\n+            c \u003d in.readAgain();\n+            if (isEndOfFile(c)) {\n+                tkn.type \u003d EOF;\n+                return tkn;\n+            }\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n-        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n-            wsBuf.append((char) c);\n-            c \u003d in.read();\n-            eol \u003d isEndOfLine(c);\n+        if (format.isLeadingSpacesIgnored()) {\n+            while (isWhitespace(c) \u0026\u0026 !eol) {\n+                wsBuf.append((char) c);\n+                c \u003d in.read();\n+                eol \u003d isEndOfLine(c);\n+            }\n         }\n         if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d format.getDelimiter()) {\n             tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512": {
      "type": "Ydocchange",
      "commitMessage": "Updated the Javadoc\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1297043 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/5/12, 5:08 AM",
      "commitName": "7bd9d1d970b04a8439fee0bd5224159f57cb2512",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 3:04 PM",
      "commitNameOld": "045dbbbe4ab84618cee8ba27d00b9283ce0a2715",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 116.59,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 287,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "",
      "extendedDetails": {
        "oldValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
        "newValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an end-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the Token.\n@return the next token found\n@throws IOException on stream access error\n"
      }
    },
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79": {
      "type": "Ybodychange",
      "commitMessage": "Turned the token types into an Enum\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199872 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 9:11 AM",
      "commitName": "16bfec07ffd785e5abbabdc4145eeac5cccc2c79",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 8:58 AM",
      "commitNameOld": "cbcfb72912f41d1fac3f6d26ca27406cca94da9e",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 245,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n-            tkn.type \u003d TT_EOF;\n+            tkn.type \u003d EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n-        tkn.type \u003d TT_EOF;\n+        tkn.type \u003d EOF;\n         return tkn;\n     }\n-    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n+    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d EOF) {\n         while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d format.getDelimiter()) {\n-            tkn.type \u003d TT_TOKEN;\n+            tkn.type \u003d TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n-            tkn.type \u003d TT_EORECORD;\n+            tkn.type \u003d EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n-            tkn.type \u003d TT_EOF;\n+            tkn.type \u003d EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8": {
      "type": "Ybodychange",
      "commitMessage": "Renamed CSVStrategy to CSVFormat\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199842 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 8:54 AM",
      "commitName": "cb99634ab3d6143dffc90938fc68e15c7f9d25b8",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 8:21 AM",
      "commitNameOld": "42476f4b08fe4b075aa36f688f0801857f3635d9",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d format.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d format.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!format.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 246,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (strategy.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+    while (format.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n-    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n+    if (isEndOfFile(lastChar) || (lastChar !\u003d format.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n-        while (strategy.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n+        while (format.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n-        if (c \u003d\u003d strategy.getCommentStart()) {\n+        if (c \u003d\u003d format.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n-        } else if (c \u003d\u003d strategy.getDelimiter()) {\n+        } else if (c \u003d\u003d format.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n-        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n+        } else if (c \u003d\u003d format.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!strategy.isLeadingSpacesIgnored()) {\n+            if (!format.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "42476f4b08fe4b075aa36f688f0801857f3635d9": {
      "type": "Ybodychange",
      "commitMessage": "CSVStrategy is now immutable (SANDBOX-279)\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199827 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 8:21 AM",
      "commitName": "42476f4b08fe4b075aa36f688f0801857f3635d9",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 6:54 AM",
      "commitNameOld": "fc4ccb426eb3934ee1656db9b18c7d797ac6bd1d",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.isLeadingSpacesIgnored()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 246,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+    while (strategy.isEmptyLinesIgnored() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n-        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n+        while (strategy.isLeadingSpacesIgnored() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!strategy.getIgnoreLeadingWhitespaces()) {\n+            if (!strategy.isLeadingSpacesIgnored()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "cacb79dab96cc98209cf14bf1b1fc6eb6f357c88": {
      "type": "Ymodifierchange",
      "commitMessage": "Changed the visibility of the Token types and the protected methods to package private\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199769 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 6:26 AM",
      "commitName": "cacb79dab96cc98209cf14bf1b1fc6eb6f357c88",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 3:17 AM",
      "commitNameOld": "165a5dcaf41b490cd80e90c65738453140c0ef61",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.13,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 317,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n-protected Token nextToken(Token tkn) throws IOException {\n+Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n         while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {
        "oldValue": "[protected]",
        "newValue": "[]"
      }
    },
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8": {
      "type": "Yfilerename",
      "commitMessage": "Moved the directories to match the Maven layout\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199691 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 2:38 AM",
      "commitName": "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "7/20/11, 9:14 AM",
      "commitNameOld": "76cab04936e8b539d983510079419fabeeaecea0",
      "commitAuthorOld": "Stephen Colebourne",
      "daysBetweenCommits": 111.77,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 325,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/commons/csv/CSVParser.java",
        "newPath": "src/main/java/org/apache/commons/csv/CSVParser.java"
      }
    },
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8": {
      "type": "Ymultichange(Ybodychange,Ydocchange)",
      "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2/1/11, 12:46 AM",
      "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
      "commitAuthor": "Jacopo Cappellato",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2/1/11, 12:46 AM",
          "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
          "commitAuthor": "Jacopo Cappellato",
          "commitDateOld": "1/31/11, 2:47 AM",
          "commitNameOld": "c6bdecabd82eebc9efce450aa4057b668984479e",
          "commitAuthorOld": "Jacopo Cappellato",
          "daysBetweenCommits": 0.92,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 325,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2/1/11, 12:46 AM",
          "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
          "commitAuthor": "Jacopo Cappellato",
          "commitDateOld": "1/31/11, 2:47 AM",
          "commitNameOld": "c6bdecabd82eebc9efce450aa4057b668984479e",
          "commitAuthorOld": "Jacopo Cappellato",
          "daysBetweenCommits": 0.92,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 325,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
            "newValue": "Returns the next token.\n\u003cp/\u003e\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\n           Token.\n@return the next token found\n@throws IOException on stream access error\n"
          }
        }
      ]
    },
    "c6bdecabd82eebc9efce450aa4057b668984479e": {
      "type": "Ybodychange",
      "commitMessage": "Fixes for typos in comments and javadoc.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065549 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "1/31/11, 2:47 AM",
      "commitName": "c6bdecabd82eebc9efce450aa4057b668984479e",
      "commitAuthor": "Jacopo Cappellato",
      "commitDateOld": "1/31/11, 12:50 AM",
      "commitNameOld": "58149e21ad7452ed45ce77b8095c0c2c7414d55b",
      "commitAuthorOld": "Jacopo Cappellato",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 305,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "",
      "extendedDetails": {}
    },
    "6b422c82bdb39da4ca3ee4e0f8d2fbe0e8a28d46": {
      "type": "Ybodychange",
      "commitMessage": "Fix for issue reported in SANDBOX-218: CSV reader doesn\u0027t handle older Mac line endings (\\r) that are also used by recent versions of Excel for Mac.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065496 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "1/30/11, 11:10 PM",
      "commitName": "6b422c82bdb39da4ca3ee4e0f8d2fbe0e8a28d46",
      "commitAuthor": "Jacopo Cappellato",
      "commitDateOld": "7/14/10, 6:32 PM",
      "commitNameOld": "4dfc8ed0747f5d7cd10ba35621add0fe4891a545",
      "commitAuthorOld": "Yonik Seeley",
      "daysBetweenCommits": 200.23,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 306,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n protected Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d \u0027\\r\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n         while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "4dfc8ed0747f5d7cd10ba35621add0fe4891a545": {
      "type": "Ybodychange",
      "commitMessage": "SANDBOX-313: Endless loops in CSV parser when last line is comment\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@964273 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "7/14/10, 6:32 PM",
      "commitName": "4dfc8ed0747f5d7cd10ba35621add0fe4891a545",
      "commitAuthor": "Yonik Seeley",
      "commitDateOld": "6/16/10, 9:12 AM",
      "commitNameOld": "02b21463e68e7b3d5f3d9980746d131a08a08eed",
      "commitAuthorOld": "Yonik Seeley",
      "daysBetweenCommits": 28.39,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 306,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n protected Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n-    while (!tkn.isReady) {\n+    while (!tkn.isReady \u0026\u0026 tkn.type !\u003d TT_EOF) {\n         while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "02b21463e68e7b3d5f3d9980746d131a08a08eed": {
      "type": "Ybodychange",
      "commitMessage": "SANDBOX-322: CSVPrinter overhaul\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@955284 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "6/16/10, 9:12 AM",
      "commitName": "02b21463e68e7b3d5f3d9980746d131a08a08eed",
      "commitAuthor": "Yonik Seeley",
      "commitDateOld": "2/26/08, 12:47 AM",
      "commitNameOld": "1b0ccbe4c7d5a183913063429198e8c51bb768f9",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 841.31,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 306,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n protected Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n-        while (isWhitespace(c) \u0026\u0026 !eol) {\n+        while (strategy.getIgnoreLeadingWhitespaces() \u0026\u0026 isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "b55fb21d78e30748ae19f1c8d16902439643799a": {
      "type": "Ybodychange",
      "commitMessage": "SANDBOX-206: add escape to strategy, turn off backslash-style escaping by default\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@609155 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "1/5/08, 7:37 AM",
      "commitName": "b55fb21d78e30748ae19f1c8d16902439643799a",
      "commitAuthor": "Yonik Seeley",
      "commitDateOld": "7/23/07, 3:25 PM",
      "commitNameOld": "14182380d59abc9c5a18504833c5c93d27fd0f8e",
      "commitAuthorOld": "Matthew Jason Benson",
      "daysBetweenCommits": 165.72,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 302,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,49 +1,49 @@\n protected Token nextToken(Token tkn) throws IOException {\n     wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n-        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n+        if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "d7e94581d784067fccddd34e19ae46aea526f9fa": {
      "type": "Ymultichange(Yparameterchange,Ybodychange,Ydocchange)",
      "commitMessage": "This patch reduces the amount of intermediate garbage significantly.\nPR: SANDBOX-166\nContributed by: Ortwin Glück\nReviewed by: Henri Yandell\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@430322 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "8/10/06, 2:01 AM",
      "commitName": "d7e94581d784067fccddd34e19ae46aea526f9fa",
      "commitAuthor": "Ortwin Glueck",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "This patch reduces the amount of intermediate garbage significantly.\nPR: SANDBOX-166\nContributed by: Ortwin Glück\nReviewed by: Henri Yandell\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@430322 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "8/10/06, 2:01 AM",
          "commitName": "d7e94581d784067fccddd34e19ae46aea526f9fa",
          "commitAuthor": "Ortwin Glueck",
          "commitDateOld": "7/31/06, 11:50 PM",
          "commitNameOld": "ce34196827e6ac834b4c566e1e6fbe863c8e8d1c",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 9.09,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 293,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,49 @@\n-protected Token nextToken() throws IOException {\n-    Token tkn \u003d new Token();\n-    StringBuffer wsBuf \u003d new StringBuffer();\n+protected Token nextToken(Token tkn) throws IOException {\n+    wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n-            tkn \u003d nextToken();\n+            tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n-                tkn.content.append(wsBuf.toString());\n+                tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[tkn-Token]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "This patch reduces the amount of intermediate garbage significantly.\nPR: SANDBOX-166\nContributed by: Ortwin Glück\nReviewed by: Henri Yandell\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@430322 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "8/10/06, 2:01 AM",
          "commitName": "d7e94581d784067fccddd34e19ae46aea526f9fa",
          "commitAuthor": "Ortwin Glueck",
          "commitDateOld": "7/31/06, 11:50 PM",
          "commitNameOld": "ce34196827e6ac834b4c566e1e6fbe863c8e8d1c",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 9.09,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 293,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,49 @@\n-protected Token nextToken() throws IOException {\n-    Token tkn \u003d new Token();\n-    StringBuffer wsBuf \u003d new StringBuffer();\n+protected Token nextToken(Token tkn) throws IOException {\n+    wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n-            tkn \u003d nextToken();\n+            tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n-                tkn.content.append(wsBuf.toString());\n+                tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "This patch reduces the amount of intermediate garbage significantly.\nPR: SANDBOX-166\nContributed by: Ortwin Glück\nReviewed by: Henri Yandell\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@430322 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "8/10/06, 2:01 AM",
          "commitName": "d7e94581d784067fccddd34e19ae46aea526f9fa",
          "commitAuthor": "Ortwin Glueck",
          "commitDateOld": "7/31/06, 11:50 PM",
          "commitNameOld": "ce34196827e6ac834b4c566e1e6fbe863c8e8d1c",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 9.09,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken(Token tkn) throws IOException {\n    wsBuf.clear();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken(tkn.reset());\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf);\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 293,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,49 @@\n-protected Token nextToken() throws IOException {\n-    Token tkn \u003d new Token();\n-    StringBuffer wsBuf \u003d new StringBuffer();\n+protected Token nextToken(Token tkn) throws IOException {\n+    wsBuf.clear();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n-            tkn \u003d nextToken();\n+            tkn \u003d nextToken(tkn.reset());\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n-            tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n-                tkn.content.append(wsBuf.toString());\n+                tkn.content.append(wsBuf);\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
            "newValue": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@param tkn an existing Token object to reuse. The caller is responsible to initialize the\nToken.\n@return the next token found\n@throws IOException on stream access error\n"
          }
        }
      ]
    },
    "f6f9fc1d480e85839c80d0890fa5ebed74971dc7": {
      "type": "Ybodychange",
      "commitMessage": "Pulled some static methods into a CSVUtils class, switched CSVPrinter to use a CSVStrategy though it doesn\u0027t use it fully yet, added a COMMENTS_DISABLED constant instead of relying on (char) 0. \n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@415323 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "6/19/06, 6:01 AM",
      "commitName": "f6f9fc1d480e85839c80d0890fa5ebed74971dc7",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "6/9/06, 12:57 AM",
      "commitNameOld": "45d972fe5b7807db5f5bb6fed182f107993da5a4",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 10.21,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 273,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,52 +1,52 @@\n protected Token nextToken() throws IOException {\n     Token tkn \u003d new Token();\n     StringBuffer wsBuf \u003d new StringBuffer();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n     if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n-        if (c \u003d\u003d strategy.getCommentStart()) {\n+        if (!strategy.isCommentingDisabled() \u0026\u0026 c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken();\n         } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf.toString());\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "eac54a225bc974157e914cf66cfa598171022018": {
      "type": "Ybodychange",
      "commitMessage": "Extracted the strategy concept into its own class\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@399987 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "5/4/06, 11:24 PM",
      "commitName": "eac54a225bc974157e914cf66cfa598171022018",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "3/5/06, 9:11 PM",
      "commitNameOld": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 60.05,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d strategy.getCommentStart()) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d strategy.getDelimiter()) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 320,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
      "diff": "@@ -1,52 +1,52 @@\n protected Token nextToken() throws IOException {\n     Token tkn \u003d new Token();\n     StringBuffer wsBuf \u003d new StringBuffer();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n-    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+    while (strategy.getIgnoreEmptyLines() \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n-    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n+    if (isEndOfFile(lastChar) || (lastChar !\u003d strategy.getDelimiter() \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n-        if (c \u003d\u003d commentStart) {\n+        if (c \u003d\u003d strategy.getCommentStart()) {\n             in.readLine();\n             tkn \u003d nextToken();\n-        } else if (c \u003d\u003d delimiter) {\n+        } else if (c \u003d\u003d strategy.getDelimiter()) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n-        } else if (c \u003d\u003d encapsulator) {\n+        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n-            if (!this.ignoreLeadingWhitespaces) {\n+            if (!strategy.getIgnoreLeadingWhitespaces()) {\n                 tkn.content.append(wsBuf.toString());\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "f047581f9526aad1c9c9e624710a4e860f88ecaa": {
      "type": "Ymultichange(Ybodychange,Ydocchange)",
      "commitMessage": "Javadoc improvements, more unit tests, change of API to a chain style, some bugfixes\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@383468 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/5/06, 9:11 PM",
      "commitName": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
      "commitAuthor": "Henri Yandell",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "Javadoc improvements, more unit tests, change of API to a chain style, some bugfixes\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@383468 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/5/06, 9:11 PM",
          "commitName": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
          "commitAuthor": "Henri Yandell",
          "commitDateOld": "12/16/05, 9:46 PM",
          "commitNameOld": "0e1f0adb716515aba5e98e5690779f2fb73ad716",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 78.98,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d commentStart) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d delimiter) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d encapsulator) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!this.ignoreLeadingWhitespaces) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 335,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,52 @@\n protected Token nextToken() throws IOException {\n     Token tkn \u003d new Token();\n     StringBuffer wsBuf \u003d new StringBuffer();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n-    if (isEndOfFile(lastChar)) {\n+    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d commentStart) {\n             in.readLine();\n             tkn \u003d nextToken();\n         } else if (c \u003d\u003d delimiter) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d encapsulator) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.content.append(\"\");\n-            tkn.type \u003d TT_EORECORD;\n+            tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!this.ignoreLeadingWhitespaces) {\n                 tkn.content.append(wsBuf.toString());\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "Javadoc improvements, more unit tests, change of API to a chain style, some bugfixes\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@383468 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/5/06, 9:11 PM",
          "commitName": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
          "commitAuthor": "Henri Yandell",
          "commitDateOld": "12/16/05, 9:46 PM",
          "commitNameOld": "0e1f0adb716515aba5e98e5690779f2fb73ad716",
          "commitAuthorOld": "Henri Yandell",
          "daysBetweenCommits": 78.98,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d commentStart) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d delimiter) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d encapsulator) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EOF;\n            tkn.isReady \u003d true;\n        } else {\n            if (!this.ignoreLeadingWhitespaces) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 335,
          "functionName": "nextToken",
          "functionAnnotation": "",
          "functionDoc": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n",
          "diff": "@@ -1,52 +1,52 @@\n protected Token nextToken() throws IOException {\n     Token tkn \u003d new Token();\n     StringBuffer wsBuf \u003d new StringBuffer();\n     int lastChar \u003d in.readAgain();\n     int c \u003d in.read();\n     boolean eol \u003d isEndOfLine(c);\n     c \u003d in.readAgain();\n     while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n         lastChar \u003d c;\n         c \u003d in.read();\n         eol \u003d isEndOfLine(c);\n         c \u003d in.readAgain();\n         if (isEndOfFile(c)) {\n             tkn.type \u003d TT_EOF;\n             return tkn;\n         }\n     }\n-    if (isEndOfFile(lastChar)) {\n+    if (isEndOfFile(lastChar) || (lastChar !\u003d delimiter \u0026\u0026 isEndOfFile(c))) {\n         tkn.type \u003d TT_EOF;\n         return tkn;\n     }\n     while (!tkn.isReady) {\n         while (isWhitespace(c) \u0026\u0026 !eol) {\n             wsBuf.append((char) c);\n             c \u003d in.read();\n             eol \u003d isEndOfLine(c);\n         }\n         if (c \u003d\u003d commentStart) {\n             in.readLine();\n             tkn \u003d nextToken();\n         } else if (c \u003d\u003d delimiter) {\n             tkn.type \u003d TT_TOKEN;\n             tkn.isReady \u003d true;\n         } else if (eol) {\n             tkn.content.append(\"\");\n             tkn.type \u003d TT_EORECORD;\n             tkn.isReady \u003d true;\n         } else if (c \u003d\u003d encapsulator) {\n             encapsulatedTokenLexer(tkn, c);\n         } else if (isEndOfFile(c)) {\n             tkn.content.append(\"\");\n-            tkn.type \u003d TT_EORECORD;\n+            tkn.type \u003d TT_EOF;\n             tkn.isReady \u003d true;\n         } else {\n             if (!this.ignoreLeadingWhitespaces) {\n                 tkn.content.append(wsBuf.toString());\n             }\n             simpleTokenLexer(tkn, c);\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "Returns the next token \n\na token coresponds to a term, a record change\nor and end-of-file indicator\n",
            "newValue": "Returns the next token.\n\nA token corresponds to a term, a record change or an\nend-of-file indicator.\n\n@return the next token found\n@throws IOException on stream access error\n"
          }
        }
      ]
    },
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8": {
      "type": "Yfilerename",
      "commitMessage": "repackaging - directory change\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/trunks-sandbox/csv@357301 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/16/05, 9:42 PM",
      "commitName": "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "12/16/05, 9:41 PM",
      "commitNameOld": "e23e79e0ceacf38d3298e7f5207c4518ad2b5955",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar)) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d commentStart) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d delimiter) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d encapsulator) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else {\n            if (!this.ignoreLeadingWhitespaces) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 303,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token \n\na token coresponds to a term, a record change\nor and end-of-file indicator\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/java/ch/netcetera/wake/core/format/csv/CSVParser.java",
        "newPath": "src/java/org/apache/commons/csv/CSVParser.java"
      }
    },
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955": {
      "type": "Yintroduced",
      "commitMessage": "import of csv parser code, as donated by netcetera [code grant recorded]\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/trunks-sandbox/csv@357300 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/16/05, 9:41 PM",
      "commitName": "e23e79e0ceacf38d3298e7f5207c4518ad2b5955",
      "commitAuthor": "Henri Yandell",
      "diff": "@@ -0,0 +1,52 @@\n+protected Token nextToken() throws IOException {\n+    Token tkn \u003d new Token();\n+    StringBuffer wsBuf \u003d new StringBuffer();\n+    int lastChar \u003d in.readAgain();\n+    int c \u003d in.read();\n+    boolean eol \u003d isEndOfLine(c);\n+    c \u003d in.readAgain();\n+    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n+        lastChar \u003d c;\n+        c \u003d in.read();\n+        eol \u003d isEndOfLine(c);\n+        c \u003d in.readAgain();\n+        if (isEndOfFile(c)) {\n+            tkn.type \u003d TT_EOF;\n+            return tkn;\n+        }\n+    }\n+    if (isEndOfFile(lastChar)) {\n+        tkn.type \u003d TT_EOF;\n+        return tkn;\n+    }\n+    while (!tkn.isReady) {\n+        while (isWhitespace(c) \u0026\u0026 !eol) {\n+            wsBuf.append((char) c);\n+            c \u003d in.read();\n+            eol \u003d isEndOfLine(c);\n+        }\n+        if (c \u003d\u003d commentStart) {\n+            in.readLine();\n+            tkn \u003d nextToken();\n+        } else if (c \u003d\u003d delimiter) {\n+            tkn.type \u003d TT_TOKEN;\n+            tkn.isReady \u003d true;\n+        } else if (eol) {\n+            tkn.content.append(\"\");\n+            tkn.type \u003d TT_EORECORD;\n+            tkn.isReady \u003d true;\n+        } else if (c \u003d\u003d encapsulator) {\n+            encapsulatedTokenLexer(tkn, c);\n+        } else if (isEndOfFile(c)) {\n+            tkn.content.append(\"\");\n+            tkn.type \u003d TT_EORECORD;\n+            tkn.isReady \u003d true;\n+        } else {\n+            if (!this.ignoreLeadingWhitespaces) {\n+                tkn.content.append(wsBuf.toString());\n+            }\n+            simpleTokenLexer(tkn, c);\n+        }\n+    }\n+    return tkn;\n+}\n\\ No newline at end of file\n",
      "actualSource": "protected Token nextToken() throws IOException {\n    Token tkn \u003d new Token();\n    StringBuffer wsBuf \u003d new StringBuffer();\n    int lastChar \u003d in.readAgain();\n    int c \u003d in.read();\n    boolean eol \u003d isEndOfLine(c);\n    c \u003d in.readAgain();\n    while (ignoreEmptyLines \u0026\u0026 eol \u0026\u0026 (lastChar \u003d\u003d \u0027\\n\u0027 || lastChar \u003d\u003d ExtendedBufferedReader.UNDEFINED) \u0026\u0026 !isEndOfFile(lastChar)) {\n        lastChar \u003d c;\n        c \u003d in.read();\n        eol \u003d isEndOfLine(c);\n        c \u003d in.readAgain();\n        if (isEndOfFile(c)) {\n            tkn.type \u003d TT_EOF;\n            return tkn;\n        }\n    }\n    if (isEndOfFile(lastChar)) {\n        tkn.type \u003d TT_EOF;\n        return tkn;\n    }\n    while (!tkn.isReady) {\n        while (isWhitespace(c) \u0026\u0026 !eol) {\n            wsBuf.append((char) c);\n            c \u003d in.read();\n            eol \u003d isEndOfLine(c);\n        }\n        if (c \u003d\u003d commentStart) {\n            in.readLine();\n            tkn \u003d nextToken();\n        } else if (c \u003d\u003d delimiter) {\n            tkn.type \u003d TT_TOKEN;\n            tkn.isReady \u003d true;\n        } else if (eol) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else if (c \u003d\u003d encapsulator) {\n            encapsulatedTokenLexer(tkn, c);\n        } else if (isEndOfFile(c)) {\n            tkn.content.append(\"\");\n            tkn.type \u003d TT_EORECORD;\n            tkn.isReady \u003d true;\n        } else {\n            if (!this.ignoreLeadingWhitespaces) {\n                tkn.content.append(wsBuf.toString());\n            }\n            simpleTokenLexer(tkn, c);\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/ch/netcetera/wake/core/format/csv/CSVParser.java",
      "functionStartLine": 303,
      "functionName": "nextToken",
      "functionAnnotation": "",
      "functionDoc": "Returns the next token \n\na token coresponds to a term, a record change\nor and end-of-file indicator\n"
    }
  }
}