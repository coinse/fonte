{
  "origin": "codeshovel",
  "repositoryName": "Csv-3b",
  "repositoryPath": "/tmp/Csv-3b//.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CSVLexer.java",
  "functionName": "parseEncapsulatedToken",
  "functionId": "parseEncapsulatedToken___tkn-Token(modifiers-final)",
  "sourceFilePath": "src/main/java/org/apache/commons/csv/CSVLexer.java",
  "functionAnnotation": "",
  "functionDoc": "Parses an encapsulated token.\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
  "functionStartLine": 198,
  "functionEndLine": 242,
  "numCommitsSeen": 155,
  "timeTaken": 2584,
  "changeHistory": [
    "c4014b6b38c9f661a12557db7ee464e158f386f7",
    "350d34d5cfe45c4e7036422e0e2e0f6039eb6f98",
    "2a8ce4a11cf42683d7abf06c591b4c0f1e8928e1",
    "3b938ba40d050c319be41a415daf5832e6097d72",
    "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
    "5e7945e1ceeb6cce60e3da5caf4d57f7bf531689",
    "93fc1f9363d911cb0a974f993d9266a89a63c41e",
    "bf06bed9b8905ccf5409179263707074167ccfc4",
    "d89a0f482f6fa06661e4fd15a31b54222224a6df",
    "911433707587a42727da375e1ec0e53dc909ac8d",
    "dd26201ac47f60cd9e18800726cc28660b81bdaf",
    "83e4a903b18c43a10caa551c50ece4e251a0f674",
    "38670dbe9232dc9b56d6464c42293e745974cf60",
    "9141cb39e6659340574a96b41d7f463ebdc2610e",
    "00d0def6953d414af6ecf36a9584c5453ee39c29",
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512",
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79",
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8",
    "42476f4b08fe4b075aa36f688f0801857f3635d9",
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8",
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
    "b55fb21d78e30748ae19f1c8d16902439643799a",
    "14182380d59abc9c5a18504833c5c93d27fd0f8e",
    "eac54a225bc974157e914cf66cfa598171022018",
    "f047581f9526aad1c9c9e624710a4e860f88ecaa",
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8",
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955"
  ],
  "changeHistoryShort": {
    "c4014b6b38c9f661a12557db7ee464e158f386f7": "Ymultichange(Yrename,Ydocchange)",
    "350d34d5cfe45c4e7036422e0e2e0f6039eb6f98": "Ybodychange",
    "2a8ce4a11cf42683d7abf06c591b4c0f1e8928e1": "Ybodychange",
    "3b938ba40d050c319be41a415daf5832e6097d72": "Ybodychange",
    "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc": "Ymultichange(Ybodychange,Yparametermetachange)",
    "5e7945e1ceeb6cce60e3da5caf4d57f7bf531689": "Yformatchange",
    "93fc1f9363d911cb0a974f993d9266a89a63c41e": "Ymultichange(Ydocchange,Yformatchange)",
    "bf06bed9b8905ccf5409179263707074167ccfc4": "Ymultichange(Ydocchange,Yformatchange)",
    "d89a0f482f6fa06661e4fd15a31b54222224a6df": "Ymultichange(Ybodychange,Ydocchange)",
    "911433707587a42727da375e1ec0e53dc909ac8d": "Ymultichange(Yparameterchange,Ybodychange,Ydocchange)",
    "dd26201ac47f60cd9e18800726cc28660b81bdaf": "Ybodychange",
    "83e4a903b18c43a10caa551c50ece4e251a0f674": "Ybodychange",
    "38670dbe9232dc9b56d6464c42293e745974cf60": "Ymovefromfile",
    "9141cb39e6659340574a96b41d7f463ebdc2610e": "Ybodychange",
    "00d0def6953d414af6ecf36a9584c5453ee39c29": "Ybodychange",
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512": "Ybodychange",
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79": "Ybodychange",
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8": "Ybodychange",
    "42476f4b08fe4b075aa36f688f0801857f3635d9": "Ybodychange",
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8": "Yfilerename",
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8": "Ymultichange(Ydocchange,Yformatchange)",
    "b55fb21d78e30748ae19f1c8d16902439643799a": "Ybodychange",
    "14182380d59abc9c5a18504833c5c93d27fd0f8e": "Ybodychange",
    "eac54a225bc974157e914cf66cfa598171022018": "Ybodychange",
    "f047581f9526aad1c9c9e624710a4e860f88ecaa": "Ybodychange",
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8": "Yfilerename",
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c4014b6b38c9f661a12557db7ee464e158f386f7": {
      "type": "Ymultichange(Yrename,Ydocchange)",
      "commitMessage": "Method names should start with a verb\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1460136 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/23/13, 5:48 AM",
      "commitName": "c4014b6b38c9f661a12557db7ee464e158f386f7",
      "commitAuthor": "Benedikt Ritter",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "Method names should start with a verb\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1460136 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/23/13, 5:48 AM",
          "commitName": "c4014b6b38c9f661a12557db7ee464e158f386f7",
          "commitAuthor": "Benedikt Ritter",
          "commitDateOld": "3/20/13, 1:31 AM",
          "commitNameOld": "374cd7b16d1ec48bb68fd748427c4b8942767c6b",
          "commitAuthorOld": "Benedikt Ritter",
          "daysBetweenCommits": 3.18,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token parseEncapsulatedToken(final Token tkn) throws IOException {\n    final long startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isQuoteChar(c)) {\n            if (isQuoteChar(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (readEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 198,
          "functionName": "parseEncapsulatedToken",
          "functionAnnotation": "",
          "functionDoc": "Parses an encapsulated token.\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "@@ -1,36 +1,36 @@\n-private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n+private Token parseEncapsulatedToken(final Token tkn) throws IOException {\n     final long startLineNumber \u003d getLineNumber();\n     int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n             tkn.content.append((char) readEscape());\n         } else if (isQuoteChar(c)) {\n             if (isQuoteChar(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (readEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "encapsulatedTokenLexer",
            "newValue": "parseEncapsulatedToken"
          }
        },
        {
          "type": "Ydocchange",
          "commitMessage": "Method names should start with a verb\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1460136 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/23/13, 5:48 AM",
          "commitName": "c4014b6b38c9f661a12557db7ee464e158f386f7",
          "commitAuthor": "Benedikt Ritter",
          "commitDateOld": "3/20/13, 1:31 AM",
          "commitNameOld": "374cd7b16d1ec48bb68fd748427c4b8942767c6b",
          "commitAuthorOld": "Benedikt Ritter",
          "daysBetweenCommits": 3.18,
          "commitsBetweenForRepo": 17,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token parseEncapsulatedToken(final Token tkn) throws IOException {\n    final long startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isQuoteChar(c)) {\n            if (isQuoteChar(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (readEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 198,
          "functionName": "parseEncapsulatedToken",
          "functionAnnotation": "",
          "functionDoc": "Parses an encapsulated token.\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "@@ -1,36 +1,36 @@\n-private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n+private Token parseEncapsulatedToken(final Token tkn) throws IOException {\n     final long startLineNumber \u003d getLineNumber();\n     int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n             tkn.content.append((char) readEscape());\n         } else if (isQuoteChar(c)) {\n             if (isQuoteChar(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (readEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
            "newValue": "Parses an encapsulated token.\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n"
          }
        }
      ]
    },
    "350d34d5cfe45c4e7036422e0e2e0f6039eb6f98": {
      "type": "Ybodychange",
      "commitMessage": "Rename encapsulator to quote char.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1398187 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/14/12, 8:37 PM",
      "commitName": "350d34d5cfe45c4e7036422e0e2e0f6039eb6f98",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "10/14/12, 8:25 PM",
      "commitNameOld": "6eddd544e56b4c376619cad6b279885962293b6d",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n    final long startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isQuoteChar(c)) {\n            if (isQuoteChar(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (readEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 198,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
      "diff": "@@ -1,36 +1,36 @@\n private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n     final long startLineNumber \u003d getLineNumber();\n     int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n             tkn.content.append((char) readEscape());\n-        } else if (isEncapsulator(c)) {\n-            if (isEncapsulator(in.lookAhead())) {\n+        } else if (isQuoteChar(c)) {\n+            if (isQuoteChar(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (readEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "2a8ce4a11cf42683d7abf06c591b4c0f1e8928e1": {
      "type": "Ybodychange",
      "commitMessage": "Rename method from \"is\" prefix to \"read\" prefix because it is not just a test method, it may actually consume input.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397923 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/13/12, 11:56 AM",
      "commitName": "2a8ce4a11cf42683d7abf06c591b4c0f1e8928e1",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "10/13/12, 10:40 AM",
      "commitNameOld": "9f6d3f541330670df684d01b8b6fae67f474bb90",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.05,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n    final long startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (readEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 193,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
      "diff": "@@ -1,36 +1,36 @@\n private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n     final long startLineNumber \u003d getLineNumber();\n     int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n             tkn.content.append((char) readEscape());\n         } else if (isEncapsulator(c)) {\n             if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n-                    } else if (isEndOfLine(c)) {\n+                    } else if (readEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "3b938ba40d050c319be41a415daf5832e6097d72": {
      "type": "Ybodychange",
      "commitMessage": "Let the line number count be a long.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397898 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/13/12, 10:11 AM",
      "commitName": "3b938ba40d050c319be41a415daf5832e6097d72",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "10/12/12, 11:29 PM",
      "commitNameOld": "992c0645e0b4d9436593f39c3bcff77328adb37c",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.45,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n    final long startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 193,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
      "diff": "@@ -1,36 +1,36 @@\n private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n-    final int startLineNumber \u003d getLineNumber();\n+    final long startLineNumber \u003d getLineNumber();\n     int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n             tkn.content.append((char) readEscape());\n         } else if (isEncapsulator(c)) {\n             if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc": {
      "type": "Ymultichange(Ybodychange,Yparametermetachange)",
      "commitMessage": "Use final keyword where possible.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397122 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/11/12, 8:47 AM",
      "commitName": "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
      "commitAuthor": "Gary D. Gregory",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "Use final keyword where possible.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397122 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/11/12, 8:47 AM",
          "commitName": "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "10/11/12, 7:02 AM",
          "commitNameOld": "4bc562f47b46372a5ac11498fe5312846dedded4",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n    final int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 193,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "@@ -1,36 +1,36 @@\n-private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n-    int startLineNumber \u003d getLineNumber();\n+private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n+    final int startLineNumber \u003d getLineNumber();\n     int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n             tkn.content.append((char) readEscape());\n         } else if (isEncapsulator(c)) {\n             if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "Use final keyword where possible.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1397122 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/11/12, 8:47 AM",
          "commitName": "6ab9b46e5a0aa9aae4ea4cbc86fd78ee72a3e2dc",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "10/11/12, 7:02 AM",
          "commitNameOld": "4bc562f47b46372a5ac11498fe5312846dedded4",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n    final int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 193,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "@@ -1,36 +1,36 @@\n-private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n-    int startLineNumber \u003d getLineNumber();\n+private Token encapsulatedTokenLexer(final Token tkn) throws IOException {\n+    final int startLineNumber \u003d getLineNumber();\n     int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n             tkn.content.append((char) readEscape());\n         } else if (isEncapsulator(c)) {\n             if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[tkn-Token]",
            "newValue": "[tkn-Token(modifiers-final)]"
          }
        }
      ]
    },
    "5e7945e1ceeb6cce60e3da5caf4d57f7bf531689": {
      "type": "Yformatchange",
      "commitMessage": "Last of the Checkstyle fixes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383758 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "9/11/12, 9:14 PM",
      "commitName": "5e7945e1ceeb6cce60e3da5caf4d57f7bf531689",
      "commitAuthor": "Gary D. Gregory",
      "commitDateOld": "9/11/12, 1:12 PM",
      "commitNameOld": "6c1b0fa1c49a3b4c51a0765c6ab3806ae4aa3ce5",
      "commitAuthorOld": "Gary D. Gregory",
      "daysBetweenCommits": 0.33,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 189,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
      "diff": "",
      "extendedDetails": {}
    },
    "93fc1f9363d911cb0a974f993d9266a89a63c41e": {
      "type": "Ymultichange(Ydocchange,Yformatchange)",
      "commitMessage": "Fix Checkstyle: Format for 120 line length.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383582 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "9/11/12, 12:47 PM",
      "commitName": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
      "commitAuthor": "Gary D. Gregory",
      "subchanges": [
        {
          "type": "Ydocchange",
          "commitMessage": "Fix Checkstyle: Format for 120 line length.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383582 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:47 PM",
          "commitName": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:41 PM",
          "commitNameOld": "42a4812bcefc07e6eb4eb7aaaed926dd08ae093f",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 189,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\nThe token is finished when one of the following conditions become true:\n\u003cul\u003e\n  \u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n  \u003cul\u003e\n      \u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n      \u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n  \u003c/ul\u003e\n  \u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e\n\u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state:\n EOF before closing encapsulator or invalid character before delimiter or EOL\n",
            "newValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n"
          }
        },
        {
          "type": "Yformatchange",
          "commitMessage": "Fix Checkstyle: Format for 120 line length.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383582 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:47 PM",
          "commitName": "93fc1f9363d911cb0a974f993d9266a89a63c41e",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:41 PM",
          "commitNameOld": "42a4812bcefc07e6eb4eb7aaaed926dd08ae093f",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 189,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string. The encapsulator itself might be included\nin the token using a doubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027). Whitespaces before and after\nan encapsulated token are ignored. The token is finished when one of the following conditions become true:\n\u003cul\u003e\n\u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n\u003cul\u003e\n\u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n\u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e \u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException\n            on invalid state: EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "",
          "extendedDetails": {}
        }
      ]
    },
    "bf06bed9b8905ccf5409179263707074167ccfc4": {
      "type": "Ymultichange(Ydocchange,Yformatchange)",
      "commitMessage": "Remove trailing spaces.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383577 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "9/11/12, 12:40 PM",
      "commitName": "bf06bed9b8905ccf5409179263707074167ccfc4",
      "commitAuthor": "Gary D. Gregory",
      "subchanges": [
        {
          "type": "Ydocchange",
          "commitMessage": "Remove trailing spaces.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383577 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:40 PM",
          "commitName": "bf06bed9b8905ccf5409179263707074167ccfc4",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:35 PM",
          "commitNameOld": "6a132b40abbefb97ff58528eab8a8835fb353df1",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 189,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\nThe token is finished when one of the following conditions become true:\n\u003cul\u003e\n  \u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n  \u003cul\u003e\n      \u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n      \u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n  \u003c/ul\u003e\n  \u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e\n\u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state:\n EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\nThe token is finished when one of the following conditions become true:\n\u003cul\u003e\n  \u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n  \u003cul\u003e\n      \u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n      \u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n  \u003c/ul\u003e\n  \u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e\n\u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state: \n EOF before closing encapsulator or invalid character before delimiter or EOL\n",
            "newValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\nThe token is finished when one of the following conditions become true:\n\u003cul\u003e\n  \u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n  \u003cul\u003e\n      \u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n      \u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n  \u003c/ul\u003e\n  \u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e\n\u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state:\n EOF before closing encapsulator or invalid character before delimiter or EOL\n"
          }
        },
        {
          "type": "Yformatchange",
          "commitMessage": "Remove trailing spaces.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1383577 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "9/11/12, 12:40 PM",
          "commitName": "bf06bed9b8905ccf5409179263707074167ccfc4",
          "commitAuthor": "Gary D. Gregory",
          "commitDateOld": "9/11/12, 12:35 PM",
          "commitNameOld": "6a132b40abbefb97ff58528eab8a8835fb353df1",
          "commitAuthorOld": "Gary D. Gregory",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 189,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\nThe token is finished when one of the following conditions become true:\n\u003cul\u003e\n  \u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n  \u003cul\u003e\n      \u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n      \u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n  \u003c/ul\u003e\n  \u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e\n\u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state:\n EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "",
          "extendedDetails": {}
        }
      ]
    },
    "d89a0f482f6fa06661e4fd15a31b54222224a6df": {
      "type": "Ymultichange(Ybodychange,Ydocchange)",
      "commitMessage": "Javadoc\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1307201 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/29/12, 6:16 PM",
      "commitName": "d89a0f482f6fa06661e4fd15a31b54222224a6df",
      "commitAuthor": "Sebastian Bazley",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "Javadoc\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1307201 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/29/12, 6:16 PM",
          "commitName": "d89a0f482f6fa06661e4fd15a31b54222224a6df",
          "commitAuthor": "Sebastian Bazley",
          "commitDateOld": "3/29/12, 9:03 AM",
          "commitNameOld": "787ab08db9230c67220ef453de211159e317d4e2",
          "commitAuthorOld": "Sebastian Bazley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 9,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 189,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\nThe token is finished when one of the following conditions become true:\n\u003cul\u003e\n  \u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n  \u003cul\u003e\n      \u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n      \u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n  \u003c/ul\u003e\n  \u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e\n\u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state: \n EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "Javadoc\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1307201 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/29/12, 6:16 PM",
          "commitName": "d89a0f482f6fa06661e4fd15a31b54222224a6df",
          "commitAuthor": "Sebastian Bazley",
          "commitDateOld": "3/29/12, 9:03 AM",
          "commitNameOld": "787ab08db9230c67220ef453de211159e317d4e2",
          "commitAuthorOld": "Sebastian Bazley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 9,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 189,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\nThe token is finished when one of the following conditions become true:\n\u003cul\u003e\n  \u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n  \u003cul\u003e\n      \u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n      \u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n  \u003c/ul\u003e\n  \u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e\n\u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state: \n EOF before closing encapsulator or invalid character before delimiter or EOL\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state\n",
            "newValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\nThe token is finished when one of the following conditions become true:\n\u003cul\u003e\n  \u003cli\u003ean unescaped encapsulator has been reached, and is followed by optional whitespace then:\u003c/li\u003e\n  \u003cul\u003e\n      \u003cli\u003edelimiter (TOKEN)\u003c/li\u003e\n      \u003cli\u003eend of line (EORECORD)\u003c/li\u003e\n  \u003c/ul\u003e\n  \u003cli\u003eend of stream has been reached (EOF)\u003c/li\u003e\n\u003c/ul\u003e\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state: \n EOF before closing encapsulator or invalid character before delimiter or EOL\n"
          }
        }
      ]
    },
    "911433707587a42727da375e1ec0e53dc909ac8d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange,Ydocchange)",
      "commitMessage": "CSV-70 Improve readability of CSVLexer\nRemove unnecessary parameters\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306062 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/27/12, 4:50 PM",
      "commitName": "911433707587a42727da375e1ec0e53dc909ac8d",
      "commitAuthor": "Sebastian Bazley",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "CSV-70 Improve readability of CSVLexer\nRemove unnecessary parameters\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306062 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/27/12, 4:50 PM",
          "commitName": "911433707587a42727da375e1ec0e53dc909ac8d",
          "commitAuthor": "Sebastian Bazley",
          "commitDateOld": "3/26/12, 12:02 PM",
          "commitNameOld": "38741a48c692ae2fc13cd2445e77ace6ecea1156",
          "commitAuthorOld": "Sebastian Bazley",
          "daysBetweenCommits": 1.2,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 180,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state\n",
          "diff": "@@ -1,35 +1,36 @@\n-private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n+private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n+    int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n-            tkn.content.append((char) readEscape(c));\n+            tkn.content.append((char) readEscape());\n         } else if (isEncapsulator(c)) {\n             if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[tkn-Token, c-int]",
            "newValue": "[tkn-Token]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "CSV-70 Improve readability of CSVLexer\nRemove unnecessary parameters\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306062 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/27/12, 4:50 PM",
          "commitName": "911433707587a42727da375e1ec0e53dc909ac8d",
          "commitAuthor": "Sebastian Bazley",
          "commitDateOld": "3/26/12, 12:02 PM",
          "commitNameOld": "38741a48c692ae2fc13cd2445e77ace6ecea1156",
          "commitAuthorOld": "Sebastian Bazley",
          "daysBetweenCommits": 1.2,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 180,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state\n",
          "diff": "@@ -1,35 +1,36 @@\n-private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n+private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n+    int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n-            tkn.content.append((char) readEscape(c));\n+            tkn.content.append((char) readEscape());\n         } else if (isEncapsulator(c)) {\n             if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "CSV-70 Improve readability of CSVLexer\nRemove unnecessary parameters\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1306062 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "3/27/12, 4:50 PM",
          "commitName": "911433707587a42727da375e1ec0e53dc909ac8d",
          "commitAuthor": "Sebastian Bazley",
          "commitDateOld": "3/26/12, 12:02 PM",
          "commitNameOld": "38741a48c692ae2fc13cd2445e77ace6ecea1156",
          "commitAuthorOld": "Sebastian Bazley",
          "daysBetweenCommits": 1.2,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    int c;\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape());\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
          "functionStartLine": 180,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state\n",
          "diff": "@@ -1,35 +1,36 @@\n-private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n+private Token encapsulatedTokenLexer(Token tkn) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n+    int c;\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n-            tkn.content.append((char) readEscape(c));\n+            tkn.content.append((char) readEscape());\n         } else if (isEncapsulator(c)) {\n             if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
            "newValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@return a valid token object\n@throws IOException on invalid state\n"
          }
        }
      ]
    },
    "dd26201ac47f60cd9e18800726cc28660b81bdaf": {
      "type": "Ybodychange",
      "commitMessage": "CSV-81 Token.Type.isReady could perhaps be removed\nNot removed, but only set on EOF if there is data to return\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303988 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 12:04 PM",
      "commitName": "dd26201ac47f60cd9e18800726cc28660b81bdaf",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 11:23 AM",
      "commitNameOld": "9ebd0d94254b468765f6c558bb10ca018a418444",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape(c));\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 181,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,37 +1,35 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     while (true) {\n         c \u003d in.read();\n         if (isEscape(c)) {\n             tkn.content.append((char) readEscape(c));\n         } else if (isEncapsulator(c)) {\n             if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n                     if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n-                        tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n-                        tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "83e4a903b18c43a10caa551c50ece4e251a0f674": {
      "type": "Ybodychange",
      "commitMessage": "CSV-71 - Add convenience Methods to CSVLexer\nUse convenience methods from Lexer parent class\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1303904 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/22/12, 10:27 AM",
      "commitName": "83e4a903b18c43a10caa551c50ece4e251a0f674",
      "commitAuthor": "Sebastian Bazley",
      "commitDateOld": "3/22/12, 9:32 AM",
      "commitNameOld": "fdfe50842f8ac0a842ba0a220bbd2613178e7a75",
      "commitAuthorOld": "Sebastian Bazley",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    while (true) {\n        c \u003d in.read();\n        if (isEscape(c)) {\n            tkn.content.append((char) readEscape(c));\n        } else if (isEncapsulator(c)) {\n            if (isEncapsulator(in.lookAhead())) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (isDelimiter(c)) {\n                        tkn.type \u003d TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 190,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,37 +1,37 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     while (true) {\n         c \u003d in.read();\n-        if (c \u003d\u003d format.getEscape()) {\n+        if (isEscape(c)) {\n             tkn.content.append((char) readEscape(c));\n-        } else if (c \u003d\u003d format.getEncapsulator()) {\n-            if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n+        } else if (isEncapsulator(c)) {\n+            if (isEncapsulator(in.lookAhead())) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 while (true) {\n                     c \u003d in.read();\n-                    if (c \u003d\u003d format.getDelimiter()) {\n+                    if (isDelimiter(c)) {\n                         tkn.type \u003d TOKEN;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "38670dbe9232dc9b56d6464c42293e745974cf60": {
      "type": "Ymovefromfile",
      "commitMessage": "Moved the lexer in a separate file\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1300850 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/15/12, 1:52 AM",
      "commitName": "38670dbe9232dc9b56d6464c42293e745974cf60",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "3/14/12, 4:12 PM",
      "commitNameOld": "35b954ed36494f64b27b495ded6e66b409d0ed79",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.4,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    while (true) {\n        c \u003d in.read();\n        if (c \u003d\u003d format.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d format.getDelimiter()) {\n                        tkn.type \u003d TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVLexer.java",
      "functionStartLine": 249,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/main/java/org/apache/commons/csv/CSVParser.java",
        "newPath": "src/main/java/org/apache/commons/csv/CSVLexer.java",
        "oldMethodName": "encapsulatedTokenLexer",
        "newMethodName": "encapsulatedTokenLexer"
      }
    },
    "9141cb39e6659340574a96b41d7f463ebdc2610e": {
      "type": "Ybodychange",
      "commitMessage": "Changed while loops (CSV-55)\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/proper/csv/trunk@1299706 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/12/12, 8:12 AM",
      "commitName": "9141cb39e6659340574a96b41d7f463ebdc2610e",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "3/11/12, 4:23 PM",
      "commitNameOld": "94b9f8dc957d3a2276232c8e6f3acc6fe633b00a",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.66,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    while (true) {\n        c \u003d in.read();\n        if (c \u003d\u003d format.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                while (true) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d format.getDelimiter()) {\n                        tkn.type \u003d TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 450,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,37 +1,37 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n-    for (; ; ) {\n+    while (true) {\n         c \u003d in.read();\n         if (c \u003d\u003d format.getEscape()) {\n             tkn.content.append((char) readEscape(c));\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n-                for (; ; ) {\n+                while (true) {\n                     c \u003d in.read();\n                     if (c \u003d\u003d format.getDelimiter()) {\n                         tkn.type \u003d TOKEN;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "00d0def6953d414af6ecf36a9584c5453ee39c29": {
      "type": "Ybodychange",
      "commitMessage": "Replaced the unicode escaping code from the parser with a class implementing java.io.Reader\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1298001 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/7/12, 7:58 AM",
      "commitName": "00d0def6953d414af6ecf36a9584c5453ee39c29",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "3/6/12, 3:23 AM",
      "commitNameOld": "9dd3dda09f09c6baa7e053b39043bc9e2ef47ee0",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 1.19,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d format.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d format.getDelimiter()) {\n                        tkn.type \u003d TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 439,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,39 +1,37 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     for (; ; ) {\n         c \u003d in.read();\n-        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 format.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n-            tkn.content.append((char) unicodeEscapeLexer(c));\n-        } else if (c \u003d\u003d format.getEscape()) {\n+        if (c \u003d\u003d format.getEscape()) {\n             tkn.content.append((char) readEscape(c));\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 for (; ; ) {\n                     c \u003d in.read();\n                     if (c \u003d\u003d format.getDelimiter()) {\n                         tkn.type \u003d TOKEN;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "7bd9d1d970b04a8439fee0bd5224159f57cb2512": {
      "type": "Ybodychange",
      "commitMessage": "Updated the Javadoc\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1297043 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/5/12, 5:08 AM",
      "commitName": "7bd9d1d970b04a8439fee0bd5224159f57cb2512",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 3:04 PM",
      "commitNameOld": "045dbbbe4ab84618cee8ba27d00b9283ce0a2715",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 116.59,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 format.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n            tkn.content.append((char) unicodeEscapeLexer(c));\n        } else if (c \u003d\u003d format.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d format.getDelimiter()) {\n                        tkn.type \u003d TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 436,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,39 +1,39 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     for (; ; ) {\n         c \u003d in.read();\n         if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 format.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n             tkn.content.append((char) unicodeEscapeLexer(c));\n         } else if (c \u003d\u003d format.getEscape()) {\n             tkn.content.append((char) readEscape(c));\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 for (; ; ) {\n                     c \u003d in.read();\n                     if (c \u003d\u003d format.getDelimiter()) {\n                         tkn.type \u003d TOKEN;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d EORECORD;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n-                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n+                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token and delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n-            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n+            throw new IOException(\"(startline \" + startLineNumber + \") EOF reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "16bfec07ffd785e5abbabdc4145eeac5cccc2c79": {
      "type": "Ybodychange",
      "commitMessage": "Turned the token types into an Enum\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199872 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 9:11 AM",
      "commitName": "16bfec07ffd785e5abbabdc4145eeac5cccc2c79",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 8:58 AM",
      "commitNameOld": "cbcfb72912f41d1fac3f6d26ca27406cca94da9e",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 format.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n            tkn.content.append((char) unicodeEscapeLexer(c));\n        } else if (c \u003d\u003d format.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d format.getDelimiter()) {\n                        tkn.type \u003d TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 394,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,39 +1,39 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     for (; ; ) {\n         c \u003d in.read();\n         if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 format.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n             tkn.content.append((char) unicodeEscapeLexer(c));\n         } else if (c \u003d\u003d format.getEscape()) {\n             tkn.content.append((char) readEscape(c));\n         } else if (c \u003d\u003d format.getEncapsulator()) {\n             if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 for (; ; ) {\n                     c \u003d in.read();\n                     if (c \u003d\u003d format.getDelimiter()) {\n-                        tkn.type \u003d TT_TOKEN;\n+                        tkn.type \u003d TOKEN;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n-                        tkn.type \u003d TT_EOF;\n+                        tkn.type \u003d EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n-                        tkn.type \u003d TT_EORECORD;\n+                        tkn.type \u003d EORECORD;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "cb99634ab3d6143dffc90938fc68e15c7f9d25b8": {
      "type": "Ybodychange",
      "commitMessage": "Renamed CSVStrategy to CSVFormat\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199842 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 8:54 AM",
      "commitName": "cb99634ab3d6143dffc90938fc68e15c7f9d25b8",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 8:21 AM",
      "commitNameOld": "42476f4b08fe4b075aa36f688f0801857f3635d9",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 format.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n            tkn.content.append((char) unicodeEscapeLexer(c));\n        } else if (c \u003d\u003d format.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d format.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d format.getDelimiter()) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 395,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,39 +1,39 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     for (; ; ) {\n         c \u003d in.read();\n-        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n+        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 format.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n             tkn.content.append((char) unicodeEscapeLexer(c));\n-        } else if (c \u003d\u003d strategy.getEscape()) {\n+        } else if (c \u003d\u003d format.getEscape()) {\n             tkn.content.append((char) readEscape(c));\n-        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n-            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n+        } else if (c \u003d\u003d format.getEncapsulator()) {\n+            if (in.lookAhead() \u003d\u003d format.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 for (; ; ) {\n                     c \u003d in.read();\n-                    if (c \u003d\u003d strategy.getDelimiter()) {\n+                    if (c \u003d\u003d format.getDelimiter()) {\n                         tkn.type \u003d TT_TOKEN;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d TT_EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d TT_EORECORD;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "42476f4b08fe4b075aa36f688f0801857f3635d9": {
      "type": "Ybodychange",
      "commitMessage": "CSVStrategy is now immutable (SANDBOX-279)\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199827 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 8:21 AM",
      "commitName": "42476f4b08fe4b075aa36f688f0801857f3635d9",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "11/9/11, 6:54 AM",
      "commitNameOld": "fc4ccb426eb3934ee1656db9b18c7d797ac6bd1d",
      "commitAuthorOld": "Emmanuel Bourg",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n            tkn.content.append((char) unicodeEscapeLexer(c));\n        } else if (c \u003d\u003d strategy.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d strategy.getDelimiter()) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 395,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,39 +1,39 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     for (; ; ) {\n         c \u003d in.read();\n-        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.getUnicodeEscapeInterpretation() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n+        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.isUnicodeEscapesInterpreted() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n             tkn.content.append((char) unicodeEscapeLexer(c));\n         } else if (c \u003d\u003d strategy.getEscape()) {\n             tkn.content.append((char) readEscape(c));\n         } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else {\n                 for (; ; ) {\n                     c \u003d in.read();\n                     if (c \u003d\u003d strategy.getDelimiter()) {\n                         tkn.type \u003d TT_TOKEN;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d TT_EOF;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d TT_EORECORD;\n                         tkn.isReady \u003d true;\n                         return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                     }\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n     }\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8": {
      "type": "Yfilerename",
      "commitMessage": "Moved the directories to match the Maven layout\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1199691 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/9/11, 2:38 AM",
      "commitName": "c9aeca5c39033c95c26c1475dcf0fd2ea86672e8",
      "commitAuthor": "Emmanuel Bourg",
      "commitDateOld": "7/20/11, 9:14 AM",
      "commitNameOld": "76cab04936e8b539d983510079419fabeeaecea0",
      "commitAuthorOld": "Stephen Colebourne",
      "daysBetweenCommits": 111.77,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.getUnicodeEscapeInterpretation() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n            tkn.content.append((char) unicodeEscapeLexer(c));\n        } else if (c \u003d\u003d strategy.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d strategy.getDelimiter()) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/main/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 474,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/commons/csv/CSVParser.java",
        "newPath": "src/main/java/org/apache/commons/csv/CSVParser.java"
      }
    },
    "1166ca605bcc035654771f1ddc1092d86f2ec1e8": {
      "type": "Ymultichange(Ydocchange,Yformatchange)",
      "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2/1/11, 12:46 AM",
      "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
      "commitAuthor": "Jacopo Cappellato",
      "subchanges": [
        {
          "type": "Ydocchange",
          "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2/1/11, 12:46 AM",
          "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
          "commitAuthor": "Jacopo Cappellato",
          "commitDateOld": "1/31/11, 2:47 AM",
          "commitNameOld": "c6bdecabd82eebc9efce450aa4057b668984479e",
          "commitAuthorOld": "Jacopo Cappellato",
          "daysBetweenCommits": 0.92,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.getUnicodeEscapeInterpretation() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n            tkn.content.append((char) unicodeEscapeLexer(c));\n        } else if (c \u003d\u003d strategy.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d strategy.getDelimiter()) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 474,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
          "diff": "",
          "extendedDetails": {
            "oldValue": "An encapsulated token lexer\n\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
            "newValue": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n"
          }
        },
        {
          "type": "Yformatchange",
          "commitMessage": "No functional changes are contained in this commit: reformatted Java code to fix several formatting inconsistencies (between classes and within the same class); sorry for the big commit, but I have preferred to isolate into one commit all the formatting changes.\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@1065950 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2/1/11, 12:46 AM",
          "commitName": "1166ca605bcc035654771f1ddc1092d86f2ec1e8",
          "commitAuthor": "Jacopo Cappellato",
          "commitDateOld": "1/31/11, 2:47 AM",
          "commitNameOld": "c6bdecabd82eebc9efce450aa4057b668984479e",
          "commitAuthorOld": "Jacopo Cappellato",
          "daysBetweenCommits": 0.92,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.getUnicodeEscapeInterpretation() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n            tkn.content.append((char) unicodeEscapeLexer(c));\n        } else if (c \u003d\u003d strategy.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d strategy.getDelimiter()) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
          "path": "src/java/org/apache/commons/csv/CSVParser.java",
          "functionStartLine": 474,
          "functionName": "encapsulatedTokenLexer",
          "functionAnnotation": "",
          "functionDoc": "An encapsulated token lexer\n\u003cp/\u003e\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
          "diff": "",
          "extendedDetails": {}
        }
      ]
    },
    "b55fb21d78e30748ae19f1c8d16902439643799a": {
      "type": "Ybodychange",
      "commitMessage": "SANDBOX-206: add escape to strategy, turn off backslash-style escaping by default\n\ngit-svn-id: https://svn.apache.org/repos/asf/commons/sandbox/csv/trunk@609155 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "1/5/08, 7:37 AM",
      "commitName": "b55fb21d78e30748ae19f1c8d16902439643799a",
      "commitAuthor": "Yonik Seeley",
      "commitDateOld": "7/23/07, 3:25 PM",
      "commitNameOld": "14182380d59abc9c5a18504833c5c93d27fd0f8e",
      "commitAuthorOld": "Matthew Jason Benson",
      "daysBetweenCommits": 165.72,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    for (; ; ) {\n        c \u003d in.read();\n        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.getUnicodeEscapeInterpretation() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n            tkn.content.append((char) unicodeEscapeLexer(c));\n        } else if (c \u003d\u003d strategy.getEscape()) {\n            tkn.content.append((char) readEscape(c));\n        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else {\n                for (; ; ) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d strategy.getDelimiter()) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                        return tkn;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                    }\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n    }\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 459,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,46 +1,39 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n-    c \u003d in.read();\n-    while (!tkn.isReady) {\n-        boolean skipRead \u003d false;\n-        if (c \u003d\u003d strategy.getEncapsulator() || c \u003d\u003d \u0027\\\\\u0027) {\n+    for (; ; ) {\n+        c \u003d in.read();\n+        if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 strategy.getUnicodeEscapeInterpretation() \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n+            tkn.content.append((char) unicodeEscapeLexer(c));\n+        } else if (c \u003d\u003d strategy.getEscape()) {\n+            tkn.content.append((char) readEscape(c));\n+        } else if (c \u003d\u003d strategy.getEncapsulator()) {\n             if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n-            } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n-                tkn.content.append((char) c);\n-                c \u003d in.read();\n-                tkn.content.append((char) c);\n-            } else if (strategy.getUnicodeEscapeInterpretation() \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n-                tkn.content.append((char) unicodeEscapeLexer(c));\n-            } else if (c \u003d\u003d \u0027\\\\\u0027) {\n-                tkn.content.append((char) c);\n             } else {\n-                while (!tkn.isReady) {\n+                for (; ; ) {\n                     c \u003d in.read();\n                     if (c \u003d\u003d strategy.getDelimiter()) {\n                         tkn.type \u003d TT_TOKEN;\n                         tkn.isReady \u003d true;\n+                        return tkn;\n                     } else if (isEndOfFile(c)) {\n                         tkn.type \u003d TT_EOF;\n                         tkn.isReady \u003d true;\n+                        return tkn;\n                     } else if (isEndOfLine(c)) {\n                         tkn.type \u003d TT_EORECORD;\n                         tkn.isReady \u003d true;\n+                        return tkn;\n                     } else if (!isWhitespace(c)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                     }\n                 }\n-                skipRead \u003d true;\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n-        if (!tkn.isReady \u0026\u0026 !skipRead) {\n-            c \u003d in.read();\n-        }\n     }\n-    return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "14182380d59abc9c5a18504833c5c93d27fd0f8e": {
      "type": "Ybodychange",
      "commitMessage": "fix eol detection\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@558883 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "7/23/07, 3:25 PM",
      "commitName": "14182380d59abc9c5a18504833c5c93d27fd0f8e",
      "commitAuthor": "Matthew Jason Benson",
      "commitDateOld": "1/30/07, 12:39 PM",
      "commitNameOld": "bf186393db6502561f54b09a09766a0287335b5c",
      "commitAuthorOld": "Yonik Seeley",
      "daysBetweenCommits": 174.07,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    c \u003d in.read();\n    while (!tkn.isReady) {\n        boolean skipRead \u003d false;\n        if (c \u003d\u003d strategy.getEncapsulator() || c \u003d\u003d \u0027\\\\\u0027) {\n            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n                tkn.content.append((char) c);\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (strategy.getUnicodeEscapeInterpretation() \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n                tkn.content.append((char) unicodeEscapeLexer(c));\n            } else if (c \u003d\u003d \u0027\\\\\u0027) {\n                tkn.content.append((char) c);\n            } else {\n                while (!tkn.isReady) {\n                    c \u003d in.read();\n                    if (c \u003d\u003d strategy.getDelimiter()) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfFile(c)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfLine(c)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                    } else if (!isWhitespace(c)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                    }\n                }\n                skipRead \u003d true;\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n        if (!tkn.isReady \u0026\u0026 !skipRead) {\n            c \u003d in.read();\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 455,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,45 +1,46 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     c \u003d in.read();\n     while (!tkn.isReady) {\n+        boolean skipRead \u003d false;\n         if (c \u003d\u003d strategy.getEncapsulator() || c \u003d\u003d \u0027\\\\\u0027) {\n             if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n                 tkn.content.append((char) c);\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else if (strategy.getUnicodeEscapeInterpretation() \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n                 tkn.content.append((char) unicodeEscapeLexer(c));\n             } else if (c \u003d\u003d \u0027\\\\\u0027) {\n                 tkn.content.append((char) c);\n             } else {\n                 while (!tkn.isReady) {\n-                    int n \u003d in.lookAhead();\n-                    if (n \u003d\u003d strategy.getDelimiter()) {\n+                    c \u003d in.read();\n+                    if (c \u003d\u003d strategy.getDelimiter()) {\n                         tkn.type \u003d TT_TOKEN;\n                         tkn.isReady \u003d true;\n-                    } else if (isEndOfFile(n)) {\n+                    } else if (isEndOfFile(c)) {\n                         tkn.type \u003d TT_EOF;\n                         tkn.isReady \u003d true;\n-                    } else if (isEndOfLine(n)) {\n+                    } else if (isEndOfLine(c)) {\n                         tkn.type \u003d TT_EORECORD;\n                         tkn.isReady \u003d true;\n-                    } else if (!isWhitespace(n)) {\n-                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsualted token end delimiter\");\n+                    } else if (!isWhitespace(c)) {\n+                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsulated token end delimiter\");\n                     }\n-                    c \u003d in.read();\n                 }\n+                skipRead \u003d true;\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n-        if (!tkn.isReady) {\n+        if (!tkn.isReady \u0026\u0026 !skipRead) {\n             c \u003d in.read();\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "eac54a225bc974157e914cf66cfa598171022018": {
      "type": "Ybodychange",
      "commitMessage": "Extracted the strategy concept into its own class\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@399987 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "5/4/06, 11:24 PM",
      "commitName": "eac54a225bc974157e914cf66cfa598171022018",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "3/5/06, 9:11 PM",
      "commitNameOld": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 60.05,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    c \u003d in.read();\n    while (!tkn.isReady) {\n        if (c \u003d\u003d strategy.getEncapsulator() || c \u003d\u003d \u0027\\\\\u0027) {\n            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n                tkn.content.append((char) c);\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (strategy.getUnicodeEscapeInterpretation() \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n                tkn.content.append((char) unicodeEscapeLexer(c));\n            } else if (c \u003d\u003d \u0027\\\\\u0027) {\n                tkn.content.append((char) c);\n            } else {\n                while (!tkn.isReady) {\n                    int n \u003d in.lookAhead();\n                    if (n \u003d\u003d strategy.getDelimiter()) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfFile(n)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfLine(n)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                    } else if (!isWhitespace(n)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsualted token end delimiter\");\n                    }\n                    c \u003d in.read();\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n        if (!tkn.isReady) {\n            c \u003d in.read();\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 474,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,45 +1,45 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     c \u003d in.read();\n     while (!tkn.isReady) {\n-        if (c \u003d\u003d encapsulator || c \u003d\u003d \u0027\\\\\u0027) {\n-            if (in.lookAhead() \u003d\u003d encapsulator) {\n+        if (c \u003d\u003d strategy.getEncapsulator() || c \u003d\u003d \u0027\\\\\u0027) {\n+            if (in.lookAhead() \u003d\u003d strategy.getEncapsulator()) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n                 tkn.content.append((char) c);\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n-            } else if (interpretUnicodeEscapes \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n+            } else if (strategy.getUnicodeEscapeInterpretation() \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n                 tkn.content.append((char) unicodeEscapeLexer(c));\n             } else if (c \u003d\u003d \u0027\\\\\u0027) {\n                 tkn.content.append((char) c);\n             } else {\n                 while (!tkn.isReady) {\n                     int n \u003d in.lookAhead();\n-                    if (n \u003d\u003d delimiter) {\n+                    if (n \u003d\u003d strategy.getDelimiter()) {\n                         tkn.type \u003d TT_TOKEN;\n                         tkn.isReady \u003d true;\n                     } else if (isEndOfFile(n)) {\n                         tkn.type \u003d TT_EOF;\n                         tkn.isReady \u003d true;\n                     } else if (isEndOfLine(n)) {\n                         tkn.type \u003d TT_EORECORD;\n                         tkn.isReady \u003d true;\n                     } else if (!isWhitespace(n)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsualted token end delimiter\");\n                     }\n                     c \u003d in.read();\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n         if (!tkn.isReady) {\n             c \u003d in.read();\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "f047581f9526aad1c9c9e624710a4e860f88ecaa": {
      "type": "Ybodychange",
      "commitMessage": "Javadoc improvements, more unit tests, change of API to a chain style, some bugfixes\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/sandbox/csv/trunk@383468 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "3/5/06, 9:11 PM",
      "commitName": "f047581f9526aad1c9c9e624710a4e860f88ecaa",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "12/16/05, 9:46 PM",
      "commitNameOld": "0e1f0adb716515aba5e98e5690779f2fb73ad716",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 78.98,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    c \u003d in.read();\n    while (!tkn.isReady) {\n        if (c \u003d\u003d encapsulator || c \u003d\u003d \u0027\\\\\u0027) {\n            if (in.lookAhead() \u003d\u003d encapsulator) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n                tkn.content.append((char) c);\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (interpretUnicodeEscapes \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n                tkn.content.append((char) unicodeEscapeLexer(c));\n            } else if (c \u003d\u003d \u0027\\\\\u0027) {\n                tkn.content.append((char) c);\n            } else {\n                while (!tkn.isReady) {\n                    int n \u003d in.lookAhead();\n                    if (n \u003d\u003d delimiter) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfFile(n)) {\n                        tkn.type \u003d TT_EOF;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfLine(n)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                    } else if (!isWhitespace(n)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsualted token end delimiter\");\n                    }\n                    c \u003d in.read();\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n        if (!tkn.isReady) {\n            c \u003d in.read();\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 489,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "@@ -1,42 +1,45 @@\n private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n     int startLineNumber \u003d getLineNumber();\n     c \u003d in.read();\n     while (!tkn.isReady) {\n         if (c \u003d\u003d encapsulator || c \u003d\u003d \u0027\\\\\u0027) {\n             if (in.lookAhead() \u003d\u003d encapsulator) {\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n+                tkn.content.append((char) c);\n                 c \u003d in.read();\n                 tkn.content.append((char) c);\n             } else if (interpretUnicodeEscapes \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n                 tkn.content.append((char) unicodeEscapeLexer(c));\n+            } else if (c \u003d\u003d \u0027\\\\\u0027) {\n+                tkn.content.append((char) c);\n             } else {\n                 while (!tkn.isReady) {\n                     int n \u003d in.lookAhead();\n                     if (n \u003d\u003d delimiter) {\n                         tkn.type \u003d TT_TOKEN;\n                         tkn.isReady \u003d true;\n                     } else if (isEndOfFile(n)) {\n-                        tkn.type \u003d TT_EORECORD;\n+                        tkn.type \u003d TT_EOF;\n                         tkn.isReady \u003d true;\n                     } else if (isEndOfLine(n)) {\n                         tkn.type \u003d TT_EORECORD;\n                         tkn.isReady \u003d true;\n                     } else if (!isWhitespace(n)) {\n                         throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsualted token end delimiter\");\n                     }\n                     c \u003d in.read();\n                 }\n             }\n         } else if (isEndOfFile(c)) {\n             throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n         } else {\n             tkn.content.append((char) c);\n         }\n         if (!tkn.isReady) {\n             c \u003d in.read();\n         }\n     }\n     return tkn;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8": {
      "type": "Yfilerename",
      "commitMessage": "repackaging - directory change\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/trunks-sandbox/csv@357301 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/16/05, 9:42 PM",
      "commitName": "4b5faabefd896ef24b21d7f9d3dc20741f6b89b8",
      "commitAuthor": "Henri Yandell",
      "commitDateOld": "12/16/05, 9:41 PM",
      "commitNameOld": "e23e79e0ceacf38d3298e7f5207c4518ad2b5955",
      "commitAuthorOld": "Henri Yandell",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    c \u003d in.read();\n    while (!tkn.isReady) {\n        if (c \u003d\u003d encapsulator || c \u003d\u003d \u0027\\\\\u0027) {\n            if (in.lookAhead() \u003d\u003d encapsulator) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (interpretUnicodeEscapes \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n                tkn.content.append((char) unicodeEscapeLexer(c));\n            } else {\n                while (!tkn.isReady) {\n                    int n \u003d in.lookAhead();\n                    if (n \u003d\u003d delimiter) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfFile(n)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfLine(n)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                    } else if (!isWhitespace(n)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsualted token end delimiter\");\n                    }\n                    c \u003d in.read();\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n        if (!tkn.isReady) {\n            c \u003d in.read();\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/org/apache/commons/csv/CSVParser.java",
      "functionStartLine": 467,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/java/ch/netcetera/wake/core/format/csv/CSVParser.java",
        "newPath": "src/java/org/apache/commons/csv/CSVParser.java"
      }
    },
    "e23e79e0ceacf38d3298e7f5207c4518ad2b5955": {
      "type": "Yintroduced",
      "commitMessage": "import of csv parser code, as donated by netcetera [code grant recorded]\n\ngit-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/trunks-sandbox/csv@357300 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/16/05, 9:41 PM",
      "commitName": "e23e79e0ceacf38d3298e7f5207c4518ad2b5955",
      "commitAuthor": "Henri Yandell",
      "diff": "@@ -0,0 +1,42 @@\n+private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n+    int startLineNumber \u003d getLineNumber();\n+    c \u003d in.read();\n+    while (!tkn.isReady) {\n+        if (c \u003d\u003d encapsulator || c \u003d\u003d \u0027\\\\\u0027) {\n+            if (in.lookAhead() \u003d\u003d encapsulator) {\n+                c \u003d in.read();\n+                tkn.content.append((char) c);\n+            } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n+                c \u003d in.read();\n+                tkn.content.append((char) c);\n+            } else if (interpretUnicodeEscapes \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n+                tkn.content.append((char) unicodeEscapeLexer(c));\n+            } else {\n+                while (!tkn.isReady) {\n+                    int n \u003d in.lookAhead();\n+                    if (n \u003d\u003d delimiter) {\n+                        tkn.type \u003d TT_TOKEN;\n+                        tkn.isReady \u003d true;\n+                    } else if (isEndOfFile(n)) {\n+                        tkn.type \u003d TT_EORECORD;\n+                        tkn.isReady \u003d true;\n+                    } else if (isEndOfLine(n)) {\n+                        tkn.type \u003d TT_EORECORD;\n+                        tkn.isReady \u003d true;\n+                    } else if (!isWhitespace(n)) {\n+                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsualted token end delimiter\");\n+                    }\n+                    c \u003d in.read();\n+                }\n+            }\n+        } else if (isEndOfFile(c)) {\n+            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n+        } else {\n+            tkn.content.append((char) c);\n+        }\n+        if (!tkn.isReady) {\n+            c \u003d in.read();\n+        }\n+    }\n+    return tkn;\n+}\n\\ No newline at end of file\n",
      "actualSource": "private Token encapsulatedTokenLexer(Token tkn, int c) throws IOException {\n    int startLineNumber \u003d getLineNumber();\n    c \u003d in.read();\n    while (!tkn.isReady) {\n        if (c \u003d\u003d encapsulator || c \u003d\u003d \u0027\\\\\u0027) {\n            if (in.lookAhead() \u003d\u003d encapsulator) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027\\\\\u0027) {\n                c \u003d in.read();\n                tkn.content.append((char) c);\n            } else if (interpretUnicodeEscapes \u0026\u0026 c \u003d\u003d \u0027\\\\\u0027 \u0026\u0026 in.lookAhead() \u003d\u003d \u0027u\u0027) {\n                tkn.content.append((char) unicodeEscapeLexer(c));\n            } else {\n                while (!tkn.isReady) {\n                    int n \u003d in.lookAhead();\n                    if (n \u003d\u003d delimiter) {\n                        tkn.type \u003d TT_TOKEN;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfFile(n)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                    } else if (isEndOfLine(n)) {\n                        tkn.type \u003d TT_EORECORD;\n                        tkn.isReady \u003d true;\n                    } else if (!isWhitespace(n)) {\n                        throw new IOException(\"(line \" + getLineNumber() + \") invalid char between encapsualted token end delimiter\");\n                    }\n                    c \u003d in.read();\n                }\n            }\n        } else if (isEndOfFile(c)) {\n            throw new IOException(\"(startline \" + startLineNumber + \")\" + \"eof reached before encapsulated token finished\");\n        } else {\n            tkn.content.append((char) c);\n        }\n        if (!tkn.isReady) {\n            c \u003d in.read();\n        }\n    }\n    return tkn;\n}",
      "path": "src/java/ch/netcetera/wake/core/format/csv/CSVParser.java",
      "functionStartLine": 467,
      "functionName": "encapsulatedTokenLexer",
      "functionAnnotation": "",
      "functionDoc": "An encapsulated token lexer\n\nEncapsulated tokens are surrounded by the given encapsulating-string.\nThe encapsulator itself might be included in the token using a\ndoubling syntax (as \"\", \u0027\u0027) or using escaping (as in \\\", \\\u0027).\nWhitespaces before and after an encapsulated token are ignored.\n\n@param tkn the current token\n@param c the current character\n@return a valid token object\n@throws IOException on invalid state\n"
    }
  }
}